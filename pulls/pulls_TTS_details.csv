,pullid,pulls_number,pulltitle,pullsbody,pullsuserlogin,pullsuserid,pullauthordate,author_association,merged_status,stats_addns,stats_delns,stats_changed_files,pull_repo_desc,pull_repo_lang,pull_commit_sha,pull_commit_message
0,https://api.github.com/repos/mozilla/TTS/pulls/690,690,Fix: text is longer than the threshold,"instead of return self.load_data(100)), `return self.load_data(len(self.items))`",bthiban,6612495,2021-03-29T03:09:27Z,NONE,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d149c241c53e1fe6fe2f68cc1f3ff627b119036a,"Fix: text is longer than the threshold

instead of return self.load_data(100)), `return self.load_data(len(self.items))`"
1,https://api.github.com/repos/mozilla/TTS/pulls/684,684,Add a GUI solution for those who don't want to use the voices from command line,"<img width=""496"" alt=""tts_gui"" src=""https://user-images.githubusercontent.com/37678351/111051686-afe57a00-841a-11eb-8e6a-e8370f5ef396.png"">
",MitchellProductions,37678351,2021-03-13T22:48:26Z,NONE,False,228,2,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,14af7f1e5334b1f34c6860f9c98bc4bdf669e5ca,adding gui
2,https://api.github.com/repos/mozilla/TTS/pulls/684,684,Add a GUI solution for those who don't want to use the voices from command line,"<img width=""496"" alt=""tts_gui"" src=""https://user-images.githubusercontent.com/37678351/111051686-afe57a00-841a-11eb-8e6a-e8370f5ef396.png"">
",MitchellProductions,37678351,2021-03-13T22:48:26Z,NONE,False,228,2,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,014ef63f720f3b7748edf65b29b539e0d3f44304,Create mozilla-tts-gui.py
3,https://api.github.com/repos/mozilla/TTS/pulls/684,684,Add a GUI solution for those who don't want to use the voices from command line,"<img width=""496"" alt=""tts_gui"" src=""https://user-images.githubusercontent.com/37678351/111051686-afe57a00-841a-11eb-8e6a-e8370f5ef396.png"">
",MitchellProductions,37678351,2021-03-13T22:48:26Z,NONE,False,228,2,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,72d29781755b656b90cb51adc9e95c38ff29c280,Create tts_gui.png
4,https://api.github.com/repos/mozilla/TTS/pulls/684,684,Add a GUI solution for those who don't want to use the voices from command line,"<img width=""496"" alt=""tts_gui"" src=""https://user-images.githubusercontent.com/37678351/111051686-afe57a00-841a-11eb-8e6a-e8370f5ef396.png"">
",MitchellProductions,37678351,2021-03-13T22:48:26Z,NONE,False,228,2,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b6ac73df7ec595c707840ad4bf25ba364814da0c,Update README.md
5,https://api.github.com/repos/mozilla/TTS/pulls/684,684,Add a GUI solution for those who don't want to use the voices from command line,"<img width=""496"" alt=""tts_gui"" src=""https://user-images.githubusercontent.com/37678351/111051686-afe57a00-841a-11eb-8e6a-e8370f5ef396.png"">
",MitchellProductions,37678351,2021-03-13T22:48:26Z,NONE,False,228,2,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b0f3d231ee4033f84c3dcd65bfb001b85285b6b5,Update README.md
6,https://api.github.com/repos/mozilla/TTS/pulls/684,684,Add a GUI solution for those who don't want to use the voices from command line,"<img width=""496"" alt=""tts_gui"" src=""https://user-images.githubusercontent.com/37678351/111051686-afe57a00-841a-11eb-8e6a-e8370f5ef396.png"">
",MitchellProductions,37678351,2021-03-13T22:48:26Z,NONE,False,228,2,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,14e4a557330f93d40c870a0ec132bd9bf7653662,Create generated.wav
7,https://api.github.com/repos/mozilla/TTS/pulls/684,684,Add a GUI solution for those who don't want to use the voices from command line,"<img width=""496"" alt=""tts_gui"" src=""https://user-images.githubusercontent.com/37678351/111051686-afe57a00-841a-11eb-8e6a-e8370f5ef396.png"">
",MitchellProductions,37678351,2021-03-13T22:48:26Z,NONE,False,228,2,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9a7dfa9973cd4b0b154a083b2a048c0e4e7d5552,remembered tkinter is a part of python
8,https://api.github.com/repos/mozilla/TTS/pulls/667,667,add 'handle multi-speaker and GST inference' in synthesizer class AND…,"Hi everyone !

This week, I worked on three things : 
- training a [better model for Chinese mandarin](https://drive.google.com/drive/folders/1Jw2Ojg9UyTvc9ykzpXA8MJZDBO-e2gAf?usp=sharing) trained on 126k epochs (here you can see the [associated google colab](https://colab.research.google.com/drive/1y2wQ0fp2ishZQVjSPp1dR8P_PLdxAvu_?usp=sharing))

- handling multi speaker and GST inference in the Synthesizer class (that is used in server.py or in the google colab for Chinese that I mentioned in the first point). Now, you can pass the following two optional parameters to the Synthesizer.tts()  method : 
_speaker_json_key_ and _style_wav_ . _speaker_json_key_ is the name of the key of one of the speaker in the provided speakers.json . _style_wav_ is either a path to a wav file for GST style transfer, or is a dict containing the {""token1"":0.25, ""token2"" -0.1, etc...}.  *The next step is to also give the user the possibility to directly provide the optional parameter _speaker_embedding_ that is a speaker embedding (as a numpy array or a list?) that will be passed to Tacotron at inference time.

- I've added some typing and made some refactoring to some functions and methods that appear in the Synthesizer class. I've added one abstract for TTS models and one abstract for Vocoder models to get better hinting from editors when handling with models. 


The synthesizer class is now easier to use, and we can see in this [google colab](https://colab.research.google.com/drive/1y2wQ0fp2ishZQVjSPp1dR8P_PLdxAvu_?usp=sharing) that this reduces the number of lines required for having working generation samples.

I look forward for your reviews :)",kirianguiller,35531073,2021-02-22T11:26:53Z,NONE,False,923,695,23,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,df7162fa820cef9685e207b8eb050bae525cb3c4,add 'handle multi-speaker and GST inference' in synthesizer class AND refactor/type some functions
9,https://api.github.com/repos/mozilla/TTS/pulls/662,662,Add Dutch model,,r-dh,14875684,2021-02-19T16:26:10Z,NONE,False,11,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,21620fac97d5dbde2bae9ba8a7e9638f1151f5e7,Add Dutch model
10,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,40f44757233fe3c80e3ea73e1bfa033cc2d375bf,"add encoding=""utf-8"""
11,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9cb02aeea78826d8085b04eb34c237ab4c006264,<add> Chinese mandarin implementation (tacotron2)
12,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3e59d3c28d918038c2e10cebcbc6613e675fc377,modify according to PR reviews
13,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a9ea71c601a31256c6fa0d9e31de7d04cbbe0d8e,remove re.Match typing in '_number_replace()'
14,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fe049cb48091562e13a0294d4df730d21816d105,add pypinyin and jieba to requierements.txt (chinese implementation)
15,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,45435624678fb756406e97f881f0bbc785748e6e,remove gst handling in synthetizer.py class
16,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c4c7bc1b88223af9799116158ed83590555bdb89,<add> Chinese mandarin implementation (tacotron2)
17,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fb0655d1e78c3348f842214e57150e860fbb9755,modify according to PR reviews
18,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3911b87e54c451b6b1f65d89d381ad4b4a82a5d6,remove re.Match typing in '_number_replace()'
19,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,184ce077180115de1fbf3e948d3b27644b5f329e,add pypinyin and jieba to requierements.txt (chinese implementation)
20,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,22a6bbfa80e049bf453f14dd3829f48c3a401ea5,remove gst handling in synthetizer.py class
21,https://api.github.com/repos/mozilla/TTS/pulls/654,654,Chinese implementation (merge into dev),"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DDC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T15:19:51Z,NONE,True,1182,3,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,35a781d5aff5de4abd59f96d9b2fa8baa4cbe678,Merge branch 'chinese-implementation' of https://github.com/kirianguiller/TTS into chinese-implementation
22,https://api.github.com/repos/mozilla/TTS/pulls/653,653,<add> chinese_mandarin implementation,"Hi everyone, 

I've made an implementation for Chinese mandarin for mozilla-TTS.

- User has to use the model by typing Chinese characters directly
- Characters are then cleaned by transforming Arabic numbers (0 -> 9) to Chinese numbers (〇 -> 九)
- Then, characters are converted to pinyin (with tone transcribed at the end of each syllable with a number from 1 to 5)
- Then, pinyin are converted to phoneme thanks to a mapping pinyin -> phonemes that was hard coded in the repo. By doing this, we can leverage overlapping of some sound (for instance, affricate being the combination of a plosive and a fricative) that are not overlapping with pinyin (""**zh**"" in pinyin is technically a ""_d+ʒ_"" and not the pinyin **z + h** (**z** alone is _dz_ and **h** alone is _x_)
- Then, the model is trained on these phonemes representations with tacotron2 , DCC and GST.

#### About the Baker dataset
The training dataset is [Baker dataset](https://www.data-baker.com/open_source.html), an open-source dataset with a non-commercial license.

#### About GST
The Baker dataset overall prosody is really similar through all the sentences. It probably helps to converge to a decent vocal synthesis, but it made the GST tokens not really influential on the prosody outputted by the model.
   
",kirianguiller,35531073,2021-02-15T14:39:56Z,NONE,False,1167,6,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2b89094c5405ea5b95224f9d9e8fc0e3c60bb0ed,<add> chinese_mandarin implementation
23,https://api.github.com/repos/mozilla/TTS/pulls/652,652,Updating models list to include EK1 TTS/vocoder,"I _think_ this should work to enable general users to download the EK1 TTS and vocoder models for their own use.  Works fine for me and I just updated from dev but would be great if someone else could verify it's good for them too.

I updated .models.json.  In my model config.json (on Google Drive) I also had to specifically add the ""characters"" field to ensure compatibility (hope I did that bit right too but it does seem to work now, was causing recent issues without it). I've stripped out the // comments (matching the other configs published this way) and also took out references to my local drive locations (just for neatness!)

Further EK1 details are here: [Discourse TTS community trained thread](https://discourse.mozilla.org/t/creating-a-github-page-for-hosting-community-trained-models/70889/11?u=nmstoker)

Hope this is useful! Of course, let me know if any of the fields / naming conventions or anything else need to change.

Neil",nmstoker,3694484,2021-02-15T00:15:19Z,CONTRIBUTOR,True,19,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,33bcdc6ff825e1175ef4c8869a7377deae34f362,Updating models list to include EK1 TTS/vocoder
24,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8b6fd76ad2351be666849303b0ce5d8e260c0a37,find unique characters in a dataset
25,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e774f68aeefd9dfac5a09847cb8def93a5e22184,save used model characters to the checkpoints
26,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,918f007a11cc9fcd603bbd398fb3718be5f8b1b7,docstring update
27,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2abfff17f928789576884dea72b88127b73cb71c,enable saving model characters in io.py
28,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,593cedee145a16c80b0cf6a23dab95142e71a3e9,parse_characters function
29,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7ab527d17e6ea91f6c7f9919a59bd4b98148eaa5,save default model chars to the training config file
30,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b28c724c0458b3565507508a4394ed146343bbe4,remove _phoneme_punctuations
31,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4244096ccb1f53dced2db91b13c6709a5ae6c356,update test_text_processing for espeak-ng
32,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,420901f4c23a2f9882dcb544cca9261f8376ec18,linter fixes
33,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c613e0142fc4e648f989e6ead42659c41ba93b8a,update ci to espeak-ng
34,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3b6ce04332245e4c87bfec1896b26e403882f887,"Update TTS/bin/find_unique_chars.py

Co-authored-by: Jörg Thalheim <Mic92@users.noreply.github.com>"
35,https://api.github.com/repos/mozilla/TTS/pulls/651,651,Save characters,"What this PR introduces
- Saving the set of characters used at training to the model checkpoints to keep the future compatibility 
- Pass the default set of characters to the config.json in the training folder if a custom character set is not introduced in the original config.json. 
- Update tests to suit ```espeak-ng```.

These two changes aim to achieve better model compatibility against future changes in character processing or changing the default set of characters used at model training and text processing. ",erogol,1402048,2021-02-12T12:16:12Z,CONTRIBUTOR,True,160,81,15,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,80af8ca5e1f7059b0a10be1ddeabf01daaae57a1,"Update TTS/utils/arguments.py

Co-authored-by: Jörg Thalheim <Mic92@users.noreply.github.com>"
36,https://api.github.com/repos/mozilla/TTS/pulls/650,650,Best model saving and loading updates,"Based on #643 this includes :
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:21:23Z,CONTRIBUTOR,True,743,626,26,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,af46727517e63147554753e6958b348fad5fe616,"loading last checkpoint/best_model works, deleting last best models options added, loading last best_loss added"
37,https://api.github.com/repos/mozilla/TTS/pulls/650,650,Best model saving and loading updates,"Based on #643 this includes :
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:21:23Z,CONTRIBUTOR,True,743,626,26,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,310d18325e8f4bc4b9c46c27fd6d4572aecb4577,brushed up printing model load path and best loss path
38,https://api.github.com/repos/mozilla/TTS/pulls/650,650,Best model saving and loading updates,"Based on #643 this includes :
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:21:23Z,CONTRIBUTOR,True,743,626,26,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,702dff3edcefd4b9e7d43cc8ec618f7c21c8d75a,added keep_best and keep_after to test configs.
39,https://api.github.com/repos/mozilla/TTS/pulls/650,650,Best model saving and loading updates,"Based on #643 this includes :
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:21:23Z,CONTRIBUTOR,True,743,626,26,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0e78e31dbf98380395060593095ecebabd2bed0e,reformated docstrings in arguments.py
40,https://api.github.com/repos/mozilla/TTS/pulls/650,650,Best model saving and loading updates,"Based on #643 this includes :
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:21:23Z,CONTRIBUTOR,True,743,626,26,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,61c88beb943db7c9a79176c17aef59757a67dbee,refactored keep_all_best
41,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,25c86ca715d7bc90d01f081f8f62d292815b9262,"README update, set default models for synthesize.py and server.py. Disable verbose for ap init."
42,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ccbd542eb07a8349eeeecc975bca33258252be9e,Added info if model already downloaded in --list_models
43,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ca28e05ed71cea7462d9a4517a121edabf900239,"update fixed stopnet_pos_weight parameter

config parameter c.stopnet_pos_weight has currently no effect as it is not used."
44,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e610ca8cdb49145897088d9cd4ba412db568360d,"Merge pull request #629 from SanjaESC/patch-4

update static stopnet_pos_weight parameter"
45,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,131a163c954433664555775fca8428e9408d5d1d,"Merge pull request #628 from thorstenMueller/dev

Added info if model already downloaded in --list_models"
46,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8a6eee7fec46da19f486f392e3233f978ea85c5c,"distill import statement, check python version in setup.py"
47,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a926aa106de1846d72f29b5b662076720c3f5002,reorder imports
48,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,094b39939f394b83ad4b9a0984ac29552aa20906,pyaml
49,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5a6abe78df8a6f1c72162a09bdd0765f92ca013c,setup import reset
50,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e81ebec7a885b52d20506ffcdf6a30c4d058695f,"fix device mismatch wavegrad training

this should fixe the device mismatch as seen here https://github.com/mozilla/TTS/issues/622#issue-789802916"
51,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,aa5f24608a2e9529ae2e2d2a807687898de7b038,hubconf.py and load .models.json from the defualt location by mange.py
52,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0354b6f35ec31659a61182d4a7b32562704d08e0,move hubconf
53,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,66c2a61f74188d506bd55afaa9d3826cfeee3983,docstring hubconf
54,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,536366dc0aa8086f0837f829e0212abf5c5636d2,"Merge pull request #635 from SanjaESC/patch-1

fix device mismatch wavegrad training"
55,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,44c4a49745628692857261996fcc8014f5bc4506,Set out_path to be required param.
56,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,dfdac1def9ddbdbebea15e2067d45ff40d56aac5,"Merge pull request #636 from thorstenMueller/dev

Set out_path to be required param in compute_statistics.py."
57,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,879d946f10cea343d83b097ae7a863cba6d07da9,"Ups. Added missing ,"
58,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c7407571fa902009ca4ebcf062f703d43eb7d3b1,fix #638
59,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d003e593477da90e9c3850b22350be7a01b2e7a7,readme update for espeak install
60,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,699d2aa1c367d6ec21af456bb5082164771cd207,pin cython verions 0.29.20
61,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5beed0ddcd346b9b0feb8fcf013702de1a16778c,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
62,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8774e374446ca1491ef9ed3dedc3bd9401c4195d,"unpin cython version and commentout pyworld in audio.py causing dep
issues"
63,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5c46543765192016a5638824cf3ff6fe88081088,linter fixes and version updates for deps
64,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,41f6579a746256d3d52598b1b4a7401b0f61a003,push numpy version up to 1.17.5
65,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,167bbc6a4a1f2823c281835b169d060e08438c8d,update version number to 0.0.9.1
66,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c75ea74914851ea5d6d549db33cc3a48b7a442ca,Added info if model already downloaded in --list_models
67,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4cb4fcf02cda3624000f47fdb3c53a0a6b11cbac,Set out_path to be required param.
68,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a82152eef353d30975c197426d66fb00d969d5cb,"Ups. Added missing ,"
69,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,23c9009cdcfbfb34c85aa447d29d9c0527bee2e6,Merge branch 'dev' of https://github.com/thorstenMueller/TTS into dev
70,https://api.github.com/repos/mozilla/TTS/pulls/649,649,Best model saving and loading,"This includes:
- best models names with a step stamp
- `best_model.pth.tar` symlink created for convinience
- saving multiple best models after a set step is available via `c.keep_best` and `c.keep_after`
- continuing training will find the checkpoint or the best model with the largest step stamp 
- when continuing training best loss is now taken from the latest best model",gerazov,15214418,2021-02-12T01:18:05Z,CONTRIBUTOR,False,1176,1136,60,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d74866cb8e3a6f722989314279437f21b4301b5a,"Merge remote-tracking branch 'upstream/dev' into dev

Fix for circleci error mentioned in PR https://github.com/mozilla/TTS/pull/637"
71,https://api.github.com/repos/mozilla/TTS/pulls/647,647,Easy Fix for #454 (which was somehow deleted?),"#456, #454
#605
Somehow the code was LOST even though it was fixed _before_, so lately the issue just keeps popping up for Windows users, like in [here](https://github.com/mozilla/TTS/issues/617#issuecomment-763138841).

I did the same thing as [lokkelvin2 here](https://github.com/mozilla/TTS/pull/456#issue-448127246):
""Replaced with open(config_path, ""r"") as f: with with open(config_path, ""r"", encoding = ""utf-8"") as f: in TTS\utils\io.py.

Fixes UnicodeDecodeError for Windows 10 in #454""",adonispujols,20978926,2021-02-11T10:33:11Z,NONE,True,3,3,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,48011a8b58f4364f09a325096943891da893e1b7,"add encoding=""utf-8"""
72,https://api.github.com/repos/mozilla/TTS/pulls/646,646,spelling error. should be multiband not mulitband,i think im sending this to the right place now,adonispujols,20978926,2021-02-11T09:50:40Z,NONE,True,4,4,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6c824a6629ed6dd26c445beb45620f08dc1b41c6,spelling error. should be multiband not mulitband
73,https://api.github.com/repos/mozilla/TTS/pulls/646,646,spelling error. should be multiband not mulitband,i think im sending this to the right place now,adonispujols,20978926,2021-02-11T09:50:40Z,NONE,True,4,4,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b29a7e9645bee1eb949283d92a4986eae237fc9a,spelling error. should be multiband not mulitband
74,https://api.github.com/repos/mozilla/TTS/pulls/645,645,"Spelling Error. ""mulitband"" should be ""multiband""","Spelling Error. ""mulitband"" should be ""multiband""",adonispujols,20978926,2021-02-11T09:32:10Z,NONE,False,19,20,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e768fb9a8e82802a8e045b6365980a607695a117,pin numpy v0.0.9.1
75,https://api.github.com/repos/mozilla/TTS/pulls/645,645,"Spelling Error. ""mulitband"" should be ""multiband""","Spelling Error. ""mulitband"" should be ""multiband""",adonispujols,20978926,2021-02-11T09:32:10Z,NONE,False,19,20,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2cd44cbc9d1637c9c49ca0a5658dfca7b71f30de,pin numpy v0.0.9.1
76,https://api.github.com/repos/mozilla/TTS/pulls/645,645,"Spelling Error. ""mulitband"" should be ""multiband""","Spelling Error. ""mulitband"" should be ""multiband""",adonispujols,20978926,2021-02-11T09:32:10Z,NONE,False,19,20,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2edab4b3f9b5ad4352126ba6d52878b71d8e2cb3,disable pw in audio that causes numpy issue
77,https://api.github.com/repos/mozilla/TTS/pulls/645,645,"Spelling Error. ""mulitband"" should be ""multiband""","Spelling Error. ""mulitband"" should be ""multiband""",adonispujols,20978926,2021-02-11T09:32:10Z,NONE,False,19,20,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cb9c3caed212fd8f592fb1c22e2f4b392f92bc44,Merge branch 'master' of https://github.com/mozilla/TTS
78,https://api.github.com/repos/mozilla/TTS/pulls/645,645,"Spelling Error. ""mulitband"" should be ""multiband""","Spelling Error. ""mulitband"" should be ""multiband""",adonispujols,20978926,2021-02-11T09:32:10Z,NONE,False,19,20,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,22173c3f3f177080e5a7a90c22583ec9be0a0593,Fix URL of MelGAN paper
79,https://api.github.com/repos/mozilla/TTS/pulls/645,645,"Spelling Error. ""mulitband"" should be ""multiband""","Spelling Error. ""mulitband"" should be ""multiband""",adonispujols,20978926,2021-02-11T09:32:10Z,NONE,False,19,20,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5dbb48daf52d27b67b6ed5bfaad57555d70ad170,"Merge pull request #640 from seungwonpark/master

Fix URL of MelGAN paper"
80,https://api.github.com/repos/mozilla/TTS/pulls/645,645,"Spelling Error. ""mulitband"" should be ""multiband""","Spelling Error. ""mulitband"" should be ""multiband""",adonispujols,20978926,2021-02-11T09:32:10Z,NONE,False,19,20,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,52e926f4081fd163e50a0ddc70291e74276ed58b,"Spelling error. change ""mulitband"" to ""multiband"" 

not sure if this will break anything but i had an error and it pointed back to this. 
spelling error is also found at : https://github.com/mozilla/TTS/blob/df5899daf4ba4ec89544edf94f9c2e105c544461/TTS/server/README.md"
81,https://api.github.com/repos/mozilla/TTS/pulls/645,645,"Spelling Error. ""mulitband"" should be ""multiband""","Spelling Error. ""mulitband"" should be ""multiband""",adonispujols,20978926,2021-02-11T09:32:10Z,NONE,False,19,20,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e39ea69ce0b4b36203bb69c0345cf71b189ec8e0,spelling error. multiband not mulitband
82,https://api.github.com/repos/mozilla/TTS/pulls/642,642,restructured arg parsing and processing to utils,"I've moved the command line parsing and processing from the `if __name__ == '__main__':` block into two separate functions in a new file `TTS/utils/arguments.py`. This avoids code douplication across the training scripts adhering to the DRY principle :slightly_smiling_face: 

It also solves the `FIXME` that was before the `main` function.

Currently updated:
- `train_glow_tts.py`
- `train_speedy_speech.py`
- `train_tacotron.py`
- `train_vocoder_gan.py`
- `train_vocoder_wavegrad.py`
- `train_vocoder_wavernn.py`

These still work as before, they are a bit different - but I can update them if necessary:
- `train_encoder.py`
- `tune_wavegrad.py`",gerazov,15214418,2021-02-06T21:28:53Z,CONTRIBUTOR,True,294,528,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4f8f274d6e20a9610a5ca8577d5786fb5e38a809,restructured arg parsing and processing to utils
83,https://api.github.com/repos/mozilla/TTS/pulls/642,642,restructured arg parsing and processing to utils,"I've moved the command line parsing and processing from the `if __name__ == '__main__':` block into two separate functions in a new file `TTS/utils/arguments.py`. This avoids code douplication across the training scripts adhering to the DRY principle :slightly_smiling_face: 

It also solves the `FIXME` that was before the `main` function.

Currently updated:
- `train_glow_tts.py`
- `train_speedy_speech.py`
- `train_tacotron.py`
- `train_vocoder_gan.py`
- `train_vocoder_wavegrad.py`
- `train_vocoder_wavernn.py`

These still work as before, they are a bit different - but I can update them if necessary:
- `train_encoder.py`
- `tune_wavegrad.py`",gerazov,15214418,2021-02-06T21:28:53Z,CONTRIBUTOR,True,294,528,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2705d27b285fba03d1f2cbc69bbcbc737137d1b5,changed train scripts
84,https://api.github.com/repos/mozilla/TTS/pulls/642,642,restructured arg parsing and processing to utils,"I've moved the command line parsing and processing from the `if __name__ == '__main__':` block into two separate functions in a new file `TTS/utils/arguments.py`. This avoids code douplication across the training scripts adhering to the DRY principle :slightly_smiling_face: 

It also solves the `FIXME` that was before the `main` function.

Currently updated:
- `train_glow_tts.py`
- `train_speedy_speech.py`
- `train_tacotron.py`
- `train_vocoder_gan.py`
- `train_vocoder_wavegrad.py`
- `train_vocoder_wavernn.py`

These still work as before, they are a bit different - but I can update them if necessary:
- `train_encoder.py`
- `tune_wavegrad.py`",gerazov,15214418,2021-02-06T21:28:53Z,CONTRIBUTOR,True,294,528,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8fdd08ea157c56c93be033dc23e1355bbf9b07d3,updated to current dev
85,https://api.github.com/repos/mozilla/TTS/pulls/642,642,restructured arg parsing and processing to utils,"I've moved the command line parsing and processing from the `if __name__ == '__main__':` block into two separate functions in a new file `TTS/utils/arguments.py`. This avoids code douplication across the training scripts adhering to the DRY principle :slightly_smiling_face: 

It also solves the `FIXME` that was before the `main` function.

Currently updated:
- `train_glow_tts.py`
- `train_speedy_speech.py`
- `train_tacotron.py`
- `train_vocoder_gan.py`
- `train_vocoder_wavegrad.py`
- `train_vocoder_wavernn.py`

These still work as before, they are a bit different - but I can update them if necessary:
- `train_encoder.py`
- `tune_wavegrad.py`",gerazov,15214418,2021-02-06T21:28:53Z,CONTRIBUTOR,True,294,528,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ad17dc9e761809ebcfbd8496bd7906e73ac2d3a0,final fixes
86,https://api.github.com/repos/mozilla/TTS/pulls/642,642,restructured arg parsing and processing to utils,"I've moved the command line parsing and processing from the `if __name__ == '__main__':` block into two separate functions in a new file `TTS/utils/arguments.py`. This avoids code douplication across the training scripts adhering to the DRY principle :slightly_smiling_face: 

It also solves the `FIXME` that was before the `main` function.

Currently updated:
- `train_glow_tts.py`
- `train_speedy_speech.py`
- `train_tacotron.py`
- `train_vocoder_gan.py`
- `train_vocoder_wavegrad.py`
- `train_vocoder_wavernn.py`

These still work as before, they are a bit different - but I can update them if necessary:
- `train_encoder.py`
- `tune_wavegrad.py`",gerazov,15214418,2021-02-06T21:28:53Z,CONTRIBUTOR,True,294,528,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e507373b553b46089654727b7fbe773b187c38be,final final fixes
87,https://api.github.com/repos/mozilla/TTS/pulls/641,641,waveRNN fix,Closes #638,gerazov,15214418,2021-02-04T09:02:23Z,CONTRIBUTOR,True,59,47,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cb77aef36c747b11ce08db7eb684760f70e99fee,waveRNN fix
88,https://api.github.com/repos/mozilla/TTS/pulls/641,641,waveRNN fix,Closes #638,gerazov,15214418,2021-02-04T09:02:23Z,CONTRIBUTOR,True,59,47,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,24ffa9e9f696121cb5326b3cba0659032d571b94,"update wavernn test config, delete cap=True"
89,https://api.github.com/repos/mozilla/TTS/pulls/641,641,waveRNN fix,Closes #638,gerazov,15214418,2021-02-04T09:02:23Z,CONTRIBUTOR,True,59,47,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f0635453256fd48091d26a474d6edfd300280429,improve robustness of defining wavernn in config file
90,https://api.github.com/repos/mozilla/TTS/pulls/640,640,Fix URL of MelGAN paper,,seungwonpark,13394294,2021-02-04T05:07:02Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,22173c3f3f177080e5a7a90c22583ec9be0a0593,Fix URL of MelGAN paper
91,https://api.github.com/repos/mozilla/TTS/pulls/639,639,Remove backslash of Windows Computers.,Remove backslash of Windows Computers.,ErfolgreichCharismatisch,18123801,2021-02-01T12:44:09Z,NONE,False,9,11,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fafb2f4b25ad7ea1f30e2e50ee467bc856edda37,"Remove backslash of Windows Computers.

Remove backslash of Windows Computers."
92,https://api.github.com/repos/mozilla/TTS/pulls/637,637,"Ups. Added missing ,","As mentioned by @MrDiscordMan here i forgot a ,
https://github.com/mozilla/TTS/commit/44c4a49745628692857261996fcc8014f5bc4506#commitcomment-46543647

Sorry.",thorstenMueller,9558265,2021-01-30T12:46:08Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,879d946f10cea343d83b097ae7a863cba6d07da9,"Ups. Added missing ,"
93,https://api.github.com/repos/mozilla/TTS/pulls/637,637,"Ups. Added missing ,","As mentioned by @MrDiscordMan here i forgot a ,
https://github.com/mozilla/TTS/commit/44c4a49745628692857261996fcc8014f5bc4506#commitcomment-46543647

Sorry.",thorstenMueller,9558265,2021-01-30T12:46:08Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c75ea74914851ea5d6d549db33cc3a48b7a442ca,Added info if model already downloaded in --list_models
94,https://api.github.com/repos/mozilla/TTS/pulls/637,637,"Ups. Added missing ,","As mentioned by @MrDiscordMan here i forgot a ,
https://github.com/mozilla/TTS/commit/44c4a49745628692857261996fcc8014f5bc4506#commitcomment-46543647

Sorry.",thorstenMueller,9558265,2021-01-30T12:46:08Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4cb4fcf02cda3624000f47fdb3c53a0a6b11cbac,Set out_path to be required param.
95,https://api.github.com/repos/mozilla/TTS/pulls/637,637,"Ups. Added missing ,","As mentioned by @MrDiscordMan here i forgot a ,
https://github.com/mozilla/TTS/commit/44c4a49745628692857261996fcc8014f5bc4506#commitcomment-46543647

Sorry.",thorstenMueller,9558265,2021-01-30T12:46:08Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a82152eef353d30975c197426d66fb00d969d5cb,"Ups. Added missing ,"
96,https://api.github.com/repos/mozilla/TTS/pulls/637,637,"Ups. Added missing ,","As mentioned by @MrDiscordMan here i forgot a ,
https://github.com/mozilla/TTS/commit/44c4a49745628692857261996fcc8014f5bc4506#commitcomment-46543647

Sorry.",thorstenMueller,9558265,2021-01-30T12:46:08Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,23c9009cdcfbfb34c85aa447d29d9c0527bee2e6,Merge branch 'dev' of https://github.com/thorstenMueller/TTS into dev
97,https://api.github.com/repos/mozilla/TTS/pulls/637,637,"Ups. Added missing ,","As mentioned by @MrDiscordMan here i forgot a ,
https://github.com/mozilla/TTS/commit/44c4a49745628692857261996fcc8014f5bc4506#commitcomment-46543647

Sorry.",thorstenMueller,9558265,2021-01-30T12:46:08Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d74866cb8e3a6f722989314279437f21b4301b5a,"Merge remote-tracking branch 'upstream/dev' into dev

Fix for circleci error mentioned in PR https://github.com/mozilla/TTS/pull/637"
98,https://api.github.com/repos/mozilla/TTS/pulls/636,636,Set out_path to be required param in compute_statistics.py.,"Fix for following issue:

When running compute_statistics.py with configfile param, but without out_path compution is running for 100% and throws an io exception afterwards, because of missing out_path.

Set out_path as required arg.

 > Avg mel spec mean: -2.5096506414089936
 > Avg mel spec scale: 0.8145479622630323
 > Avg linear spec mean: -1.8196869894752261
 > Avg lienar spec scale: 0.7276981902559411
Traceback (most recent call last):
  File ""./compute_statistics.py"", line 90, in <module>
    main()
  File ""./compute_statistics.py"", line 85, in main
    np.save(output_file_path, stats, allow_pickle=True)
  File ""<__array_function__ internals>"", line 6, in save
  File ""/home/thorsten/___prj/tts/models/taco2/lib/python3.6/site-packages/numpy/lib/npyio.py"", line 538, in save
    file = os_fspath(file)
TypeError: expected str, bytes or os.PathLike object, not NoneType
",thorstenMueller,9558265,2021-01-29T16:31:11Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,44c4a49745628692857261996fcc8014f5bc4506,Set out_path to be required param.
99,https://api.github.com/repos/mozilla/TTS/pulls/635,635,fix device mismatch wavegrad training,this should fixe the device mismatch as seen here https://github.com/mozilla/TTS/issues/622#issue-789802916 when continuing the wavegrad training,SanjaESC,6319070,2021-01-29T14:20:05Z,CONTRIBUTOR,True,4,4,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e81ebec7a885b52d20506ffcdf6a30c4d058695f,"fix device mismatch wavegrad training

this should fixe the device mismatch as seen here https://github.com/mozilla/TTS/issues/622#issue-789802916"
100,https://api.github.com/repos/mozilla/TTS/pulls/632,632,Fix greedy substitution in read_json_with_comments,"The substitution tries to match comments like this:

```
  // this is a comment
```

but accidentally also matched

```
  ""url"": ""tcp://localhost:54321"",
```

and transformed it into

```
  ""url"": ""tcp:
```

which in turn broke the JSON import.

Fix this by making sure the substitution only happens when the comment
starts at the beginning of a line or only has white spaces preceeding
it.

Fixes: #631",mweinelt,131599,2021-01-29T03:24:30Z,CONTRIBUTOR,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c5e05a8040576ec5f1e7989892ea6be48dce4a09,"Fix greedy substitution in read_json_with_comments

The substitution tries to match comments like this:

  // this is a comment

but accidentally also matched

  ""url"": ""tcp://localhost:54321"",

and transformed it into

  ""url"": ""tcp:

which in turn broke the JSON import.

Fix this by making sure the substitution only happens when the comment
starts at the beginning of a line or only has white spaces preceeding
it.

Fixes: #631"
101,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,25c86ca715d7bc90d01f081f8f62d292815b9262,"README update, set default models for synthesize.py and server.py. Disable verbose for ap init."
102,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ccbd542eb07a8349eeeecc975bca33258252be9e,Added info if model already downloaded in --list_models
103,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ca28e05ed71cea7462d9a4517a121edabf900239,"update fixed stopnet_pos_weight parameter

config parameter c.stopnet_pos_weight has currently no effect as it is not used."
104,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e610ca8cdb49145897088d9cd4ba412db568360d,"Merge pull request #629 from SanjaESC/patch-4

update static stopnet_pos_weight parameter"
105,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,131a163c954433664555775fca8428e9408d5d1d,"Merge pull request #628 from thorstenMueller/dev

Added info if model already downloaded in --list_models"
106,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8a6eee7fec46da19f486f392e3233f978ea85c5c,"distill import statement, check python version in setup.py"
107,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a926aa106de1846d72f29b5b662076720c3f5002,reorder imports
108,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,094b39939f394b83ad4b9a0984ac29552aa20906,pyaml
109,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5a6abe78df8a6f1c72162a09bdd0765f92ca013c,setup import reset
110,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e81ebec7a885b52d20506ffcdf6a30c4d058695f,"fix device mismatch wavegrad training

this should fixe the device mismatch as seen here https://github.com/mozilla/TTS/issues/622#issue-789802916"
111,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,aa5f24608a2e9529ae2e2d2a807687898de7b038,hubconf.py and load .models.json from the defualt location by mange.py
112,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0354b6f35ec31659a61182d4a7b32562704d08e0,move hubconf
113,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,66c2a61f74188d506bd55afaa9d3826cfeee3983,docstring hubconf
114,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,536366dc0aa8086f0837f829e0212abf5c5636d2,"Merge pull request #635 from SanjaESC/patch-1

fix device mismatch wavegrad training"
115,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,44c4a49745628692857261996fcc8014f5bc4506,Set out_path to be required param.
116,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,dfdac1def9ddbdbebea15e2067d45ff40d56aac5,"Merge pull request #636 from thorstenMueller/dev

Set out_path to be required param in compute_statistics.py."
117,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,879d946f10cea343d83b097ae7a863cba6d07da9,"Ups. Added missing ,"
118,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c7407571fa902009ca4ebcf062f703d43eb7d3b1,fix #638
119,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d003e593477da90e9c3850b22350be7a01b2e7a7,readme update for espeak install
120,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,699d2aa1c367d6ec21af456bb5082164771cd207,pin cython verions 0.29.20
121,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5beed0ddcd346b9b0feb8fcf013702de1a16778c,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
122,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8774e374446ca1491ef9ed3dedc3bd9401c4195d,"unpin cython version and commentout pyworld in audio.py causing dep
issues"
123,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5c46543765192016a5638824cf3ff6fe88081088,linter fixes and version updates for deps
124,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,41f6579a746256d3d52598b1b4a7401b0f61a003,push numpy version up to 1.17.5
125,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,167bbc6a4a1f2823c281835b169d060e08438c8d,update version number to 0.0.9.1
126,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c75ea74914851ea5d6d549db33cc3a48b7a442ca,Added info if model already downloaded in --list_models
127,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4cb4fcf02cda3624000f47fdb3c53a0a6b11cbac,Set out_path to be required param.
128,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a82152eef353d30975c197426d66fb00d969d5cb,"Ups. Added missing ,"
129,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,23c9009cdcfbfb34c85aa447d29d9c0527bee2e6,Merge branch 'dev' of https://github.com/thorstenMueller/TTS into dev
130,https://api.github.com/repos/mozilla/TTS/pulls/630,630,Dev v0.0.10,"### 🐞Bug Fixes
- [x] Make ```synthesizer.py``` saving the output audio with the vocoder sampling rate. It is necessary if there is sampling rates of the tts and the vocoder models are different and interpolation is applied to the tts model output before running the vocoder. Practically, it fixes generated Spanish and French voices by ```tts``` or ```tts-server``` on the terminal. 
- [x] Handling utf-8 on Windows. (by @adonispujols)


### 💾 Code updates
- [x] **Breaking Change:** Update default set of characters in ```symbols.py```. This might require you to set your character set in ```config.json ``` if you like to use this version with your models trained with the previous version. 
- [x] **Chinese** backend for text processing (#654  by @kirianguiller)
- [x] Enable torch.hub integration for the released models.
- [x] First github release. 
- [x] dep. version fixes. Using numpy > 1.17.5 breaks some of the tests. 
- [x] WaveRNN fix (by @gerazov )
- [x] Big refactoring for the training scripts to share the init part of the code. (by @gerazov)
- [x] Enable ModelManager to download models from Github releases.
- [x] Add a test for ```compute_statistics.py```
- [x] light-touch updates in ```tts``` and ```tts-server``` entry points. (thanks @thorstenMueller )
- [x] Define default vocoder models for each tts model in ```.models.json```.  ```tts``` and ```tts-server``` entry points use the default vocoder if the user does not specify. 
- [x] ```find_unique_chars.py``` to find all the unique characters in a dataset.
- [x] A better way to handling best_models through training. (thx @gerazov )
- [x] pass used characters to the model config.json at the beginning of the training. This prevents any code update later to affect the trained models. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
- [x] ek1 **English** Tacotron2 model and WaveGrad vocoder under ```.models.json```.  (huge THX!! to @nmstoker) 
- [x] **Russian** ~~Tacotron2-DCA~~ Tacotron2-DDC model.
- [x] Dutch model.  (huge THX!! to @r-dh )
- [ ] **Chinese** Tacotron2 model. (huge THX!! to @kirianguiller)",erogol,1402048,2021-01-28T17:05:12Z,CONTRIBUTOR,False,2801,1364,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d74866cb8e3a6f722989314279437f21b4301b5a,"Merge remote-tracking branch 'upstream/dev' into dev

Fix for circleci error mentioned in PR https://github.com/mozilla/TTS/pull/637"
131,https://api.github.com/repos/mozilla/TTS/pulls/629,629,update static stopnet_pos_weight parameter,"config parameter `c.stopnet_pos_weight` currently has no effect as it is not used.

I suppose it could be passed as a parameter as proposed.
Or similar to other parameters read from config in losses.py",SanjaESC,6319070,2021-01-27T15:36:20Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ca28e05ed71cea7462d9a4517a121edabf900239,"update fixed stopnet_pos_weight parameter

config parameter c.stopnet_pos_weight has currently no effect as it is not used."
132,https://api.github.com/repos/mozilla/TTS/pulls/628,628,Added info if model already downloaded in --list_models,If server.py is executed with --list_models a list of available tts and vocoder models is shown. Now it's additionally shown if a model has been already downloaded.,thorstenMueller,9558265,2021-01-27T15:21:40Z,CONTRIBUTOR,True,6,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ccbd542eb07a8349eeeecc975bca33258252be9e,Added info if model already downloaded in --list_models
133,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,435943ba39379d0d954d8b003f0ca1389542d549,update issue template
134,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c96f7a2614ae336ac8b4c1657af444846719cd83,TorchSTFT to device fix
135,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b2b4828f17f745856d6abb642f5cb8991da0edfe,set requires_grad=False
136,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b70bef579a3953210dde51f73be7c95d97f914ab,"Merge pull request #620 from gerazov/dev

TorchSTFT to device fix"
137,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3d30dae8f32c2631af60ccd57afb00b2e6e8e84d,.models.json and synthesize.py update for interfacing with model manager
138,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5c87753e88b681ef71688b73c68f84eea456d53c,glow-tts fix for saving inverse weight
139,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1faf565e3ae2270e7c603368afa7e2234a5877f2,add load_checkpoint func to tts models
140,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,563bc921d884996113d4311b040e2ff5f93dec87,optional verbose for audio.py init
141,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ea39715305b2b835757bc45b7bc1e64d82516a48,read_json_with_comments
142,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ca3743539a85f753f64405ba77179ee2047297df,load_checkpoint func for vocoder models
143,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5bd7238153c67aa79a51a7353fb7acce06c80f88,"interpolate spectrogram in vocoder generic utils for matching sample
rates"
144,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1bc8fbbd3cb95941e15c5006f78f0f985cc48ce2,set eval mode whe nloading models
145,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e414582be658778861b37f55f9c1bdc57d7a8651,Added option for server ui details page.
146,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8cfed633981a8687838d5060513e5e37c54c36da,update install instructions
147,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6b6e989fd2d11df5644d86141e558bb44b06e61c,update server readme
148,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,007a4d7139a378d752eadfcc284278c0dc65c5e8,remove 3rd paty wavernn support from server.py and add ModelManager arguments
149,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,50fee59a2c60ca711b7959baa1711d586aa49758,update synthesizer.py for better interfacing to different models
150,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9addfabc430ba6956d4f796d08fc2bd6fd10eac5,wavernn load_checkpoint function
151,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0ab2eb26648ed8f672051e6983ac3c32d20bb202,use synthesizer in both synthesize.py and server.pu
152,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,26540d507db03d29acd686fa64159d52c4070d0c,add pyproject.toml
153,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f251dc8c0e6a0e6cdcacaca17c5590726d29b59a,"Update train_tacotron.py

When attempting to fine-tune a model with ""prenet_type"": ""bn"" that was originally trained with ""prenet_type"": ""original"", a RuntimeError is thrown that stops the training.

By catching the RuntimeError, the required layers can be partially restored and the training will continue without any problems."
154,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,32d21545ace69def11b013a5332cad013508b6eb,README update
155,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c990b3a59c4731cbde3b9fdd95e987ceb3051745,linter fixes and test fixes
156,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ca8ad9c21eafa39bfbba5aaf3540c841f67a5583,rename audio._normalize to audio.normalize
157,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ca647cf222b071483145e2e2504350780a3e9173,Model Manager to download released models
158,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5fb611ef40256e1cc441a1a2c7969fae0755cb33,static image for server index.html
159,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9c1b3226f5745e52bb9883dade23f36f3b562882,update version
160,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5ee73c2bae1949da4e2f0ea4e8ffc127e8172e70,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
161,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fae10309e4d172831997e08d5ce5ee22774a67ec,"Merge pull request #624 from SanjaESC/patch-3

Update train_tacotron.py"
162,https://api.github.com/repos/mozilla/TTS/pulls/625,625,Dev v0.0.9,"### 💾 Code updates
- [x] ```server.py``` and ```synthesize.py``` can use the released models by passing the model names as command-line arguments.
- [x] Synthesizer interface to support inference for any tts - vocoder couple.  It is being used by ```synthesize.py``` and ```server.py``` as a common inference interface.
- [x] ```TTS.utils.manage``` to moderate released models and automatically download when needed.  It is being used by ```synthesize.py``` and ```server.py``` to call the released models. Each model is downloaded under ```~/.tts/``` and re-used if it is downloaded already. The released models are listed in ```.models.json``` file and it is to be updated with new released models.
- [x] Each model has a ```load_checkpoint()``` function.  
- [x] TorchSTFT fix for better parameter handling.  (@gerazov)
- [x] Optional model details prompt on the demo server. (@thorstenMueller )
- [x] First PyPI release. You can ```pip install TTS``` for using ```tts``` and ```tts-server``` on the terminal for inference. 

### 🏅 Model updates
---
  

### 🚀 Pre-Trained Models  
---",erogol,1402048,2021-01-22T12:40:21Z,CONTRIBUTOR,True,1075,531,43,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1d3de15b163a27a11c19f8115de04e9143b61f82,circleCI update
163,https://api.github.com/repos/mozilla/TTS/pulls/624,624,Update train_tacotron.py,"When attempting to fine-tune a model with `""prenet_type"": ""bn""` that was originally trained with `""prenet_type"": ""original""`, a `RuntimeError` is thrown that stops the training.

By catching the `RuntimeError`, the required layers can be partially restored and the training will continue without any problems.",SanjaESC,6319070,2021-01-21T20:17:46Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f251dc8c0e6a0e6cdcacaca17c5590726d29b59a,"Update train_tacotron.py

When attempting to fine-tune a model with ""prenet_type"": ""bn"" that was originally trained with ""prenet_type"": ""original"", a RuntimeError is thrown that stops the training.

By catching the RuntimeError, the required layers can be partially restored and the training will continue without any problems."
164,https://api.github.com/repos/mozilla/TTS/pulls/623,623,Added option for server ui details page.,Added ability to show a detail page on server web ui with details on tacotron2 and vocoder model.,thorstenMueller,9558265,2021-01-20T21:00:29Z,CONTRIBUTOR,True,147,0,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e414582be658778861b37f55f9c1bdc57d7a8651,Added option for server ui details page.
165,https://api.github.com/repos/mozilla/TTS/pulls/623,623,Added option for server ui details page.,Added ability to show a detail page on server web ui with details on tacotron2 and vocoder model.,thorstenMueller,9558265,2021-01-20T21:00:29Z,CONTRIBUTOR,True,147,0,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,afb7db2a1dec6d7a135e94a808e73b04f6135e7e,Removed unneeded check and removed specific taco2 model name.
166,https://api.github.com/repos/mozilla/TTS/pulls/621,621,Fix minor typo in README.md,,KathyReid,114158,2021-01-18T06:51:26Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,23edc0533ff32c5699e7e5d3be36d4c385e0f2c6,Fix minor typo in README.md
167,https://api.github.com/repos/mozilla/TTS/pulls/620,620,TorchSTFT to device fix,This should close  #619,gerazov,15214418,2021-01-16T11:35:47Z,CONTRIBUTOR,True,6,3,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c96f7a2614ae336ac8b4c1657af444846719cd83,TorchSTFT to device fix
168,https://api.github.com/repos/mozilla/TTS/pulls/620,620,TorchSTFT to device fix,This should close  #619,gerazov,15214418,2021-01-16T11:35:47Z,CONTRIBUTOR,True,6,3,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b2b4828f17f745856d6abb642f5cb8991da0edfe,set requires_grad=False
169,https://api.github.com/repos/mozilla/TTS/pulls/613,613,requirements.txt: set umap-learn version to 0.4.4,Latest umap-learn requires numba>=0.49,NarutoUA,6840502,2021-01-03T00:28:05Z,NONE,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b47faad401b47e6c84b94e335c7c2a2301b79f84,"requirements.txt: set umap-learn version to 0.4.4

Latest umap-learn requires numba>=0.49"
170,https://api.github.com/repos/mozilla/TTS/pulls/602,602,Increase robustness in synthesize with wavegrad model,"I didn't succeed on running synthesize.py with my wavegrad model. But @SanjaESC did an amazing job and helped me out with the right code adjustments. With his nice permission, i can create this PR.

It increases the robustness for following issues:

* AttributeError: 'NoneType' object has no attribute 'to'
* RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward
* Added codesnipplet when using computed npy file from tune-wavegrad

Thanks @SanjaESC 🥇",thorstenMueller,9558265,2020-12-19T22:05:09Z,CONTRIBUTOR,True,10,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8c81ca7bfda6223426e523a39543c8cac4ee0d77,"Merge pull request #1 from mozilla/dev

Sync with Mozilla TTS dev branch"
171,https://api.github.com/repos/mozilla/TTS/pulls/602,602,Increase robustness in synthesize with wavegrad model,"I didn't succeed on running synthesize.py with my wavegrad model. But @SanjaESC did an amazing job and helped me out with the right code adjustments. With his nice permission, i can create this PR.

It increases the robustness for following issues:

* AttributeError: 'NoneType' object has no attribute 'to'
* RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward
* Added codesnipplet when using computed npy file from tune-wavegrad

Thanks @SanjaESC 🥇",thorstenMueller,9558265,2020-12-19T22:05:09Z,CONTRIBUTOR,True,10,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,28a64221eaf6d6435d61d4ca72730bb994e22cc4,Improve robostness on cpu / gpu model mix
172,https://api.github.com/repos/mozilla/TTS/pulls/602,602,Increase robustness in synthesize with wavegrad model,"I didn't succeed on running synthesize.py with my wavegrad model. But @SanjaESC did an amazing job and helped me out with the right code adjustments. With his nice permission, i can create this PR.

It increases the robustness for following issues:

* AttributeError: 'NoneType' object has no attribute 'to'
* RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward
* Added codesnipplet when using computed npy file from tune-wavegrad

Thanks @SanjaESC 🥇",thorstenMueller,9558265,2020-12-19T22:05:09Z,CONTRIBUTOR,True,10,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2aa0354b44266e48655973cca8cea8f2e17c483c,Fix for 'NoneType' object has no attribute 'to'
173,https://api.github.com/repos/mozilla/TTS/pulls/602,602,Increase robustness in synthesize with wavegrad model,"I didn't succeed on running synthesize.py with my wavegrad model. But @SanjaESC did an amazing job and helped me out with the right code adjustments. With his nice permission, i can create this PR.

It increases the robustness for following issues:

* AttributeError: 'NoneType' object has no attribute 'to'
* RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward
* Added codesnipplet when using computed npy file from tune-wavegrad

Thanks @SanjaESC 🥇",thorstenMueller,9558265,2020-12-19T22:05:09Z,CONTRIBUTOR,True,10,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f673f8f74dd343889b6b81658e09fb61e33700ea,Added support for npy output from tune-wavegrad
174,https://api.github.com/repos/mozilla/TTS/pulls/597,597,inflect negative numbers correctly,,Mic92,96200,2020-12-10T14:27:51Z,CONTRIBUTOR,True,14,17,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ea2c57b0ac1fb67332364bf91cdaee2db0ccbe20,"test_text_processing: remove assertion message

pytest does a better job at diffing anyway in case of an error"
175,https://api.github.com/repos/mozilla/TTS/pulls/597,597,inflect negative numbers correctly,,Mic92,96200,2020-12-10T14:27:51Z,CONTRIBUTOR,True,14,17,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cdb81f8c5dcf109c28bb253c0da304d621ad112e,"test_text_cleaners: don't re-invent assertions

pytest does treat assert special and does a better job w.r.t error reporting"
176,https://api.github.com/repos/mozilla/TTS/pulls/597,597,inflect negative numbers correctly,,Mic92,96200,2020-12-10T14:27:51Z,CONTRIBUTOR,True,14,17,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,62fd4ca70dec5851c44265147b389aa135861a3e,inflect negative numbers correctly
177,https://api.github.com/repos/mozilla/TTS/pulls/596,596,Better currency/time expansion,,Mic92,96200,2020-12-10T13:52:54Z,CONTRIBUTOR,True,122,23,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,58687f9c34b9d6d644eaebb9a4e31b27c522cbca,tests/test_text_processing: fix undefined variable
178,https://api.github.com/repos/mozilla/TTS/pulls/596,596,Better currency/time expansion,,Mic92,96200,2020-12-10T13:52:54Z,CONTRIBUTOR,True,122,23,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,76138687d3445514e7c615617267a4203f193a7f,expand more currencies
179,https://api.github.com/repos/mozilla/TTS/pulls/596,596,Better currency/time expansion,,Mic92,96200,2020-12-10T13:52:54Z,CONTRIBUTOR,True,122,23,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,664668265068243cfaa8796093acca17147c7fa3,cleaners: expand english time
180,https://api.github.com/repos/mozilla/TTS/pulls/596,596,Better currency/time expansion,,Mic92,96200,2020-12-10T13:52:54Z,CONTRIBUTOR,True,122,23,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2007b0bcee90f9d4a08d22c8c4759d1cad4ab113,add tests for currency/time expansion
181,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2202e171c53dde2359e95c7fa82bd1c7686604de,"Fix import to grab the encoder model save function

I saw that this was recently changed but I'm not sure if it should have been. This is the correct function given the arguments provided to it in the train loop."
182,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0c6f7e4c77b7897f715ff4a219cf0c9924dc5b97,resample audio if flag set true
183,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7b0a93d2f864d5273bd0f777cd824ae24c444e7c,fix
184,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a757b203bc619146d4ea6b8af5135656ee11966a,fix longer phoneme seqs
185,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,06a389bc08e3e152f5f3562fb6ae0f3a9ebb9c08,Added option for saving raw spectograms
186,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ac46c3ff4ce7ae85d99b1b40dde0802e31de5767,"Merge pull request #580 from thorstenMueller/dev

Added option for saving raw spectograms"
187,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7c3cdced1a1be312efde5563e70eb852af85cc7f,make speaker_mapping a global variable to prevent reload. Fix glow-tts training
188,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f42ca2b73fae96d0f6598d7cfecf5c4729c52c1b,"Update wavegrad.py

This should fix the issue https://github.com/mozilla/TTS/issues/581"
189,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8c29bc6bb4ddcc122ef7a90d675a1660d7dbc7cf,"Merge pull request #586 from SanjaESC/patch-2

Update wavegrad.py"
190,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,affe1c1138160b84ca5fe80a8328dbe2473f52ee,setup training scripts for computing phonemes before training optionally. And define data_loaders before starting training and re-use them instead of re-define for every train and eval calls. This is to enable better instance filtering based on input length.
191,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,20c86489d764969a4f06012da4c977705c2c9a0e,make static methods for faster multiprocess call
192,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7505c0ba27d622fd006be9ea8f903ff6a5d300dd,muliprocess phoneme computation
193,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,482e725752da48d8d3757fb0ba9c4670c122c7f4,sync torch calls before logging training results
194,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5595cbd8382b52aaad9e7b7c8813aacd974ed1be,update version
195,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0252a07fa6802db952ee4b7878936be8a244d769,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
196,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,06612ce3055d483a9a347abe746551658ee0a43a,test fixes
197,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c57fd7387209d7da3dae754e0aa440e5e9c336ad,"specify build dependencies

Reading setup.py will import numpy already,
hence pip has no way to figure out what dependencies are needed."
198,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,857172ba3fddbc1c6573535ec5f06b259da46ff6,Migrate to github actions for CI tests
199,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,128fd94ab178382314af5f6bb3dc875e1335e409,"Pin numpy<1.20 for continued python3.6 support

Numpy starting with 1.20 has dropped support for Python 3.6."
200,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2f689cbd3a0925bd2521b9aecc1e524e140b6bb2,"Merge pull request #572 from mweinelt/gh-actions

Introduce github action for CI"
201,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d9c518e12d9c9fb18c64787a9e93d91e55684184,update test
202,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1b133d6ea4cad524c55b80b2aa7bae5b550bffaa,"Revert ""Introduce github action for CI"""
203,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,261e35fce6dd5301a0f9426cbf0e1ba5d118a7ff,"Merge pull request #593 from mozilla/revert-572-gh-actions

Revert ""Introduce github action for CI"""
204,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a141a717e475f3c92663b7d33da365204b4d9f36,circle-ci config.yml
205,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d19eca24614423b894e037268276ed25970c4df5,update CI status badge
206,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e39628ce2fa94cbb784b245f84a602855bd9be22,Limit filenames to 10 chars
207,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,045b8c8ba3feda2391087b1b94e731c473ac2919,"Merge pull request #594 from thorstenMueller/dev

Limit filenames in synthesize.py to max. 10 chars"
208,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,df180148e9fd7a8cfe428179bc6e7d0533cdd56a,use noise augmentation in TTSDataset
209,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,62bc171db5caadb45f6c27114538039fc8a0f532,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
210,https://api.github.com/repos/mozilla/TTS/pulls/595,595,Test ci,sasd,erogol,1402048,2020-12-10T11:11:46Z,CONTRIBUTOR,False,289,192,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,53679b706da2bc38510b467289be844f8e6e9d24,glow-tts distributed fix
211,https://api.github.com/repos/mozilla/TTS/pulls/594,594,Limit filenames in synthesize.py to max. 10 chars,"After trying to synthesize a whole fairytale story i ran into an exception on ""filename too long"", so i stripped filename (based on text) to a maximum of 10 chars.",thorstenMueller,9558265,2020-12-08T21:09:00Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e39628ce2fa94cbb784b245f84a602855bd9be22,Limit filenames to 10 chars
212,https://api.github.com/repos/mozilla/TTS/pulls/593,593,"Revert ""Introduce github action for CI""",Reverts mozilla/TTS#572,erogol,1402048,2020-12-08T10:30:00Z,CONTRIBUTOR,True,64,64,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1b133d6ea4cad524c55b80b2aa7bae5b550bffaa,"Revert ""Introduce github action for CI"""
213,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2202e171c53dde2359e95c7fa82bd1c7686604de,"Fix import to grab the encoder model save function

I saw that this was recently changed but I'm not sure if it should have been. This is the correct function given the arguments provided to it in the train loop."
214,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0c6f7e4c77b7897f715ff4a219cf0c9924dc5b97,resample audio if flag set true
215,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7b0a93d2f864d5273bd0f777cd824ae24c444e7c,fix
216,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a757b203bc619146d4ea6b8af5135656ee11966a,fix longer phoneme seqs
217,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,06a389bc08e3e152f5f3562fb6ae0f3a9ebb9c08,Added option for saving raw spectograms
218,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ac46c3ff4ce7ae85d99b1b40dde0802e31de5767,"Merge pull request #580 from thorstenMueller/dev

Added option for saving raw spectograms"
219,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7c3cdced1a1be312efde5563e70eb852af85cc7f,make speaker_mapping a global variable to prevent reload. Fix glow-tts training
220,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f42ca2b73fae96d0f6598d7cfecf5c4729c52c1b,"Update wavegrad.py

This should fix the issue https://github.com/mozilla/TTS/issues/581"
221,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8c29bc6bb4ddcc122ef7a90d675a1660d7dbc7cf,"Merge pull request #586 from SanjaESC/patch-2

Update wavegrad.py"
222,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,affe1c1138160b84ca5fe80a8328dbe2473f52ee,setup training scripts for computing phonemes before training optionally. And define data_loaders before starting training and re-use them instead of re-define for every train and eval calls. This is to enable better instance filtering based on input length.
223,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,20c86489d764969a4f06012da4c977705c2c9a0e,make static methods for faster multiprocess call
224,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7505c0ba27d622fd006be9ea8f903ff6a5d300dd,muliprocess phoneme computation
225,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,482e725752da48d8d3757fb0ba9c4670c122c7f4,sync torch calls before logging training results
226,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5595cbd8382b52aaad9e7b7c8813aacd974ed1be,update version
227,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0252a07fa6802db952ee4b7878936be8a244d769,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
228,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,06612ce3055d483a9a347abe746551658ee0a43a,test fixes
229,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c57fd7387209d7da3dae754e0aa440e5e9c336ad,"specify build dependencies

Reading setup.py will import numpy already,
hence pip has no way to figure out what dependencies are needed."
230,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,857172ba3fddbc1c6573535ec5f06b259da46ff6,Migrate to github actions for CI tests
231,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,128fd94ab178382314af5f6bb3dc875e1335e409,"Pin numpy<1.20 for continued python3.6 support

Numpy starting with 1.20 has dropped support for Python 3.6."
232,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2f689cbd3a0925bd2521b9aecc1e524e140b6bb2,"Merge pull request #572 from mweinelt/gh-actions

Introduce github action for CI"
233,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d9c518e12d9c9fb18c64787a9e93d91e55684184,update test
234,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1b133d6ea4cad524c55b80b2aa7bae5b550bffaa,"Revert ""Introduce github action for CI"""
235,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,261e35fce6dd5301a0f9426cbf0e1ba5d118a7ff,"Merge pull request #593 from mozilla/revert-572-gh-actions

Revert ""Introduce github action for CI"""
236,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a141a717e475f3c92663b7d33da365204b4d9f36,circle-ci config.yml
237,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d19eca24614423b894e037268276ed25970c4df5,update CI status badge
238,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e39628ce2fa94cbb784b245f84a602855bd9be22,Limit filenames to 10 chars
239,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,045b8c8ba3feda2391087b1b94e731c473ac2919,"Merge pull request #594 from thorstenMueller/dev

Limit filenames in synthesize.py to max. 10 chars"
240,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,df180148e9fd7a8cfe428179bc6e7d0533cdd56a,use noise augmentation in TTSDataset
241,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,62bc171db5caadb45f6c27114538039fc8a0f532,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
242,https://api.github.com/repos/mozilla/TTS/pulls/592,592,Dev (v0.0.8),"### 💾 Code updates
- [x] save raw spectrograms using synthesize.py (thx @thorstenMueller )
   - as you compute the output voice you can also save spectrograms to be used in later stages.
- [x] compute phonemes optionally at the beginning of training if ```compute_input_seq_cache``` set True. 
   - This enables better filtering of instances based on sequence length. For instance, transcripts with numbers are short before converting them to phonemes but after phonemes, they might get too long and cause OMM issues.
- [x] move CI to an alternative (Circle CI) (Thx @Mic92 @mweinelt)
   - Travis is not shown on Github therefore we need an alternative.
- [x] ```TTS/bin/compute_attention_masks.py```  -> computer attention masks from trained Tacotron models.  These masks are used to train the speedy speech model however, they also can be used for other purposes.
- [x] Initial docstring coverage for TTS/tts models


### 🏅 Model updates
- [x] Dynamic convolutional attention for Tacotron models. [paper](https://arxiv.org/abs/1910.10288)
- [x] Speedy Speech model initial implementation. [paper](https://arxiv.org/abs/2008.03802)
- [x] Glow-TTS Refactoring 
- [ ] ~~HiFi-GAN implementation (**help needed**)~~
    - This is to be implemented if there is help from the community. 
  

### 🚀 Pre-Trained Models  
[Released Models](https://github.com/mozilla/TTS/wiki/Released-Models)
- [x] new Glow-TTS LJSpeech model
- [x] Tacotron2_r=2 dynamic convolutional attention  LJSpeech",erogol,1402048,2020-12-07T10:35:10Z,CONTRIBUTOR,True,17345,1060,103,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,53679b706da2bc38510b467289be844f8e6e9d24,glow-tts distributed fix
243,https://api.github.com/repos/mozilla/TTS/pulls/591,591,Migrate to github actions,,Mic92,96200,2020-12-06T05:34:51Z,CONTRIBUTOR,False,41,37,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a21bad679f5266ca12c78c26eae74ea0b0659b73,"specify build dependencies

Reading setup.py will import numpy already,
hence pip has no way to figure out what dependencies are needed."
244,https://api.github.com/repos/mozilla/TTS/pulls/591,591,Migrate to github actions,,Mic92,96200,2020-12-06T05:34:51Z,CONTRIBUTOR,False,41,37,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0b479f4bfad3b4863dfa78c79e0bf5c5859d35e7,migrate to github actions
245,https://api.github.com/repos/mozilla/TTS/pulls/590,590,expand time and currencies,,Mic92,96200,2020-12-05T08:58:01Z,CONTRIBUTOR,False,124,25,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,61f3b72ee25ce5ebfafcc1b5b832508e53d6b89d,Update README.md
246,https://api.github.com/repos/mozilla/TTS/pulls/590,590,expand time and currencies,,Mic92,96200,2020-12-05T08:58:01Z,CONTRIBUTOR,False,124,25,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b5b2a688cf6229cfbecde3de1a4278701a96c6e9,tests/test_text_processing: fix undefined variable
247,https://api.github.com/repos/mozilla/TTS/pulls/590,590,expand time and currencies,,Mic92,96200,2020-12-05T08:58:01Z,CONTRIBUTOR,False,124,25,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4982d46ad31accfc5a24639b747caaf3d1783467,expand more currencies
248,https://api.github.com/repos/mozilla/TTS/pulls/590,590,expand time and currencies,,Mic92,96200,2020-12-05T08:58:01Z,CONTRIBUTOR,False,124,25,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,23a113563c43b205bd33caf083911d9b92bc27fd,cleaners: expand english time
249,https://api.github.com/repos/mozilla/TTS/pulls/590,590,expand time and currencies,,Mic92,96200,2020-12-05T08:58:01Z,CONTRIBUTOR,False,124,25,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e423fb454a3d59528f2399b43f961f310843c1af,add tests for currency/time expansion
250,https://api.github.com/repos/mozilla/TTS/pulls/588,588,inflect negative numbers correctly,fixes https://github.com/mozilla/TTS/issues/587,Mic92,96200,2020-12-04T21:56:13Z,CONTRIBUTOR,False,14,1,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2ee09f257f6846428e2e870120f524dcf938f663,inflect negative numbers correctly
251,https://api.github.com/repos/mozilla/TTS/pulls/586,586,Update wavegrad.py,This should fix issue https://github.com/mozilla/TTS/issues/581,SanjaESC,6319070,2020-12-04T15:44:32Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f42ca2b73fae96d0f6598d7cfecf5c4729c52c1b,"Update wavegrad.py

This should fix the issue https://github.com/mozilla/TTS/issues/581"
252,https://api.github.com/repos/mozilla/TTS/pulls/580,580,Added option for saving raw spectograms,For those beginners (_as me_) who want to test vocoders on raw model spectograms i've added an option to save these easily. Thanks to @SanjaESC and @domcross for providing me the codesnipplets. So all honors to them. I only put the pieces together for this pr.,thorstenMueller,9558265,2020-11-27T14:55:50Z,CONTRIBUTOR,True,18,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,06a389bc08e3e152f5f3562fb6ae0f3a9ebb9c08,Added option for saving raw spectograms
253,https://api.github.com/repos/mozilla/TTS/pulls/573,573,speed up metafile build for voxceleb,avoid string concats in tight loop,houqp,670302,2020-11-15T07:43:54Z,CONTRIBUTOR,True,4,5,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b0b97d636fdd31b07a18c492a00466ce880c6094,speed up metafile build for voxceleb
254,https://api.github.com/repos/mozilla/TTS/pulls/572,572,Introduce github action for CI,"It seemed to me like Travis-CI checks are not working anymore. I'm aware of the new pricing policy they introduced recently and suspected it might be due to that.

The CI last ran somewhere mid-october. 

Since this project is hosted on GitHub, I believe their actions feature might be a good fit for the time being. So I started to port the travis tests to the best of my understanding. I hope that is alright.

You can look at the current state over here: https://github.com/mweinelt/TTS/actions/runs/363907718

---

There is currently the following issue, that was introduced in 39c71ee8a98bcbfea242e6b203556150ee64205b:

```
 ======================================================================
ERROR: Test if all layers are updated in a basic training cycle
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/runner/work/TTS/TTS/tests/test_wavegrad_train.py"", line 36, in test_train_step
    model.compute_noise_level(1000, 1e-6, 1e-2)
TypeError: compute_noise_level() takes 2 positional arguments but 4 were given

----------------------------------------------------------------------
```

I'll happyily rebase once this fix has hit the dev branch, so we can check if this works.
",mweinelt,131599,2020-11-15T02:59:02Z,CONTRIBUTOR,True,64,64,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c57fd7387209d7da3dae754e0aa440e5e9c336ad,"specify build dependencies

Reading setup.py will import numpy already,
hence pip has no way to figure out what dependencies are needed."
255,https://api.github.com/repos/mozilla/TTS/pulls/572,572,Introduce github action for CI,"It seemed to me like Travis-CI checks are not working anymore. I'm aware of the new pricing policy they introduced recently and suspected it might be due to that.

The CI last ran somewhere mid-october. 

Since this project is hosted on GitHub, I believe their actions feature might be a good fit for the time being. So I started to port the travis tests to the best of my understanding. I hope that is alright.

You can look at the current state over here: https://github.com/mweinelt/TTS/actions/runs/363907718

---

There is currently the following issue, that was introduced in 39c71ee8a98bcbfea242e6b203556150ee64205b:

```
 ======================================================================
ERROR: Test if all layers are updated in a basic training cycle
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/runner/work/TTS/TTS/tests/test_wavegrad_train.py"", line 36, in test_train_step
    model.compute_noise_level(1000, 1e-6, 1e-2)
TypeError: compute_noise_level() takes 2 positional arguments but 4 were given

----------------------------------------------------------------------
```

I'll happyily rebase once this fix has hit the dev branch, so we can check if this works.
",mweinelt,131599,2020-11-15T02:59:02Z,CONTRIBUTOR,True,64,64,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,857172ba3fddbc1c6573535ec5f06b259da46ff6,Migrate to github actions for CI tests
256,https://api.github.com/repos/mozilla/TTS/pulls/572,572,Introduce github action for CI,"It seemed to me like Travis-CI checks are not working anymore. I'm aware of the new pricing policy they introduced recently and suspected it might be due to that.

The CI last ran somewhere mid-october. 

Since this project is hosted on GitHub, I believe their actions feature might be a good fit for the time being. So I started to port the travis tests to the best of my understanding. I hope that is alright.

You can look at the current state over here: https://github.com/mweinelt/TTS/actions/runs/363907718

---

There is currently the following issue, that was introduced in 39c71ee8a98bcbfea242e6b203556150ee64205b:

```
 ======================================================================
ERROR: Test if all layers are updated in a basic training cycle
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/runner/work/TTS/TTS/tests/test_wavegrad_train.py"", line 36, in test_train_step
    model.compute_noise_level(1000, 1e-6, 1e-2)
TypeError: compute_noise_level() takes 2 positional arguments but 4 were given

----------------------------------------------------------------------
```

I'll happyily rebase once this fix has hit the dev branch, so we can check if this works.
",mweinelt,131599,2020-11-15T02:59:02Z,CONTRIBUTOR,True,64,64,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,128fd94ab178382314af5f6bb3dc875e1335e409,"Pin numpy<1.20 for continued python3.6 support

Numpy starting with 1.20 has dropped support for Python 3.6."
257,https://api.github.com/repos/mozilla/TTS/pulls/571,571,support loading config in yaml,"when file extension doesn't end in `.yml` or `.yaml`, fallback to custom json parser.

fixes #538 ",houqp,670302,2020-11-14T08:15:00Z,CONTRIBUTOR,True,19,7,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0cc3650ef61e8d304305f6a39e33a2876be9baa1,support loading config in yaml
258,https://api.github.com/repos/mozilla/TTS/pulls/570,570,Bump tensorflow from 2.3.0 to 2.3.1,"Bumps [tensorflow](https://github.com/tensorflow/tensorflow) from 2.3.0 to 2.3.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/tensorflow/tensorflow/releases"">tensorflow's releases</a>.</em></p>
<blockquote>
<h2>TensorFlow 2.3.1</h2>
<h1>Release 2.3.1</h1>
<h2>Bug Fixes and Other Changes</h2>
<ul>
<li>Fixes an undefined behavior causing a segfault in <code>tf.raw_ops.Switch</code> (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15190"">CVE-2020-15190</a>)</li>
<li>Fixes three vulnerabilities in conversion to DLPack format (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15191"">CVE-2020-15191</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15192"">CVE-2020-15192</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15193"">CVE-2020-15193</a>)</li>
<li>Fixes two vulnerabilities in <code>SparseFillEmptyRowsGrad</code> (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15194"">CVE-2020-15194</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15195"">CVE-2020-15195</a>)</li>
<li>Fixes several vulnerabilities in <code>RaggedCountSparseOutput</code> and <code>SparseCountSparseOutput</code> operations (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15196"">CVE-2020-15196</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15197"">CVE-2020-15197</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15198"">CVE-2020-15198</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15199"">CVE-2020-15199</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15200"">CVE-2020-15200</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15201"">CVE-2020-15201</a>)</li>
<li>Fixes an integer truncation vulnerability in code using the work sharder API (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15202"">CVE-2020-15202</a>)</li>
<li>Fixes a format string vulnerability in <code>tf.strings.as_string</code> (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15203"">CVE-2020-15203</a>)</li>
<li>Fixes segfault raised by calling session-only ops in eager mode (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15204"">CVE-2020-15204</a>)</li>
<li>Fixes data leak and potential ASLR violation from <code>tf.raw_ops.StringNGrams</code> (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15205"">CVE-2020-15205</a>)</li>
<li>Fixes segfaults caused by incomplete <code>SavedModel</code> validation (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15206"">CVE-2020-15206</a>)</li>
<li>Fixes a data corruption due to a bug in negative indexing support in TFLite (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15207"">CVE-2020-15207</a>)</li>
<li>Fixes a data corruption due to dimension mismatch in TFLite (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15208"">CVE-2020-15208</a>)</li>
<li>Fixes several vulnerabilities in TFLite saved model format (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15209"">CVE-2020-15209</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15210"">CVE-2020-15210</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15211"">CVE-2020-15211</a>)</li>
<li>Fixes several vulnerabilities in TFLite implementation of segment sum (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15212"">CVE-2020-15212</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15213"">CVE-2020-15213</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15214"">CVE-2020-15214</a>)</li>
<li>Updates <code>sqlite3</code> to <code>3.33.00</code> to handle <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358"">CVE-2020-15358</a>.</li>
<li>Fixes deprecated usage of <code>collections</code> API</li>
<li>Removes <code>scipy</code> dependency from <code>setup.py</code> since TensorFlow does not need it to install the pip package</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md"">tensorflow's changelog</a>.</em></p>
<blockquote>
<h1>Release 2.3.1</h1>
<h2>Bug Fixes and Other Changes</h2>
<ul>
<li>Fixes an undefined behavior causing a segfault in <code>tf.raw_ops.Switch</code>
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15190"">CVE-2020-15190</a>)</li>
<li>Fixes three vulnerabilities in conversion to DLPack format
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15191"">CVE-2020-15191</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15192"">CVE-2020-15192</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15193"">CVE-2020-15193</a>)</li>
<li>Fixes two vulnerabilities in <code>SparseFillEmptyRowsGrad</code>
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15194"">CVE-2020-15194</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15195"">CVE-2020-15195</a>)</li>
<li>Fixes several vulnerabilities in <code>RaggedCountSparseOutput</code> and
<code>SparseCountSparseOutput</code> operations
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15196"">CVE-2020-15196</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15197"">CVE-2020-15197</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15198"">CVE-2020-15198</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15199"">CVE-2020-15199</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15200"">CVE-2020-15200</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15201"">CVE-2020-15201</a>)</li>
<li>Fixes an integer truncation vulnerability in code using the work sharder API
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15202"">CVE-2020-15202</a>)</li>
<li>Fixes a format string vulnerability in <code>tf.strings.as_string</code>
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15203"">CVE-2020-15203</a>)</li>
<li>Fixes segfault raised by calling session-only ops in eager mode
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15204"">CVE-2020-15204</a>)</li>
<li>Fixes data leak and potential ASLR violation from <code>tf.raw_ops.StringNGrams</code>
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15205"">CVE-2020-15205</a>)</li>
<li>Fixes segfaults caused by incomplete <code>SavedModel</code> validation
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15206"">CVE-2020-15206</a>)</li>
<li>Fixes a data corruption due to a bug in negative indexing support in TFLite
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15207"">CVE-2020-15207</a>)</li>
<li>Fixes a data corruption due to dimension mismatch in TFLite
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15208"">CVE-2020-15208</a>)</li>
<li>Fixes several vulnerabilities in TFLite saved model format
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15209"">CVE-2020-15209</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15210"">CVE-2020-15210</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15211"">CVE-2020-15211</a>)</li>
<li>Fixes several vulnerabilities in TFLite implementation of segment sum
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15212"">CVE-2020-15212</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15213"">CVE-2020-15213</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15214"">CVE-2020-15214</a>)</li>
<li>Updates <code>sqlite3</code> to <code>3.33.00</code> to handle
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358"">CVE-2020-15358</a>.</li>
<li>Fixes deprecated usage of <code>collections</code> API</li>
<li>Removes <code>scipy</code> dependency from <code>setup.py</code> since TensorFlow does not need it
to install the pip package</li>
</ul>
<h1>Release 2.2.1</h1>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/fcc4b966f1265f466e82617020af93670141b009""><code>fcc4b96</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/43446"">#43446</a> from tensorflow-jenkins/version-numbers-2.3.1-16251</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/4cf223069a94c78b208e6c829d5f938a0fae7d07""><code>4cf2230</code></a> Update version numbers to 2.3.1</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/eee82247288e52e9b8a5c2badeb65f871b4da4c4""><code>eee8224</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/43441"">#43441</a> from tensorflow-jenkins/relnotes-2.3.1-24672</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/0d41b1dfc97500e1177cb718a0b14b04914df661""><code>0d41b1d</code></a> Update RELEASE.md</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/d99bd631ea9b67ffc39c22b35fbf7deca77ad1f7""><code>d99bd63</code></a> Insert release notes place-fill</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/d71d3ce2520587b752e5d27b2d4a4ba8720e4bd5""><code>d71d3ce</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/43414"">#43414</a> from tensorflow/mihaimaruseac-patch-1-1</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/9c91596d4d24bc07b6d36ae48581a2e7b2584edf""><code>9c91596</code></a> Fix missing import</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/f9f12f61867159120ce6eb08fdbd225d454232b5""><code>f9f12f6</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/43391"">#43391</a> from tensorflow/mihaimaruseac-patch-4</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/3ed271b0b05b4f1dfd5660944c54b5fe8cc3d8dc""><code>3ed271b</code></a> Solve leftover from merge conflict</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/9cf3773b717dfd46b37be2ba8cad4f038a8ff6f7""><code>9cf3773</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/43358"">#43358</a> from tensorflow/mm-patch-r2.3</li>
<li>Additional commits viewable in <a href=""https://github.com/tensorflow/tensorflow/compare/v2.3.0...v2.3.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tensorflow&package-manager=pip&previous-version=2.3.0&new-version=2.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/TTS/network/alerts).

</details>",dependabot[bot],49699333,2020-11-13T18:53:06Z,CONTRIBUTOR,True,2,2,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e33f1fc28c8c5e9130a4dc3f12ed30f4e7b710c0,"Bump tensorflow from 2.3.0 to 2.3.1

Bumps [tensorflow](https://github.com/tensorflow/tensorflow) from 2.3.0 to 2.3.1.
- [Release notes](https://github.com/tensorflow/tensorflow/releases)
- [Changelog](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md)
- [Commits](https://github.com/tensorflow/tensorflow/compare/v2.3.0...v2.3.1)

Signed-off-by: dependabot[bot] <support@github.com>"
259,https://api.github.com/repos/mozilla/TTS/pulls/565,565,requirements.txt: Install correct umap-learn library,"There is a name clash among several umap projects and the wrong umap has
been introduced into requirements.txt.

Ref: https://github.com/koorukuroo/umap/issues/1",mweinelt,131599,2020-11-10T22:28:02Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b0f7b02930bdc2ddd5a4d3c1559ccc50cdfe55bd,"requirements.txt: Install correct umap-learn library

There is a name clash among several umap projects and the wrong umap has
been introduced into requirements.txt.

Ref: https://github.com/koorukuroo/umap/issues/1"
260,https://api.github.com/repos/mozilla/TTS/pulls/559,559,Fix import to grab the encoder model save function,I saw that this was recently changed but I'm not sure if it should have been. This is the correct function given the arguments provided to it in the train loop. Should the arguments be updated to reflect the new model save function or should the import be reverted? I am currently running a model training with the old save function and things appear to work fine.,krzim,44442910,2020-11-02T21:47:40Z,CONTRIBUTOR,True,1,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2202e171c53dde2359e95c7fa82bd1c7686604de,"Fix import to grab the encoder model save function

I saw that this was recently changed but I'm not sure if it should have been. This is the correct function given the arguments provided to it in the train loop."
261,https://api.github.com/repos/mozilla/TTS/pulls/555,555,Fix cython files search path,Fixes #543 - make possible to build from venv when you create venv in root directory of the project,lstolcman,4583553,2020-10-28T17:42:07Z,CONTRIBUTOR,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ce74f5c8eab0122c4663bf82b4f273aef462edba,Fix cython files search path
262,https://api.github.com/repos/mozilla/TTS/pulls/554,554,Bring back deleted notebook,"`PlotUmapLibriTTS.ipynb` was deleted in PR #415 (commit: 3131308baaa33879cde27aaa4ddcb9689252e3e5)

It is used with speaker encoder training https://github.com/mozilla/TTS/wiki/Speaker-Encoder",lstolcman,4583553,2020-10-28T17:31:37Z,CONTRIBUTOR,True,737,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9f41538fc0d3e53d83ea858937dd9a0d7a25b3a4,Bring back deleted notebook
263,https://api.github.com/repos/mozilla/TTS/pulls/553,553,bug fix in the inference with GlowTTS,,Edresson,28763586,2020-10-28T16:27:14Z,CONTRIBUTOR,True,11,8,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f01502a9dbe65eaa5d6b9f796e9673bd08ff929d, bug fix in glowTTS sythesize
264,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5044f295165a801424415a8ffd7baf890aafa417,"Bump tensorflow from 2.3.0 to 2.3.1

Bumps [tensorflow](https://github.com/tensorflow/tensorflow) from 2.3.0 to 2.3.1.
- [Release notes](https://github.com/tensorflow/tensorflow/releases)
- [Changelog](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md)
- [Commits](https://github.com/tensorflow/tensorflow/compare/v2.3.0...v2.3.1)

Signed-off-by: dependabot[bot] <support@github.com>"
265,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f632f59f4000e547a5def0e4029dc3af30da4047,"Merge pull request #528 from mozilla/dependabot/pip/tensorflow-2.3.1

Bump tensorflow from 2.3.0 to 2.3.1"
266,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d6bd3cd8b8981add60fa727dd6385b2f1d99822a,add initial wavernn support
267,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,72bd90b497f4e406b3e93ab4a0e77afa2e890e31,wavernn stuff...
268,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,da60f35c14a10eed418668a88120e610d3bc74de,Merge branch 'master' of https://github.com/mozilla/TTS into wavernn
269,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9a120f28edbb47f771db0b9e48be03a504e895d3,some minor changes to wavernn
270,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,995d84f6d74fa3592fcb7cd5b31f9246155191a8,added feature preprocessing if not set in config
271,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,64adfbf4a59b9bf0aa21fe3effceed332458bf7b,fixing pylint errors
272,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2ca63c013f88caac2444b32fdb1b2e77d001e430,fix no loss masking loss computation
273,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,24d18d20e34c331bc0d3a067de66389c98a9b03c,fix formatting + pylint
274,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b7f9ebd32be758c59649f9ec489bc2bd49840ff4,add check arguments for GlowTTS and multispeaker training bug fix
275,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9270e27cd7df82f5967174da18e0e92967674120,add wavernn tests + name refactoring
276,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6245dd2b93a1c58215fc73c96274ca99c02ccf33,added to device cpu/gpu + formatting
277,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4d5da4b663d7a2210a9fe4965ab942ad7557efb0,fix travis + pylint tests
278,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,07345099ee8ba3b2ca6aa412d53615273177845e,GlowTTS zero-shot TTS Support
279,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fbea058c596e4a0b1d0c21c68438d4ce6d85ae60,add parse speakers function
280,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4a989e3cebf68ef9ae2ab4f675fcfbbeb983288a,compute audio feat on dataload
281,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,80f5e39e56fe862eba0248398d4c755232a70d60,add model params to config
282,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d158ec0806d545d7a053542670e0c02969c89503,fix pylint once again
283,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d9540a5857d79dcfd260c776988cd03ad6d02b2a,add blank token in sequence for encrease glowtts results
284,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,741d278cacb0ce1646468252414c5b87ba887d00,Merge branch 'wavernn' of https://github.com/SanjaESC/TTS into SanjaESC-wavernn
285,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e98215600919b915631c39b079537be18930bf67,small updates
286,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,89e9bfe3a2a5e0cac2180078fa79fa934d8cc4ba,add text processing blank token test
287,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3894d44dc5ad7498394cc0222e1b8035b3ee76c5,update version
288,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,486de1a08933fb4a1caebae4a6bb683d03b6a423,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
289,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5ce04832ce750f029bbcc11076bae9674afa4adb,"Bump tensorflow from 2.3.0 to 2.3.1

Bumps [tensorflow](https://github.com/tensorflow/tensorflow) from 2.3.0 to 2.3.1.
- [Release notes](https://github.com/tensorflow/tensorflow/releases)
- [Changelog](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md)
- [Commits](https://github.com/tensorflow/tensorflow/compare/v2.3.0...v2.3.1)

Signed-off-by: dependabot[bot] <support@github.com>"
290,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6378fa2b075bb9d37220350b7aca2cfb2f74d3b0,add initial wavernn support
291,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9c3c7ce2f8452ee835b2b13162c008278406fe33,wavernn stuff...
292,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e495e03ea11ba570dfef73e5581d84b8090a1672,some minor changes to wavernn
293,https://api.github.com/repos/mozilla/TTS/pulls/551,551,Dev (v0.0.6),"- [x] wavernn integration (by @SanjaESC )  
- [x] wavegrad implementation 
- [x] glow-tts improvements (by @Edresson )
- [x] multi-speaker DDC model with VCTK
- [x] pre-trained Universal Wavegrad. 
",erogol,1402048,2020-10-27T11:21:28Z,CONTRIBUTOR,True,5251,422,72,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,878b7c373ef5e7b590a116d71340b16c7a93fe39,added feature preprocessing if not set in config
294,https://api.github.com/repos/mozilla/TTS/pulls/549,549,Update losses.py,"Seems like in the latest dev merge, this change was reverted. Any specific reason for this?
Without it the problem as stated here https://github.com/mozilla/TTS/issues/473 occurs.",SanjaESC,6319070,2020-10-23T12:15:22Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,47d74ced1c0cc462590a51817bbc31617ce97a30,"Update losses.py

Seems like in the latest dev merge, this change was reverted. Any specific reason for this?
Without it the problem as stated here https://github.com/mozilla/TTS/issues/473 occurs."
295,https://api.github.com/repos/mozilla/TTS/pulls/546,546,Fix readme and config file,"Updated readme and fixed a missing parameter in config.json, which was causing https://github.com/mozilla/TTS/blob/master/TTS/tts/utils/generic_utils.py#L249 to fail.

Closes #544 

@erogol ",ayush-1506,49805996,2020-10-21T08:15:25Z,CONTRIBUTOR,True,5,4,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2a3559f02b617b013e14bd150016d1b9d8f5df39,Fix readme and config file
296,https://api.github.com/repos/mozilla/TTS/pulls/545,545,GlowTTS zeroshot TTS support,Added support for external embeddings in the GlowTTS model and fixed some bugs in the multispeaker training.,Edresson,28763586,2020-10-20T13:15:22Z,CONTRIBUTOR,True,268,135,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b7f9ebd32be758c59649f9ec489bc2bd49840ff4,add check arguments for GlowTTS and multispeaker training bug fix
297,https://api.github.com/repos/mozilla/TTS/pulls/545,545,GlowTTS zeroshot TTS support,Added support for external embeddings in the GlowTTS model and fixed some bugs in the multispeaker training.,Edresson,28763586,2020-10-20T13:15:22Z,CONTRIBUTOR,True,268,135,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,07345099ee8ba3b2ca6aa412d53615273177845e,GlowTTS zero-shot TTS Support
298,https://api.github.com/repos/mozilla/TTS/pulls/545,545,GlowTTS zeroshot TTS support,Added support for external embeddings in the GlowTTS model and fixed some bugs in the multispeaker training.,Edresson,28763586,2020-10-20T13:15:22Z,CONTRIBUTOR,True,268,135,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fbea058c596e4a0b1d0c21c68438d4ce6d85ae60,add parse speakers function
299,https://api.github.com/repos/mozilla/TTS/pulls/545,545,GlowTTS zeroshot TTS support,Added support for external embeddings in the GlowTTS model and fixed some bugs in the multispeaker training.,Edresson,28763586,2020-10-20T13:15:22Z,CONTRIBUTOR,True,268,135,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d9540a5857d79dcfd260c776988cd03ad6d02b2a,add blank token in sequence for encrease glowtts results
300,https://api.github.com/repos/mozilla/TTS/pulls/545,545,GlowTTS zeroshot TTS support,Added support for external embeddings in the GlowTTS model and fixed some bugs in the multispeaker training.,Edresson,28763586,2020-10-20T13:15:22Z,CONTRIBUTOR,True,268,135,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,89e9bfe3a2a5e0cac2180078fa79fa934d8cc4ba,add text processing blank token test
301,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0e43bfa54ff56cab6c87f7d3562199bc745bf698,"Update README.md

update MOS figure"
302,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,acda8a6e338e1838056dab4aa3e82378181b9875,Update README.md
303,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1a87ad82e335a355072d127037463b20d2ec0848,Merge branch 'master' of https://github.com/mozilla/TTS
304,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2f5a08d04716025c936dfc75b6803c038307e65d,Update README.md
305,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,98f15e1154324533fd75de12e2fbd610fc306d04,Update README.md
306,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d6bd3cd8b8981add60fa727dd6385b2f1d99822a,add initial wavernn support
307,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,72bd90b497f4e406b3e93ab4a0e77afa2e890e31,wavernn stuff...
308,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,da60f35c14a10eed418668a88120e610d3bc74de,Merge branch 'master' of https://github.com/mozilla/TTS into wavernn
309,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9a120f28edbb47f771db0b9e48be03a504e895d3,some minor changes to wavernn
310,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,995d84f6d74fa3592fcb7cd5b31f9246155191a8,added feature preprocessing if not set in config
311,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,64adfbf4a59b9bf0aa21fe3effceed332458bf7b,fixing pylint errors
312,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,24d18d20e34c331bc0d3a067de66389c98a9b03c,fix formatting + pylint
313,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9270e27cd7df82f5967174da18e0e92967674120,add wavernn tests + name refactoring
314,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6245dd2b93a1c58215fc73c96274ca99c02ccf33,added to device cpu/gpu + formatting
315,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4d5da4b663d7a2210a9fe4965ab942ad7557efb0,fix travis + pylint tests
316,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4a989e3cebf68ef9ae2ab4f675fcfbbeb983288a,compute audio feat on dataload
317,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,80f5e39e56fe862eba0248398d4c755232a70d60,add model params to config
318,https://api.github.com/repos/mozilla/TTS/pulls/542,542,Initial WaveRNN support,"This should enable native support for the WaveRNN vocoder within this repo.
It is mostly a migration of the external [WaveRNN](https://github.com/erogol/WaveRNN) repo from @erogol.
I've aligned the structure of the training routine with those of the GAN vocoders, so that everything looks uniform.

As stated here https://github.com/mozilla/TTS/issues/458#issuecomment-710856183. I've only done some course testing so far, since I currently lack access to a GPU.
Further testing is welcome.",SanjaESC,6319070,2020-10-19T12:48:29Z,CONTRIBUTOR,True,1694,18,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d158ec0806d545d7a053542670e0c02969c89503,fix pylint once again
319,https://api.github.com/repos/mozilla/TTS/pulls/537,537,fix cython build,"Numpy header dir is not added to include path during builds without this fix.

Due to a bug in cython, cythonize actually doesn't support include_dirs override:
https://github.com/cython/cython/issues/1480.",houqp,670302,2020-10-11T05:57:06Z,CONTRIBUTOR,True,9,3,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,34329a0d2c6e2da2cb1848901ce4217b8fc69b21,"fix cython build

Due to a bug in cython, cythonize actually doesn't support include_dirs override:
https://github.com/cython/cython/issues/1480"
320,https://api.github.com/repos/mozilla/TTS/pulls/533,533,add Speaker Conditional GST support,Add support for Speaker Conditional Global Style Tokens (SC-GSTs). This allows the MultiSpeaker model to work with GST reference samples and speaker embedding from different speakers.,Edresson,28763586,2020-09-29T19:42:16Z,CONTRIBUTOR,True,192,26,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,99d5a0ac0749f7daa0c09a8b62d33efe812eaff6,add Speaker Conditional GST support
321,https://api.github.com/repos/mozilla/TTS/pulls/533,533,add Speaker Conditional GST support,Add support for Speaker Conditional Global Style Tokens (SC-GSTs). This allows the MultiSpeaker model to work with GST reference samples and speaker embedding from different speakers.,Edresson,28763586,2020-09-29T19:42:16Z,CONTRIBUTOR,True,192,26,11,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c1fff5b5569c5715433b0ff7d7ca2a4179a19961,add unit tests for SC-GST
322,https://api.github.com/repos/mozilla/TTS/pulls/531,531,Adding support for french cleaners,The goal of this PR is to add support for french cleaners and make it easier for other languages to handle abbreviations.,WeberJulian,17219561,2020-09-29T13:46:11Z,CONTRIBUTOR,True,81,27,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b2817e9e9372b4d8ffd177fa0a1033378d9b763b,Adding french cleaners
323,https://api.github.com/repos/mozilla/TTS/pulls/531,531,Adding support for french cleaners,The goal of this PR is to add support for french cleaners and make it easier for other languages to handle abbreviations.,WeberJulian,17219561,2020-09-29T13:46:11Z,CONTRIBUTOR,True,81,27,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,da134eeee4c2b55e052a347434a09de8b633c07e,Subjective improvements
324,https://api.github.com/repos/mozilla/TTS/pulls/531,531,Adding support for french cleaners,The goal of this PR is to add support for french cleaners and make it easier for other languages to handle abbreviations.,WeberJulian,17219561,2020-09-29T13:46:11Z,CONTRIBUTOR,True,81,27,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,54b4031391acce2e1c519e163aa9e8731977c07c,Merge remote-tracking branch 'origin/dev' into french-cleaners
325,https://api.github.com/repos/mozilla/TTS/pulls/531,531,Adding support for french cleaners,The goal of this PR is to add support for french cleaners and make it easier for other languages to handle abbreviations.,WeberJulian,17219561,2020-09-29T13:46:11Z,CONTRIBUTOR,True,81,27,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ea7c2e15c00e06afc5a949a4cfce8adbb9b4332a,Adding french abbreviations
326,https://api.github.com/repos/mozilla/TTS/pulls/530,530,fix: split_dataset,"Fix: `split_dataset`, this reduces runtime from minutes to seconds on large datasets such as common_voice",mueller91,9288660,2020-09-28T10:11:10Z,CONTRIBUTOR,True,6,4,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,227b9c886429f3f8f8074f5377646cd5bbc58ba8,"fix: split_dataset() runtime reduced from O(N * |items|) to O(N) where N is the size of the eval split (max 500)
I notice a significant speedup on the initial loading of large datasets such as common voice (from minutes to seconds)"
327,https://api.github.com/repos/mozilla/TTS/pulls/528,528,Bump tensorflow from 2.3.0 to 2.3.1,"Bumps [tensorflow](https://github.com/tensorflow/tensorflow) from 2.3.0 to 2.3.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/tensorflow/tensorflow/releases"">tensorflow's releases</a>.</em></p>
<blockquote>
<h2>TensorFlow 2.3.1</h2>
<h1>Release 2.3.1</h1>
<h2>Bug Fixes and Other Changes</h2>
<ul>
<li>Fixes an undefined behavior causing a segfault in <code>tf.raw_ops.Switch</code> (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15190"">CVE-2020-15190</a>)</li>
<li>Fixes three vulnerabilities in conversion to DLPack format (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15191"">CVE-2020-15191</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15192"">CVE-2020-15192</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15193"">CVE-2020-15193</a>)</li>
<li>Fixes two vulnerabilities in <code>SparseFillEmptyRowsGrad</code> (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15194"">CVE-2020-15194</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15195"">CVE-2020-15195</a>)</li>
<li>Fixes several vulnerabilities in <code>RaggedCountSparseOutput</code> and <code>SparseCountSparseOutput</code> operations (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15196"">CVE-2020-15196</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15197"">CVE-2020-15197</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15198"">CVE-2020-15198</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15199"">CVE-2020-15199</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15200"">CVE-2020-15200</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15201"">CVE-2020-15201</a>)</li>
<li>Fixes an integer truncation vulnerability in code using the work sharder API (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15202"">CVE-2020-15202</a>)</li>
<li>Fixes a format string vulnerability in <code>tf.strings.as_string</code> (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15203"">CVE-2020-15203</a>)</li>
<li>Fixes segfault raised by calling session-only ops in eager mode (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15204"">CVE-2020-15204</a>)</li>
<li>Fixes data leak and potential ASLR violation from <code>tf.raw_ops.StringNGrams</code> (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15205"">CVE-2020-15205</a>)</li>
<li>Fixes segfaults caused by incomplete <code>SavedModel</code> validation (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15206"">CVE-2020-15206</a>)</li>
<li>Fixes a data corruption due to a bug in negative indexing support in TFLite (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15207"">CVE-2020-15207</a>)</li>
<li>Fixes a data corruption due to dimension mismatch in TFLite (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15208"">CVE-2020-15208</a>)</li>
<li>Fixes several vulnerabilities in TFLite saved model format (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15209"">CVE-2020-15209</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15210"">CVE-2020-15210</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15211"">CVE-2020-15211</a>)</li>
<li>Fixes several vulnerabilities in TFLite implementation of segment sum (<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15212"">CVE-2020-15212</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15213"">CVE-2020-15213</a>, <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15214"">CVE-2020-15214</a>)</li>
<li>Updates <code>sqlite3</code> to <code>3.33.00</code> to handle <a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358"">CVE-2020-15358</a>.</li>
<li>Fixes deprecated usage of <code>collections</code> API</li>
<li>Removes <code>scipy</code> dependency from <code>setup.py</code> since TensorFlow does not need it to install the pip package</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md"">tensorflow's changelog</a>.</em></p>
<blockquote>
<h1>Release 2.3.1</h1>
<h2>Bug Fixes and Other Changes</h2>
<ul>
<li>Fixes an undefined behavior causing a segfault in <code>tf.raw_ops.Switch</code>
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15190"">CVE-2020-15190</a>)</li>
<li>Fixes three vulnerabilities in conversion to DLPack format
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15191"">CVE-2020-15191</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15192"">CVE-2020-15192</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15193"">CVE-2020-15193</a>)</li>
<li>Fixes two vulnerabilities in <code>SparseFillEmptyRowsGrad</code>
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15194"">CVE-2020-15194</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15195"">CVE-2020-15195</a>)</li>
<li>Fixes several vulnerabilities in <code>RaggedCountSparseOutput</code> and
<code>SparseCountSparseOutput</code> operations
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15196"">CVE-2020-15196</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15197"">CVE-2020-15197</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15198"">CVE-2020-15198</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15199"">CVE-2020-15199</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15200"">CVE-2020-15200</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15201"">CVE-2020-15201</a>)</li>
<li>Fixes an integer truncation vulnerability in code using the work sharder API
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15202"">CVE-2020-15202</a>)</li>
<li>Fixes a format string vulnerability in <code>tf.strings.as_string</code>
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15203"">CVE-2020-15203</a>)</li>
<li>Fixes segfault raised by calling session-only ops in eager mode
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15204"">CVE-2020-15204</a>)</li>
<li>Fixes data leak and potential ASLR violation from <code>tf.raw_ops.StringNGrams</code>
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15205"">CVE-2020-15205</a>)</li>
<li>Fixes segfaults caused by incomplete <code>SavedModel</code> validation
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15206"">CVE-2020-15206</a>)</li>
<li>Fixes a data corruption due to a bug in negative indexing support in TFLite
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15207"">CVE-2020-15207</a>)</li>
<li>Fixes a data corruption due to dimension mismatch in TFLite
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15208"">CVE-2020-15208</a>)</li>
<li>Fixes several vulnerabilities in TFLite saved model format
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15209"">CVE-2020-15209</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15210"">CVE-2020-15210</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15211"">CVE-2020-15211</a>)</li>
<li>Fixes several vulnerabilities in TFLite implementation of segment sum
(<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15212"">CVE-2020-15212</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15213"">CVE-2020-15213</a>,
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15214"">CVE-2020-15214</a>)</li>
<li>Updates <code>sqlite3</code> to <code>3.33.00</code> to handle
<a href=""https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-15358"">CVE-2020-15358</a>.</li>
<li>Fixes deprecated usage of <code>collections</code> API</li>
<li>Removes <code>scipy</code> dependency from <code>setup.py</code> since TensorFlow does not need it
to install the pip package</li>
</ul>
<h1>Release 2.2.1</h1>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/fcc4b966f1265f466e82617020af93670141b009""><code>fcc4b96</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/43446"">#43446</a> from tensorflow-jenkins/version-numbers-2.3.1-16251</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/4cf223069a94c78b208e6c829d5f938a0fae7d07""><code>4cf2230</code></a> Update version numbers to 2.3.1</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/eee82247288e52e9b8a5c2badeb65f871b4da4c4""><code>eee8224</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/43441"">#43441</a> from tensorflow-jenkins/relnotes-2.3.1-24672</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/0d41b1dfc97500e1177cb718a0b14b04914df661""><code>0d41b1d</code></a> Update RELEASE.md</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/d99bd631ea9b67ffc39c22b35fbf7deca77ad1f7""><code>d99bd63</code></a> Insert release notes place-fill</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/d71d3ce2520587b752e5d27b2d4a4ba8720e4bd5""><code>d71d3ce</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/43414"">#43414</a> from tensorflow/mihaimaruseac-patch-1-1</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/9c91596d4d24bc07b6d36ae48581a2e7b2584edf""><code>9c91596</code></a> Fix missing import</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/f9f12f61867159120ce6eb08fdbd225d454232b5""><code>f9f12f6</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/43391"">#43391</a> from tensorflow/mihaimaruseac-patch-4</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/3ed271b0b05b4f1dfd5660944c54b5fe8cc3d8dc""><code>3ed271b</code></a> Solve leftover from merge conflict</li>
<li><a href=""https://github.com/tensorflow/tensorflow/commit/9cf3773b717dfd46b37be2ba8cad4f038a8ff6f7""><code>9cf3773</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/43358"">#43358</a> from tensorflow/mm-patch-r2.3</li>
<li>Additional commits viewable in <a href=""https://github.com/tensorflow/tensorflow/compare/v2.3.0...v2.3.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tensorflow&package-manager=pip&previous-version=2.3.0&new-version=2.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/TTS/network/alerts).

</details>",dependabot[bot],49699333,2020-09-25T19:19:15Z,CONTRIBUTOR,True,2,2,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5044f295165a801424415a8ffd7baf890aafa417,"Bump tensorflow from 2.3.0 to 2.3.1

Bumps [tensorflow](https://github.com/tensorflow/tensorflow) from 2.3.0 to 2.3.1.
- [Release notes](https://github.com/tensorflow/tensorflow/releases)
- [Changelog](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md)
- [Commits](https://github.com/tensorflow/tensorflow/compare/v2.3.0...v2.3.1)

Signed-off-by: dependabot[bot] <support@github.com>"
328,https://api.github.com/repos/mozilla/TTS/pulls/527,527,fix: fixing the RenamingUnpickler fix,,WeberJulian,17219561,2020-09-22T15:38:09Z,CONTRIBUTOR,True,1,3,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3c212be5a8272be3fc1f6361faea8e257ea9df22,fix: fixing the RenamingUnpickler fix
329,https://api.github.com/repos/mozilla/TTS/pulls/526,526,Fix: Check storage params only for speaker encoder,"I just noticed that my previous PR breaks the training of the TTS model:
For the Speaker Encoder, i use the new 'storage' parameter group; but the TTS model config does not have this, so the check has to be made conditional.",mueller91,9288660,2020-09-22T08:43:13Z,CONTRIBUTOR,True,218,10,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7029452228edc6731013e0afcdd5a2f289d978df,fix: make speaker encoder's storage parameters non-restriced
330,https://api.github.com/repos/mozilla/TTS/pulls/526,526,Fix: Check storage params only for speaker encoder,"I just noticed that my previous PR breaks the training of the TTS model:
For the Speaker Encoder, i use the new 'storage' parameter group; but the TTS model config does not have this, so the check has to be made conditional.",mueller91,9288660,2020-09-22T08:43:13Z,CONTRIBUTOR,True,218,10,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0ea7f4e2bd9a90ce9f5724915ef5c774d7a6a655,fix: make speaker encoder's storage parameters non-restriced
331,https://api.github.com/repos/mozilla/TTS/pulls/526,526,Fix: Check storage params only for speaker encoder,"I just noticed that my previous PR breaks the training of the TTS model:
For the Speaker Encoder, i use the new 'storage' parameter group; but the TTS model config does not have this, so the check has to be made conditional.",mueller91,9288660,2020-09-22T08:43:13Z,CONTRIBUTOR,True,218,10,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,df4caec4b773377a1285e3133bd24be0ba0b11b9,add: check_config for speaker_encoder
332,https://api.github.com/repos/mozilla/TTS/pulls/526,526,Fix: Check storage params only for speaker encoder,"I just noticed that my previous PR breaks the training of the TTS model:
For the Speaker Encoder, i use the new 'storage' parameter group; but the TTS model config does not have this, so the check has to be made conditional.",mueller91,9288660,2020-09-22T08:43:13Z,CONTRIBUTOR,True,218,10,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1fe5eb054f550d09f1652380ddf98e3ade9c58c4,"Merge branch 'dev' of https://github.com/mozilla/TTS into dev

 Conflicts:
	TTS/bin/train_encoder.py
	requirements.txt"
333,https://api.github.com/repos/mozilla/TTS/pulls/526,526,Fix: Check storage params only for speaker encoder,"I just noticed that my previous PR breaks the training of the TTS model:
For the Speaker Encoder, i use the new 'storage' parameter group; but the TTS model config does not have this, so the check has to be made conditional.",mueller91,9288660,2020-09-22T08:43:13Z,CONTRIBUTOR,True,218,10,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cfeeef7a7f8ad828e4e4ff34081e61103bee3d65,"fix: broken imports and missing files after merging in latest commits from mozilla/dev into mueller91/dev.
speaker_encoder's config.json and visuals.py are missing in the current dev branch of MozillaTTS, and some imports are broken."
334,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f9001a4bdd8a169da8b4eefd481461f370def8f9,refactor and fix compat issues for speaker encoder
335,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f511521e010835fb601889be2defdd6d67d25efc,install cython deps
336,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,95de34e8efb64ec6ca250d9964b5ff79563aa6eb,find cython files insetup
337,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,89d15bf118078c79b22e422d6e9228c3bdc5100e,merge glow-tts after rebranding
338,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d5c6d608848fab1643605a635cac28ab0cd930d7,synthesis update for glow tts
339,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,673ba74a802a00170ec057fbdd260863601fcf95,glow tts training and inference fixes
340,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1dea2c903419f8c2a82521a3913089e7c65c3e9f,faster sequence masking
341,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,43771a3a5c24bceb83e74ccf70a38c19eb739bae,remove redundant arguments
342,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,383c5f71854c5695f1ea6fc956f6dc4e03a6affa,add glow-tts model and layers
343,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,77c577ddab6cc803c9dbb4a58be003ffab4dfaf3,don't use +=
344,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,09ad6a09b0f52d2fff6c6ab11d796fb05a244c20,remove debug code
345,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,14356d32501beeb0e1a0a6713b88f3f936cf3292,glow-tts with relative pos encoding
346,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1b238f04b2c7b018adb9699528d1f0c9353ab4b0,add gated conv encoder to glow-tts
347,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a012537908ce69c8b978a5755d687e8a9c15adaa,remove breakpoint
348,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1c1984d25b150dd703746372c55d0226a5840d1b,comments update
349,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0ffe91b21dbf04ca9e6b2da2e54455eeabdf9ce8,remove breakpoint()
350,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,15e6ab3912f3b410e3f37dad25c265e15c30d14f,glow-tts module renaming updates
351,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,72b8ac0ff64c87d3193335480af9d21771ad1e90,remove redundant arguments
352,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,498a3ea36fdb51870f859ed6c2cd908f1f04cd44,fix condition check
353,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,45fbc0d0038e9632a05397e4028e121d0185ae7a,convolution encoder with GLU and res connections
354,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,53523eebbe1238ccbad2c94e36360857649ee9c2,layer norm before GLU
355,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7c2c4d6f27bbcd5d150c6109a5d92df6e486caf2,pass x_mask to layer norm
356,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f1a75468c260cb2efc5cce7683771ba631eafcdc,fix arguments
357,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,60ce86211392405f2a8e8a575ea5ad80cb7d0107,use difflib for string matching
358,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e732db76f12636b789d616de62fc78a5bb64b4a2,"Merge pull request #513 from maxbachmann/master

use difflib for string matching"
359,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d733b902552295be41b1f88c8343b5e7b4ff8a9b,Improve runtime of __parse_items() from O(|speakers|*|items|) to O(|items|)
360,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c909ca3855b28e0d4a6b90bf9071c746dfcec89b,Improve runtime of __parse_items() from O(|speakers|*|items|) to O(|items|)
361,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,95d2906307b2a3c9d8cce033b11f208da769a461,"add: Mozilla Commonvoice, VoxCeleb1+2, LibriTTS to Speaker Encoder Training"
362,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3660c57f1ea7a1fc519ae528c52b7ec3b437b168,"time seperable convolution encoder, huber loss for duration predictor"
363,https://api.github.com/repos/mozilla/TTS/pulls/525,525,Dev (WIP) v0.0.5,"- [X] Initial Glow-TTS implementation
- [X] Universal FullBand-MelGAN vocoder.
- [X] New version Multi-Speaker model. (by @Edresson )
- [X] Improvements for Speaker Encoder. (by @mueller91)
- [x] Setting Tacotron losses weights from config.json.
- [x] Differential Spectral Loss 
- [x] French text cleaner. (by @WeberJulian)
- [x] Spanish model release. [Details](https://github.com/mozilla/TTS/issues/536).
- [x] French model release.",erogol,1402048,2020-09-22T01:59:09Z,CONTRIBUTOR,True,4193,1126,69,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1511076fde3e27a493c0d505ec7c611af4f01b97,"add: Configurable encoder dataset storage to reduce disk I/O
add: Averaged time for data loader to console and Tensorboard output"
364,https://api.github.com/repos/mozilla/TTS/pulls/519,519,Speaker Encoder: New Datasets + DataLoader optimized,see https://github.com/mozilla/TTS/issues/512,mueller91,9288660,2020-09-17T17:46:45Z,CONTRIBUTOR,True,227,74,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d733b902552295be41b1f88c8343b5e7b4ff8a9b,Improve runtime of __parse_items() from O(|speakers|*|items|) to O(|items|)
365,https://api.github.com/repos/mozilla/TTS/pulls/519,519,Speaker Encoder: New Datasets + DataLoader optimized,see https://github.com/mozilla/TTS/issues/512,mueller91,9288660,2020-09-17T17:46:45Z,CONTRIBUTOR,True,227,74,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c909ca3855b28e0d4a6b90bf9071c746dfcec89b,Improve runtime of __parse_items() from O(|speakers|*|items|) to O(|items|)
366,https://api.github.com/repos/mozilla/TTS/pulls/519,519,Speaker Encoder: New Datasets + DataLoader optimized,see https://github.com/mozilla/TTS/issues/512,mueller91,9288660,2020-09-17T17:46:45Z,CONTRIBUTOR,True,227,74,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,95d2906307b2a3c9d8cce033b11f208da769a461,"add: Mozilla Commonvoice, VoxCeleb1+2, LibriTTS to Speaker Encoder Training"
367,https://api.github.com/repos/mozilla/TTS/pulls/519,519,Speaker Encoder: New Datasets + DataLoader optimized,see https://github.com/mozilla/TTS/issues/512,mueller91,9288660,2020-09-17T17:46:45Z,CONTRIBUTOR,True,227,74,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1511076fde3e27a493c0d505ec7c611af4f01b97,"add: Configurable encoder dataset storage to reduce disk I/O
add: Averaged time for data loader to console and Tensorboard output"
368,https://api.github.com/repos/mozilla/TTS/pulls/519,519,Speaker Encoder: New Datasets + DataLoader optimized,see https://github.com/mozilla/TTS/issues/512,mueller91,9288660,2020-09-17T17:46:45Z,CONTRIBUTOR,True,227,74,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e36a3067e4af08f6990532140e910df911638a88,"add: save wavs instead feats to storage.
This is done in order to mitigate staleness when caching and loading from data storage"
369,https://api.github.com/repos/mozilla/TTS/pulls/519,519,Speaker Encoder: New Datasets + DataLoader optimized,see https://github.com/mozilla/TTS/issues/512,mueller91,9288660,2020-09-17T17:46:45Z,CONTRIBUTOR,True,227,74,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a273b1a2102c5928c7e12da233f2ecd86dc8719a,add: add random noise to dataset
370,https://api.github.com/repos/mozilla/TTS/pulls/519,519,Speaker Encoder: New Datasets + DataLoader optimized,see https://github.com/mozilla/TTS/issues/512,mueller91,9288660,2020-09-17T17:46:45Z,CONTRIBUTOR,True,227,74,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6b0621c794fb686c87b7268e3141147072c3058f,cleanup
371,https://api.github.com/repos/mozilla/TTS/pulls/519,519,Speaker Encoder: New Datasets + DataLoader optimized,see https://github.com/mozilla/TTS/issues/512,mueller91,9288660,2020-09-17T17:46:45Z,CONTRIBUTOR,True,227,74,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,45b3c3d1b039d0e3a34ade3df7b4e1c7fc145cf5,"fix: Update common_voice.tsv and test_preprocessors.py to current .tsv format
(common_voice.tsv is the first 6 lines of the dev.tsv)"
372,https://api.github.com/repos/mozilla/TTS/pulls/519,519,Speaker Encoder: New Datasets + DataLoader optimized,see https://github.com/mozilla/TTS/issues/512,mueller91,9288660,2020-09-17T17:46:45Z,CONTRIBUTOR,True,227,74,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9b4aac94a824898bbec135b930f954914f3a19c1,fix: linter issues
373,https://api.github.com/repos/mozilla/TTS/pulls/517,517,Feature/server,"TTS server enhancements:
- support for configuration file
- simple caching mechanism",domcross,39655102,2020-09-16T18:07:19Z,NONE,False,107,49,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ac14c310d7bc9da36ad8659c84690f25f813e533,"Merge pull request #7 from mozilla/dev

update dev"
374,https://api.github.com/repos/mozilla/TTS/pulls/517,517,Feature/server,"TTS server enhancements:
- support for configuration file
- simple caching mechanism",domcross,39655102,2020-09-16T18:07:19Z,NONE,False,107,49,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6c1364996e5e41fdebcaf556877aff12cdc977d4,TTS server: config and cache
375,https://api.github.com/repos/mozilla/TTS/pulls/517,517,Feature/server,"TTS server enhancements:
- support for configuration file
- simple caching mechanism",domcross,39655102,2020-09-16T18:07:19Z,NONE,False,107,49,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4a67b8162fa786f8a03dde5c9399baf7b25a5126,fix travis CI failures
376,https://api.github.com/repos/mozilla/TTS/pulls/517,517,Feature/server,"TTS server enhancements:
- support for configuration file
- simple caching mechanism",domcross,39655102,2020-09-16T18:07:19Z,NONE,False,107,49,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,46a4a269180826a4759c5084ac55ab0391131de9,Feature/server
377,https://api.github.com/repos/mozilla/TTS/pulls/517,517,Feature/server,"TTS server enhancements:
- support for configuration file
- simple caching mechanism",domcross,39655102,2020-09-16T18:07:19Z,NONE,False,107,49,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,12dc4e62b224d32b836c6e58bfb5b926e6799a46,fixes for Travis CI errors
378,https://api.github.com/repos/mozilla/TTS/pulls/517,517,Feature/server,"TTS server enhancements:
- support for configuration file
- simple caching mechanism",domcross,39655102,2020-09-16T18:07:19Z,NONE,False,107,49,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,28d0dae4df00be32a12591f4522f6f823b2cef75,fix for Travis CI failure
379,https://api.github.com/repos/mozilla/TTS/pulls/513,513,use difflib for string matching,"When using the slower version of FuzzyWuzzy it is using difflib internally, so there is not really a need to add a GPL licensed dependency for this. (When better performance is required [rapidfuzz](https://github.com/maxbachmann/rapidfuzz) is a faster alternative to Fuzzywuzzy, thats MIT Licensed aswell)",maxbachmann,44199644,2020-09-14T22:24:30Z,CONTRIBUTOR,True,4,5,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,60ce86211392405f2a8e8a575ea5ad80cb7d0107,use difflib for string matching
380,https://api.github.com/repos/mozilla/TTS/pulls/507,507,Add a language_switch='remove-flags' argument when calling phonemize,"Hi

I'm trying out the Japanese voice training, referring to [TTS_recipes](https://github.com/erogol/TTS_recipes/blob/master/Thorsten_DE/DoubleDecoderConsistency/train_model.sh).

Along the way, I realized that the phonemize's language_switch defaults to ```keep-flags```, but I just think that data containing the flags can be noisy.
Would it matter if I modified it to add ```remove-flags``` as shown below?

sample:
```
import phonemizer
from phonemizer.phonemize import phonemize
seperator = phonemizer.separator.Separator(' |', '', '|')

# AS IS
ph = phonemize('こんにちは. OK.', separator=seperator, strip=False, njobs=1, backend='espeak', language='ja', preserve_punctuation=True)
print(""こんにちは. OK. (keep-flags)\t"" + ph)

# TO BE
ph = phonemize('こんにちは. OK.', separator=seperator, strip=False, njobs=1, backend='espeak', language='ja', preserve_punctuation=True, language_switch='remove-flags')
print(""こんにちは. OK. (remove-flags)\t"" + ph)
```

result:
```
こんにちは. OK. (keep-flags)	k|o̞|n|n|i|tɕ|i|h|ä| |. |(en)|əʊ| ||k|eɪ|(ja)| |.
こんにちは. OK. (remove-flags)	k|o̞|n|n|i|tɕ|i|h|ä| |. ||əʊ| ||k|eɪ|| |.
```",tset-tset-tset,47290160,2020-08-31T16:38:05Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4f3917b9a673a4039e577a8098f545978df5ea2f,"Add a language_switch argument when calling phonemize

The language_switch defaults to keep-flags, but the result is inappropriate."
381,https://api.github.com/repos/mozilla/TTS/pulls/499,499,convert spec and wav to float32 in compute style gst,,Edresson,28763586,2020-08-14T11:17:14Z,CONTRIBUTOR,False,1,3,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1f6419550b64ecaeffbc7f3d9a94735312b12cd2,convert to float32 in compute style gst
382,https://api.github.com/repos/mozilla/TTS/pulls/498,498,Missing speaker_mapping argument causes training to break,Closes #497 ,thllwg,31413490,2020-08-14T09:13:40Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c90fce8d8c98fc58d9ab329a2ca95bc2539d4061,Fix for #497
383,https://api.github.com/repos/mozilla/TTS/pulls/498,498,Missing speaker_mapping argument causes training to break,Closes #497 ,thllwg,31413490,2020-08-14T09:13:40Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e07ff8abe8f66e60b07f864f85d08e488d8a988a,remove empty space
384,https://api.github.com/repos/mozilla/TTS/pulls/496,496,Update train_tts.py,"align style_input with the new config key ""gst_style_input""",SanjaESC,6319070,2020-08-14T07:39:03Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2a2a0864c15ba7e7369d07a300a0cc56302ee42e,"Update train_tts.py

align style_input with the new config key ""gst_style_input"""
385,https://api.github.com/repos/mozilla/TTS/pulls/494,494,Fix: Imports in Speaker Encoder,,thllwg,31413490,2020-08-13T07:58:52Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b71f31eae4f74b6a426861f8085d73f2eb1c063a,Added support for Tacotron2 GST + abbility to condition style input with wav or tokens
386,https://api.github.com/repos/mozilla/TTS/pulls/494,494,Fix: Imports in Speaker Encoder,,thllwg,31413490,2020-08-13T07:58:52Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,998f33a104652a2253e570b9de4431d55fb94511,No need to query every token when none were passed
387,https://api.github.com/repos/mozilla/TTS/pulls/494,494,Fix: Imports in Speaker Encoder,,thllwg,31413490,2020-08-13T07:58:52Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2a840222dac441e199c6a4219fe341b996e3a9bc,fix fft_size key error
388,https://api.github.com/repos/mozilla/TTS/pulls/494,494,Fix: Imports in Speaker Encoder,,thllwg,31413490,2020-08-13T07:58:52Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,564fc0aab456aef569b04f68e08d636c25dcfd34,pylint
389,https://api.github.com/repos/mozilla/TTS/pulls/494,494,Fix: Imports in Speaker Encoder,,thllwg,31413490,2020-08-13T07:58:52Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6d3ddae64e16933c3f2a26db928676afed41d550,tacotrongst test + test fixes
390,https://api.github.com/repos/mozilla/TTS/pulls/494,494,Fix: Imports in Speaker Encoder,,thllwg,31413490,2020-08-13T07:58:52Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,69367bd2aeca0723b0f23196be5c4c052bdb8b82,override compute_gst in tacotron2 model
391,https://api.github.com/repos/mozilla/TTS/pulls/494,494,Fix: Imports in Speaker Encoder,,thllwg,31413490,2020-08-13T07:58:52Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,18007e389d5d015dc1ce86fbebb9958cfca5883d,small gst config change
392,https://api.github.com/repos/mozilla/TTS/pulls/494,494,Fix: Imports in Speaker Encoder,,thllwg,31413490,2020-08-13T07:58:52Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c865dd86bc1c99264f37a1d913e1e413a538ea87,update comment
393,https://api.github.com/repos/mozilla/TTS/pulls/494,494,Fix: Imports in Speaker Encoder,,thllwg,31413490,2020-08-13T07:58:52Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,63401797f6b38207673025ccccc61a4fdffd68b7,Merge remote-tracking branch 'TTS/dev' into dev
394,https://api.github.com/repos/mozilla/TTS/pulls/494,494,Fix: Imports in Speaker Encoder,,thllwg,31413490,2020-08-13T07:58:52Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8b4eb256f67ebb927532ff15e290cd09b5c446ba,Merge remote-tracking branch 'TTS/dev' into dev
395,https://api.github.com/repos/mozilla/TTS/pulls/494,494,Fix: Imports in Speaker Encoder,,thllwg,31413490,2020-08-13T07:58:52Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3efea6e827133f5b85e3c7ec750661377d7def3b,Import fix
396,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b96e74dd4906df02a4fba23519eb947491f96716,add multi-speaker arguments to the model def
397,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8d0d4919fdce201b138deb774ef5aec5cd60d04e,No need to query every token when none were passed
398,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,bdf69446653fe84e6fd69fb91c2bf99adfd7efff,fix fft_size key error
399,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,eb51d5409af0b70f48cfb817241159d691fd81d6,pylint
400,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e206ff8a28f28beed5b44be363025f5cdd4ecd87,override compute_gst in tacotron2 model
401,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b0c4a77aea67b0ea93a4c2419f2e2c4dba518577,small gst config change
402,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,571f5761c950008f343c59282455ba1c5fc292e6,update comment
403,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,93a9cc4683316eafbe6d9a3e951bd13938527fec,add support fot VCTK and BRSpeech dataset
404,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b7504527828eb3e2377b932fe6dd5bcf1aa50a58,add Portuguese Cleaner
405,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e265810e8c430be60e3775a41fff4de70e4ecb1e,bugfix in DDC now DDC work on Tacotron1
406,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8a1c113df6403b0aae6d951fec8624643953e018,add External Embedding per sample instead of nn.Embedding
407,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1d73566e4e2fe9a4f5e799b80f8506a0f92768e3,bugfix in GST
408,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7c12e94ee4c922c79397b2abd496b5103f8cb83d,fix Lint check
409,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,def7e49f5986ed8955a0befb3daddecb0bdb4392,travis unit tests fix and add Tacotron and Tacotron 2 GST and MultiSpeaker Tests
410,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6e7f33c798ce5277916efe6f0047d6ac20db48cb,add support for synthesize using variable size external embedding and add bugfix in scipy.io import
411,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5c752799aea6b04c5c98a773a44bb971b95fccb5,linter update
412,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fe081d4f7c5078aef1df677680f10e79f18d6dfc,fixing rebase issues
413,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,84b7ab6ee67a214fdac26458806886c319d430ed,Added support for Tacotron2 GST + abbility to condition style input with wav or tokens
414,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c2d8a338a1254faade08a5b17645f8fa83d0b24c,No need to query every token when none were passed
415,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,447176258c5a91518e9a76858b6e8bb1f3dcc262,fix fft_size key error
416,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,89918c6e5351506395fad0545ca5af1cfda08d59,pylint
417,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,77bfb881d74e753e25e2b40f8fa389620d169eca,tacotrongst test + test fixes
418,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1436206224630253c42c153a00e20c7067eb7573,override compute_gst in tacotron2 model
419,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c4828b2b9e94fa70e5f8097aae405077fbb24aca,small gst config change
420,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,70c665b9c4c3716059b1bb774f93f775771eead4,add support fot VCTK and BRSpeech dataset
421,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,be77e24a39dcc65c842096d9c289b4091811ddcf,bugfix in DDC now DDC work on Tacotron1
422,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,89d338358e5c698876bb5c4a3ffeace98b98c0e4,add External Embedding per sample instead of nn.Embedding
423,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a2ee48c28e6c4cf9d00063218154e3c3cd2747a4,bugfix in GST
424,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f91b9eeda1ab104c8ba6888c2599d7f0fa2e3a35,fix Lint check
425,https://api.github.com/repos/mozilla/TTS/pulls/489,489,Multi speaker,,erogol,1402048,2020-08-05T17:41:27Z,CONTRIBUTOR,True,28771,316,35,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,496a4be3e35e127b6df09033ff3b57a0a00c970e,add support for synthesize using variable size external embedding and add bugfix in scipy.io import
426,https://api.github.com/repos/mozilla/TTS/pulls/482,482,Update to PhonemeCoverage.ipynb,Use multiprocessing for phoneme processing,SanjaESC,6319070,2020-08-03T14:57:48Z,CONTRIBUTOR,True,39,19,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,33e9a3a8d6396b52232f1f13a03b35b2b318d2c7,"Update PhonemeCoverage.ipynb

Use from multiprocessing for phoneme processing"
427,https://api.github.com/repos/mozilla/TTS/pulls/482,482,Update to PhonemeCoverage.ipynb,Use multiprocessing for phoneme processing,SanjaESC,6319070,2020-08-03T14:57:48Z,CONTRIBUTOR,True,39,19,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,841fb2159b9aab0c253347621c4aa0b7c9327045,multiprocessing
428,https://api.github.com/repos/mozilla/TTS/pulls/482,482,Update to PhonemeCoverage.ipynb,Use multiprocessing for phoneme processing,SanjaESC,6319070,2020-08-03T14:57:48Z,CONTRIBUTOR,True,39,19,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b7e65a37985ee4a46d17de7b433c131fdcc8548d,clean output
429,https://api.github.com/repos/mozilla/TTS/pulls/482,482,Update to PhonemeCoverage.ipynb,Use multiprocessing for phoneme processing,SanjaESC,6319070,2020-08-03T14:57:48Z,CONTRIBUTOR,True,39,19,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,170fec205f03a73d5a7a359edad7b74a12f7c905,clean output
430,https://api.github.com/repos/mozilla/TTS/pulls/482,482,Update to PhonemeCoverage.ipynb,Use multiprocessing for phoneme processing,SanjaESC,6319070,2020-08-03T14:57:48Z,CONTRIBUTOR,True,39,19,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9b194f2143c438bc1d0a055048e408eef14f9f30,woops fix imports
431,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6db09a3078da415bdabf1ba66992bd0e4e8bfd6d,added jupyter notebook for phoneme coverage analysis
432,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7abc736b5fc0b6e4e347606f754b6d409b49076a,small import fix
433,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9b76947a53db15a53706ae586dd3314a4f2ebf40,Added phoneme frequency percentage in plot
434,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6682c8e0259202e3c7d99fd844259a45913e259b,newline output of percentage value in plot
435,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ce5b2d822f3febbe8de253efdd289d3aecae9fe5,Adjusted code to mass refactoring on dev branch
436,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0905fde5bd25cc80c5ff17f0e074fe39a889c625,Remove old target folder
437,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a4ac0abdc25651db8c05c069a84996b474838713,update imports in notebook
438,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,06090b5594b81cb02f354e4afdff185043eaf7a3,added jupyter notebook for phoneme coverage analysis
439,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5b7329e66d6b6bd559a13c3518fa3fb088da86dd,small import fix
440,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,06e76e1d49d58cf47ee58c58342ca13d2fa1715b,Added phoneme frequency percentage in plot
441,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,937bed72df24e139469aa0c5f14154de4e0a59a7,newline output of percentage value in plot
442,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8bcd5cc1d759328aecc40098b5a0ea228403b566,Adjusted code to mass refactoring on dev branch
443,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d1759d47a5f033cd530647bd1968516aef0b34b4,Remove old target folder
444,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4086e18b302aee8f448371108d57050f3cf72591,update imports in notebook
445,https://api.github.com/repos/mozilla/TTS/pulls/481,481,Phoneme Coverage Notebook Edit,Just remove the manual import in the notebook. ,erogol,1402048,2020-08-03T10:24:16Z,CONTRIBUTOR,True,231,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,178ea9b26d322dc864a955f754b20c0453d93f48,Merge branch 'phoneme_pr' of https://github.com/mozilla/TTS into phoneme_pr
446,https://api.github.com/repos/mozilla/TTS/pulls/480,480,Fix import of scipy.io.wavfile in master,"This is a candidate PR to fix issue #477 in the master branch.

Prior to this change, test_audio.py fails with:

```

(tts) ll-Series:~/dev/models/tensorflow/TTS$ nosetests tests/test_audio.py 
E.....
======================================================================
ERROR: 1. load wav
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/jim/dev/models/tensorflow/TTS/tests/test_audio.py"", line 44, in test_audio_synthesis
    _test(1., False, False, False)
  File ""/home/jim/dev/models/tensorflow/TTS/tests/test_audio.py"", line 41, in _test
    self.ap.save_wav(wav_, OUT_PATH + file_name)
  File ""/home/jim/dev/models/tensorflow/TTS/utils/audio.py"", line 322, in save_wav
    scipy.io.wavfile.write(path, self.sample_rate, wav_norm.astype(np.int16))
AttributeError: module 'scipy.io' has no attribute 'wavfile'
-------------------- >> begin captured stdout << ---------------------
 > Sanity check for the process wav -> mel -> wav
 | > Creating wav file at :  /audio_test-melspec_max_norm_1.0-signal_norm_False-symmetric_False-clip_norm_False.wav

--------------------- >> end captured stdout << ----------------------

----------------------------------------------------------------------
Ran 6 tests in 0.450s

FAILED (errors=1)

```
Subsequent to change, test passes:

```

(tts) ll-Series:~/dev/models/tensorflow/TTS$ nosetests tests/test_audio.py 

----------------------------------------------------------------------
Ran 6 tests in 3.605s

OK

```
",jyegerlehner,2138320,2020-08-03T01:33:33Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c7c8b5c1550c9d20bb7aa1c67edda6c5db061445,Fix import of scipy.io.wavfile
447,https://api.github.com/repos/mozilla/TTS/pulls/479,479,Fix scipy.io.wavfile import in dev branch,"This is a candidate PR to fix issue #477 in the master branch.

Prior to this change, test_audio.py fails with:
```

(tts) ll-Series:~/dev/models/tensorflow/TTS$ nosetests tests/test_audio.py 
E.....
======================================================================
ERROR: 1. load wav
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""/home/jim/dev/models/tensorflow/TTS/tests/test_audio.py"", line 44, in test_audio_synthesis
    _test(1., False, False, False)
  File ""/home/jim/dev/models/tensorflow/TTS/tests/test_audio.py"", line 41, in _test
    self.ap.save_wav(wav_, OUT_PATH + file_name)
  File ""/home/jim/dev/models/tensorflow/TTS/utils/audio.py"", line 322, in save_wav
    scipy.io.wavfile.write(path, self.sample_rate, wav_norm.astype(np.int16))
AttributeError: module 'scipy.io' has no attribute 'wavfile'
-------------------- >> begin captured stdout << ---------------------
 > Sanity check for the process wav -> mel -> wav
 | > Creating wav file at :  /audio_test-melspec_max_norm_1.0-signal_norm_False-symmetric_False-clip_norm_False.wav

--------------------- >> end captured stdout << ----------------------

----------------------------------------------------------------------
Ran 6 tests in 0.450s

FAILED (errors=1)

```

Subsequent to change, test passes:

```
(tts) ll-Series:~/dev/models/tensorflow/TTS$ nosetests tests/test_audio.py 
......
----------------------------------------------------------------------
Ran 6 tests in 3.605s

OK

```
",jyegerlehner,2138320,2020-08-03T01:04:56Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,36fee428b9f3f4ec1914b090a2ec9d785314d9aa,Fix scipy.io.wavfile import
448,https://api.github.com/repos/mozilla/TTS/pulls/478,478,Fix scipy.io.wavfile import in master,This is a candidate PR to fix issue #477 in the master branch.,jyegerlehner,2138320,2020-08-03T01:01:31Z,CONTRIBUTOR,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3edecff642d9b80a3c53ea01e26860b8883b560c,Fix scipy.io.wavfile import
449,https://api.github.com/repos/mozilla/TTS/pulls/478,478,Fix scipy.io.wavfile import in master,This is a candidate PR to fix issue #477 in the master branch.,jyegerlehner,2138320,2020-08-03T01:01:31Z,CONTRIBUTOR,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,31dc727d0fbc13de75c80abb9e21d77f7a6c6ad6,simplified change.
450,https://api.github.com/repos/mozilla/TTS/pulls/478,478,Fix scipy.io.wavfile import in master,This is a candidate PR to fix issue #477 in the master branch.,jyegerlehner,2138320,2020-08-03T01:01:31Z,CONTRIBUTOR,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,63b998b3d46f960f8191a5e7053ee3a68c255e1b,"Fix scipy.io.wavfile import

simplified change."
451,https://api.github.com/repos/mozilla/TTS/pulls/478,478,Fix scipy.io.wavfile import in master,This is a candidate PR to fix issue #477 in the master branch.,jyegerlehner,2138320,2020-08-03T01:01:31Z,CONTRIBUTOR,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,85b3c9dd76537ac7ba564f89a5ebc1b07693f8b9,Merge branch 'fix-scipy.io.wavfile-import' of https://github.com/jyegerlehner/TTS into fix-scipy.io.wavfile-import
452,https://api.github.com/repos/mozilla/TTS/pulls/476,476,Enforce device consistency in GuidedAttentionLoss (dev branch),"This is a candidate fix for issue #473, suggested by @SanjaESC. This one is for the dev branch. Looks like same change is also required for the master branch (see PR #474).
",jyegerlehner,2138320,2020-08-03T00:14:41Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b0ba5778765597b6d41bf41716fc98a4a981c72e,Enforce device consistency in GuidedAttentionLoss (dev branch)
453,https://api.github.com/repos/mozilla/TTS/pulls/475,475,Add jupyter notebook for phoneme coverage analysis,"As filed in issue https://github.com/mozilla/TTS/issues/470 i've added a jupyter notebook for phoneme coverage analysis and send pr on dev branch.

Follwing these steps should work:
- cd ~
- git clone https://github.com/mozilla/TTS.git
  - alt.: git clone --single-branch --branch dev https://github.com/mozilla/TTS.git
- cd TTS
- python3 -m venv .mozilla_tts_dev
- source .mozilla_tts_dev/bin/activate
- pip install pip --upgrade
- python3 ./setup.py develop
- cd ~/TTS/notebooks/dataset_analysis
- jupyter notebook
- execute ""phoneme coverage"" notebook

**check path and ensure config for dataset and phonemes are correct**",thorstenMueller,9558265,2020-08-02T17:46:27Z,CONTRIBUTOR,True,286,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6db09a3078da415bdabf1ba66992bd0e4e8bfd6d,added jupyter notebook for phoneme coverage analysis
454,https://api.github.com/repos/mozilla/TTS/pulls/475,475,Add jupyter notebook for phoneme coverage analysis,"As filed in issue https://github.com/mozilla/TTS/issues/470 i've added a jupyter notebook for phoneme coverage analysis and send pr on dev branch.

Follwing these steps should work:
- cd ~
- git clone https://github.com/mozilla/TTS.git
  - alt.: git clone --single-branch --branch dev https://github.com/mozilla/TTS.git
- cd TTS
- python3 -m venv .mozilla_tts_dev
- source .mozilla_tts_dev/bin/activate
- pip install pip --upgrade
- python3 ./setup.py develop
- cd ~/TTS/notebooks/dataset_analysis
- jupyter notebook
- execute ""phoneme coverage"" notebook

**check path and ensure config for dataset and phonemes are correct**",thorstenMueller,9558265,2020-08-02T17:46:27Z,CONTRIBUTOR,True,286,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7abc736b5fc0b6e4e347606f754b6d409b49076a,small import fix
455,https://api.github.com/repos/mozilla/TTS/pulls/475,475,Add jupyter notebook for phoneme coverage analysis,"As filed in issue https://github.com/mozilla/TTS/issues/470 i've added a jupyter notebook for phoneme coverage analysis and send pr on dev branch.

Follwing these steps should work:
- cd ~
- git clone https://github.com/mozilla/TTS.git
  - alt.: git clone --single-branch --branch dev https://github.com/mozilla/TTS.git
- cd TTS
- python3 -m venv .mozilla_tts_dev
- source .mozilla_tts_dev/bin/activate
- pip install pip --upgrade
- python3 ./setup.py develop
- cd ~/TTS/notebooks/dataset_analysis
- jupyter notebook
- execute ""phoneme coverage"" notebook

**check path and ensure config for dataset and phonemes are correct**",thorstenMueller,9558265,2020-08-02T17:46:27Z,CONTRIBUTOR,True,286,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9b76947a53db15a53706ae586dd3314a4f2ebf40,Added phoneme frequency percentage in plot
456,https://api.github.com/repos/mozilla/TTS/pulls/475,475,Add jupyter notebook for phoneme coverage analysis,"As filed in issue https://github.com/mozilla/TTS/issues/470 i've added a jupyter notebook for phoneme coverage analysis and send pr on dev branch.

Follwing these steps should work:
- cd ~
- git clone https://github.com/mozilla/TTS.git
  - alt.: git clone --single-branch --branch dev https://github.com/mozilla/TTS.git
- cd TTS
- python3 -m venv .mozilla_tts_dev
- source .mozilla_tts_dev/bin/activate
- pip install pip --upgrade
- python3 ./setup.py develop
- cd ~/TTS/notebooks/dataset_analysis
- jupyter notebook
- execute ""phoneme coverage"" notebook

**check path and ensure config for dataset and phonemes are correct**",thorstenMueller,9558265,2020-08-02T17:46:27Z,CONTRIBUTOR,True,286,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6682c8e0259202e3c7d99fd844259a45913e259b,newline output of percentage value in plot
457,https://api.github.com/repos/mozilla/TTS/pulls/475,475,Add jupyter notebook for phoneme coverage analysis,"As filed in issue https://github.com/mozilla/TTS/issues/470 i've added a jupyter notebook for phoneme coverage analysis and send pr on dev branch.

Follwing these steps should work:
- cd ~
- git clone https://github.com/mozilla/TTS.git
  - alt.: git clone --single-branch --branch dev https://github.com/mozilla/TTS.git
- cd TTS
- python3 -m venv .mozilla_tts_dev
- source .mozilla_tts_dev/bin/activate
- pip install pip --upgrade
- python3 ./setup.py develop
- cd ~/TTS/notebooks/dataset_analysis
- jupyter notebook
- execute ""phoneme coverage"" notebook

**check path and ensure config for dataset and phonemes are correct**",thorstenMueller,9558265,2020-08-02T17:46:27Z,CONTRIBUTOR,True,286,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ce5b2d822f3febbe8de253efdd289d3aecae9fe5,Adjusted code to mass refactoring on dev branch
458,https://api.github.com/repos/mozilla/TTS/pulls/475,475,Add jupyter notebook for phoneme coverage analysis,"As filed in issue https://github.com/mozilla/TTS/issues/470 i've added a jupyter notebook for phoneme coverage analysis and send pr on dev branch.

Follwing these steps should work:
- cd ~
- git clone https://github.com/mozilla/TTS.git
  - alt.: git clone --single-branch --branch dev https://github.com/mozilla/TTS.git
- cd TTS
- python3 -m venv .mozilla_tts_dev
- source .mozilla_tts_dev/bin/activate
- pip install pip --upgrade
- python3 ./setup.py develop
- cd ~/TTS/notebooks/dataset_analysis
- jupyter notebook
- execute ""phoneme coverage"" notebook

**check path and ensure config for dataset and phonemes are correct**",thorstenMueller,9558265,2020-08-02T17:46:27Z,CONTRIBUTOR,True,286,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0905fde5bd25cc80c5ff17f0e074fe39a889c625,Remove old target folder
459,https://api.github.com/repos/mozilla/TTS/pulls/474,474,Enforce device consistency in GuidedAttentionLoss,"This is a candidate fix for #473, with changes suggested by @SanjaESC.",jyegerlehner,2138320,2020-08-02T01:37:01Z,CONTRIBUTOR,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c3dc3202b9bac63c067643dc709406ae7cc7e89c,Initial commit
460,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,51955763249df9f22876f18547b24a3220480e81,Added support for Tacotron2 GST + abbility to condition style input with wav or tokens
461,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2dc316969458296fddbede5fbdddbfeef1231063,No need to query every token when none were passed
462,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5c7924397133948a9acdcf9fd0c76a3c3e88854e,fix fft_size key error
463,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,361721e562cdc4785799fc8097d4c08146ad5bfb,pylint
464,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,30195a3bc2abcb0ac1f7625c03fbbfd4f833b85e,tacotrongst test + test fixes
465,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c4a0f4dc153bb6581a731f67cf501f0a906de9be,Merge remote-tracking branch 'upstream/dev' into dev
466,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c5eaf12d7b9b5b74b99a633a5622a44b123e49e4,override compute_gst in tacotron2 model
467,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,960b4f58eca6e98df2fad7ffd82f030a21c1b251,small gst config change
468,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,51ecab29daac2b1be00044887bc8173b48fab849,update comment
469,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e18bf0191211f00ca7f8264a73d2db5befd7af70,merge dev into branch
470,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3b7c51f18654ca3c668cd0a87e9eab38e007cff8,add support fot VCTK and BRSpeech dataset
471,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6289e6d92e2a808a64e7f08044f308448e0c721e,add Portuguese Cleaner
472,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b06da9d586b4fbb5280dfbe4860948122503363c,bugfix in DDC now DDC work on Tacotron1
473,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d92cb8f68bff6d1925975c045d4f054bc2897e7e,add External Embedding per sample instead of nn.Embedding
474,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8d1d9bc84b33efcea94b00bcd7e0bad9705c2606,bugfix in GST
475,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ff64a964405f0406c58fdb8186439c28ce4f27b9,Merge branch 'dev' into dev-gst-embeddings
476,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3d6f368db44972ef8edffb7320bef13c5033c153,fix Lint check
477,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4ed43ca1cc2bbc70bf536f70cb25ee0d8a6735d6,travis unit tests fix and add Tacotron and Tacotron 2 GST and MultiSpeaker Tests
478,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f0284e8665951d26c81b07d93a1a07b7edae7e70,add support for synthesize using variable size external embedding and add bugfix in scipy.io import
479,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,899d577e1e91bcf2590a41f6370d9fcdb161d4e7,Force the loading of the wav in synthesis using the AP sample rate to avoid breaking the demo
480,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,aeb2f31f6d830bf116ba98e149a087262eb748d8,add gst suport in synthesize
481,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,aaf4f5f3eaf4eb19a2319098ff7d6a1db6ae45f9,add gst style dict  suport in synthesize
482,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e7c31e39d0302fc6a7b8e863e99bd9f5fc7bf234,bugfix in tacotron and tacotron 2 gst inference
483,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a374e9e6d1f9496cd06dc367ec8a99dd08c8e1af,added integrity test for GST dictionary in synthesis
484,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,af3f675d9fab5272a2d28f4a3e6fa8876f8e75bb,add Colab Notebook from TTS Multi-Speaker
485,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3081c9022ee5441fe5570dcdae5342fcb0d29591,clean Colab Notebook outputs
486,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,52be0710265070a738d138187460cad3b5ea95e1,add Colab Notebook from TTS Multi-Speaker with GST
487,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,15ea23401bd025ed83c8aa2d281afc1457053c2c,add Jupyter Notebook for Extract Speaker Embedding per sample using GE2E
488,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3e07b37637447c9eba49365917ffbebbdd81db5d,Ops! Map Notebooks imports for TTS current version
489,https://api.github.com/repos/mozilla/TTS/pulls/472,472,MultiSpeaker TTS with external variable size embedding,"In this PR we implemented the paper
[Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis](https://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis.pdf). So this PR allows you to train a multi-speaker model that you can generalize to new speakers without needing extra training.

In addition, bug fixing was done in the GST implementation of the PR (#451 ) and unit tests for the GST were added.

My initial experiments were carried out in PR #394, but Mozilla TTS underwent several changes, so it was necessary to reimplement my best experiments.
",Edresson,28763586,2020-07-29T14:56:47Z,CONTRIBUTOR,False,28231,321,34,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,82133e6d3c127f2695c1408c10e82a4073790fea,Implement Angular Prototypical loss
490,https://api.github.com/repos/mozilla/TTS/pulls/468,468,Empty commit to test Travis,,reuben,477142,2020-07-27T14:01:16Z,MEMBER,False,0,0,0,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4787295ab08d56efbf4041110ca070d37e235ab4,Empty commit to test Travis
491,https://api.github.com/repos/mozilla/TTS/pulls/467,467,Minor clean-ups from looking at refactored code,,reuben,477142,2020-07-27T13:10:14Z,MEMBER,True,8,437,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9e63cf4072fa5a0ed3a97380fbc7603e4a0da88c,Load requirements from requirements.txt to avoid duplication and out-of-sync issues
492,https://api.github.com/repos/mozilla/TTS/pulls/467,467,Minor clean-ups from looking at refactored code,,reuben,477142,2020-07-27T13:10:14Z,MEMBER,True,8,437,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b21dceb351483f6b685288bfddb7055d11047c4e,Remove some duplicated or unused files
493,https://api.github.com/repos/mozilla/TTS/pulls/462,462,Refactoring TTS ,Refactoring the code base to be more consistent with the general Python project structure.,erogol,1402048,2020-07-16T12:46:23Z,CONTRIBUTOR,False,3796,13840,150,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ab00321b207db8be8496d5b3b302aa02d8d2ec17,args comment update
494,https://api.github.com/repos/mozilla/TTS/pulls/462,462,Refactoring TTS ,Refactoring the code base to be more consistent with the general Python project structure.,erogol,1402048,2020-07-16T12:46:23Z,CONTRIBUTOR,False,3796,13840,150,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2e26884c0dbca38a65333fab67215d4afee432db,refactoring tts submodule initial commit [WIP]
495,https://api.github.com/repos/mozilla/TTS/pulls/462,462,Refactoring TTS ,Refactoring the code base to be more consistent with the general Python project structure.,erogol,1402048,2020-07-16T12:46:23Z,CONTRIBUTOR,False,3796,13840,150,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cb87ff499702d41a890b9e579eb99ccbb9b8dbe9,travis update
496,https://api.github.com/repos/mozilla/TTS/pulls/462,462,Refactoring TTS ,Refactoring the code base to be more consistent with the general Python project structure.,erogol,1402048,2020-07-16T12:46:23Z,CONTRIBUTOR,False,3796,13840,150,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a723582aed16d896542b6cc9b21ee13a9852fa38,setup update
497,https://api.github.com/repos/mozilla/TTS/pulls/462,462,Refactoring TTS ,Refactoring the code base to be more consistent with the general Python project structure.,erogol,1402048,2020-07-16T12:46:23Z,CONTRIBUTOR,False,3796,13840,150,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,544fb10009e6964b8547467e5929e2ead5e6a302,update tests and import statemets
498,https://api.github.com/repos/mozilla/TTS/pulls/462,462,Refactoring TTS ,Refactoring the code base to be more consistent with the general Python project structure.,erogol,1402048,2020-07-16T12:46:23Z,CONTRIBUTOR,False,3796,13840,150,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d1ffd3c1326e476584369648b9951ce538a5932a,Mass refactoring v2
499,https://api.github.com/repos/mozilla/TTS/pulls/461,461,Server improvements,"Small improvements for server module:
- support for MelGAN models
- new command line option `--config_file` for loading configuration from file",domcross,39655102,2020-07-15T17:09:16Z,NONE,False,43,11,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,efdb015ab4668f711945677fd25a52fb5781c9d1,"Merge pull request #1 from mozilla/master

update to latest master"
500,https://api.github.com/repos/mozilla/TTS/pulls/461,461,Server improvements,"Small improvements for server module:
- support for MelGAN models
- new command line option `--config_file` for loading configuration from file",domcross,39655102,2020-07-15T17:09:16Z,NONE,False,43,11,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1ea20f2e75825943743e019bb648d5f576541067,"Merge pull request #2 from mozilla/master

update to latest master"
501,https://api.github.com/repos/mozilla/TTS/pulls/461,461,Server improvements,"Small improvements for server module:
- support for MelGAN models
- new command line option `--config_file` for loading configuration from file",domcross,39655102,2020-07-15T17:09:16Z,NONE,False,43,11,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c6958144903169a3761146773a4a2755d4ad5a1e,"Merge pull request #3 from mozilla/master

update master"
502,https://api.github.com/repos/mozilla/TTS/pulls/461,461,Server improvements,"Small improvements for server module:
- support for MelGAN models
- new command line option `--config_file` for loading configuration from file",domcross,39655102,2020-07-15T17:09:16Z,NONE,False,43,11,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,890e17a6d3359ae5e8a5c23bfe2c4698f2c5cb1f,"Merge pull request #4 from mozilla/master

update from origin/master"
503,https://api.github.com/repos/mozilla/TTS/pulls/461,461,Server improvements,"Small improvements for server module:
- support for MelGAN models
- new command line option `--config_file` for loading configuration from file",domcross,39655102,2020-07-15T17:09:16Z,NONE,False,43,11,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e5ba4da7e122a3a7cb3b376b53365857fce7deaa,"support for MelGAN, config_file option"
504,https://api.github.com/repos/mozilla/TTS/pulls/459,459,Several small fixes in config.json and stats printing,,thllwg,31413490,2020-07-13T17:03:07Z,CONTRIBUTOR,True,4,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c96028f464da74695fafffd17d27458a49e0a16d,Merge remote-tracking branch 'TTS/dev' into dev
505,https://api.github.com/repos/mozilla/TTS/pulls/459,459,Several small fixes in config.json and stats printing,,thllwg,31413490,2020-07-13T17:03:07Z,CONTRIBUTOR,True,4,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,673148b567159853acb02c08431f53fcee5c5005,Fix: Logger prints epoch instead of epoch_time
506,https://api.github.com/repos/mozilla/TTS/pulls/459,459,Several small fixes in config.json and stats printing,,thllwg,31413490,2020-07-13T17:03:07Z,CONTRIBUTOR,True,4,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fb3cd968937953984941f68fb36efc92cb8e3676,Merge remote-tracking branch 'TTS/dev' into dev
507,https://api.github.com/repos/mozilla/TTS/pulls/459,459,Several small fixes in config.json and stats printing,,thllwg,31413490,2020-07-13T17:03:07Z,CONTRIBUTOR,True,4,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,07e600547188634594681d54ed34858c5733dc55,FIX: misplaced quote sign causes key error in config
508,https://api.github.com/repos/mozilla/TTS/pulls/459,459,Several small fixes in config.json and stats printing,,thllwg,31413490,2020-07-13T17:03:07Z,CONTRIBUTOR,True,4,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d8bdf750b79a6d7e4dc7acfa178a14c30a85f518,Merge remote-tracking branch 'TTS/dev' into dev
509,https://api.github.com/repos/mozilla/TTS/pulls/459,459,Several small fixes in config.json and stats printing,,thllwg,31413490,2020-07-13T17:03:07Z,CONTRIBUTOR,True,4,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9530a6bdaf970c89d3aea0e455ca52658ad8bc6f,Merge remote-tracking branch 'TTS/dev' into dev
510,https://api.github.com/repos/mozilla/TTS/pulls/459,459,Several small fixes in config.json and stats printing,,thllwg,31413490,2020-07-13T17:03:07Z,CONTRIBUTOR,True,4,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2f241395ab7daf48b9829d02da5dd3bc640f28fe,Merge remote-tracking branch 'TTS/dev' into dev
511,https://api.github.com/repos/mozilla/TTS/pulls/459,459,Several small fixes in config.json and stats printing,,thllwg,31413490,2020-07-13T17:03:07Z,CONTRIBUTOR,True,4,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1267e778460e040303d209ed54fcc8e3127d2544,FIX: spec_gain should be float as indicated by assert
512,https://api.github.com/repos/mozilla/TTS/pulls/459,459,Several small fixes in config.json and stats printing,,thllwg,31413490,2020-07-13T17:03:07Z,CONTRIBUTOR,True,4,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b87a7ac356a5a0bf14a16631be5cc047de13a7be,Round seconds to two decimals
513,https://api.github.com/repos/mozilla/TTS/pulls/456,456,Fix for #454,"Replaced `with open(config_path, ""r"") as f:` with `with open(config_path, ""r"", encoding = ""utf-8"") as f:` in TTS\utils\io.py.

Fixes UnicodeDecodeError for Windows 10 in #454 ",lokkelvin2,56050360,2020-07-13T09:23:37Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,baf6240c57fbb94cb4501b11f6057d71171d8715,"add encoding=""utf-8"""
514,https://api.github.com/repos/mozilla/TTS/pulls/455,455,Handle wider range of sentence splitting on demo server,"There are some limitations with the way the demo server currently splits sentences.

Using [pysbd](https://github.com/nipunsadvilkar/pySBD), which specialises in this and is quite light weight (no dependencies if you don't, _optionally_, install spacy), allows a variety of common sentences to be handled well.

Whilst there are areas of the number handling that could benefit a bit more for things like broader currency cases (even after the recent inflect changes which are great), just by improving the sentence splitting here, it already helps some number cases:

```
This one costs $99.99, which is a bargain.
```

Put into words:

**Before:** 'This one costs ninety nine dollars.', 'Ninety nine, which is a bargain.' _(spoken as two distinct sentences)_
**Now:** 'This one costs ninety nine dollars ninety nine cents, which is a bargain.'

It also makes the server a little more robust (eg ""Hey!! So good to see you."" currently causes a server error due to not handling the repeated ""!"")

I put in some tests (in **tests/test_demo_server.py**) for the sentence splitter too.  Some of that may be possible in a more Pythonic / elegant way but figured I'd get this ready and see what people thought.

If the tests are acceptable and there's interest in going further with this, I can look at some of the number scenarios next.",nmstoker,3694484,2020-07-13T01:51:28Z,CONTRIBUTOR,True,38,41,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,95b6a16d65c420e8b8f6b781822f3eb0c8cf509f,"Merge pull request #1 from mozilla/dev

Update Dev"
515,https://api.github.com/repos/mozilla/TTS/pulls/455,455,Handle wider range of sentence splitting on demo server,"There are some limitations with the way the demo server currently splits sentences.

Using [pysbd](https://github.com/nipunsadvilkar/pySBD), which specialises in this and is quite light weight (no dependencies if you don't, _optionally_, install spacy), allows a variety of common sentences to be handled well.

Whilst there are areas of the number handling that could benefit a bit more for things like broader currency cases (even after the recent inflect changes which are great), just by improving the sentence splitting here, it already helps some number cases:

```
This one costs $99.99, which is a bargain.
```

Put into words:

**Before:** 'This one costs ninety nine dollars.', 'Ninety nine, which is a bargain.' _(spoken as two distinct sentences)_
**Now:** 'This one costs ninety nine dollars ninety nine cents, which is a bargain.'

It also makes the server a little more robust (eg ""Hey!! So good to see you."" currently causes a server error due to not handling the repeated ""!"")

I put in some tests (in **tests/test_demo_server.py**) for the sentence splitter too.  Some of that may be possible in a more Pythonic / elegant way but figured I'd get this ready and see what people thought.

If the tests are acceptable and there's interest in going further with this, I can look at some of the number scenarios next.",nmstoker,3694484,2020-07-13T01:51:28Z,CONTRIBUTOR,True,38,41,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ce2481d9cd9db3ab1c7b37b460882793d204500a,Handle wider range of sentence splits
516,https://api.github.com/repos/mozilla/TTS/pulls/455,455,Handle wider range of sentence splitting on demo server,"There are some limitations with the way the demo server currently splits sentences.

Using [pysbd](https://github.com/nipunsadvilkar/pySBD), which specialises in this and is quite light weight (no dependencies if you don't, _optionally_, install spacy), allows a variety of common sentences to be handled well.

Whilst there are areas of the number handling that could benefit a bit more for things like broader currency cases (even after the recent inflect changes which are great), just by improving the sentence splitting here, it already helps some number cases:

```
This one costs $99.99, which is a bargain.
```

Put into words:

**Before:** 'This one costs ninety nine dollars.', 'Ninety nine, which is a bargain.' _(spoken as two distinct sentences)_
**Now:** 'This one costs ninety nine dollars ninety nine cents, which is a bargain.'

It also makes the server a little more robust (eg ""Hey!! So good to see you."" currently causes a server error due to not handling the repeated ""!"")

I put in some tests (in **tests/test_demo_server.py**) for the sentence splitter too.  Some of that may be possible in a more Pythonic / elegant way but figured I'd get this ready and see what people thought.

If the tests are acceptable and there's interest in going further with this, I can look at some of the number scenarios next.",nmstoker,3694484,2020-07-13T01:51:28Z,CONTRIBUTOR,True,38,41,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,654ecef4b23f31378400ffb3e5dda5a3d3ec8828,Update requirements for sentence splitting
517,https://api.github.com/repos/mozilla/TTS/pulls/452,452,Small changes for vocoder,"In vocoder, moves padding of wavs prior to mel creation as discussed in #450 .
Also includes tiny clarification of GPU Id mentioned in vocoder directory README.md",nmstoker,3694484,2020-07-11T17:01:35Z,CONTRIBUTOR,True,10,9,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,74f83b2d135357eacc7fe58d3720b7c404ca6c88,Fixes #450
518,https://api.github.com/repos/mozilla/TTS/pulls/452,452,Small changes for vocoder,"In vocoder, moves padding of wavs prior to mel creation as discussed in #450 .
Also includes tiny clarification of GPU Id mentioned in vocoder directory README.md",nmstoker,3694484,2020-07-11T17:01:35Z,CONTRIBUTOR,True,10,9,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3d9e2faba857d945f15d2c78c0bacc9709544d8b,Clarify GPU Id use with vocoder training
519,https://api.github.com/repos/mozilla/TTS/pulls/451,451,Support for Mutlispeaker Tacotron2 with GST and the ability to condition on tokens,"GST style input can be conditioned either on wav file or tokens 
- If using tokens you need to pass a dictionary with the tokens you want to modify to ""gst_style_input"" in the config.
- Example: {""0"": 0.15, ""1"": 0.15, ""5"": -0.15}  Key=Token 
- Where the dictionary being len(dict) <= len(gst_style_tokens).
",SanjaESC,6319070,2020-07-10T10:25:50Z,CONTRIBUTOR,False,165,71,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,51955763249df9f22876f18547b24a3220480e81,Added support for Tacotron2 GST + abbility to condition style input with wav or tokens
520,https://api.github.com/repos/mozilla/TTS/pulls/451,451,Support for Mutlispeaker Tacotron2 with GST and the ability to condition on tokens,"GST style input can be conditioned either on wav file or tokens 
- If using tokens you need to pass a dictionary with the tokens you want to modify to ""gst_style_input"" in the config.
- Example: {""0"": 0.15, ""1"": 0.15, ""5"": -0.15}  Key=Token 
- Where the dictionary being len(dict) <= len(gst_style_tokens).
",SanjaESC,6319070,2020-07-10T10:25:50Z,CONTRIBUTOR,False,165,71,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2dc316969458296fddbede5fbdddbfeef1231063,No need to query every token when none were passed
521,https://api.github.com/repos/mozilla/TTS/pulls/451,451,Support for Mutlispeaker Tacotron2 with GST and the ability to condition on tokens,"GST style input can be conditioned either on wav file or tokens 
- If using tokens you need to pass a dictionary with the tokens you want to modify to ""gst_style_input"" in the config.
- Example: {""0"": 0.15, ""1"": 0.15, ""5"": -0.15}  Key=Token 
- Where the dictionary being len(dict) <= len(gst_style_tokens).
",SanjaESC,6319070,2020-07-10T10:25:50Z,CONTRIBUTOR,False,165,71,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5c7924397133948a9acdcf9fd0c76a3c3e88854e,fix fft_size key error
522,https://api.github.com/repos/mozilla/TTS/pulls/451,451,Support for Mutlispeaker Tacotron2 with GST and the ability to condition on tokens,"GST style input can be conditioned either on wav file or tokens 
- If using tokens you need to pass a dictionary with the tokens you want to modify to ""gst_style_input"" in the config.
- Example: {""0"": 0.15, ""1"": 0.15, ""5"": -0.15}  Key=Token 
- Where the dictionary being len(dict) <= len(gst_style_tokens).
",SanjaESC,6319070,2020-07-10T10:25:50Z,CONTRIBUTOR,False,165,71,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,361721e562cdc4785799fc8097d4c08146ad5bfb,pylint
523,https://api.github.com/repos/mozilla/TTS/pulls/451,451,Support for Mutlispeaker Tacotron2 with GST and the ability to condition on tokens,"GST style input can be conditioned either on wav file or tokens 
- If using tokens you need to pass a dictionary with the tokens you want to modify to ""gst_style_input"" in the config.
- Example: {""0"": 0.15, ""1"": 0.15, ""5"": -0.15}  Key=Token 
- Where the dictionary being len(dict) <= len(gst_style_tokens).
",SanjaESC,6319070,2020-07-10T10:25:50Z,CONTRIBUTOR,False,165,71,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,30195a3bc2abcb0ac1f7625c03fbbfd4f833b85e,tacotrongst test + test fixes
524,https://api.github.com/repos/mozilla/TTS/pulls/451,451,Support for Mutlispeaker Tacotron2 with GST and the ability to condition on tokens,"GST style input can be conditioned either on wav file or tokens 
- If using tokens you need to pass a dictionary with the tokens you want to modify to ""gst_style_input"" in the config.
- Example: {""0"": 0.15, ""1"": 0.15, ""5"": -0.15}  Key=Token 
- Where the dictionary being len(dict) <= len(gst_style_tokens).
",SanjaESC,6319070,2020-07-10T10:25:50Z,CONTRIBUTOR,False,165,71,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c4a0f4dc153bb6581a731f67cf501f0a906de9be,Merge remote-tracking branch 'upstream/dev' into dev
525,https://api.github.com/repos/mozilla/TTS/pulls/451,451,Support for Mutlispeaker Tacotron2 with GST and the ability to condition on tokens,"GST style input can be conditioned either on wav file or tokens 
- If using tokens you need to pass a dictionary with the tokens you want to modify to ""gst_style_input"" in the config.
- Example: {""0"": 0.15, ""1"": 0.15, ""5"": -0.15}  Key=Token 
- Where the dictionary being len(dict) <= len(gst_style_tokens).
",SanjaESC,6319070,2020-07-10T10:25:50Z,CONTRIBUTOR,False,165,71,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c5eaf12d7b9b5b74b99a633a5622a44b123e49e4,override compute_gst in tacotron2 model
526,https://api.github.com/repos/mozilla/TTS/pulls/451,451,Support for Mutlispeaker Tacotron2 with GST and the ability to condition on tokens,"GST style input can be conditioned either on wav file or tokens 
- If using tokens you need to pass a dictionary with the tokens you want to modify to ""gst_style_input"" in the config.
- Example: {""0"": 0.15, ""1"": 0.15, ""5"": -0.15}  Key=Token 
- Where the dictionary being len(dict) <= len(gst_style_tokens).
",SanjaESC,6319070,2020-07-10T10:25:50Z,CONTRIBUTOR,False,165,71,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,960b4f58eca6e98df2fad7ffd82f030a21c1b251,small gst config change
527,https://api.github.com/repos/mozilla/TTS/pulls/451,451,Support for Mutlispeaker Tacotron2 with GST and the ability to condition on tokens,"GST style input can be conditioned either on wav file or tokens 
- If using tokens you need to pass a dictionary with the tokens you want to modify to ""gst_style_input"" in the config.
- Example: {""0"": 0.15, ""1"": 0.15, ""5"": -0.15}  Key=Token 
- Where the dictionary being len(dict) <= len(gst_style_tokens).
",SanjaESC,6319070,2020-07-10T10:25:50Z,CONTRIBUTOR,False,165,71,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,51ecab29daac2b1be00044887bc8173b48fab849,update comment
528,https://api.github.com/repos/mozilla/TTS/pulls/447,447,Fixed Import,`load_config` is incorrectly imported from `TTS.utils.generic_utils` instead of `TTS.utils.io`.,thllwg,31413490,2020-06-29T16:29:33Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cf84a80c8f8bd8f80d8442c11cbf4fce139db2ce,Fixed Import
529,https://api.github.com/repos/mozilla/TTS/pulls/444,444,use apex AMP O1 optimizations,,repodiac,53218201,2020-06-23T11:46:39Z,CONTRIBUTOR,False,48,10,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,84dfd9426d079c7764bef7a95bb0e75d0b03286c,Locking version of numba to match librosa
530,https://api.github.com/repos/mozilla/TTS/pulls/444,444,use apex AMP O1 optimizations,,repodiac,53218201,2020-06-23T11:46:39Z,CONTRIBUTOR,False,48,10,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3366328126b329380dcf9d81b064976e9eb96e17,"Merge pull request #438 from xeb/master

Locking version of numba to match librosa"
531,https://api.github.com/repos/mozilla/TTS/pulls/444,444,use apex AMP O1 optimizations,,repodiac,53218201,2020-06-23T11:46:39Z,CONTRIBUTOR,False,48,10,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,293aae284a3926291fe74726c1cd49473dcbb43c,Merge remote-tracking branch 'upstream/dev' into dev
532,https://api.github.com/repos/mozilla/TTS/pulls/444,444,use apex AMP O1 optimizations,,repodiac,53218201,2020-06-23T11:46:39Z,CONTRIBUTOR,False,48,10,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4f793a9eeda353cddf7c19bbbed189008a619adc,apex AMP O1 optimizations
533,https://api.github.com/repos/mozilla/TTS/pulls/438,438,Locking version of numba to match librosa,This closes #437 ,xeb,7634,2020-06-19T05:19:36Z,CONTRIBUTOR,True,1,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,84dfd9426d079c7764bef7a95bb0e75d0b03286c,Locking version of numba to match librosa
534,https://api.github.com/repos/mozilla/TTS/pulls/427,427,handling librosa conflict with numba,https://github.com/librosa/librosa/issues/1160,erogol,1402048,2020-06-15T09:41:48Z,CONTRIBUTOR,True,1,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9f83b6797f26be631d7717bcb8be53e59846f596,"handling librosa conflict with numba 

https://github.com/librosa/librosa/issues/1160"
535,https://api.github.com/repos/mozilla/TTS/pulls/426,426,load ParallelWaveGAN from PYTHONPATH if pwgan_lib_path is unset,,Mic92,96200,2020-06-13T18:38:51Z,CONTRIBUTOR,True,9,4,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3e5ce85bf7b4d84575632908c962151b355a6a25,load ParallelWaveGAN from PYTHONPATH if pwgan_lib_path is unset
536,https://api.github.com/repos/mozilla/TTS/pulls/425,425,add tts-server executable,This makes the project easier to use when installing via package manager.,Mic92,96200,2020-06-13T10:05:36Z,CONTRIBUTOR,True,10,1,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,82f8e9cb123abadb4dcdebc108d2f1b2f4daf6f9,"add tts-server executable

This makes the project easier to use when installing via package manager."
537,https://api.github.com/repos/mozilla/TTS/pulls/422,422,Update generic_utils.py,len of int is meaningless,mastermobin,28312566,2020-06-11T13:25:38Z,NONE,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,89c047d4cf1b2c28ccfeb66a91c9d8068f55f307,"Update generic_utils.py

len of int is meaningless"
538,https://api.github.com/repos/mozilla/TTS/pulls/421,421,MelGAN,"This integrates the [MelGAN example from the notebook](https://colab.research.google.com/drive/1Zg9jR27Pr-ziVa0krjtdoy2dKv6whv7b#scrollTo=NNdbDVInkzEw) into the TTS server.

I don't expect this to merge to master. I am just sending you this for review.

Advantage is that it's significantly faster, while still giving good quality output. Speed is roughly realtime (i.e. speech generation takes about as long as the speech itself), on a Ryzen 1700X, while using 1 core only.",benbucksch,1907525,2020-06-09T03:07:22Z,NONE,False,145,117,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0fdd70c0dcaca265853bb365d7e89d89a0c60174,Use MelGAN experiement in TTS HTTP server
539,https://api.github.com/repos/mozilla/TTS/pulls/421,421,MelGAN,"This integrates the [MelGAN example from the notebook](https://colab.research.google.com/drive/1Zg9jR27Pr-ziVa0krjtdoy2dKv6whv7b#scrollTo=NNdbDVInkzEw) into the TTS server.

I don't expect this to merge to master. I am just sending you this for review.

Advantage is that it's significantly faster, while still giving good quality output. Speed is roughly realtime (i.e. speech generation takes about as long as the speech itself), on a Ryzen 1700X, while using 1 core only.",benbucksch,1907525,2020-06-09T03:07:22Z,NONE,False,145,117,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5e0872f1b2a47c6e0fb998ea15f6a849058f0270,"Default to localhost only, for security"
540,https://api.github.com/repos/mozilla/TTS/pulls/421,421,MelGAN,"This integrates the [MelGAN example from the notebook](https://colab.research.google.com/drive/1Zg9jR27Pr-ziVa0krjtdoy2dKv6whv7b#scrollTo=NNdbDVInkzEw) into the TTS server.

I don't expect this to merge to master. I am just sending you this for review.

Advantage is that it's significantly faster, while still giving good quality output. Speed is roughly realtime (i.e. speech generation takes about as long as the speech itself), on a Ryzen 1700X, while using 1 core only.",benbucksch,1907525,2020-06-09T03:07:22Z,NONE,False,145,117,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,799cbfc23d6fcdbb225a4fc7d5310797056a8185,Model download locations
541,https://api.github.com/repos/mozilla/TTS/pulls/421,421,MelGAN,"This integrates the [MelGAN example from the notebook](https://colab.research.google.com/drive/1Zg9jR27Pr-ziVa0krjtdoy2dKv6whv7b#scrollTo=NNdbDVInkzEw) into the TTS server.

I don't expect this to merge to master. I am just sending you this for review.

Advantage is that it's significantly faster, while still giving good quality output. Speed is roughly realtime (i.e. speech generation takes about as long as the speech itself), on a Ryzen 1700X, while using 1 core only.",benbucksch,1907525,2020-06-09T03:07:22Z,NONE,False,145,117,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,69f711b31b9357ed0e99ac13cbcb4b39c628be1c,"Ensure that text ends with '.', to work around lisp model bug"
542,https://api.github.com/repos/mozilla/TTS/pulls/421,421,MelGAN,"This integrates the [MelGAN example from the notebook](https://colab.research.google.com/drive/1Zg9jR27Pr-ziVa0krjtdoy2dKv6whv7b#scrollTo=NNdbDVInkzEw) into the TTS server.

I don't expect this to merge to master. I am just sending you this for review.

Advantage is that it's significantly faster, while still giving good quality output. Speed is roughly realtime (i.e. speech generation takes about as long as the speech itself), on a Ryzen 1700X, while using 1 core only.",benbucksch,1907525,2020-06-09T03:07:22Z,NONE,False,145,117,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,565b9279f27e4432f25c699f1bc7f4af15c9fa5b,split wave variable not the right type
543,https://api.github.com/repos/mozilla/TTS/pulls/421,421,MelGAN,"This integrates the [MelGAN example from the notebook](https://colab.research.google.com/drive/1Zg9jR27Pr-ziVa0krjtdoy2dKv6whv7b#scrollTo=NNdbDVInkzEw) into the TTS server.

I don't expect this to merge to master. I am just sending you this for review.

Advantage is that it's significantly faster, while still giving good quality output. Speed is roughly realtime (i.e. speech generation takes about as long as the speech itself), on a Ryzen 1700X, while using 1 core only.",benbucksch,1907525,2020-06-09T03:07:22Z,NONE,False,145,117,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,58ed013e52bb9570be423516baefb82a9504fd52,Tweak README
544,https://api.github.com/repos/mozilla/TTS/pulls/418,418,Fix phoneme cache file name aliasing problem,"When the wav file has multiple dots in the file name,
_load_or_generate_phoneme_sequence would only use only the first segment
of the file name and cause overwrite (or not generate) of *_phoneme.npy",forcecore,632278,2020-05-31T10:59:19Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3f789187159e5bd385f49f26b8643e801d5838a5,"Fix phoneme cache file name aliasing problem

When the wav file has multiple dots in the file name,
_load_or_generate_phoneme_sequence would only use only the first segment
of the file name and cause overwrite of *_phoneme.npy"
545,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3c20afa1c98beb292055a493b8957526346cebf3,do not call .item() if returned loss is not torch type
546,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,98fd3b53f293e6908509982f22b4ad8479a566b5,load mel features if 'feature_path' is provided
547,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,460d0675a6657f4037d38340ed7b997eb90ef593,bug fix for vocoder feature macthing loss
548,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c90145eef91350e476d64070fd63001ea646c097,add feature path to vocder config
549,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e0c44e2cfa23f3220e07bd7fc6ae085906dc104e,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
550,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f3d4d1f83178e6c8519905400c58b1f52dda1d58,bug fix init AudioProcessor in train.py
551,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f18f6e6d3e8473d0ffcceb3a7108e1cdfa197558,plot spectrograms undenormalized if no ap is provided
552,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0de38c261769a1f184c906589882a8fe79951a4a,fixing naming convention in vocoder losses
553,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6948e4ce386a3e7215adb7b2e4be0aa5dfb1bf28,change sample data
554,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b2e9c05acc7fc5f934d5b5785b13ed1855543207,losses bug fix
555,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,55230bb317a8e5fd67b547b9a3a3dda3c6a71692,plot spectrogram transpose fix
556,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,82f8e9cb123abadb4dcdebc108d2f1b2f4daf6f9,"add tts-server executable

This makes the project easier to use when installing via package manager."
557,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,df10e2a92af5fd30a4dd84b3338e38a8a9a30f10,fixinf discriminator configuration
558,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ceea5512aa96598b4dc2df6e1ea01803e2babc52,"Merge pull request #425 from Mic92/server

add tts-server executable"
559,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,25aec41626286cde412643f63068f16612db3393,README update
560,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cc2104935efcd5979d3a652fd947e819fb9f8b44,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
561,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1611a7182df8efc7843ca0a4c9d4b39aeeb3a085,"Update README.md

Co-authored-by: Jörg Thalheim <Mic92@users.noreply.github.com>"
562,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,58784ad09c05a5d07d3b86cd53b89e34972e34bc,renaming for melgan generator
563,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6b2ff0823924d5a5a197f4f7a07b252590826c29,Issue #435 - Convert melgan vocoder models to TF2.0
564,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ce076330bf817d44bb464e66af9b020a083591f7,linter fixes
565,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0176cd6b2c673ee5a9b2d7e3226dcf1cd37a82ee,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
566,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,aad51bc4f9f3f9970a8773c1fc8416c418f33574,readme update
567,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,de7ed4176c190d54fc3d68ec4624e8664fdd55f3,README directory structure
568,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4b99eacb38d9983271610947267063cfd39606a6,README update add models and method section
569,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ec7aa4496eb83f1a9d6acef0f8f4e183dbaa4aa8,README updates added models and method ssection
570,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d587094dc522aa420f309831346133b593ae8766,formatting fix
571,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,dbb4bd884a8745181dee3111d0ad1ab48cd82050,print more info in compute_statistics.py
572,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,18d4ed3dc42184295e269f9acb7567b94d312921,replace n_fft with fft_size
573,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,70c83671e68b0b73bf41605ed91b7134e1cba159,init coarse decoder with argument list
574,https://api.github.com/repos/mozilla/TTS/pulls/415,415,v0.0.4,"- [x] Tensorflow updates
   - [x] TF melgan implementation 
   - [x] Convert the latest model releases to TF
   - [x] Colab sample for TF inference
   - [x] TFLite conversion script for Tacotron2
   - [x] TFlite conversion script for Melgan
- [x] Adding a new VOCODER module. Now we can use Mozilla TTS directly to train the latest vocoder models and enable end-to-end faster than real-time inference performance.
    - [x] Melgan
    - [x] MultiBandMelgan
    - [x] Random Window Discriminator
    - [x] Enable native vocoder support in server.py
- [X] Masking intermediate model outputs against sequence padding. 
    - This aims to mitigate the distortion propagated by the convolution of padded parts of shorter sequences in a batch.
- [X] Double Decoder Consistency [Optional]
    - [Details](https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/)
    - enable/disable using ```double_decoder_consistency``` field in `config.json`
    - set `ddc_r` in `config.json`. (try 7 as your initial run)
- [X] Refactoring Tacotron/Tacotron2 models based on a abstract class. 
- [X] Make masking of decoder/postnet outputs and attention weights optional. 
   - I observed that using masking is useful for a hard dataset but it hurts spectrogram predictions.  Therefore I made it optional to set it accordingly.
- [X] Big refactoring to a more consistent project tree. 
- [X] Add notebooks for the new models and samples.
- [X] OOM fix due to open figures in training.
- [X] Phoneme coverage notebook by @thorstenMueller
- [X] APEX float16 training by @repodiac 
- [X] Multi-speaker model by @Edresson 

",erogol,1402048,2020-05-30T16:23:56Z,CONTRIBUTOR,True,42375,2829,190,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2f3f43844e80306a5d83e42101cfa5e937ef4583,spec_gain fft_size and stft_pad_mode parameters for audio_processor
575,https://api.github.com/repos/mozilla/TTS/pulls/414,414,"initial commit, O1 optimization with apex AMP","This is the PR related to https://github.com/mozilla/TTS/issues/98 and the discussion going on in the mozilla ML chat.

So far, only O1 optimization works!

O2 was not successful, since some architecture of the used (sub)nets seems to interfere with half and float precision. I'll further comment on that in https://github.com/mozilla/TTS/issues/98 comments",repodiac,53218201,2020-05-25T09:50:58Z,CONTRIBUTOR,False,360,357,23,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4708c923aeeb96df6beeaff329331e1c87b84db3,"initial commit, O1 optimization with apex AMP"
576,https://api.github.com/repos/mozilla/TTS/pulls/414,414,"initial commit, O1 optimization with apex AMP","This is the PR related to https://github.com/mozilla/TTS/issues/98 and the discussion going on in the mozilla ML chat.

So far, only O1 optimization works!

O2 was not successful, since some architecture of the used (sub)nets seems to interfere with half and float precision. I'll further comment on that in https://github.com/mozilla/TTS/issues/98 comments",repodiac,53218201,2020-05-25T09:50:58Z,CONTRIBUTOR,False,360,357,23,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,306977c7deff56ef452095ccf2e03e2137416025,manual merge for training.py
577,https://api.github.com/repos/mozilla/TTS/pulls/414,414,"initial commit, O1 optimization with apex AMP","This is the PR related to https://github.com/mozilla/TTS/issues/98 and the discussion going on in the mozilla ML chat.

So far, only O1 optimization works!

O2 was not successful, since some architecture of the used (sub)nets seems to interfere with half and float precision. I'll further comment on that in https://github.com/mozilla/TTS/issues/98 comments",repodiac,53218201,2020-05-25T09:50:58Z,CONTRIBUTOR,False,360,357,23,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5d0b8ed9ab0186f96909ad940073155fbc888ddf,change requests resolved for PR #414
578,https://api.github.com/repos/mozilla/TTS/pulls/414,414,"initial commit, O1 optimization with apex AMP","This is the PR related to https://github.com/mozilla/TTS/issues/98 and the discussion going on in the mozilla ML chat.

So far, only O1 optimization works!

O2 was not successful, since some architecture of the used (sub)nets seems to interfere with half and float precision. I'll further comment on that in https://github.com/mozilla/TTS/issues/98 comments",repodiac,53218201,2020-05-25T09:50:58Z,CONTRIBUTOR,False,360,357,23,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5743579488f766ffaecc221ca6207541c902bc44,state_dict saving/loading resolved
579,https://api.github.com/repos/mozilla/TTS/pulls/414,414,"initial commit, O1 optimization with apex AMP","This is the PR related to https://github.com/mozilla/TTS/issues/98 and the discussion going on in the mozilla ML chat.

So far, only O1 optimization works!

O2 was not successful, since some architecture of the used (sub)nets seems to interfere with half and float precision. I'll further comment on that in https://github.com/mozilla/TTS/issues/98 comments",repodiac,53218201,2020-05-25T09:50:58Z,CONTRIBUTOR,False,360,357,23,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,91d9ba1868caf12fb5ad5dbe6cb5c077341cd778,Merge branch 'dev' into dev
580,https://api.github.com/repos/mozilla/TTS/pulls/413,413,Update compute_statistics.py,change import location of load_config (is in io),george-roussos,25833833,2020-05-23T21:23:27Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1d8ac4c571f543acf666cccdc0e4d4d214c8b96e,"Update compute_statistics.py

change import of load_config (is in io)"
581,https://api.github.com/repos/mozilla/TTS/pulls/411,411,"Fix ""TypeError: The argument is not a tensor"" when training","As mentioned in this comment: https://gist.github.com/erogol/97516ad65b44dbddb8cd694953187c5b

When following the colab example we see `TypeError: The argument is not a tensor`

Looks like this slipped in a couple days ago here: https://github.com/mozilla/TTS/commit/dc166b42e37a20ab950c3d39cfacb33444dca102",smith-kyle,5474861,2020-05-22T02:55:30Z,NONE,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,81ec5e8f9c1a72b8d238172830cc4216f79cac18,"Fix ""TypeError: The argument is not a tensor"" when training

`torch.isinf` accepts a tensor not a float"
582,https://api.github.com/repos/mozilla/TTS/pulls/409,409,Server README Fix,Readme referenced `setup.py` instead of `server.py`,thllwg,31413490,2020-05-20T15:31:57Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,74a9b3016daca653aac450ef56db1d10acd22987,"Merge pull request #1 from mozilla/dev

Dev"
583,https://api.github.com/repos/mozilla/TTS/pulls/409,409,Server README Fix,Readme referenced `setup.py` instead of `server.py`,thllwg,31413490,2020-05-20T15:31:57Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1a0d8c155854abed6b26069b89b35d7b5087a47b,fix: wrong script referenced
584,https://api.github.com/repos/mozilla/TTS/pulls/408,408,"Improve runtime of __parse_items(), +1","Two small changes:
1) Improve runtime of __parse_items() from O(|speakers|*|items|) to O(|items|)
2) Small fix in batch_compute_embedding, where divisor was in incorrect format (was shape [32], should be shape [32, 1])",mueller91,9288660,2020-05-18T13:30:38Z,CONTRIBUTOR,False,13,11,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2fc362b5a8c36ea2d7ca1067b9b177115da6fd10,fix batch_compute_embedding invalid tensor format
585,https://api.github.com/repos/mozilla/TTS/pulls/408,408,"Improve runtime of __parse_items(), +1","Two small changes:
1) Improve runtime of __parse_items() from O(|speakers|*|items|) to O(|items|)
2) Small fix in batch_compute_embedding, where divisor was in incorrect format (was shape [32], should be shape [32, 1])",mueller91,9288660,2020-05-18T13:30:38Z,CONTRIBUTOR,False,13,11,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b72e0285e2e14d6a09fc917e5a83c28e0af707b9,"reduce time complexity of __parse_items
from O(|speaker| * |items|) to O(|items|)"
586,https://api.github.com/repos/mozilla/TTS/pulls/408,408,"Improve runtime of __parse_items(), +1","Two small changes:
1) Improve runtime of __parse_items() from O(|speakers|*|items|) to O(|items|)
2) Small fix in batch_compute_embedding, where divisor was in incorrect format (was shape [32], should be shape [32, 1])",mueller91,9288660,2020-05-18T13:30:38Z,CONTRIBUTOR,False,13,11,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d05115298eb7efd17c195e04d523b40ee97dac86,touchup to runtime improvement
587,https://api.github.com/repos/mozilla/TTS/pulls/407,407,Configurable number of workers for DataLoader,"As discussed [here](https://discourse.mozilla.org/t/update-released-speaker-encoder/47903/2), training the Speaker Encoder is rather slow, with the `DataLoader` being the bottleneck. This PR allows to set the number of workers of the `DataLoader` via the respective `config.json`. ",thllwg,31413490,2020-05-15T08:32:38Z,CONTRIBUTOR,True,2,1,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,65b9c7d3d655e34741ff5adf75bc1b2a6df22158,number of workers as config parameter
588,https://api.github.com/repos/mozilla/TTS/pulls/406,406,small change for multispeaker,just threads speaker_id through decoder.run_model,mittimithai,18408037,2020-05-12T22:02:41Z,CONTRIBUTOR,True,6,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,85a822e3190f6c7207c28f7485ecb0ebe7e480ba,"small change for multispeaker

just threads speaker_id through decoder.run_model"
589,https://api.github.com/repos/mozilla/TTS/pulls/406,406,small change for multispeaker,just threads speaker_id through decoder.run_model,mittimithai,18408037,2020-05-12T22:02:41Z,CONTRIBUTOR,True,6,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a4aca623c34243e065bd49ee5520fd714e461c1a,"removed + chars

silly mistake copy pasting"
590,https://api.github.com/repos/mozilla/TTS/pulls/406,406,small change for multispeaker,just threads speaker_id through decoder.run_model,mittimithai,18408037,2020-05-12T22:02:41Z,CONTRIBUTOR,True,6,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,42ff83f9b9e1151ccaba6d7f9d8f520d274a0d31,trying to fix trailing whitespace
591,https://api.github.com/repos/mozilla/TTS/pulls/406,406,small change for multispeaker,just threads speaker_id through decoder.run_model,mittimithai,18408037,2020-05-12T22:02:41Z,CONTRIBUTOR,True,6,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,25f466f2994dad707f0aa00db36187d6a43844ee,more whitespace problems
592,https://api.github.com/repos/mozilla/TTS/pulls/405,405,load_wav should use the ap sampling rate,This allows resampling datasets in place,mittimithai,18408037,2020-05-12T18:50:11Z,CONTRIBUTOR,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4ea1e83e19117e89e6d534b54589c4a7865111d1,"load_wav should use the ap sampling rate

This allows resampling datasets in place"
593,https://api.github.com/repos/mozilla/TTS/pulls/404,404,Fix bug in Graves Attn,"On my machine at Graves attention the variable self.J ( self.J = torch.arange(0, inputs.shape[1]+2).to(inputs.device) + 0.5) is a LongTensor, but it must be a float tensor. So I get the following error:

Traceback (most recent call last):
  File ""train.py"", line 704, in <module>
    main(args)
  File ""train.py"", line 619, in main
    global_step, epoch)
  File ""train.py"", line 170, in train
    text_input, text_lengths, mel_input, speaker_embeddings=speaker_embeddings)
  File ""/home/edresson/anaconda3/envs/TTS2/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/mnt/edresson/DD/TTS/voice-clonning/TTS/tts_namespace/TTS/models/tacotron.py"", line 121, in forward
    self.speaker_embeddings_projected)
  File ""/home/edresson/anaconda3/envs/TTS2/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/mnt/edresson/DD/TTS/voice-clonning/TTS/tts_namespace/TTS/layers/tacotron.py"", line 435, in forward
    output, stop_token, attention = self.decode(inputs, mask)
  File ""/mnt/edresson/DD/TTS/voice-clonning/TTS/tts_namespace/TTS/layers/tacotron.py"", line 367, in decode
    self.attention_rnn_hidden, inputs, self.processed_inputs, mask)
  File ""/home/edresson/anaconda3/envs/TTS2/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/mnt/edresson/DD/TTS/voice-clonning/TTS/tts_namespace/TTS/layers/common_layers.py"", line 180, in forward
    phi_t = g_t.unsqueeze(-1) * (1.0 / (1.0 + torch.sigmoid((mu_t.unsqueeze(-1) - j) / sig_t.unsqueeze(-1))))
RuntimeError: expected type torch.cuda.FloatTensor but got torch.cuda.LongTensor


In addition the + 0.5 operation is canceled if it is a LongTensor.
Test: 
>>> torch.arange(0, 10) 
tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
>>> torch.arange(0, 10) + 0.5
tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
>>> torch.arange(0, 10.0) + 0.5
tensor([0.5000, 1.5000, 2.5000, 3.5000, 4.5000, 5.5000, 6.5000, 7.5000, 8.5000,
        9.5000])

To resolve this I forced the arrange range to float:
self.J = torch.arange(0, inputs.shape[1]+2.0).to(inputs.device) + 0.5",Edresson,28763586,2020-05-04T20:54:47Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cce13ee245fab03717d2afa1860e35986ebd9de9,"Fix bug in Graves Attn

On my machine at Graves attention the variable self.J ( self.J = torch.arange(0, inputs.shape[1]+2).to(inputs.device) + 0.5) is a LongTensor, but it must be a float tensor. So I get the following error:

Traceback (most recent call last):
  File ""train.py"", line 704, in <module>
    main(args)
  File ""train.py"", line 619, in main
    global_step, epoch)
  File ""train.py"", line 170, in train
    text_input, text_lengths, mel_input, speaker_embeddings=speaker_embeddings)
  File ""/home/edresson/anaconda3/envs/TTS2/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/mnt/edresson/DD/TTS/voice-clonning/TTS/tts_namespace/TTS/models/tacotron.py"", line 121, in forward
    self.speaker_embeddings_projected)
  File ""/home/edresson/anaconda3/envs/TTS2/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/mnt/edresson/DD/TTS/voice-clonning/TTS/tts_namespace/TTS/layers/tacotron.py"", line 435, in forward
    output, stop_token, attention = self.decode(inputs, mask)
  File ""/mnt/edresson/DD/TTS/voice-clonning/TTS/tts_namespace/TTS/layers/tacotron.py"", line 367, in decode
    self.attention_rnn_hidden, inputs, self.processed_inputs, mask)
  File ""/home/edresson/anaconda3/envs/TTS2/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 489, in __call__
    result = self.forward(*input, **kwargs)
  File ""/mnt/edresson/DD/TTS/voice-clonning/TTS/tts_namespace/TTS/layers/common_layers.py"", line 180, in forward
    phi_t = g_t.unsqueeze(-1) * (1.0 / (1.0 + torch.sigmoid((mu_t.unsqueeze(-1) - j) / sig_t.unsqueeze(-1))))
RuntimeError: expected type torch.cuda.FloatTensor but got torch.cuda.LongTensor


In addition the + 0.5 operation is canceled if it is a LongTensor.
Test: 
>>> torch.arange(0, 10) 
tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
>>> torch.arange(0, 10) + 0.5
tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
>>> torch.arange(0, 10.0) + 0.5
tensor([0.5000, 1.5000, 2.5000, 3.5000, 4.5000, 5.5000, 6.5000, 7.5000, 8.5000,
        9.5000])

To resolve this I forced the arrange range to float:
self.J = torch.arange(0, inputs.shape[1]+2.0).to(inputs.device) + 0.5"
594,https://api.github.com/repos/mozilla/TTS/pulls/403,403,fix bug in bidirectional decoder train,,Edresson,28763586,2020-05-04T20:39:49Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e4e29f716e5bc2049d3316896401fae64933a716,fix bug in bidirectional decoder train
595,https://api.github.com/repos/mozilla/TTS/pulls/399,399,Tacotron1 + wavernn configuration fix,"Tacotron1 + wavernn configuration: corrected the input format for wavernn vocoder, converted spectrograms to mels",fatihkiralioglu,38240476,2020-04-25T12:21:38Z,CONTRIBUTOR,True,6,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,70a8210283bbbd613fcd55f17ef8ebb7bdaac32e,"Tacotron1 + wavernn configuration fix

Tacotron1 + wavernn configuration: corrected the input format for wavernn vocoder, converted spectrograms to mels"
596,https://api.github.com/repos/mozilla/TTS/pulls/399,399,Tacotron1 + wavernn configuration fix,"Tacotron1 + wavernn configuration: corrected the input format for wavernn vocoder, converted spectrograms to mels",fatihkiralioglu,38240476,2020-04-25T12:21:38Z,CONTRIBUTOR,True,6,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cc11be06d7efd1e9a2a1cd5a35e7f790592e5067,"fixing ""No space allowed before..."" compile errors

fixing ""No space allowed before..."" compile errors"
597,https://api.github.com/repos/mozilla/TTS/pulls/398,398,numpy to use CPU when using CUDA,"Fixes the following error

`TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.`",PNRxA,16978632,2020-04-25T06:33:11Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,61a1d59ac5fe693320360cb7bf913d87e70a87bf,numpy to use CPU when using CUDA
598,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,604321a480659e068107a797882dccd7ff5d4cf9, add parameter for embedding file in config.json
599,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1e562380dbbd8c92602fb364a5c9b9a651b38254,Merge remote-tracking branch 'upstream/dev' into dev-embedding
600,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4296658bd712c682b209c3bfabe8f3437fdb9614,add load speakers embedding from tacotron model and add notebook for Speech2Phone extract speaker embeddings
601,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b42d2a89fb1ede04a3bd479cad428423e273cdfd,Merge branch 'dev' into dev-embedding
602,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ab30f66da675f769fe63cd1a5ebd1a01bae747e9,add GE2E speaker encoder Extract Embeddings Notebook
603,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a2d22bb8f3dfd135294b483256949f6102b35342,bug fix in GE2E-Speaker_Encoder- ExtractSpeakerEmbeddings.ipynb
604,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ffb02cc7ecc0b48d66cf98e75e60cfc7d5bd5c0a,bug fix
605,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d1ffc339ee7fb0d69e0479cbca22a0739e51a96f,add portuguese cleaners and fix wav_load bug
606,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,46f4bb5cfbfc12a9a38454eb3213ea62b6c0c5b5,add portuguese cleaners
607,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,037819c3b4a6d5df60eb4e5a054fa764e32d1264,Merge remote-tracking branch 'upstream2/master' into dev
608,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0f8613a9942a08dc12574816fc6b82fe7943d184,Resolved merge conflicts
609,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7baa1b2b2c73e08f67b395f1009dbcff3d002185, add tacotron2 support for external variable size embeddings
610,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,eb82668a2af9ba01ddfb2899dac6ca17f22626a3,fix int checks
611,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7851ef1298d9ca673ebd4b2308054ff92ab8f99f, add unit test for tacotron multispeaker with external emebddings
612,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d9e0ad20c38a4b801c6681bdd9c328f4b0c06c61, add unit test for tacotron2 multispeaker with external emebddings
613,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4d6e7b447bdc7440f6fc7c6c4b7fbc0f66123685,fix incorrect indentation on Tacotron 2 model
614,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,85519cd348f2029d043da5a7df5dbd02ba77155a,Merge branch 'dev' into dev-embedding
615,https://api.github.com/repos/mozilla/TTS/pulls/394,394,Support for external embeddings with variable size,"Status: In Progress

 *  [x] Tacotron 1 support for external embeddings with variable size
 * [x] Ipython notebook for extract embeddings from speaker_encoder ( in the expected format)
 *  [x]  Support BRSpeech Potuguese dataset
 * [x]  Ipython notebook for extracting embeddigns from the [Speech2Phone](https://arxiv.org/abs/2002.11213) system
* [x] Tacotron 2 support for external embeddings with variable size
*  [ ] Experiment 1:  Concatenate the Speaker Embedding on the StopNet (in a multi speaker scenario the big problem is in the convergence of the stop token loss, this should help)
* [ ]  Experiment 2: Support for embeddings by samples and not by speaker (each speaker sample will have an embedding), this should have better results for voice cloning. (I do not see how to implement this while maintaining the current implementation that uses nn.Embedding, I will test in a branch itself in case of positive results we can think of how to add this !)",Edresson,28763586,2020-04-10T12:43:17Z,CONTRIBUTOR,False,876,68,21,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,997eac6ca12d44999f0dc2331049e12960bcbf6d,Remove Trailing whitespace after merge
616,https://api.github.com/repos/mozilla/TTS/pulls/389,389,add missing phonemes for Portuguese,,Edresson,28763586,2020-04-03T19:48:19Z,CONTRIBUTOR,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ede65b6a2854732a4f8ba0184a868c5b67eb9b9c,add missing phonemes for Portuguese
617,https://api.github.com/repos/mozilla/TTS/pulls/388,388,"Small fix for ""Tacotron"" use","""Tacotron"" won't work without this fix, since the linear spectrograms end up not getting computed",mittimithai,18408037,2020-04-01T18:58:07Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6501369b0a2c32e896900d913f31f10b583045b4,"Small fix for ""Tacotron"" use

""Tacotron"" won't work without this fix, since the linear spectrograms end up not getting computed"
618,https://api.github.com/repos/mozilla/TTS/pulls/385,385,Add support for external embeddings,In the form of txt file. If it must be on the dev branch it is ok,george-roussos,25833833,2020-03-25T10:58:22Z,CONTRIBUTOR,False,26,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,73b7d95f9568e754a73651e544ddbc97a67e4bc1,Add support for external embeddings
619,https://api.github.com/repos/mozilla/TTS/pulls/385,385,Add support for external embeddings,In the form of txt file. If it must be on the dev branch it is ok,george-roussos,25833833,2020-03-25T10:58:22Z,CONTRIBUTOR,False,26,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8e67e1cc9da305858b26d2a38452f308b7c4083c,Delete blablah.txt
620,https://api.github.com/repos/mozilla/TTS/pulls/385,385,Add support for external embeddings,In the form of txt file. If it must be on the dev branch it is ok,george-roussos,25833833,2020-03-25T10:58:22Z,CONTRIBUTOR,False,26,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1de146001705bb3751d01625d1420b7073046435,Delete test_me.py
621,https://api.github.com/repos/mozilla/TTS/pulls/385,385,Add support for external embeddings,In the form of txt file. If it must be on the dev branch it is ok,george-roussos,25833833,2020-03-25T10:58:22Z,CONTRIBUTOR,False,26,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d93d2d07b0806604a44033dbd1510a6f5e7cb022,Add support for external embeddings
622,https://api.github.com/repos/mozilla/TTS/pulls/385,385,Add support for external embeddings,In the form of txt file. If it must be on the dev branch it is ok,george-roussos,25833833,2020-03-25T10:58:22Z,CONTRIBUTOR,False,26,4,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8538c1311c6183146dbc2d03a851c1f750fb40b0,Add support for external embeddings
623,https://api.github.com/repos/mozilla/TTS/pulls/384,384,reduce_tensor was being called on undeclared loss variables,I think all the losses are in the dictionary now?  These guys are being reduced before they are declared.,mittimithai,18408037,2020-03-13T03:14:34Z,CONTRIBUTOR,False,0,7,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,bc514a22a2c98f6ac1894db8c2b92fe33123cf0a,"Update train.py

I think all the losses are in the dictionary now?  These guys are being reduced before they are declared."
624,https://api.github.com/repos/mozilla/TTS/pulls/380,380,Add detailed build instructions,"Make a single and complete list of steps how to get to a working build with self-build source and a per-generated model, and which model to get.",benbucksch,1907525,2020-03-10T19:31:51Z,NONE,False,21,4,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4a90ee39a6e43115b850f06e47301faa2ec89cbf,Add detailed build instructions
625,https://api.github.com/repos/mozilla/TTS/pulls/380,380,Add detailed build instructions,"Make a single and complete list of steps how to get to a working build with self-build source and a per-generated model, and which model to get.",benbucksch,1907525,2020-03-10T19:31:51Z,NONE,False,21,4,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e9213fc7278d1e46321e56fb23b839ef6eb9fc6a,Fix link
626,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,57cbb3ab0c3792e055d55b1de47a9145ad793ba7,config update for guided attention and normalization
627,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d83b58e35d0018a6acef3ad739af69986bb1c9d9,TTS Loss aggregated all loss functuons
628,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,796a59d0ccdbea791e2a72040904870ee81c7085,Rename in-mel-spec
629,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,032bf312c6ee5c443061d4e4453d5e48e936c958,update train.py for guided attention
630,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a2e900ef3bffceac4bf6d7d92e4a23ca0ee8c5ed,formatting audio.py
631,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e97bb45abae249b28004f635cd95f38a20de9f28,bug fixes and fixing unit tests
632,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,669a2e1d7320d5f11e726af5a90a269ab7f442b9,linter fixes
633,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,975842f71ad4ea11e26b554b4824a9321a53e28b,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
634,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,201f04d3b3787d6f813f729962ad3c8be881a9fe,dropout graves attention heads to decorrelate and prevent overpowering of a single head
635,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,912cfb206848701630ea98565d363384606e4a66,add template config and remove de sentences
636,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cbcdec83da59453644a7f518d6c9a7c8dd5c8b3f,remove redundant files
637,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3472a41255f02a9ac367e617f94183bc1811f623,"make it optional to load linear specs in dataloader and fix tests
respectively"
638,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2a15e391669f9073ba10ef7ff20bb54ec5246977,bug fix and run desc in tensorboard
639,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c5540d80cc4e8918a93833d389c2a83ddf98afca,bug fix
640,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,871588c3918ee864e690a3df4a68c2a99023ee2e,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
641,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,069c8e43151f332cde6c7a9ce795e8238a7bb97e,update compute_statistics.py
642,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0ee1dd54a377e2062fd98141410f26a75ddcc213,config update for mean-var scaling
643,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,141797b6ae44aa714adc70974c40204e0d4fa861,write model description to tensorboard
644,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,acccac72f5ffa8aa199dc49858fef7cfb64003c2,update test attention notebooks
645,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d1e9f8dff1845c3871f59c91bd0cfc98ab8f4b6d,testing mean-var scalingand updating test config
646,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,92ebec01b150bf018555c1b0dc9763ee24781d35,changes of audio.py for mean-vat scaling
647,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d7cf34ca34ff55a95b63d657470cba1611eea1b7,StandardScaler added
648,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3bbeb43f5770adf1fb310c24bba2fd017b3a79c7,visualization updates wrt mean-var scaling
649,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2a903888c1db598048ba79333461fd83071bad3f,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
650,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,568c743632a342ce2f9f420190f72161d7621f84,update compute_statistics.py
651,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,25bcbe28879ee578ca21b32b46d3ea3c648499f5,config update for mean-var scaling
652,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,40cb4a53a67fac2b13256b27acfa00ad2baba3f8,update test attention notebooks
653,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,52b0dc39a64053a718422184e665fca13e5c8b94,testing mean-var scalingand updating test config
654,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cef9f06887fb0c7819fea68ec203d3d3dbf564c4,changes of audio.py for mean-vat scaling
655,https://api.github.com/repos/mozilla/TTS/pulls/379,379,[WIP] v0.0.2,"- [x] guided attention
   - guided attention is a method adding a new loss function penalizing attention alignments that are not diagonal.
- [x] aggregate all TTS losses in as single function
- [x] better and more flexible console logging
   - all loss values are automatically parsed and printed at training time. It provides flexibility for trying new things.
- [x] mean-var normalization
   - You can now compute mean and variance of a target dataset and use these to normalize spectrograms. All previous normalization methods are still available.
    - **USAGE:** Mean and variance need to be computed in advance by ```compute_statistics.py```. The output of this script needs to be given in ```config.json``` under ```stats_path```. If this is provided in ```config.json```, all other normalization arguments are ignored and only mean-var normalization is used. Audio parameters used to compute mean and variance have to be the same as the values used in your training. Otherwise, this will cause an error.
- [x] Bug fixes for distributed training.
- [x] Tensorflow 2 model and conversion script
    - TF related objects and codes are released under ```tf``` folder.
    - This enables conversion of Torch TTS models to Tensorflow (>= 2.2).
    - This conversion script only works Torch models trained after commit ```6ccf32c ```.

",erogol,1402048,2020-03-10T10:36:39Z,CONTRIBUTOR,True,2640,1602,57,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,77f36b65b86042585617212e336b2f371985b0cb,StandardScaler added
656,https://api.github.com/repos/mozilla/TTS/pulls/375,375,added use_griffin_lim = True,"I think this needs to be here, synth will produce errors on 'wav is None' otherwise.",mittimithai,18408037,2020-03-07T00:58:40Z,CONTRIBUTOR,False,2,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fe544ed85994d09d378a2e9f01a4557effc4c4cc,"added use_griffin_lim = True

I think this needs to be here, synth will produce errors on 'wav is None' otherwise."
657,https://api.github.com/repos/mozilla/TTS/pulls/371,371,add text parameters in config.json,Added suggestion for [issue 355](https://github.com/mozilla/TTS/issues/355).,Edresson,28763586,2020-03-01T19:22:11Z,CONTRIBUTOR,True,196,60,18,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8feb326a60fce455ba439d4e1fb7bf0e66642bd4,add text parameters in config.json
658,https://api.github.com/repos/mozilla/TTS/pulls/371,371,add text parameters in config.json,Added suggestion for [issue 355](https://github.com/mozilla/TTS/issues/355).,Edresson,28763586,2020-03-01T19:22:11Z,CONTRIBUTOR,True,196,60,18,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,59e2752107162b7b6060c3096d24c16a3cbbd0b3,fix travis unit test errors
659,https://api.github.com/repos/mozilla/TTS/pulls/371,371,add text parameters in config.json,Added suggestion for [issue 355](https://github.com/mozilla/TTS/issues/355).,Edresson,28763586,2020-03-01T19:22:11Z,CONTRIBUTOR,True,196,60,18,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4e53896438b5365269e54dae999b6ddab837b0c4,fix travis lint check
660,https://api.github.com/repos/mozilla/TTS/pulls/371,371,add text parameters in config.json,Added suggestion for [issue 355](https://github.com/mozilla/TTS/issues/355).,Edresson,28763586,2020-03-01T19:22:11Z,CONTRIBUTOR,True,196,60,18,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,36235c5e3fc0f47c56253a99941fc769d744469d,rename text to characters in config.json
661,https://api.github.com/repos/mozilla/TTS/pulls/371,371,add text parameters in config.json,Added suggestion for [issue 355](https://github.com/mozilla/TTS/issues/355).,Edresson,28763586,2020-03-01T19:22:11Z,CONTRIBUTOR,True,196,60,18,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7ffc1025424e49e40a2b325892d359a3fe21b68c,add unittest for vocabulary parameters
662,https://api.github.com/repos/mozilla/TTS/pulls/370,370,add text parameters in config.json,Added suggestion for [issue 355](https://github.com/mozilla/TTS/issues/355).,Edresson,28763586,2020-02-29T19:29:27Z,CONTRIBUTOR,False,119,29,14,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2541b7014a83025e805bf2e39380e49ea4d2e947,add text parameters in config.json
663,https://api.github.com/repos/mozilla/TTS/pulls/364,364,Restore regular command line capability,"Recent changes to use server.py appear to have broken the ability to run it from the command line. This change should (I believe) restore that ability, whilst (I hope) not interfering with usage for people who have installed a model package.",nmstoker,3694484,2020-02-24T23:14:47Z,CONTRIBUTOR,False,1,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5de4d4da68a0a42c0c4c797a3f829548549be882,"Restore regular command line capability

Recent changes to use server.py appear to have broken the ability to run it from the command line. This change should (I believe) restore that ability (whilst, I hope) not interfering with usage for people who have installed a model package."
664,https://api.github.com/repos/mozilla/TTS/pulls/362,362,Update server README to include h5py package,Signed-off-by: Alex Robbins <alex.robbins@emc.com>,kaleo211,2776475,2020-02-21T16:31:08Z,NONE,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a5d3e727e7eb64109b246f49601b8d0b60fe2806,"Update server README to include h5py package

Signed-off-by: Alex Robbins <alex.robbins@emc.com>"
665,https://api.github.com/repos/mozilla/TTS/pulls/353,353,Fix GL overriding PWGAN inference,,richardburleigh,11144777,2020-02-15T03:49:00Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,02df28c7d6059afa31d615a6f24eb27b7c017cff,Fix GL overriding PWGAN inference
666,https://api.github.com/repos/mozilla/TTS/pulls/352,352,"Load embedded vocoder models if present, and use PWGAN if available in Synthesizer.tts",,reuben,477142,2020-02-13T15:03:54Z,MEMBER,True,45,31,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,02e6d0538272f589d6c3c290b81575b7bd866991,Use PWGAN if available in Synthesizer.tts
667,https://api.github.com/repos/mozilla/TTS/pulls/352,352,"Load embedded vocoder models if present, and use PWGAN if available in Synthesizer.tts",,reuben,477142,2020-02-13T15:03:54Z,MEMBER,True,45,31,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b539ffafc0a0c185438bab262719f4259b6c8f9f,Load PWGAN/WaveRNN embedded files if present
668,https://api.github.com/repos/mozilla/TTS/pulls/352,352,"Load embedded vocoder models if present, and use PWGAN if available in Synthesizer.tts",,reuben,477142,2020-02-13T15:03:54Z,MEMBER,True,45,31,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,995eb1bf074caae257a87f5ef54ae5f63617b227,Fix bug where sometimes the second sentence disappears if it doesn't end with punctuation
669,https://api.github.com/repos/mozilla/TTS/pulls/352,352,"Load embedded vocoder models if present, and use PWGAN if available in Synthesizer.tts",,reuben,477142,2020-02-13T15:03:54Z,MEMBER,True,45,31,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ffd00ce295e8b68e59dccda99bc467823a62940d,Fix linter and server package test
670,https://api.github.com/repos/mozilla/TTS/pulls/349,349,Fix vocoder normalization when no vocoder is used,"When G&L is used, ap_vocoder is None and crashes",m-toman,9433378,2020-02-07T10:09:01Z,CONTRIBUTOR,True,3,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,631fbdcb8e158733b4ec1c9996c6c7cc105cd114,"Fix vocoder normalization when no vocoder is used

When G&L is used, ap_vocoder is None and crashes"
671,https://api.github.com/repos/mozilla/TTS/pulls/349,349,Fix vocoder normalization when no vocoder is used,"When G&L is used, ap_vocoder is None and crashes",m-toman,9433378,2020-02-07T10:09:01Z,CONTRIBUTOR,True,3,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3f54c39b0a4bb4678aec99a2e6b13b825387d712,Pacify pylint
672,https://api.github.com/repos/mozilla/TTS/pulls/349,349,Fix vocoder normalization when no vocoder is used,"When G&L is used, ap_vocoder is None and crashes",m-toman,9433378,2020-02-07T10:09:01Z,CONTRIBUTOR,True,3,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8f37ea9b84c556440c0fca3c7682f101be03cb0a,Pacify pylint even more
673,https://api.github.com/repos/mozilla/TTS/pulls/344,344,Adapting server to ParallelWaveGAN,,erogol,1402048,2020-02-04T16:35:50Z,CONTRIBUTOR,True,54,22,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,542141c9783c2f7445827460fb00f5c63ace0c61,set silence trimming threshold in config
674,https://api.github.com/repos/mozilla/TTS/pulls/344,344,Adapting server to ParallelWaveGAN,,erogol,1402048,2020-02-04T16:35:50Z,CONTRIBUTOR,True,54,22,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9feec72d44a59fdaea7d5af0b66e97c762a56f7b,tacotron2 stop condition
675,https://api.github.com/repos/mozilla/TTS/pulls/344,344,Adapting server to ParallelWaveGAN,,erogol,1402048,2020-02-04T16:35:50Z,CONTRIBUTOR,True,54,22,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9809fda14419f7f6ec2bfb03e0d68b4bc6a23f78,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
676,https://api.github.com/repos/mozilla/TTS/pulls/344,344,Adapting server to ParallelWaveGAN,,erogol,1402048,2020-02-04T16:35:50Z,CONTRIBUTOR,True,54,22,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5c78816f5181a743dc46df3a0ee1746207a57da9,update server and synthesizer to handle ParallelWaveGAN
677,https://api.github.com/repos/mozilla/TTS/pulls/344,344,Adapting server to ParallelWaveGAN,,erogol,1402048,2020-02-04T16:35:50Z,CONTRIBUTOR,True,54,22,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,61bdb265540321889a3e959676a0995842833562,README update
678,https://api.github.com/repos/mozilla/TTS/pulls/344,344,Adapting server to ParallelWaveGAN,,erogol,1402048,2020-02-04T16:35:50Z,CONTRIBUTOR,True,54,22,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2a6bce31cb41fb365c5d5f605bb1084ff49f1b5f,update server test
679,https://api.github.com/repos/mozilla/TTS/pulls/344,344,Adapting server to ParallelWaveGAN,,erogol,1402048,2020-02-04T16:35:50Z,CONTRIBUTOR,True,54,22,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,451f7da6980301820402b82d502b29976fd6ca31,pylint check
680,https://api.github.com/repos/mozilla/TTS/pulls/343,343,Only use embedded model files if they're not overriden by CLI flags,,reuben,477142,2020-02-04T10:17:19Z,MEMBER,True,20,15,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,57e7c1de08c527dbd97dddfe9804d7de969739cd,Only use embedded model files if they're not overriden by CLI flags
681,https://api.github.com/repos/mozilla/TTS/pulls/341,341,Added espeak to Dockerfile,Had issue where espeak was not installed in the docker container. This fixes it.,jcc10,1398636,2020-01-17T04:14:53Z,NONE,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b1b330b7617b0c921462f0ddaec3ce465d771ccd,Added espeak to Dockerfile
682,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5e148038be5971f2c7c811d46a1d7b28c759ecda,simpler gmm attention implementaiton
683,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e5bf2719bdfd23be8c118276c1009853d1b146ca,graves attention as in melnet paper
684,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3d59e61c6025f077cb0bc9d44dc830f83656080b,graves v2
685,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,04ba700b1f5d9af3be7d33bf10dbdd69e188592f,seq_len_norm for imbalanced datasets
686,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6fd61e82b0965381cb6905b57ebf5048f641e71e,seq_len_norm set in config
687,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3af989643b16a36c182e614461bf301489028293,bug fix for losses
688,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a391a7f859463744d7f67d42f2e475945cd91336,stop dividing g_t with sig_t and commenting
689,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,eb63c95d979a0156af95122479d92c2ebf3609e1,bug fixes
690,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a77f6e5d9160f6c7d0fcb5b6d35039072b778965,Merge branch 'graves-discretev2' into dev
691,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7a616aa9ef85fa4833eff6b78fd8e155a152a002,remove old graves
692,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f4678cbd6bd9281957a35627d26bd96b307fa04a,testing seq_len_norm
693,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9d669d1024e554d3460963c7a31a94810dd2f442,bug fix
694,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,542141c9783c2f7445827460fb00f5c63ace0c61,set silence trimming threshold in config
695,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9feec72d44a59fdaea7d5af0b66e97c762a56f7b,tacotron2 stop condition
696,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,57e7c1de08c527dbd97dddfe9804d7de969739cd,Only use embedded model files if they're not overriden by CLI flags
697,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9809fda14419f7f6ec2bfb03e0d68b4bc6a23f78,Merge branch 'dev' of https://github.com/mozilla/TTS into dev
698,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,20a6ab3d612eea849a49801d365fcd071839b7a1,"Merge pull request #343 from reuben/server-override-flags

Only use embedded model files if they're not overriden by CLI flags"
699,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5c78816f5181a743dc46df3a0ee1746207a57da9,update server and synthesizer to handle ParallelWaveGAN
700,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,61bdb265540321889a3e959676a0995842833562,README update
701,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2a6bce31cb41fb365c5d5f605bb1084ff49f1b5f,update server test
702,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,451f7da6980301820402b82d502b29976fd6ca31,pylint check
703,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,631fbdcb8e158733b4ec1c9996c6c7cc105cd114,"Fix vocoder normalization when no vocoder is used

When G&L is used, ap_vocoder is None and crashes"
704,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3f54c39b0a4bb4678aec99a2e6b13b825387d712,Pacify pylint
705,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8f37ea9b84c556440c0fca3c7682f101be03cb0a,Pacify pylint even more
706,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2996d631457388be3970ec742447d30cd1bc03f0,config fixes and enable graves attention wq
707,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6ee7653fcf8e81d47c0114d9057d3fe070aa83e7,Notebook for PWGAN vocoder
708,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c553c7ecd42e8dab2cf55e4dff127b1ee776b035,use decorater for torch.no_grad
709,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,566c2a4678856d23d1cce4b22ff1a960855d315a,add torch.no_grad decorator for inference
710,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,78464f1eada09f2332194bc004f2a98c138997cf,linter fix
711,https://api.github.com/repos/mozilla/TTS/pulls/338,338,Dev,"*    sequence length based loss normalization
*    ParallelWaveGAN integration https://github.com/erogol/ParallelWaveGAN
*    Enable loading PWGAN model with the server.py 
* Discrete Graves Attention which provides more reliable performance.
* Release new LJSpeech model
    * Tacotron2 with forward attention
    * Tacotron2 with Discreete Graves attention
    * Parallel WaveGAN model trained on Ground-Truth spectrograms
    * MelGAN (Generator) trained with Ground-Truth spectrograms.
* Checking config.json values.
* Set a custom charset in the config file (thx @Edresson)
* Phonemizer updates wrt versions 2.1 and 2.2",erogol,1402048,2020-01-15T11:57:46Z,CONTRIBUTOR,True,1412,369,33,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4130674e46b5f5be8bc751c95e0ee0cf72c9f96c,update for phonemizer 2.1
712,https://api.github.com/repos/mozilla/TTS/pulls/331,331,Corrected GMMv2b attention model,"Per discussion on discourse forum, this is the corrected implementation of GMMv2b model. I also cleaned up code by using parametrized ranges. ",geneing,10255558,2020-01-06T02:38:18Z,CONTRIBUTOR,True,7,6,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,20b4211af54f68415f24717bbaaf8415b94196f1,Change to GMMv2b
713,https://api.github.com/repos/mozilla/TTS/pulls/331,331,Corrected GMMv2b attention model,"Per discussion on discourse forum, this is the corrected implementation of GMMv2b model. I also cleaned up code by using parametrized ranges. ",geneing,10255558,2020-01-06T02:38:18Z,CONTRIBUTOR,True,7,6,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,34e0291ba798110e66dd3ae9faf0a885513f1045,Change to GMMv2b
714,https://api.github.com/repos/mozilla/TTS/pulls/331,331,Corrected GMMv2b attention model,"Per discussion on discourse forum, this is the corrected implementation of GMMv2b model. I also cleaned up code by using parametrized ranges. ",geneing,10255558,2020-01-06T02:38:18Z,CONTRIBUTOR,True,7,6,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,748cbbc4039d5ec14e961235e58fbcc56b62cb05,Change to GMMv2b
715,https://api.github.com/repos/mozilla/TTS/pulls/327,327,Server fix without breaking uWSGI ,@erogol does this solve your problem?,reuben,477142,2019-12-11T13:41:11Z,MEMBER,True,7,5,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e2e92b63d59279e1ad38687660f4bd9f5daf7c2c,"load model checkpoint on cpu, set 'r' for all models with gradual training enabled for all"
716,https://api.github.com/repos/mozilla/TTS/pulls/327,327,Server fix without breaking uWSGI ,@erogol does this solve your problem?,reuben,477142,2019-12-11T13:41:11Z,MEMBER,True,7,5,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,856e87a6a88c823dc34f28fd5e7fddaeafbc0ba6,Override checkpoint and config with CLI args if present
717,https://api.github.com/repos/mozilla/TTS/pulls/326,326,Fix server,"- use given arguments, if they are defined in server.py 
- bug fix regarding gradual training ",erogol,1402048,2019-12-10T10:23:55Z,CONTRIBUTOR,False,15,32,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c5e8e06874bfbae9bf1ead8580e5e71b68d97c0f,use default model path if args are not given
718,https://api.github.com/repos/mozilla/TTS/pulls/326,326,Fix server,"- use given arguments, if they are defined in server.py 
- bug fix regarding gradual training ",erogol,1402048,2019-12-10T10:23:55Z,CONTRIBUTOR,False,15,32,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a0d9a8f660673b1bdf138e10a4a724f427e30bbe,"load model checkpoint on cpu, set 'r' for all models with gradual training enabled for all"
719,https://api.github.com/repos/mozilla/TTS/pulls/326,326,Fix server,"- use given arguments, if they are defined in server.py 
- bug fix regarding gradual training ",erogol,1402048,2019-12-10T10:23:55Z,CONTRIBUTOR,False,15,32,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,077cddd40e645b0d3a41b9a9b564d8d12557bb9f,reuben fix
720,https://api.github.com/repos/mozilla/TTS/pulls/326,326,Fix server,"- use given arguments, if they are defined in server.py 
- bug fix regarding gradual training ",erogol,1402048,2019-12-10T10:23:55Z,CONTRIBUTOR,False,15,32,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,696bba46e790e929780d9cc24a0c69f2379556e7,reuben fix
721,https://api.github.com/repos/mozilla/TTS/pulls/326,326,Fix server,"- use given arguments, if they are defined in server.py 
- bug fix regarding gradual training ",erogol,1402048,2019-12-10T10:23:55Z,CONTRIBUTOR,False,15,32,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6fa586e31d0bbfa23fdffbffc5f30100853e0347,linter fix
722,https://api.github.com/repos/mozilla/TTS/pulls/325,325,Fix README instructions and add docs on how to create package,,reuben,477142,2019-12-09T16:26:29Z,MEMBER,True,23,13,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a0f72decb738a4adde90bce08604a3f2e2072518,Fix README instructions and add docs on how to create package
723,https://api.github.com/repos/mozilla/TTS/pulls/322,322,Corrected Typo error, prunning ->model pruning,anand-371,40825655,2019-12-01T07:57:23Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,464a3bc46d211624972e20e81cb7fce5b845e2a9,"Corrected Typo error

 prunning ->model pruning"
724,https://api.github.com/repos/mozilla/TTS/pulls/319,319,wip,,intro23,20466064,2019-11-28T06:51:36Z,NONE,False,64,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,32a30c19e48b0a132e3db3904830bf83a70612ac,wip
725,https://api.github.com/repos/mozilla/TTS/pulls/317,317,Simple packaging option with model embedded in the wheel (Fixes #316),"The way this works is that when `setup.py` is called with arguments specifying a checkpoint file and config file, they get embedded in the package. When `server.py` runs, it looks for an available checkpoint and config at the predetermined location, and if it's there, it gets used.",reuben,477142,2019-11-27T16:25:24Z,MEMBER,True,169,48,10,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d62234e06e1195f21ee414f11b135054aa347200,Make running the server easier
726,https://api.github.com/repos/mozilla/TTS/pulls/317,317,Simple packaging option with model embedded in the wheel (Fixes #316),"The way this works is that when `setup.py` is called with arguments specifying a checkpoint file and config file, they get embedded in the package. When `server.py` runs, it looks for an available checkpoint and config at the predetermined location, and if it's there, it gets used.",reuben,477142,2019-11-27T16:25:24Z,MEMBER,True,169,48,10,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e89d62a7726064c5fa153fbdb64d7d9529d9eea9,Add integration test for server package
727,https://api.github.com/repos/mozilla/TTS/pulls/310,310,Add Bokeh interactive plotting,"Some small changes to **compute_embeddings.py** to allow it to work for single-speaker corpus based on LJSpeech style file arrangement where it'll read in files from a pipe-separated .csv too

Main change is **PlotUmapLibriTTS.ipynb** which now uses Bokeh for interactive plot of embeddings (either single speaker or multi-speaker), running a local server to enable playing the relevant wav file in the browser by clicking in the chart",nmstoker,3694484,2019-11-11T01:37:18Z,CONTRIBUTOR,True,632,71,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,58bf3244ac319d679ddec6ae8c393b7a02fee311,Add Bokeh interactive plotting
728,https://api.github.com/repos/mozilla/TTS/pulls/310,310,Add Bokeh interactive plotting,"Some small changes to **compute_embeddings.py** to allow it to work for single-speaker corpus based on LJSpeech style file arrangement where it'll read in files from a pipe-separated .csv too

Main change is **PlotUmapLibriTTS.ipynb** which now uses Bokeh for interactive plot of embeddings (either single speaker or multi-speaker), running a local server to enable playing the relevant wav file in the browser by clicking in the chart",nmstoker,3694484,2019-11-11T01:37:18Z,CONTRIBUTOR,True,632,71,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f8b883fabe19761747f9794122db66e39fdd54f0,Update README
729,https://api.github.com/repos/mozilla/TTS/pulls/310,310,Add Bokeh interactive plotting,"Some small changes to **compute_embeddings.py** to allow it to work for single-speaker corpus based on LJSpeech style file arrangement where it'll read in files from a pipe-separated .csv too

Main change is **PlotUmapLibriTTS.ipynb** which now uses Bokeh for interactive plot of embeddings (either single speaker or multi-speaker), running a local server to enable playing the relevant wav file in the browser by clicking in the chart",nmstoker,3694484,2019-11-11T01:37:18Z,CONTRIBUTOR,True,632,71,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e602534ed710a89426caa54725172cdcc0efabdc,Update README image
730,https://api.github.com/repos/mozilla/TTS/pulls/308,308,Remove restriction on matplotlib version,So far as I can tell the matplotlib version restriction (to 2.0.2) is not necessary and causes difficulties in conda (for me at least it triggers reinstallation of an older version which then fails to compile),nmstoker,3694484,2019-10-31T00:00:46Z,CONTRIBUTOR,True,12,7,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,83f73861bd89edd98fd0f17857be9cfdb0a5d9b8,"Merge pull request #258 from mozilla/dev

Dev"
731,https://api.github.com/repos/mozilla/TTS/pulls/308,308,Remove restriction on matplotlib version,So far as I can tell the matplotlib version restriction (to 2.0.2) is not necessary and causes difficulties in conda (for me at least it triggers reinstallation of an older version which then fails to compile),nmstoker,3694484,2019-10-31T00:00:46Z,CONTRIBUTOR,True,12,7,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fe38c26b86efaf1b3a1e0e85afc27344993b436e,Update README.md
732,https://api.github.com/repos/mozilla/TTS/pulls/308,308,Remove restriction on matplotlib version,So far as I can tell the matplotlib version restriction (to 2.0.2) is not necessary and causes difficulties in conda (for me at least it triggers reinstallation of an older version which then fails to compile),nmstoker,3694484,2019-10-31T00:00:46Z,CONTRIBUTOR,True,12,7,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,92b7bd1c85475aba43916e9a1a5cc5febdf75a5b,Spanish Dataset added
733,https://api.github.com/repos/mozilla/TTS/pulls/308,308,Remove restriction on matplotlib version,So far as I can tell the matplotlib version restriction (to 2.0.2) is not necessary and causes difficulties in conda (for me at least it triggers reinstallation of an older version which then fails to compile),nmstoker,3694484,2019-10-31T00:00:46Z,CONTRIBUTOR,True,12,7,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4ff2b2f6a6fc6c5bd7a3f35007d8f3c58a576fb4,"Update README.md

some typo errors which were identified:
integrade->integrate 
listenning->listening to"
734,https://api.github.com/repos/mozilla/TTS/pulls/308,308,Remove restriction on matplotlib version,So far as I can tell the matplotlib version restriction (to 2.0.2) is not necessary and causes difficulties in conda (for me at least it triggers reinstallation of an older version which then fails to compile),nmstoker,3694484,2019-10-31T00:00:46Z,CONTRIBUTOR,True,12,7,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3abf3a479c2a15f1fb96a3e65538ae3b061f0104,"Merge pull request #285 from anand372/master

Update README.md"
735,https://api.github.com/repos/mozilla/TTS/pulls/308,308,Remove restriction on matplotlib version,So far as I can tell the matplotlib version restriction (to 2.0.2) is not necessary and causes difficulties in conda (for me at least it triggers reinstallation of an older version which then fails to compile),nmstoker,3694484,2019-10-31T00:00:46Z,CONTRIBUTOR,True,12,7,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,50088cbf3ba60b139692fa1666bda9f116980cad,"Merge pull request #279 from mozilla/dev

merging dev branch"
736,https://api.github.com/repos/mozilla/TTS/pulls/308,308,Remove restriction on matplotlib version,So far as I can tell the matplotlib version restriction (to 2.0.2) is not necessary and causes difficulties in conda (for me at least it triggers reinstallation of an older version which then fails to compile),nmstoker,3694484,2019-10-31T00:00:46Z,CONTRIBUTOR,True,12,7,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7eb291cae64d5510f847af1d8216af4f2c6f4c2f,Update CODE_OF_CONDUCT.md
737,https://api.github.com/repos/mozilla/TTS/pulls/308,308,Remove restriction on matplotlib version,So far as I can tell the matplotlib version restriction (to 2.0.2) is not necessary and causes difficulties in conda (for me at least it triggers reinstallation of an older version which then fails to compile),nmstoker,3694484,2019-10-31T00:00:46Z,CONTRIBUTOR,True,12,7,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5ffd4e24ecc2bf07bc980591fb6b2b347e70cb7c,"Remove matplotlib version restriction

So far as I can tell the matplotlib version restriction (to 2.0.2) is not necessary and causes difficulties in conda (for me at least it triggers reinstallation of an older version which then fails to compile)"
738,https://api.github.com/repos/mozilla/TTS/pulls/308,308,Remove restriction on matplotlib version,So far as I can tell the matplotlib version restriction (to 2.0.2) is not necessary and causes difficulties in conda (for me at least it triggers reinstallation of an older version which then fails to compile),nmstoker,3694484,2019-10-31T00:00:46Z,CONTRIBUTOR,True,12,7,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,52e4f9940072db64a503c3056656376e9a2a5726,Update requirements.txt
739,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e83a4b07d2558a25b0ad84dea642385a61660bd6,"commention model outputs for tacotron, align outputs shapes of tacotron and tracotron2, merge bidirectional decoder"
740,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5a56a2c096b5d8b5da733092c1b18962a622544a,bug fixes for forward backward training and load_data for parsing data_loader
741,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,89ef71ead8ab347620b5b01522c8dd1afb29e92f,"bug fix tacotron2, decoder return order fixed"
742,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,002991ca1584a20449dd14d1cc0ac345b9c3d0be,"bug fixes, linter update and test updates"
743,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,60b6ec18fe332985fb088342dd8458c8b0b5a7de,bug fix for synthesis.py
744,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0e0d0345cdbde9e24de5b9eb6ed02032d81054dd,call truncated inference
745,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8f53f9fc8ffa81ccf6ede7ea73e0df4cf48cd822,bug fix
746,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,05f038880b1fdad7b2ec73738fc669562fec4af7,continuining training from where it is left off
747,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,06798c7b9bd550d6b4d7f60a5c64a783a1e457b2,fix test
748,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5ffd4e24ecc2bf07bc980591fb6b2b347e70cb7c,"Remove matplotlib version restriction

So far as I can tell the matplotlib version restriction (to 2.0.2) is not necessary and causes difficulties in conda (for me at least it triggers reinstallation of an older version which then fails to compile)"
749,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,52e4f9940072db64a503c3056656376e9a2a5726,Update requirements.txt
750,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9b6021318de4acb7246064f733d49f90c47de30a,conditional required args for train and distribute.py
751,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ec579d02a1c2536285f2f4e237382cb4feeb7a83,bug fix argparser
752,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5268c782dac82972a1d3de52625c88df95ecbbf9,"Merge pull request #308 from nmstoker/patch-1

Remove restriction on matplotlib version"
753,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6906adc39ee54b0f03eb60433847c5732b32fc88,speaker encoder implementation
754,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6a8aa42d87239220e0fe972763d346de74e3b732,Merge branch 'dev' of github.com:mozilla/TTS into dev
755,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b89d04c151a2c8f03a874208dd11f62d0553c44f,Update README.md
756,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c13e7f483a9f1c48770c94c4605bddfa21c3dcbd,commenting config.json
757,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8040ccc3b093add619f60c0a25334379a5aaa291,config edit
758,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,537cd66f27b0d39a7a44419f65a086d658362e17,reduce lr
759,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,58bf3244ac319d679ddec6ae8c393b7a02fee311,Add Bokeh interactive plotting
760,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f8b883fabe19761747f9794122db66e39fdd54f0,Update README
761,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e602534ed710a89426caa54725172cdcc0efabdc,Update README image
762,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,84d81b6579fe0e3fafc31549bad7bf6f6299a2a7,graves attention [WIP]
763,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,adf9ebd629abc21e0969db2a1c29f389b5301c9d,Graves attention and setting attn type by config.json
764,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b9e0faca98cf036c2c21d21b966381a29557080e,config update and bug fixes
765,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,695bf1a1f64399cc2eba83932869de57ddccc373,bug fix for illegal memory reach
766,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fb34c7b272f4a9a8b426af7ddeb8b80163bf698e,config and bug fix
767,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,926a4d36cedc9f53800f18196dbc27f80d9784c8,change tanh layer size for graves attention
768,https://api.github.com/repos/mozilla/TTS/pulls/307,307,Dev,"- bidirectional decoding (https://arxiv.org/abs/1907.09006), it provides more robust alignment, especially for hard datasets.
- some code refactoring
- continuing training from where it is left off without creating a new folder.
- Speaker encoding model as a subproject following https://arxiv.org/abs/1806.04558
- Release a pre-trained Speaker Encoder trained on LibriTTS.
- Graves Attention (It is more stable for some datasets) (thx @geneing )
- Speaker embedding visualization by @nmstoker 
- Easier server usage by @reuben 
- Fix memory overload for restoring a model.
- TestAttention notebook for testing model attention performance on 50 hard sentences.",erogol,1402048,2019-10-29T13:22:19Z,CONTRIBUTOR,True,2601,1057,53,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b904bc02d6a516968871a9c4df67e8d9624c9ded,config update and initial bias for graves attention
769,https://api.github.com/repos/mozilla/TTS/pulls/285,285,Update README.md,"some typo errors which were identified:
integrade->integrate 
listenning->listening to",anand-371,40825655,2019-09-22T14:07:32Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4ff2b2f6a6fc6c5bd7a3f35007d8f3c58a576fb4,"Update README.md

some typo errors which were identified:
integrade->integrate 
listenning->listening to"
770,https://api.github.com/repos/mozilla/TTS/pulls/283,283,Enable style prediction from text,"I implemented the method of predicting style tokens from text alone as described in ""Predicting Expressive Speaking Style From Text In End-To-End Speech Synthesis"". The method works, and the effect, while subtle, is that of a more expressive speech. 
",geneing,10255558,2019-09-16T19:24:51Z,CONTRIBUTOR,False,357,145,13,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,eab174d3980d6e46fde3704e418ecfc7aeac311d,"# Conflicts:
#	config.json
#	models/tacotrongst.py
#	train.py"
771,https://api.github.com/repos/mozilla/TTS/pulls/283,283,Enable style prediction from text,"I implemented the method of predicting style tokens from text alone as described in ""Predicting Expressive Speaking Style From Text In End-To-End Speech Synthesis"". The method works, and the effect, while subtle, is that of a more expressive speech. 
",geneing,10255558,2019-09-16T19:24:51Z,CONTRIBUTOR,False,357,145,13,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e2f7f28e3cfa383f5e5a4d3e6fc433587b4967d3,Cleanup
772,https://api.github.com/repos/mozilla/TTS/pulls/283,283,Enable style prediction from text,"I implemented the method of predicting style tokens from text alone as described in ""Predicting Expressive Speaking Style From Text In End-To-End Speech Synthesis"". The method works, and the effect, while subtle, is that of a more expressive speech. 
",geneing,10255558,2019-09-16T19:24:51Z,CONTRIBUTOR,False,357,145,13,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,40ba7172aa3b3d48e8673a5abd571c07e3dd57cf,"Update notebook

(cherry picked from commit 4f65b2907ee57194cadc281739cdb34131c69e8a)"
773,https://api.github.com/repos/mozilla/TTS/pulls/283,283,Enable style prediction from text,"I implemented the method of predicting style tokens from text alone as described in ""Predicting Expressive Speaking Style From Text In End-To-End Speech Synthesis"". The method works, and the effect, while subtle, is that of a more expressive speech. 
",geneing,10255558,2019-09-16T19:24:51Z,CONTRIBUTOR,False,357,145,13,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,47b42320517a8a4d5cfcd9ef6101db3ddba0d193,changing url for ranger submodule.
774,https://api.github.com/repos/mozilla/TTS/pulls/283,283,Enable style prediction from text,"I implemented the method of predicting style tokens from text alone as described in ""Predicting Expressive Speaking Style From Text In End-To-End Speech Synthesis"". The method works, and the effect, while subtle, is that of a more expressive speech. 
",geneing,10255558,2019-09-16T19:24:51Z,CONTRIBUTOR,False,357,145,13,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3d78a0e6bfbd943f00e182adb9a26804d8a902fa,Making lint happy.
775,https://api.github.com/repos/mozilla/TTS/pulls/283,283,Enable style prediction from text,"I implemented the method of predicting style tokens from text alone as described in ""Predicting Expressive Speaking Style From Text In End-To-End Speech Synthesis"". The method works, and the effect, while subtle, is that of a more expressive speech. 
",geneing,10255558,2019-09-16T19:24:51Z,CONTRIBUTOR,False,357,145,13,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ee34e23c81b8e6c672999fa2f3b3440510bdecd1,Making lint happy.
776,https://api.github.com/repos/mozilla/TTS/pulls/283,283,Enable style prediction from text,"I implemented the method of predicting style tokens from text alone as described in ""Predicting Expressive Speaking Style From Text In End-To-End Speech Synthesis"". The method works, and the effect, while subtle, is that of a more expressive speech. 
",geneing,10255558,2019-09-16T19:24:51Z,CONTRIBUTOR,False,357,145,13,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,826fe422427eb2f4bd43dc9398298657e29bb963,Making lint happy.
777,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,609d8efa69f3f6e089b5c5af7d167d290734514c,compute alignment diagonality score and encapsulate stats averaging with a class in traning
778,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d45d963dc11c37cafb4b86c73d81a18114342e2c,linter fix
779,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a1322530dfd63ec2b9433699b36a647774f9aaa5,integrade concatinative speker embedding to tacotron
780,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,14a4d1a061872622d992ec39369bd24a78e292cc,update TacotronGST and its test. Inherit it from Tacotron class
781,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6561013d286476624e3bffebdd394885f5e9a2d1,sum style tokesn with encoder outputs instead of concat
782,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1f4ec804b6b0cf8345f96397ff4ea7dc21245010,compute and add style tokens in gst
783,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8d3775a7d695cea3bc398eb3e84da9606184299a,Update  tacotron2 for gradual training and chnage the indexing of prenet nputs to  oick the last frame
784,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c8a548d375ae1679169eb429636fe8c356e30359,fix the debug
785,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e085c4757dcb7b2bf694f577ac125644d645bd9e,bug fix
786,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9a2bd7f9af6456abbb452eba0260fb3b67312405,fix for 2 dim memory tensor
787,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b0739e0e17788a425713807cb0be2c851bc47f5c,config
788,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7e5c20500b2d9697132d7ceca5dde0d6cf3110c2,compute
789,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e8d29613f1a1b52f437cf97cf57d45d59877c5a3,fix stop condition
790,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,98af061d2e38dc3ee2077a217d37398ea14fdbaa,"formatting, merge GST model with Tacotron"
791,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5b6b1f354d4b6032c814d23082f7c0828d907b30,add use_gst to enable global style token
792,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,113f5860b8f2dec2b3919af5e6754911a0854c5f,update benchmark notebook
793,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,23f6743ac9cf869679df8fa57faa62681ed3ebb9,fix synthesize.py
794,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,53d658fb74c06e16ba041fbe73bb75b19c268aef,formatting
795,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b76aaf8ad46a67da06b94fc86129f3dd426a32df,"skip weight decay for BN and biases, some formatting"
796,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8565c508e45ef52dd14887ef54b38ace8e2a1119,remove debug line
797,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,99d7f2a666f61dba206036dc457b6946765f834c,update set_weight_decay
798,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,acbafb456bdc460c5adeb7b1394d418f8f2f6758,"Weighting positive values for stopnet loss, change adam_weight_decay name"
799,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1fad04e31723edae9ef6af809b8d48191890c20a,load meta data function
800,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,64a01f584b1d8ad3de4434028c4579211de14f74,load_meta_data changes
801,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fc9af0ab3c0d9782bfb61079a509387eb248270c,bug fix for load__meta_data
802,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8dec2a9e95894891a72e98869185f5e39d78dd83,fix memory leak duee to diagonal alingmnet score
803,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0849e3c42ffddc89f34955ea3b7dc3dcc8e017f7,"sound normalization while reading, adapting get_Speaker for multiple datasets"
804,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fbfa20e3b39330dd7f40d9456318a0f57ae218bb,linter fix
805,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,53ec066733237dbc215b2aeb3a1a749ba2e9170f,replace zeros() with a better alternative
806,https://api.github.com/repos/mozilla/TTS/pulls/279,279,Dev,"- capsulate training stats with a class
- compute attention diagonality score in training.
- enable gradual training with Tacotron2
- fix bugs for Tacotron2
- merge GST model with Tacotron implementation (No more TacotronGST model)
- fix prenet bug in Tacotron2
- update synthesize.py.
- skip weight decay for rnns, BN and bias parameters
- apply positive class weighting for stopnet loss to balance out the class frequencies.",erogol,1402048,2019-09-11T08:42:29Z,CONTRIBUTOR,True,846,744,17,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2dcdc14ea6cdd56e31c7aeb4ce24ae07ccb7161c,UPDATE TRIM SILENCE
807,https://api.github.com/repos/mozilla/TTS/pulls/270,270,Adding better test sentences. Increasing decoder max steps.,Added two long sentences (from Hunchback of Notre Dame) that expose problems with attention. Increased max decoder steps to allow synthesizing longer sentences.,geneing,10255558,2019-09-02T05:41:45Z,CONTRIBUTOR,False,4,2,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fdc19f7fb0353596545afb1f96a1b2d72cc714dd,Adding longer test sentences that expose problems with attention layers. Increasing decoder steps to accommodate long sentences.
808,https://api.github.com/repos/mozilla/TTS/pulls/269,269,Fix installation by using an explicit symlink,"@JRMeyer @erogol never underestimate the power of hacks. With this patch I can do both `setup.py develop`/`pip install -e` and `setup.py install`/`pip install`. I also tested `python setup.py bdist_wheel`, and it works too. The important changes are:

 - Adding __init__.py to the root folder
 - tts_namespace with the symlink (see the README there for an explanation)
 - The setup.py changes

The rest of the changes are just adding `TTS.` to import lines.

@erogol This is more invasive than the previous change but it supports `pip install -e` which is a pretty important use case, and is still less invasive than actually moving all the code to a new subfolder. If this causes too much rebase pain, feel free to ignore this PR.",reuben,477142,2019-08-29T09:57:03Z,MEMBER,True,107,75,32,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3c5aeb5e22e7938aef41702eab8a1ee683209f75,Fix installation by using an explicit symlink
809,https://api.github.com/repos/mozilla/TTS/pulls/269,269,Fix installation by using an explicit symlink,"@JRMeyer @erogol never underestimate the power of hacks. With this patch I can do both `setup.py develop`/`pip install -e` and `setup.py install`/`pip install`. I also tested `python setup.py bdist_wheel`, and it works too. The important changes are:

 - Adding __init__.py to the root folder
 - tts_namespace with the symlink (see the README there for an explanation)
 - The setup.py changes

The rest of the changes are just adding `TTS.` to import lines.

@erogol This is more invasive than the previous change but it supports `pip install -e` which is a pretty important use case, and is still less invasive than actually moving all the code to a new subfolder. If this causes too much rebase pain, feel free to ignore this PR.",reuben,477142,2019-08-29T09:57:03Z,MEMBER,True,107,75,32,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,28644a717e8bd8fd9fce644b6874a216b6e2d20f,Fix tests
810,https://api.github.com/repos/mozilla/TTS/pulls/267,267,Fixed postnet for GST. Cleaned up.,"GST model was applying sigmoid to the output of the postnet. This doesn't match regular tacotron model. Sound generated by the GST branch was all wrong because of the extra sigmoid applied.

Removed extraneous edits from my previous commit. 
",geneing,10255558,2019-08-27T05:55:26Z,CONTRIBUTOR,True,2,3,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2563fb873eaaa54f6539012d1c7e9fad12fb474b,Fixed postnet for GST.
811,https://api.github.com/repos/mozilla/TTS/pulls/266,266,Use direct link for specifying phonemizer dependency,"Seems like dependency_links is broken due to https://xkcd.com/927/

This solution works for a cloned folder but not if you publish to PyPi, so we would need a better solution if we wanted to publish TTS.",reuben,477142,2019-08-26T14:39:38Z,MEMBER,True,1,3,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d9e56d2b4c4a0eb2c9d69f610c3dc628e52aaec3,Use direct link dependency for phonemizer
812,https://api.github.com/repos/mozilla/TTS/pulls/263,263,Fixed postnet for GST.,GST model was applying sigmoid to the output of the postnet. This doesn't match regular tacotron model. Sound generated by the GST branch was all wrong because of the extra sigmoid applied. ,geneing,10255558,2019-08-24T21:19:49Z,CONTRIBUTOR,False,98,15,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,23faf53a8c8c1a62f9cb43011be05b6ab5f6e483,Fixed postnet for GST.
813,https://api.github.com/repos/mozilla/TTS/pulls/263,263,Fixed postnet for GST.,GST model was applying sigmoid to the output of the postnet. This doesn't match regular tacotron model. Sound generated by the GST branch was all wrong because of the extra sigmoid applied. ,geneing,10255558,2019-08-24T21:19:49Z,CONTRIBUTOR,False,98,15,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,92136588848038e18a0d7ad69abc65091a792b25,Merge remote-tracking branch 'upstream/dev' into upstream_dev
814,https://api.github.com/repos/mozilla/TTS/pulls/263,263,Fixed postnet for GST.,GST model was applying sigmoid to the output of the postnet. This doesn't match regular tacotron model. Sound generated by the GST branch was all wrong because of the extra sigmoid applied. ,geneing,10255558,2019-08-24T21:19:49Z,CONTRIBUTOR,False,98,15,4,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d383b14f7f8061740f243091488aa5f1969d2424,Checkpoint
815,https://api.github.com/repos/mozilla/TTS/pulls/262,262,Make the project properly installable via setup.py by adding a 'TTS' namespace to all packages,Here's a less invasive attempt at fixing #261.,reuben,477142,2019-08-21T16:49:26Z,MEMBER,True,3,7,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,256dbe7c6587a23db2b328694f45477a665102c2,Add a TTS namespace to all packages in setup.py
816,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d47ba5d310377026f612bbe480c88be117c565a1,gradual traning with memory queue
817,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,721e781216e782722b2603fbed8b5e2fe265e0c1,config update
818,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f4eaec12648addb76b56e0c74faa3ddb4c60cad9,compute update
819,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f038b1aa3fd670b406d7ad6898a613e4870c6c60,new way of handling memory queue and enable/disable queuing in right/wrong conditions
820,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ee706b50f68896cfb20f5163455f09af364cf449,enalbe graudal training by config.json
821,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2bbb3f7a400b92780451caf12d6a4c7729b5302d,"don't use sigmoid output for tacotron, fix bug for memory queue handling, remove maxout"
822,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1827f77752c279e489a9fcee44f68d28b32d7412,demo server update
823,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,713b3df7924850713384f8574aa84a36dcdb70df,prompt data loade time per iteartion
824,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,78c3897599d415d9312f57d61fde715feacef595,"root path speaker matching

added data root path in speaker matching for mailabs, this way you don't need to start at the very bottom of the folder hierarchy if you want to explicitly define metafiles."
825,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,537879482dc31592f51fb8cae79919615091d49a,fixed config comment strings for attention parameters
826,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4c9fbeeaf81c2df8461fe5f35225ae9ecd0728a9,simplified folder variable
827,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d4045fd47b1dc5939d6100c9f8a2faf3863fc1fc,unused var
828,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,98edb7a4f8d7e99ab7dcdca036d27762f27e4dd9,renamed attention_rnn to query_rnn
829,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,82db35530f327afbaea99f249a23369faba30513,unused var
830,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fb7c5b1996532ccc5b214b9b6e462c574b037dbd,unused instance vars
831,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,468abc0872cb61cb694dc283dd75e8b0e12f4acb,Merge branch 'dev' of github.com:mozilla/TTS into patch-6
832,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5c17a3378977da1dd0934f0e6650af28e5e9dcb1,Merge branch 'dev' of github.com:mozilla/TTS into config_comments
833,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5db302179a64bc1d8e0f925ba183a47daebd33ee,Merge branch 'dev' of github.com:mozilla/TTS into attention_naming
834,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a6118564d578f314dfa787a80cc288dba2228dfa,renamed query_rnn back to attention_rnn
835,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,40f56f9b000bb03384ebe883c03380b260a6a205,simplified code for fwd attn
836,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f3dac0aa840a893f7222b6444d5bc7f5f40d623d,updating location attn after calculating fwd attention
837,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a77baefbebfe927ee4c467ef7bb568f643bfeabc,"Merge pull request #243 from twerkmeister/patch-6

root path speaker matching"
838,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0261ce79a6a043e8f530bc261e8b5fc6f464540b,"Merge pull request #244 from twerkmeister/config_comments

fixed config comment strings for attention parameters"
839,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4a23354d3c6c9941eb401ebfc4f4b5f154fb51af,stylewav for testing inference
840,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ab42396fbfbd647f8f7f67f660250d9f75219643,undo loc attn after fwd attn
841,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,11f9edd849e3f2bcaf4226553d76cba2fcf5f44a,Merge branch 'dev' of github.com:mozilla/TTS into stylemel_in_testing
842,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1edd9e1f3d8af775f667bba5c36719a084822db5,"Merge pull request #247 from twerkmeister/stylemel_in_testing

Stylemel in testing"
843,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,215eb014ca67b6945eaffaa6f8c0c5cfc9453536,enforce list append semantic; prevents numpy add
844,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,91acb1d1ecda7743b8ba48b451a7353a2c763f86,"Merge pull request #248 from twerkmeister/boseos-listappend

enforce list append semantic; prevents numpy add"
845,https://api.github.com/repos/mozilla/TTS/pulls/258,258,Dev,"- gradual training for Tacotron, that leads to faster convergence.
- a better way to handle memory queue for Tacotron
- lot's of refactoring and bug fixes by @twerkmeister 
- better style (TacotronGST) and speaker embedding (experimental)
- don't use sigmoid output for Tacotron.
- updates for pytorch 1.2
- server.py updates
- updated Benchmark.ipynb for gradual training.
- installation namespace fix by @reuben 
- exporting Tacotron model with LibTorch (experimental) by @reuben 
- fixing setup.py by @reuben
- switching to RADAM 
",erogol,1402048,2019-08-16T12:35:38Z,CONTRIBUTOR,True,796,561,51,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,69abea55d64cef6a8bda149cf1046577226d9e51,"Merge pull request #245 from twerkmeister/attention_naming

renamed attention_rnn to query_rnn"
846,https://api.github.com/repos/mozilla/TTS/pulls/257,257,fix normalization min val,"spectrogram normalization was using the wrong minimum value. In both linear- and mel spec generation `ref_level_db` is subtracted before normalizing, moving the lowest value - coming from `amp_to_db` and `min_level_db` - even lower. The result of this error is that either the spec is not properly normalized (e.g. interval `[-0.2, 1.0]` for `min_level_db=100` and `ref_level_db=20` instead of `[0,1]`, or clipping to interval `[0,1]` removes resolution of values.",twerkmeister,1107341,2019-08-08T08:29:44Z,CONTRIBUTOR,False,3,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,efb5f4af6be924306e5d7f34f3dd859009a6609b,"fix normalization min val

spectrogram normalization was using the wrong minimum value. In both linear- and mel spec generation `ref_level_db` is subtracted before normalizing, moving the lowest value - coming from `amp_to_db` and `min_level_db` - even lower. The result of this error is that either the spec is not properly normalized (e.g. interval `[-0.2, 1.0]` for `min_level_db=100` and `ref_level_db=20` instead of `[0,1]`, or clipping to interval `[0,1]` removes resolution of values."
847,https://api.github.com/repos/mozilla/TTS/pulls/257,257,fix normalization min val,"spectrogram normalization was using the wrong minimum value. In both linear- and mel spec generation `ref_level_db` is subtracted before normalizing, moving the lowest value - coming from `amp_to_db` and `min_level_db` - even lower. The result of this error is that either the spec is not properly normalized (e.g. interval `[-0.2, 1.0]` for `min_level_db=100` and `ref_level_db=20` instead of `[0,1]`, or clipping to interval `[0,1]` removes resolution of values.",twerkmeister,1107341,2019-08-08T08:29:44Z,CONTRIBUTOR,False,3,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ca279578207b7a958aa5ac3270cb484793e764b9,range fix
848,https://api.github.com/repos/mozilla/TTS/pulls/257,257,fix normalization min val,"spectrogram normalization was using the wrong minimum value. In both linear- and mel spec generation `ref_level_db` is subtracted before normalizing, moving the lowest value - coming from `amp_to_db` and `min_level_db` - even lower. The result of this error is that either the spec is not properly normalized (e.g. interval `[-0.2, 1.0]` for `min_level_db=100` and `ref_level_db=20` instead of `[0,1]`, or clipping to interval `[0,1]` removes resolution of values.",twerkmeister,1107341,2019-08-08T08:29:44Z,CONTRIBUTOR,False,3,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,af7f02aeaf2c62f01003f51963381185d928cd4b,proper normalization
849,https://api.github.com/repos/mozilla/TTS/pulls/257,257,fix normalization min val,"spectrogram normalization was using the wrong minimum value. In both linear- and mel spec generation `ref_level_db` is subtracted before normalizing, moving the lowest value - coming from `amp_to_db` and `min_level_db` - even lower. The result of this error is that either the spec is not properly normalized (e.g. interval `[-0.2, 1.0]` for `min_level_db=100` and `ref_level_db=20` instead of `[0,1]`, or clipping to interval `[0,1]` removes resolution of values.",twerkmeister,1107341,2019-08-08T08:29:44Z,CONTRIBUTOR,False,3,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ae082e1cb48fee22d1588726377b913f4239c63b,range is positive
850,https://api.github.com/repos/mozilla/TTS/pulls/257,257,fix normalization min val,"spectrogram normalization was using the wrong minimum value. In both linear- and mel spec generation `ref_level_db` is subtracted before normalizing, moving the lowest value - coming from `amp_to_db` and `min_level_db` - even lower. The result of this error is that either the spec is not properly normalized (e.g. interval `[-0.2, 1.0]` for `min_level_db=100` and `ref_level_db=20` instead of `[0,1]`, or clipping to interval `[0,1]` removes resolution of values.",twerkmeister,1107341,2019-08-08T08:29:44Z,CONTRIBUTOR,False,3,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e8bd3efded4b57d7e31792bdcfc6232187f3c75e,uniform/generic normalization again
851,https://api.github.com/repos/mozilla/TTS/pulls/255,255,generic phoneme cleaners,"The original `phoneme_cleaners` are not suited for German (or languages other than English) at all. For example, they remove German umlauts and replace numbers with their english equivalents. Since we are using espeak which is doing good work with the normalization already,  `phoneme_cleaners` shouldn't be doing much work. The specialized English version (now `phoneme_cleaners_en`) should have a better name to avoid confusion.

This change invalidates phoneme caches.",twerkmeister,1107341,2019-08-06T10:58:29Z,CONTRIBUTOR,False,6,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a2b3c0465a4ac813809023270c41bdbc80731640,"basic phoneme cleaners

The original phoneme cleaners are not suited for German (or languages other than English) at all. For example, they remove German umlauts and replace numbers with their english equivalents. Since we are using espeak which is doing good work with the normalization already,  `phoneme_cleaners` shouldn't be doing much work. The specialized English version should have that name to avoid confusion.

This change invalidates phoneme caches."
852,https://api.github.com/repos/mozilla/TTS/pulls/253,253,unified memory handling,"unified memory handling between tacotron 1 and 2:
* increased similarity/understandability between the two decoding procedures
* fewer side effects
* tacotron now has a memory_size parameter and value r can be adjusted in subsequent trainings
* prenet is applied at once for tacotron 1
* trainings and inference now work for r > memory_size",twerkmeister,1107341,2019-07-29T17:22:09Z,CONTRIBUTOR,False,127,87,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,35d3300d43e332684bdfbc0776f8432ea37484f1,unified memory handling
853,https://api.github.com/repos/mozilla/TTS/pulls/253,253,unified memory handling,"unified memory handling between tacotron 1 and 2:
* increased similarity/understandability between the two decoding procedures
* fewer side effects
* tacotron now has a memory_size parameter and value r can be adjusted in subsequent trainings
* prenet is applied at once for tacotron 1
* trainings and inference now work for r > memory_size",twerkmeister,1107341,2019-07-29T17:22:09Z,CONTRIBUTOR,False,127,87,5,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,76a4fb7893886628cadd436bf7850a276ea73951,truncated inference fix
854,https://api.github.com/repos/mozilla/TTS/pulls/252,252,fix memory queue,training was broken for `r < memory_size`,twerkmeister,1107341,2019-07-29T11:13:48Z,CONTRIBUTOR,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,29faaf2923d505c981ac2049dac3a66de339f8ca,"fix memory queue

training was broken for `r < memory_size`"
855,https://api.github.com/repos/mozilla/TTS/pulls/250,250,"gst as config variable, available for taco2","Turned usage of gst into a config variable instead of a model. This way it can be enabled and disabled instead of having a completely new model type. Also, made it possible to enable it for taco2",twerkmeister,1107341,2019-07-27T13:39:07Z,CONTRIBUTOR,False,98,137,13,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8fbe752f7599cde1fb0c7022c180e0bcbd0d513e,"gst as config variable, available for taco2"
856,https://api.github.com/repos/mozilla/TTS/pulls/250,250,"gst as config variable, available for taco2","Turned usage of gst into a config variable instead of a model. This way it can be enabled and disabled instead of having a completely new model type. Also, made it possible to enable it for taco2",twerkmeister,1107341,2019-07-27T13:39:07Z,CONTRIBUTOR,False,98,137,13,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,09e5a3dbc6c4d1e519cdbe0f4f185fe8a901d54d,rename use_gst
857,https://api.github.com/repos/mozilla/TTS/pulls/250,250,"gst as config variable, available for taco2","Turned usage of gst into a config variable instead of a model. This way it can be enabled and disabled instead of having a completely new model type. Also, made it possible to enable it for taco2",twerkmeister,1107341,2019-07-27T13:39:07Z,CONTRIBUTOR,False,98,137,13,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ca155a849550c0709d1c25a363b5adda1c839fb4,added config param to test config
858,https://api.github.com/repos/mozilla/TTS/pulls/248,248,enforce list append semantic; prevents numpy add,"in pad_with_eos_bos when sequence was a numpy array, the integer values for the bos and eos char would get added on top of the elements of the sequence. The intended effect, however, was appending the elements. Casting sequence to a list makes sure we always have the right semantics. ",twerkmeister,1107341,2019-07-26T11:43:51Z,CONTRIBUTOR,True,2,1,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,215eb014ca67b6945eaffaa6f8c0c5cfc9453536,enforce list append semantic; prevents numpy add
859,https://api.github.com/repos/mozilla/TTS/pulls/247,247,Stylemel in testing,"Optional config parameter to use style wav for testing inference. In my experience, training with GST but not supplying any style during inference breaks attention",twerkmeister,1107341,2019-07-25T11:25:35Z,CONTRIBUTOR,True,5,2,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4a23354d3c6c9941eb401ebfc4f4b5f154fb51af,stylewav for testing inference
860,https://api.github.com/repos/mozilla/TTS/pulls/247,247,Stylemel in testing,"Optional config parameter to use style wav for testing inference. In my experience, training with GST but not supplying any style during inference breaks attention",twerkmeister,1107341,2019-07-25T11:25:35Z,CONTRIBUTOR,True,5,2,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,11f9edd849e3f2bcaf4226553d76cba2fcf5f44a,Merge branch 'dev' of github.com:mozilla/TTS into stylemel_in_testing
861,https://api.github.com/repos/mozilla/TTS/pulls/245,245,renamed attention_rnn to query_rnn,"I renamed attention_rnn in Taco1 and Taco2 decoders to query_rnn to avoid the confusion with the attention layer. At least personally I had my head spinning distinguishing attention_rnn, attention_rnn_hidden, attention_layer, attention, etc.  

I think this naming change makes more clear that there is a part generating the query and then the attention part that uses the query. Especially since `attention_rnn_hidden` turned to `query` inside the attention layer at some point already.

Other changes that you should specifically look at:
1. In forward attention: moved the to_device to directly after the cloning, not after padding
2. in forward attention: removed the cloning where the alpha tensor is just multiplied with the u tensor
3. in tacotron - decoder - decode: removed the del statements. I believe this is not saving memory since a) you just created another reference beforehand without cloning, and b) the tensors have to be kept around for back prop. Also, invoking the garbage collector inside the training loop might cost performance",twerkmeister,1107341,2019-07-23T16:49:41Z,CONTRIBUTOR,True,104,100,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,98edb7a4f8d7e99ab7dcdca036d27762f27e4dd9,renamed attention_rnn to query_rnn
862,https://api.github.com/repos/mozilla/TTS/pulls/245,245,renamed attention_rnn to query_rnn,"I renamed attention_rnn in Taco1 and Taco2 decoders to query_rnn to avoid the confusion with the attention layer. At least personally I had my head spinning distinguishing attention_rnn, attention_rnn_hidden, attention_layer, attention, etc.  

I think this naming change makes more clear that there is a part generating the query and then the attention part that uses the query. Especially since `attention_rnn_hidden` turned to `query` inside the attention layer at some point already.

Other changes that you should specifically look at:
1. In forward attention: moved the to_device to directly after the cloning, not after padding
2. in forward attention: removed the cloning where the alpha tensor is just multiplied with the u tensor
3. in tacotron - decoder - decode: removed the del statements. I believe this is not saving memory since a) you just created another reference beforehand without cloning, and b) the tensors have to be kept around for back prop. Also, invoking the garbage collector inside the training loop might cost performance",twerkmeister,1107341,2019-07-23T16:49:41Z,CONTRIBUTOR,True,104,100,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,82db35530f327afbaea99f249a23369faba30513,unused var
863,https://api.github.com/repos/mozilla/TTS/pulls/245,245,renamed attention_rnn to query_rnn,"I renamed attention_rnn in Taco1 and Taco2 decoders to query_rnn to avoid the confusion with the attention layer. At least personally I had my head spinning distinguishing attention_rnn, attention_rnn_hidden, attention_layer, attention, etc.  

I think this naming change makes more clear that there is a part generating the query and then the attention part that uses the query. Especially since `attention_rnn_hidden` turned to `query` inside the attention layer at some point already.

Other changes that you should specifically look at:
1. In forward attention: moved the to_device to directly after the cloning, not after padding
2. in forward attention: removed the cloning where the alpha tensor is just multiplied with the u tensor
3. in tacotron - decoder - decode: removed the del statements. I believe this is not saving memory since a) you just created another reference beforehand without cloning, and b) the tensors have to be kept around for back prop. Also, invoking the garbage collector inside the training loop might cost performance",twerkmeister,1107341,2019-07-23T16:49:41Z,CONTRIBUTOR,True,104,100,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fb7c5b1996532ccc5b214b9b6e462c574b037dbd,unused instance vars
864,https://api.github.com/repos/mozilla/TTS/pulls/245,245,renamed attention_rnn to query_rnn,"I renamed attention_rnn in Taco1 and Taco2 decoders to query_rnn to avoid the confusion with the attention layer. At least personally I had my head spinning distinguishing attention_rnn, attention_rnn_hidden, attention_layer, attention, etc.  

I think this naming change makes more clear that there is a part generating the query and then the attention part that uses the query. Especially since `attention_rnn_hidden` turned to `query` inside the attention layer at some point already.

Other changes that you should specifically look at:
1. In forward attention: moved the to_device to directly after the cloning, not after padding
2. in forward attention: removed the cloning where the alpha tensor is just multiplied with the u tensor
3. in tacotron - decoder - decode: removed the del statements. I believe this is not saving memory since a) you just created another reference beforehand without cloning, and b) the tensors have to be kept around for back prop. Also, invoking the garbage collector inside the training loop might cost performance",twerkmeister,1107341,2019-07-23T16:49:41Z,CONTRIBUTOR,True,104,100,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5db302179a64bc1d8e0f925ba183a47daebd33ee,Merge branch 'dev' of github.com:mozilla/TTS into attention_naming
865,https://api.github.com/repos/mozilla/TTS/pulls/245,245,renamed attention_rnn to query_rnn,"I renamed attention_rnn in Taco1 and Taco2 decoders to query_rnn to avoid the confusion with the attention layer. At least personally I had my head spinning distinguishing attention_rnn, attention_rnn_hidden, attention_layer, attention, etc.  

I think this naming change makes more clear that there is a part generating the query and then the attention part that uses the query. Especially since `attention_rnn_hidden` turned to `query` inside the attention layer at some point already.

Other changes that you should specifically look at:
1. In forward attention: moved the to_device to directly after the cloning, not after padding
2. in forward attention: removed the cloning where the alpha tensor is just multiplied with the u tensor
3. in tacotron - decoder - decode: removed the del statements. I believe this is not saving memory since a) you just created another reference beforehand without cloning, and b) the tensors have to be kept around for back prop. Also, invoking the garbage collector inside the training loop might cost performance",twerkmeister,1107341,2019-07-23T16:49:41Z,CONTRIBUTOR,True,104,100,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a6118564d578f314dfa787a80cc288dba2228dfa,renamed query_rnn back to attention_rnn
866,https://api.github.com/repos/mozilla/TTS/pulls/245,245,renamed attention_rnn to query_rnn,"I renamed attention_rnn in Taco1 and Taco2 decoders to query_rnn to avoid the confusion with the attention layer. At least personally I had my head spinning distinguishing attention_rnn, attention_rnn_hidden, attention_layer, attention, etc.  

I think this naming change makes more clear that there is a part generating the query and then the attention part that uses the query. Especially since `attention_rnn_hidden` turned to `query` inside the attention layer at some point already.

Other changes that you should specifically look at:
1. In forward attention: moved the to_device to directly after the cloning, not after padding
2. in forward attention: removed the cloning where the alpha tensor is just multiplied with the u tensor
3. in tacotron - decoder - decode: removed the del statements. I believe this is not saving memory since a) you just created another reference beforehand without cloning, and b) the tensors have to be kept around for back prop. Also, invoking the garbage collector inside the training loop might cost performance",twerkmeister,1107341,2019-07-23T16:49:41Z,CONTRIBUTOR,True,104,100,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,40f56f9b000bb03384ebe883c03380b260a6a205,simplified code for fwd attn
867,https://api.github.com/repos/mozilla/TTS/pulls/245,245,renamed attention_rnn to query_rnn,"I renamed attention_rnn in Taco1 and Taco2 decoders to query_rnn to avoid the confusion with the attention layer. At least personally I had my head spinning distinguishing attention_rnn, attention_rnn_hidden, attention_layer, attention, etc.  

I think this naming change makes more clear that there is a part generating the query and then the attention part that uses the query. Especially since `attention_rnn_hidden` turned to `query` inside the attention layer at some point already.

Other changes that you should specifically look at:
1. In forward attention: moved the to_device to directly after the cloning, not after padding
2. in forward attention: removed the cloning where the alpha tensor is just multiplied with the u tensor
3. in tacotron - decoder - decode: removed the del statements. I believe this is not saving memory since a) you just created another reference beforehand without cloning, and b) the tensors have to be kept around for back prop. Also, invoking the garbage collector inside the training loop might cost performance",twerkmeister,1107341,2019-07-23T16:49:41Z,CONTRIBUTOR,True,104,100,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f3dac0aa840a893f7222b6444d5bc7f5f40d623d,updating location attn after calculating fwd attention
868,https://api.github.com/repos/mozilla/TTS/pulls/245,245,renamed attention_rnn to query_rnn,"I renamed attention_rnn in Taco1 and Taco2 decoders to query_rnn to avoid the confusion with the attention layer. At least personally I had my head spinning distinguishing attention_rnn, attention_rnn_hidden, attention_layer, attention, etc.  

I think this naming change makes more clear that there is a part generating the query and then the attention part that uses the query. Especially since `attention_rnn_hidden` turned to `query` inside the attention layer at some point already.

Other changes that you should specifically look at:
1. In forward attention: moved the to_device to directly after the cloning, not after padding
2. in forward attention: removed the cloning where the alpha tensor is just multiplied with the u tensor
3. in tacotron - decoder - decode: removed the del statements. I believe this is not saving memory since a) you just created another reference beforehand without cloning, and b) the tensors have to be kept around for back prop. Also, invoking the garbage collector inside the training loop might cost performance",twerkmeister,1107341,2019-07-23T16:49:41Z,CONTRIBUTOR,True,104,100,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ab42396fbfbd647f8f7f67f660250d9f75219643,undo loc attn after fwd attn
869,https://api.github.com/repos/mozilla/TTS/pulls/244,244,fixed config comment strings for attention parameters,comments in the config files were still stating that attention parameters only applied to Taco2 models although both taco1 and taco2 now have a shared attention layer,twerkmeister,1107341,2019-07-23T11:33:23Z,CONTRIBUTOR,True,26,26,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,537879482dc31592f51fb8cae79919615091d49a,fixed config comment strings for attention parameters
870,https://api.github.com/repos/mozilla/TTS/pulls/244,244,fixed config comment strings for attention parameters,comments in the config files were still stating that attention parameters only applied to Taco2 models although both taco1 and taco2 now have a shared attention layer,twerkmeister,1107341,2019-07-23T11:33:23Z,CONTRIBUTOR,True,26,26,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5c17a3378977da1dd0934f0e6650af28e5e9dcb1,Merge branch 'dev' of github.com:mozilla/TTS into config_comments
871,https://api.github.com/repos/mozilla/TTS/pulls/243,243,root path speaker matching,"added data root path in speaker matching for mailabs, this way you don't need to start at the very bottom of the folder hierarchy if you want to explicitly define metafiles.",twerkmeister,1107341,2019-07-23T07:48:15Z,CONTRIBUTOR,True,4,6,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,78c3897599d415d9312f57d61fde715feacef595,"root path speaker matching

added data root path in speaker matching for mailabs, this way you don't need to start at the very bottom of the folder hierarchy if you want to explicitly define metafiles."
872,https://api.github.com/repos/mozilla/TTS/pulls/243,243,root path speaker matching,"added data root path in speaker matching for mailabs, this way you don't need to start at the very bottom of the folder hierarchy if you want to explicitly define metafiles.",twerkmeister,1107341,2019-07-23T07:48:15Z,CONTRIBUTOR,True,4,6,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4c9fbeeaf81c2df8461fe5f35225ae9ecd0728a9,simplified folder variable
873,https://api.github.com/repos/mozilla/TTS/pulls/243,243,root path speaker matching,"added data root path in speaker matching for mailabs, this way you don't need to start at the very bottom of the folder hierarchy if you want to explicitly define metafiles.",twerkmeister,1107341,2019-07-23T07:48:15Z,CONTRIBUTOR,True,4,6,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d4045fd47b1dc5939d6100c9f8a2faf3863fc1fc,unused var
874,https://api.github.com/repos/mozilla/TTS/pulls/243,243,root path speaker matching,"added data root path in speaker matching for mailabs, this way you don't need to start at the very bottom of the folder hierarchy if you want to explicitly define metafiles.",twerkmeister,1107341,2019-07-23T07:48:15Z,CONTRIBUTOR,True,4,6,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,468abc0872cb61cb694dc283dd75e8b0e12f4acb,Merge branch 'dev' of github.com:mozilla/TTS into patch-6
875,https://api.github.com/repos/mozilla/TTS/pulls/239,239,Not using mix folder for mailabs data,"The mix folder contains datasets with more than 10 speakers internally. It is not useful for multi speaker training, since there are no annotations for the different speakers.",twerkmeister,1107341,2019-07-19T14:24:26Z,CONTRIBUTOR,True,5,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c613f8e66487cbf7735c1d4b8e199d891d9adc4a,Not using mix folder for mailabs data
876,https://api.github.com/repos/mozilla/TTS/pulls/238,238,fixed usage of bos&eos char with caching,"Previously the caching mechanism effectively overwrote the eos/bos config option. 

1. If a phoneme sequence had been cached without eos/bos, activating it would still give the cached sequence without eos/bos tokens. 
2. vice versa, if a phoneme sequence had been cached with eos/bos, disabling it would still give the cached sequence with eos/bos tokens.

This PR fixes this problem by never caching eos/bos tokens but adding these dynamically based on the config options after restoring the cached sequence.",twerkmeister,1107341,2019-07-19T14:17:24Z,CONTRIBUTOR,True,40,28,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f59543d1273f6cc5a19947fce98c1604de92f2e8,fixed usage of bos&eos char with caching
877,https://api.github.com/repos/mozilla/TTS/pulls/238,238,fixed usage of bos&eos char with caching,"Previously the caching mechanism effectively overwrote the eos/bos config option. 

1. If a phoneme sequence had been cached without eos/bos, activating it would still give the cached sequence without eos/bos tokens. 
2. vice versa, if a phoneme sequence had been cached with eos/bos, disabling it would still give the cached sequence with eos/bos tokens.

This PR fixes this problem by never caching eos/bos tokens but adding these dynamically based on the config options after restoring the cached sequence.",twerkmeister,1107341,2019-07-19T14:17:24Z,CONTRIBUTOR,True,40,28,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,116a21b659f9b560990bd46b38f5d6a81754489e,lint indentation
878,https://api.github.com/repos/mozilla/TTS/pulls/235,235,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as python -m unittest. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.",reuben,477142,2019-07-19T09:42:16Z,MEMBER,True,964,328,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,509292d56a3fbb0d4cdaffea8bbcce9fe2dc3ed4,"Add pylint and cardboardlinter config, enable Travis lint check on PRs"
879,https://api.github.com/repos/mozilla/TTS/pulls/235,235,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as python -m unittest. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.",reuben,477142,2019-07-19T09:42:16Z,MEMBER,True,964,328,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,11e789532905beb702b492432dc72b136a37587e,Fix Pylint issues
880,https://api.github.com/repos/mozilla/TTS/pulls/235,235,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as python -m unittest. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.",reuben,477142,2019-07-19T09:42:16Z,MEMBER,True,964,328,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4a24cff3a7559bf3aeaeedc7056ca2729a476dee,Add a job to run unit tests
881,https://api.github.com/repos/mozilla/TTS/pulls/235,235,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as python -m unittest. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.",reuben,477142,2019-07-19T09:42:16Z,MEMBER,True,964,328,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9a61dfa155086c78d8b5ffe3c6cd22a6fd457d23,Address additional lint problems
882,https://api.github.com/repos/mozilla/TTS/pulls/235,235,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as python -m unittest. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.",reuben,477142,2019-07-19T09:42:16Z,MEMBER,True,964,328,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,057a50a889d5166270afb195e906c5262b09e04a,Merge branch 'dev' into contribution-grease
883,https://api.github.com/repos/mozilla/TTS/pulls/235,235,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as python -m unittest. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.",reuben,477142,2019-07-19T09:42:16Z,MEMBER,True,964,328,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e3f841742d3f2c0a919f9f220d5286723d1cd082,Address even more lint problems
884,https://api.github.com/repos/mozilla/TTS/pulls/235,235,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as python -m unittest. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.",reuben,477142,2019-07-19T09:42:16Z,MEMBER,True,964,328,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a9c4b7cc4d489bdec88b016bfb1fd2b1f76ef303,Always fetch PR target branch before running tests
885,https://api.github.com/repos/mozilla/TTS/pulls/234,234,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as `python -m unittest`. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.

When fixing the Pylint issues I added some FIXME comments for things that were non-trivial to fix, so I can take a look after I get the automated builds working.",reuben,477142,2019-07-19T07:18:04Z,MEMBER,False,1005,361,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,509292d56a3fbb0d4cdaffea8bbcce9fe2dc3ed4,"Add pylint and cardboardlinter config, enable Travis lint check on PRs"
886,https://api.github.com/repos/mozilla/TTS/pulls/234,234,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as `python -m unittest`. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.

When fixing the Pylint issues I added some FIXME comments for things that were non-trivial to fix, so I can take a look after I get the automated builds working.",reuben,477142,2019-07-19T07:18:04Z,MEMBER,False,1005,361,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,11e789532905beb702b492432dc72b136a37587e,Fix Pylint issues
887,https://api.github.com/repos/mozilla/TTS/pulls/234,234,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as `python -m unittest`. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.

When fixing the Pylint issues I added some FIXME comments for things that were non-trivial to fix, so I can take a look after I get the automated builds working.",reuben,477142,2019-07-19T07:18:04Z,MEMBER,False,1005,361,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4a24cff3a7559bf3aeaeedc7056ca2729a476dee,Add a job to run unit tests
888,https://api.github.com/repos/mozilla/TTS/pulls/234,234,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as `python -m unittest`. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.

When fixing the Pylint issues I added some FIXME comments for things that were non-trivial to fix, so I can take a look after I get the automated builds working.",reuben,477142,2019-07-19T07:18:04Z,MEMBER,False,1005,361,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4336e1d33818b9f7a9d5757cacc6b5e5d7dc9db8,fix unittests for the latest updates
889,https://api.github.com/repos/mozilla/TTS/pulls/234,234,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as `python -m unittest`. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.

When fixing the Pylint issues I added some FIXME comments for things that were non-trivial to fix, so I can take a look after I get the automated builds working.",reuben,477142,2019-07-19T07:18:04Z,MEMBER,False,1005,361,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9a61dfa155086c78d8b5ffe3c6cd22a6fd457d23,Address additional lint problems
890,https://api.github.com/repos/mozilla/TTS/pulls/234,234,Add automated linter and unittest checks,"This adds a simple Travis config that should run cardboardlinter as well as `python -m unittest`. The linter is run on PRs only, and only on the changes made in that PR. Unit tests are run on all pushes.

When fixing the Pylint issues I added some FIXME comments for things that were non-trivial to fix, so I can take a look after I get the automated builds working.",reuben,477142,2019-07-19T07:18:04Z,MEMBER,False,1005,361,40,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,057a50a889d5166270afb195e906c5262b09e04a,Merge branch 'dev' into contribution-grease
891,https://api.github.com/repos/mozilla/TTS/pulls/231,231,quick fix for multi-speaker,"`synthesize.py` sends 2 args to `setup_model()`, but 3 are now needed

related to ba8cc8054b87779f78e5cc774f63476b2801df3b AFAIK",JRMeyer,8389864,2019-07-17T17:10:58Z,NONE,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,059f37a906052b07f246b26912968bd081a7b125,"quick fix for multi-speaker down stream

related to ba8cc8054b87779f78e5cc774f63476b2801df3b AFAIK"
892,https://api.github.com/repos/mozilla/TTS/pulls/230,230,default argument mailabs,,twerkmeister,1107341,2019-07-17T14:04:26Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7be11457e7edb06216033c821ea5a4339ab6a0e9,default argument mailabs
893,https://api.github.com/repos/mozilla/TTS/pulls/229,229,check for speaker id is None before put on cuda,,twerkmeister,1107341,2019-07-17T12:09:09Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ee4d55549dc866eb90372d26e3eaeee1ef68acdf,check for speaker id is None before put on cuda
894,https://api.github.com/repos/mozilla/TTS/pulls/228,228,use min and max seq length during eval,,twerkmeister,1107341,2019-07-17T10:11:27Z,CONTRIBUTOR,True,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,721345f1f24890d1aa5264759b65f09025c558e0,use min and max seq length during eval
895,https://api.github.com/repos/mozilla/TTS/pulls/227,227,Improvements for CheckSNR notebook,"* handling file paths with spaces
* handling multi channel audio in output
* macos build instructions for wada snr tool
* histrogram of snrs",twerkmeister,1107341,2019-07-12T12:30:11Z,CONTRIBUTOR,True,87,552,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f83b5d7fbb7221dbca9c98944aa3dac1437cf4d8,improvements CheckSNR
896,https://api.github.com/repos/mozilla/TTS/pulls/222,222,Multispeaker support,"Complete multispeaker support

Summary:
* Preprocessors now return tuples of text, wav file, speaker name
* in the main training loop, the speaker names are turned into speaker ids
* Speaker name to ID mapping is managed in the main training loop, and saved as `speakers.json` in the OUT_PATH. Thus it can be reused in between loops, for evaluation, inference, and for restoring a model for further training
* Models have an additional embedding for speakers that gets broadcasted and added on top of encoder outputs
* `num_speakers` is a new config variable. It doesn't need to be set to an exact value as long as the value is higher than the actual number of speakers.
* synthesis method has an additional parameter to define which speaker should be used",twerkmeister,1107341,2019-06-26T11:43:13Z,CONTRIBUTOR,True,380,134,19,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d172a3d3d5f74734f8e3ef074431a1b3ae57c804,multispeaker
897,https://api.github.com/repos/mozilla/TTS/pulls/222,222,Multispeaker support,"Complete multispeaker support

Summary:
* Preprocessors now return tuples of text, wav file, speaker name
* in the main training loop, the speaker names are turned into speaker ids
* Speaker name to ID mapping is managed in the main training loop, and saved as `speakers.json` in the OUT_PATH. Thus it can be reused in between loops, for evaluation, inference, and for restoring a model for further training
* Models have an additional embedding for speakers that gets broadcasted and added on top of encoder outputs
* `num_speakers` is a new config variable. It doesn't need to be set to an exact value as long as the value is higher than the actual number of speakers.
* synthesis method has an additional parameter to define which speaker should be used",twerkmeister,1107341,2019-06-26T11:43:13Z,CONTRIBUTOR,True,380,134,19,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,05ff8801d1591cc13a4ece52fadb59c5443d32ab,"config, benchmark notebook, synthesis fixed"
898,https://api.github.com/repos/mozilla/TTS/pulls/222,222,Multispeaker support,"Complete multispeaker support

Summary:
* Preprocessors now return tuples of text, wav file, speaker name
* in the main training loop, the speaker names are turned into speaker ids
* Speaker name to ID mapping is managed in the main training loop, and saved as `speakers.json` in the OUT_PATH. Thus it can be reused in between loops, for evaluation, inference, and for restoring a model for further training
* Models have an additional embedding for speakers that gets broadcasted and added on top of encoder outputs
* `num_speakers` is a new config variable. It doesn't need to be set to an exact value as long as the value is higher than the actual number of speakers.
* synthesis method has an additional parameter to define which speaker should be used",twerkmeister,1107341,2019-06-26T11:43:13Z,CONTRIBUTOR,True,380,134,19,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,765597e983653b10f35921048b287d5814fe5f98,proper error message for when num_speakers is set too low
899,https://api.github.com/repos/mozilla/TTS/pulls/222,222,Multispeaker support,"Complete multispeaker support

Summary:
* Preprocessors now return tuples of text, wav file, speaker name
* in the main training loop, the speaker names are turned into speaker ids
* Speaker name to ID mapping is managed in the main training loop, and saved as `speakers.json` in the OUT_PATH. Thus it can be reused in between loops, for evaluation, inference, and for restoring a model for further training
* Models have an additional embedding for speakers that gets broadcasted and added on top of encoder outputs
* `num_speakers` is a new config variable. It doesn't need to be set to an exact value as long as the value is higher than the actual number of speakers.
* synthesis method has an additional parameter to define which speaker should be used",twerkmeister,1107341,2019-06-26T11:43:13Z,CONTRIBUTOR,True,380,134,19,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,04e452d8cbd7a88d1687bb47e3c769e523fdf43e,Merge branch 'tacotron-gst' of github.com:mozilla/TTS into multispeaker
900,https://api.github.com/repos/mozilla/TTS/pulls/222,222,Multispeaker support,"Complete multispeaker support

Summary:
* Preprocessors now return tuples of text, wav file, speaker name
* in the main training loop, the speaker names are turned into speaker ids
* Speaker name to ID mapping is managed in the main training loop, and saved as `speakers.json` in the OUT_PATH. Thus it can be reused in between loops, for evaluation, inference, and for restoring a model for further training
* Models have an additional embedding for speakers that gets broadcasted and added on top of encoder outputs
* `num_speakers` is a new config variable. It doesn't need to be set to an exact value as long as the value is higher than the actual number of speakers.
* synthesis method has an additional parameter to define which speaker should be used",twerkmeister,1107341,2019-06-26T11:43:13Z,CONTRIBUTOR,True,380,134,19,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ba8cc8054b87779f78e5cc774f63476b2801df3b,disabling multispeaker with num_speakers=0
901,https://api.github.com/repos/mozilla/TTS/pulls/222,222,Multispeaker support,"Complete multispeaker support

Summary:
* Preprocessors now return tuples of text, wav file, speaker name
* in the main training loop, the speaker names are turned into speaker ids
* Speaker name to ID mapping is managed in the main training loop, and saved as `speakers.json` in the OUT_PATH. Thus it can be reused in between loops, for evaluation, inference, and for restoring a model for further training
* Models have an additional embedding for speakers that gets broadcasted and added on top of encoder outputs
* `num_speakers` is a new config variable. It doesn't need to be set to an exact value as long as the value is higher than the actual number of speakers.
* synthesis method has an additional parameter to define which speaker should be used",twerkmeister,1107341,2019-06-26T11:43:13Z,CONTRIBUTOR,True,380,134,19,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,81c5df71f6e0b68189de35947b68b8423a90c7f7,removed in-place changes
902,https://api.github.com/repos/mozilla/TTS/pulls/222,222,Multispeaker support,"Complete multispeaker support

Summary:
* Preprocessors now return tuples of text, wav file, speaker name
* in the main training loop, the speaker names are turned into speaker ids
* Speaker name to ID mapping is managed in the main training loop, and saved as `speakers.json` in the OUT_PATH. Thus it can be reused in between loops, for evaluation, inference, and for restoring a model for further training
* Models have an additional embedding for speakers that gets broadcasted and added on top of encoder outputs
* `num_speakers` is a new config variable. It doesn't need to be set to an exact value as long as the value is higher than the actual number of speakers.
* synthesis method has an additional parameter to define which speaker should be used",twerkmeister,1107341,2019-06-26T11:43:13Z,CONTRIBUTOR,True,380,134,19,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d23e29ea1f1d9bafec387a604de3069a3cfd00e4,extracted id to torch code
903,https://api.github.com/repos/mozilla/TTS/pulls/222,222,Multispeaker support,"Complete multispeaker support

Summary:
* Preprocessors now return tuples of text, wav file, speaker name
* in the main training loop, the speaker names are turned into speaker ids
* Speaker name to ID mapping is managed in the main training loop, and saved as `speakers.json` in the OUT_PATH. Thus it can be reused in between loops, for evaluation, inference, and for restoring a model for further training
* Models have an additional embedding for speakers that gets broadcasted and added on top of encoder outputs
* `num_speakers` is a new config variable. It doesn't need to be set to an exact value as long as the value is higher than the actual number of speakers.
* synthesis method has an additional parameter to define which speaker should be used",twerkmeister,1107341,2019-06-26T11:43:13Z,CONTRIBUTOR,True,380,134,19,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6390c3b2e63dd6f524d456e2f711858c7e131ccd,num_speakers larger than 1
904,https://api.github.com/repos/mozilla/TTS/pulls/222,222,Multispeaker support,"Complete multispeaker support

Summary:
* Preprocessors now return tuples of text, wav file, speaker name
* in the main training loop, the speaker names are turned into speaker ids
* Speaker name to ID mapping is managed in the main training loop, and saved as `speakers.json` in the OUT_PATH. Thus it can be reused in between loops, for evaluation, inference, and for restoring a model for further training
* Models have an additional embedding for speakers that gets broadcasted and added on top of encoder outputs
* `num_speakers` is a new config variable. It doesn't need to be set to an exact value as long as the value is higher than the actual number of speakers.
* synthesis method has an additional parameter to define which speaker should be used",twerkmeister,1107341,2019-06-26T11:43:13Z,CONTRIBUTOR,True,380,134,19,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2f2482f9b4130ef1cb72caaadc9314a523ec2e88,reading all speakers upfront
905,https://api.github.com/repos/mozilla/TTS/pulls/216,216,This error when build docker,"simple changes, just comment out a few lines of code",luhavis,20457282,2019-06-17T02:15:12Z,NONE,True,3,3,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6aebf9cd5610d09d556b7993423c24dd123781cb,comment out this code
906,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,10524b885c39ab7f286bdbf90014ecbdb5302a0b,"Fix NameError: name 'model_dict' is not defined

Closes #91"
907,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2634abbbd5fe22f554a742437df41a795bfa3926,"Merge pull request #92 from yweweler/yweweler-fix-model-dict-restore

Fix NameError: name 'model_dict' is not defined"
908,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c7ee056f21212bdd4f1b4e734939ae5e4f01784d,Merge branch 'master' of github.com:mozilla/TTS
909,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,90f0cd640bee768e4d210c4ee977c897ccd6b7a0,memoru queueing
910,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,55605c9b58f1ebc3117189aa6e5f028679be1c7a,banner added
911,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,bc615339d5633daf2da3213d1038e08c21464a12,Update README.md
912,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,11b6080cfd2c0a0dcd2243ee1a32f7b115d26187,config update for r=2
913,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6ea31e47df9e575d2295d6c9436ad1100cdf4389,Constant queue size for autoregression window
914,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4d2c374cfda56778d10a461d3a67f136a8f0ac02,Filter out shape mismatch laeyrs in restoriong model for finetunning
915,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,97a16cedbf857e9c30d17e150b9d0257efc91398,phoneme punctuation bug fix
916,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1c99be2ffddb0ed368bae82616d76fa2e287b401,Change window size for attention
917,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,81b40f00e71c36d98627e0dd9b95c37d633acd09,Update Benchmark notebook
918,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e2d9b0e27cdb551583e2627a44b4916d72602ece,Merge branch 'dev'
919,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,db7f3d36e7768f9179d42a8f19b88c2c736d87eb,README updates
920,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cc88284c8a5ca718763ddb4b21c88f85e82454fd,README update
921,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e2052f9f0661ba2cbdaa05875a93bf70cc63980d,README update
922,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f6c4c101ff0c8f5cf0024794f7a320f1f13eee40,Merge branch 'master' of github.com:mozilla/TTS
923,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e8259441005d1963358e1247e80cebdba4d94c3d,README update
924,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6e86d0d0c49f2e2a7f32f991f8fa9a7d4c584bfa,.compute update
925,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9fecbb7bcc1bccfe77a2ea255da66b549e5c3fb0,setup.py update
926,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,71f1f0c4c093197067e147981e801c17736ab3de,partial initialization fix
927,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b57109518621ffa8dc73e2055cd77612160bb84d,Update README.md
928,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8100360c71b1cc0a327f9a32e7edd169e7186ad5,bug fix for initialization of the model
929,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2eaa1fec5af1702b16879fdf6358ebf81fe5bef8,Merge branch 'master' of github.com:mozilla/TTS
930,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,5a91db56cc9051060df35cc374730467982b3c85,remove aux file
931,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a60c9ee47d6e5ae1de4ef470a49762c337e199c9,add mozilla preprocessor
932,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,caae1af4f6020277d16bb9e6cbfab26782308f29,visual updates for phoenemes
933,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,dce1715e0f17084a64cb4b7b7e37ab95c3e341df,tests updates
934,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,bf5f18d11e550a791cb862bbfe813c395425e548,Formatting changes and distributed training
935,https://api.github.com/repos/mozilla/TTS/pulls/215,215,This error when build docker. ,"My first PR. I hope you understand
Just simple change
Comment out this",luhavis,20457282,2019-06-17T01:40:12Z,NONE,False,3430,5483,62,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,97f74fbf3bedc8b55d9126ebd9c71d84e461862c,distribute.py
936,https://api.github.com/repos/mozilla/TTS/pulls/200,200,Fix broken link in README,,Yorwba,6555947,2019-05-16T16:35:52Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8af6af18960b62c625fd07343d6234fb84e9d63d,Fix broken link in README
937,https://api.github.com/repos/mozilla/TTS/pulls/195,195,Removed access to self.cached in dataset,remnant of caching,twerkmeister,1107341,2019-05-15T09:48:06Z,CONTRIBUTOR,False,0,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,61c5da2dc371f5714007aabe055cfda8076abb36,Removed access to self.cached in dataset
938,https://api.github.com/repos/mozilla/TTS/pulls/192,192,"Config handling, minor refactorings","* handing down config to model instead of early unpacking, solves problems with different interfaces of models Taco1 and 2, makes it easier to introduce new config variables for the models, less verbose. For example `num_mels` wasn't handed down properly to taco2 model before...
* few other small refactorings, removed a bit of duplicated code, fewer global variables in train.py",twerkmeister,1107341,2019-05-14T17:29:59Z,CONTRIBUTOR,False,69,75,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,19830e1af62b2bcc34ccb407672d77b107c4cb15,"handing down config to model instead of early unpacking, minor refactorings, e.g. global variables"
939,https://api.github.com/repos/mozilla/TTS/pulls/192,192,"Config handling, minor refactorings","* handing down config to model instead of early unpacking, solves problems with different interfaces of models Taco1 and 2, makes it easier to introduce new config variables for the models, less verbose. For example `num_mels` wasn't handed down properly to taco2 model before...
* few other small refactorings, removed a bit of duplicated code, fewer global variables in train.py",twerkmeister,1107341,2019-05-14T17:29:59Z,CONTRIBUTOR,False,69,75,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,991aca64052c8295d6d59c1f24651073f17dafa8,Merge branch 'dev-tacotron2' of github.com:mozilla/TTS into better_config_handling
940,https://api.github.com/repos/mozilla/TTS/pulls/192,192,"Config handling, minor refactorings","* handing down config to model instead of early unpacking, solves problems with different interfaces of models Taco1 and 2, makes it easier to introduce new config variables for the models, less verbose. For example `num_mels` wasn't handed down properly to taco2 model before...
* few other small refactorings, removed a bit of duplicated code, fewer global variables in train.py",twerkmeister,1107341,2019-05-14T17:29:59Z,CONTRIBUTOR,False,69,75,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c8af56fae2b3eaa1ba4e569a46a6e9d18d833002,fixed tests
941,https://api.github.com/repos/mozilla/TTS/pulls/184,184,drop dataset upfront caching,Based on the discussion in #176 - dropping upfront caching with `extract_features.py`. Instead it might be worth implementing on-the-fly caching during a training run,twerkmeister,1107341,2019-04-29T09:21:18Z,CONTRIBUTOR,True,17,188,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7b2804cc0d02f2ffa9012ae6271f81205fc2d55c,dropped dataset caching
942,https://api.github.com/repos/mozilla/TTS/pulls/184,184,drop dataset upfront caching,Based on the discussion in #176 - dropping upfront caching with `extract_features.py`. Instead it might be worth implementing on-the-fly caching during a training run,twerkmeister,1107341,2019-04-29T09:21:18Z,CONTRIBUTOR,True,17,188,9,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f9c6cde17f27a2355a1cafb30b9ac337abf82e48,no cached mel/linear anymore
943,https://api.github.com/repos/mozilla/TTS/pulls/178,178,Improved build workflow,"Several improvements to the build workflow:

Docker:
* **faster build, better caching - no downloads and only 2MB instead of 3GB upload for src changes** 
* starting from pytorch container with newer cuda version
* installing espeak to use phonemizer inside container

setup.py
* more declarative
* removed git dependency from setup.py
* removed deprecated depenceny_links option
* updated requirements.txt to reflect dependencies in setup.py

Was the existing versioning scheme using git important? I wasn't sure, but happy to discuss!",twerkmeister,1107341,2019-04-26T13:24:18Z,CONTRIBUTOR,False,53,109,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6c4f89d39988ccbc50c524de7ab5ecd46793f77e,"faster build, better caching, only 2MB instead of 3GB upload for src change"
944,https://api.github.com/repos/mozilla/TTS/pulls/178,178,Improved build workflow,"Several improvements to the build workflow:

Docker:
* **faster build, better caching - no downloads and only 2MB instead of 3GB upload for src changes** 
* starting from pytorch container with newer cuda version
* installing espeak to use phonemizer inside container

setup.py
* more declarative
* removed git dependency from setup.py
* removed deprecated depenceny_links option
* updated requirements.txt to reflect dependencies in setup.py

Was the existing versioning scheme using git important? I wasn't sure, but happy to discuss!",twerkmeister,1107341,2019-04-26T13:24:18Z,CONTRIBUTOR,False,53,109,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,96c3f552c75e3e400dd228643e3af621756d164c,"simplify versioning, no git requirement, removed deprecated dependency_links option"
945,https://api.github.com/repos/mozilla/TTS/pulls/178,178,Improved build workflow,"Several improvements to the build workflow:

Docker:
* **faster build, better caching - no downloads and only 2MB instead of 3GB upload for src changes** 
* starting from pytorch container with newer cuda version
* installing espeak to use phonemizer inside container

setup.py
* more declarative
* removed git dependency from setup.py
* removed deprecated depenceny_links option
* updated requirements.txt to reflect dependencies in setup.py

Was the existing versioning scheme using git important? I wasn't sure, but happy to discuss!",twerkmeister,1107341,2019-04-26T13:24:18Z,CONTRIBUTOR,False,53,109,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,dbeca993e4581240ac1d548addbf86e322c694e0,numpy
946,https://api.github.com/repos/mozilla/TTS/pulls/177,177,renamed tests so that testrunner finds them,"Using the current naming scheme the python test runner, e.g. when executing `python -m unittest`, doesn't find any tests. With the renaming, it works and all tests are executed. ",twerkmeister,1107341,2019-04-26T13:03:10Z,CONTRIBUTOR,True,0,0,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,fefedbc605dead71dc00e92803303280404f8608,renamed tests so that testrunner finds them
947,https://api.github.com/repos/mozilla/TTS/pulls/174,174,Mozilla common voice preprocessor,"Common voice preprocessor fixes #168 

Also, removed shuffling of data in all preprocessors",twerkmeister,1107341,2019-04-25T09:59:16Z,CONTRIBUTOR,True,133,64,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d1a7ad545de7115ffabd6124585debf25cbb396d,"common voice preprocessor and tests, small refactoring within tests"
948,https://api.github.com/repos/mozilla/TTS/pulls/174,174,Mozilla common voice preprocessor,"Common voice preprocessor fixes #168 

Also, removed shuffling of data in all preprocessors",twerkmeister,1107341,2019-04-25T09:59:16Z,CONTRIBUTOR,True,133,64,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a9f6c400828c88b48046a5d9e60b5ac6d20afecb,removed duplicate lws requirement
949,https://api.github.com/repos/mozilla/TTS/pulls/174,174,Mozilla common voice preprocessor,"Common voice preprocessor fixes #168 

Also, removed shuffling of data in all preprocessors",twerkmeister,1107341,2019-04-25T09:59:16Z,CONTRIBUTOR,True,133,64,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,41e3e42989e680a184e2b56f64ed33cad9ca2fb7,added .idea to gitignore for pycharm users
950,https://api.github.com/repos/mozilla/TTS/pulls/174,174,Mozilla common voice preprocessor,"Common voice preprocessor fixes #168 

Also, removed shuffling of data in all preprocessors",twerkmeister,1107341,2019-04-25T09:59:16Z,CONTRIBUTOR,True,133,64,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f279fe9e8b7a291fec7d27feb94ca27d26574ed4,"removed shuffling of data in the preprocessor, uniform indentation"
951,https://api.github.com/repos/mozilla/TTS/pulls/174,174,Mozilla common voice preprocessor,"Common voice preprocessor fixes #168 

Also, removed shuffling of data in all preprocessors",twerkmeister,1107341,2019-04-25T09:59:16Z,CONTRIBUTOR,True,133,64,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7ac66661d77b2e8c5ab460db9d3cac8368772791,Merge branch 'dev-tacotron2' of github.com:mozilla/TTS into dev-tacotron2
952,https://api.github.com/repos/mozilla/TTS/pulls/173,173,common voice preprocessor,"Preprocessor for common voice data with tests.

@erogol I removed the `random.shuffle(items)` from the last line of the preprocessor. Seems to me this can be removed from all the others as well given that the dataset class orders them by length anyway. Or am I missing something?",twerkmeister,1107341,2019-04-24T10:04:37Z,CONTRIBUTOR,False,85,12,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9dbcfaf4b169a1889c09dbf2a1294c5ca6d84ff7,added .idea to gitignore for pycharm users
953,https://api.github.com/repos/mozilla/TTS/pulls/173,173,common voice preprocessor,"Preprocessor for common voice data with tests.

@erogol I removed the `random.shuffle(items)` from the last line of the preprocessor. Seems to me this can be removed from all the others as well given that the dataset class orders them by length anyway. Or am I missing something?",twerkmeister,1107341,2019-04-24T10:04:37Z,CONTRIBUTOR,False,85,12,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7587b8ed4640f1f058eace1467e2f5b5796b944d,removed duplicate lws requirement
954,https://api.github.com/repos/mozilla/TTS/pulls/173,173,common voice preprocessor,"Preprocessor for common voice data with tests.

@erogol I removed the `random.shuffle(items)` from the last line of the preprocessor. Seems to me this can be removed from all the others as well given that the dataset class orders them by length anyway. Or am I missing something?",twerkmeister,1107341,2019-04-24T10:04:37Z,CONTRIBUTOR,False,85,12,7,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f1f801018d3ad3cd887b08270d861a98ad00cd42,"common voice preprocessor and tests, small refactoring within tests"
955,https://api.github.com/repos/mozilla/TTS/pulls/157,157,Update requirements.txt,"I faced with it here:
```
$ python3 server/server.py -c server/conf.json
/home/vitaly_zdanevich/.local/lib/python3.6/site-packages/numba/errors.py:105: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9
  warnings.warn(msg)
Traceback (most recent call last):
  File ""server/server.py"", line 3, in <module>
    from synthesizer import Synthesizer
  File ""/home/vitaly_zdanevich/TTS/server/synthesizer.py"", line 7, in <module>
    import soundfile as sf
ModuleNotFoundError: No module named 'soundfile'
```",vitaly-zdanevich,3514015,2019-04-16T12:41:41Z,NONE,False,1,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2edc179233b8d667a4d0bce65b6866be3d238826,Update requirements.txt
956,https://api.github.com/repos/mozilla/TTS/pulls/145,145,Add Mozilla Code of Conduct,"Fixes #144


As of January 1 2019, Mozilla requires that all GitHub projects include this [CODE_OF_CONDUCT.md](https://github.com/mozilla/repo-templates/blob/master/templates/CODE_OF_CONDUCT.md) file in the project root. The file has two parts:

1. Required Text - All text under the headings *Community Participation Guidelines and How to Report*, are required, and should not be altered.
2. Optional Text - The Project Specific Etiquette heading provides a space to speak more specifically about ways people can work effectively and inclusively together. Some examples of those can be found on the [Firefox Debugger](https://github.com/devtools-html/debugger.html/blob/master/CODE_OF_CONDUCT.md) project, and [Common Voice](https://github.com/mozilla/voice-web/blob/master/CODE_OF_CONDUCT.md). (The optional part is commented out in the [raw template file](https://raw.githubusercontent.com/mozilla/repo-templates/blob/master/templates/CODE_OF_CONDUCT.md), and will not be visible until you modify and uncomment that part.)

If you have any questions about this file, or Code of Conduct policies and procedures, please see [Mozilla-GitHub-Standards](https://wiki.mozilla.org/GitHub/Repository_Requirements) or email Mozilla-GitHub-Standards+CoC@mozilla.com.

_(Message COC002)_",Mozilla-GitHub-Standards,48073334,2019-03-30T06:47:54Z,CONTRIBUTOR,True,15,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b7f1b1a0952039dd659233632c939d38239f1960,"Add Mozilla Code of Conduct file

Fixes #144.

_(Message COC002)_"
957,https://api.github.com/repos/mozilla/TTS/pulls/139,139,Fix 185k model,,gnosly,2919922,2019-03-25T23:19:45Z,CONTRIBUTOR,True,7,5,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,ecc5938986b5474b9916003a0787fc633c2d7458,phonetic size was missing
958,https://api.github.com/repos/mozilla/TTS/pulls/139,139,Fix 185k model,,gnosly,2919922,2019-03-25T23:19:45Z,CONTRIBUTOR,True,7,5,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,863830b5a84a51e00ea381b80a560ae34660f333,now model input is converted from chars to phonemes as the model expected
959,https://api.github.com/repos/mozilla/TTS/pulls/139,139,Fix 185k model,,gnosly,2919922,2019-03-25T23:19:45Z,CONTRIBUTOR,True,7,5,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,eb7b099526a91ccfdae84a96dfe0753642594fb4,io array instantiated only one time
960,https://api.github.com/repos/mozilla/TTS/pulls/127,127,"added missing phonemes, synthesizer.py now setup the correct input layer",,gnosly,2919922,2019-03-11T20:58:16Z,CONTRIBUTOR,True,41,26,3,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,95de2cd5595a403bdd59565bcf6dc4b80b00dfa5,"added missing phonemes, synthesizer.py now setup the correct input layer"
961,https://api.github.com/repos/mozilla/TTS/pulls/121,121,Update symbols.py,"More phonemes for Kabyle.
Kabyle Alphabet: abcdefghijklmnopqrstuvwxyz + 'č','ḍ','ǧ','ḥ','ṛ','ṣ','ṭ','ẓ','ɣ','ɛ'
Maj: ČḌǦḤṚṢṬẒƔƐ",mozillakab,7033740,2019-03-02T19:02:16Z,NONE,False,2,2,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a767389deb8a04aad945ae4bd5c37ff4ceb6858a,"Update symbols.py

More phonemes for Kabyle.
Kabyle Alphabet: abcdefghijklmnopqrstuvwxyz + 'č','ḍ','ǧ','ḥ','ṛ','ṣ','ṭ','ẓ','ɣ','ɛ'
Maj: ČḌǦḤṚṢṬẒƔƐ"
962,https://api.github.com/repos/mozilla/TTS/pulls/117,117,Issue#110,"Hi,
i tried to solve the issue #110 . With this PR I propose you to add a new model config parameter called `input_chars` that identifies the inputs of the Tacotron Embedding layer.",gnosly,2919922,2019-02-28T23:53:45Z,CONTRIBUTOR,False,4,4,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8d8dd877d5bf2a01f5ad7926e284c28ea81e341e,now first network input size comes from model configuration input_chars
963,https://api.github.com/repos/mozilla/TTS/pulls/117,117,Issue#110,"Hi,
i tried to solve the issue #110 . With this PR I propose you to add a new model config parameter called `input_chars` that identifies the inputs of the Tacotron Embedding layer.",gnosly,2919922,2019-02-28T23:53:45Z,CONTRIBUTOR,False,4,4,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,812099feedc97769af5dab83e359a809787d9767,now we know symbols and phonemes sizes
964,https://api.github.com/repos/mozilla/TTS/pulls/92,92,Fix NameError: name 'model_dict' is not defined,"Adopt the necessary code changes from the dev branch  for the master branch.

Closes #91 ",yweweler,10332831,2018-12-31T12:41:53Z,CONTRIBUTOR,True,16,13,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,10524b885c39ab7f286bdbf90014ecbdb5302a0b,"Fix NameError: name 'model_dict' is not defined

Closes #91"
965,https://api.github.com/repos/mozilla/TTS/pulls/90,90,Initial Dockerfile,"This is an initial version of a `Dockerfile` that can be used to quickly train/test/use TTS.

Tested using d5d8458093816be7b3caf4303b239e3c240582e3 and the model available at https://drive.google.com/drive/folders/1Y_0zez0GeZSHpehKZZmjbh2p4urBCVqB.",tomzx,188960,2018-12-24T17:39:37Z,CONTRIBUTOR,True,43,9,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e410dd7a3abf7b589afd97b1cf850768695acc08,Initial Dockerfile
966,https://api.github.com/repos/mozilla/TTS/pulls/90,90,Initial Dockerfile,"This is an initial version of a `Dockerfile` that can be used to quickly train/test/use TTS.

Tested using d5d8458093816be7b3caf4303b239e3c240582e3 and the model available at https://drive.google.com/drive/folders/1Y_0zez0GeZSHpehKZZmjbh2p4urBCVqB.",tomzx,188960,2018-12-24T17:39:37Z,CONTRIBUTOR,True,43,9,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2b69a76e5d39d2055d97d62e469f0885dca67f31,Add minimal instructions for using the Dockerfile
967,https://api.github.com/repos/mozilla/TTS/pulls/80,80,Small typos,,bajibabu,1410316,2018-12-18T13:52:19Z,CONTRIBUTOR,True,2,2,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,dce5a05e80d7ebde61afecc1f15d78fb0fb89394,Update train.py
968,https://api.github.com/repos/mozilla/TTS/pulls/80,80,Small typos,,bajibabu,1410316,2018-12-18T13:52:19Z,CONTRIBUTOR,True,2,2,2,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a97e4b28843e201082e271a79347199ccce5ebda,"Update extract_features.py

linear_len is undefined if args.only_mel is set"
969,https://api.github.com/repos/mozilla/TTS/pulls/77,77,Add tqdm to requirements.txt,While tqdm is contained in setup.py it is missing in the requirements.txt,yweweler,10332831,2018-12-15T13:56:06Z,CONTRIBUTOR,True,2,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e35c5f463e213a4a1eebd410069467709bfcae4a,"Add tqdm to requirements.txt

While tqdm is contained in setup.py it is missing in the requirements.txt"
970,https://api.github.com/repos/mozilla/TTS/pulls/55,55,Update README.md,"There was just a small syntax mistake in README.md's TODO list. There has to be a blank space between the square brackets. Otherwise, the checklists will not be displayed as intended.",0xMilly,12900358,2018-10-17T19:35:05Z,CONTRIBUTOR,True,3,3,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0ad7a7bd4754e01468b221899ae657bf1663df60,"Update README.md

Fixed the TODO list syntax."
971,https://api.github.com/repos/mozilla/TTS/pulls/52,52,Fixed restore_step for new training,"last_epoch for _LRScheduler should be -1 if not resuming a previous optimization process
see https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html",m-toman,9433378,2018-10-08T09:45:29Z,CONTRIBUTOR,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,e201598ad0a02dfa61141565274bd1320c872ff3,"Fixed restore_step for new training

last_epoch for _LRScheduler should be -1 if not resuming a previous optimization process
see https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html"
972,https://api.github.com/repos/mozilla/TTS/pulls/47,47,fixed headline,,0xflotus,26602940,2018-09-19T19:14:37Z,NONE,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0395680f9d343f30c28d76250f80886a4628eefd,fixed headline
973,https://api.github.com/repos/mozilla/TTS/pulls/38,38,Demo Server targeting #25,,erogol,1402048,2018-06-06T13:51:48Z,CONTRIBUTOR,True,226,1,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,bf0d1a7b3c2f82ae1e4a601c78c84c735fc60a3a,Server component added
974,https://api.github.com/repos/mozilla/TTS/pulls/38,38,Demo Server targeting #25,,erogol,1402048,2018-06-06T13:51:48Z,CONTRIBUTOR,True,226,1,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,25969c60a4c0e218afa2586db1a6cf427fdb475c,Update requirements
975,https://api.github.com/repos/mozilla/TTS/pulls/38,38,Demo Server targeting #25,,erogol,1402048,2018-06-06T13:51:48Z,CONTRIBUTOR,True,226,1,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,249e2b9a278d214f8ccd940ca9832ac89bc2a991,Update server readme
976,https://api.github.com/repos/mozilla/TTS/pulls/38,38,Demo Server targeting #25,,erogol,1402048,2018-06-06T13:51:48Z,CONTRIBUTOR,True,226,1,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,6e4145ee4b2a6b3d89c010d1e5ab436f15f48e3c,Remove the noise in the code
977,https://api.github.com/repos/mozilla/TTS/pulls/38,38,Demo Server targeting #25,,erogol,1402048,2018-06-06T13:51:48Z,CONTRIBUTOR,True,226,1,6,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,12d5f051d423dca25c7f337fc6a05c22cee59298,Small edit
978,https://api.github.com/repos/mozilla/TTS/pulls/29,29,Fix link for 170k iteration model commit,Fixes README link for 170k iteration model commit to point to the repo tree for this commit hash.,pshah123,6960204,2018-05-09T17:59:54Z,CONTRIBUTOR,True,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,cee99c8f0bf99cdce0bcb45c0d9ddf819a52eeae,Fix link for 170k iteration model commit
979,https://api.github.com/repos/mozilla/TTS/pulls/15,15,Add missing dependencies from requirements.txt,Just making it easier to get started training.,reuben,477142,2018-04-09T15:53:12Z,MEMBER,True,3,0,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,16d89600a62c153f133b456b150195750ce7134e,Add missing dependencies from requirements.txt
980,https://api.github.com/repos/mozilla/TTS/pulls/5,5,"fix references in readme, change format todo list","Linked pdfs did not match the link text. This change resolves that.
Also changed the formatting of the todo list, so that github can show the items as checkboxes",Vproject,6201446,2018-03-06T21:08:15Z,CONTRIBUTOR,True,10,9,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c7fc31bcb2a890cc80debf57c4821392298c6463,"fix references in readme, change format todo list"
981,https://api.github.com/repos/mozilla/TTS/pulls/4,4,Update WaveRNN to ArXiv,Use ArXiv site instead of IP address which could change,ghexp,9085086,2018-03-04T14:20:33Z,NONE,False,1,1,1,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0962b5836379bb12d71a0f06e634130a2daf546d,"Update WaveRNN to ArXiv

Use ArXiv site instead of IP address which could change"
982,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,37c98602df7ae25497aacb325525ef84e9c9aa0f,Update README.md
983,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0277f6ef5b423655efd2c8ef20337020c15de32d,Update README.md
984,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,0e6061e884af42a4fcdbb8c7feafa956cc4530c1,Change descriptions
985,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4014e974d52aeabf1394a78b63baad9b3ac4f211,Remove redun
986,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2a20b7c2ac317720eb64a92d8e5e8c7fed53556f,"Audio Precessing class, passing data fetching argummetns from config"
987,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,d95a2ce26fbd319be1b9b6df189405b07ef1c43c,fix handling CTRL C
988,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2f92246c8aed5d226a8d794ea9194b13a220d0c5,Requirements
989,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1fa791f83e0c0636e2dd66de43b7242fbb8d2f59,Tensorboard plotting
990,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,49f61d0b9efaf270c569679b448027481490fbdb,Checkpoint fix
991,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,191e2b3f1ec3a7e42830778cd99adbb0786c2119,debug config
992,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2eca96bfbb4e988b99a0d7e9daaf5f24779dcdb6,"LR and time loggin on TB, checkpoint fix"
993,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9af37e43a4bb61f6b148743ca780fe11e7864701,Better config for training
994,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,a47b65e01454e2d98e266265143950b2a204bdf1,Update README.md
995,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9a22f5d085c7c4214e468cbde189f95e5fda24e4,Update README.md
996,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1320d5344a6cc007626da121a98c508786a11b11,Bug solve on attention module and a new Notebook to experiment spectrogram reconstruction
997,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,03c1d22cae3909934b27b44e3e28eaa3336eb380,rrf
998,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,85da275bdfd28122c1e6094c3e4ee8f234a43a4d,gitignore update
999,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f623b4e58692041a4e94bffc9dad7b6cb0623365,rrf
1000,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,088a105a4315efc3eeb7b802cc7d16e532369f0b,Log spectrogram constraction
1001,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3519f2f33c4e38311fa999c3cf604e465db9fee5,log grad norm on tf
1002,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,7304978be3491cf5c5b6f58c762506af097a66f3,new lr schedule
1003,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,235ce071c6a419658cb48d4c8aa21d210b9e39ae,Lr update
1004,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,4e0ab65bbf20e2d52b7f47921b239140bffe8c3c,plot attention alignments
1005,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,966d5675405067dc255878de1fd116a644382509,Mask inputs by length to reduce the effetc on attention module
1006,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,86f3a56f5995d26473519afacac44bc9ac58d552,config change
1007,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9f5e10247353387f0e69bfb4cacf7b6d2d5dec23,"A big revision: visualization, data loader, tests"
1008,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,2fd37a5bad9374002873db26927694dd0d329e90,Better naming of variables
1009,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b6c5771a6f9ed5a7b53c79d70581edf3b30d53d4,Update attention module Possible BUG FIX
1010,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,3cafc6568c220502ba6ea9421239860ffcbee4bd,Update attention module Possible BUG FIX2
1011,https://api.github.com/repos/mozilla/TTS/pulls/3,3,Tests and some changes on the architecture.,,erogol,1402048,2018-02-13T16:11:39Z,CONTRIBUTOR,True,1120,320,30,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,584c8fbf5ecf387fcfc1ad66424b0cfdcbec091e,BUG fixes and more visualization changes
1012,https://api.github.com/repos/mozilla/TTS/pulls/1,1,Development,,erogol,1402048,2018-01-24T16:59:02Z,CONTRIBUTOR,False,239,119,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,bf423ebd8e81aeb9eb59101c101fbfd9fc2a0a2e,"Audio Precessing class, passing data fetching argummetns from config"
1013,https://api.github.com/repos/mozilla/TTS/pulls/1,1,Development,,erogol,1402048,2018-01-24T16:59:02Z,CONTRIBUTOR,False,239,119,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,1dd8b53177d3b46b23b04e3ae48eece18da2b324,fix handling CTRL C
1014,https://api.github.com/repos/mozilla/TTS/pulls/1,1,Development,,erogol,1402048,2018-01-24T16:59:02Z,CONTRIBUTOR,False,239,119,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,8b712f2690be06c6006f554de14bc1438c5c510e,Requirements
1015,https://api.github.com/repos/mozilla/TTS/pulls/1,1,Development,,erogol,1402048,2018-01-24T16:59:02Z,CONTRIBUTOR,False,239,119,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,f32a3de4259802cc061827f724778ae2c66b4868,Tensorboard plotting
1016,https://api.github.com/repos/mozilla/TTS/pulls/1,1,Development,,erogol,1402048,2018-01-24T16:59:02Z,CONTRIBUTOR,False,239,119,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,b8f5594d71b008ecba294d30a0d09540ebd0c8f4,Checkpoint fix
1017,https://api.github.com/repos/mozilla/TTS/pulls/1,1,Development,,erogol,1402048,2018-01-24T16:59:02Z,CONTRIBUTOR,False,239,119,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,76a33e24525f840ee709169d68bba25aba68ba39,debug config
1018,https://api.github.com/repos/mozilla/TTS/pulls/1,1,Development,,erogol,1402048,2018-01-24T16:59:02Z,CONTRIBUTOR,False,239,119,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,eba477fc82d3f91c706543d70b5d67bc6135c39d,"LR and time loggin on TB, checkpoint fix"
1019,https://api.github.com/repos/mozilla/TTS/pulls/1,1,Development,,erogol,1402048,2018-01-24T16:59:02Z,CONTRIBUTOR,False,239,119,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,04ae97ca1be9a2aba9e295a0582f2dc7631df6e9,Better config for training
1020,https://api.github.com/repos/mozilla/TTS/pulls/1,1,Development,,erogol,1402048,2018-01-24T16:59:02Z,CONTRIBUTOR,False,239,119,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,c1a0f6b99508ca8f74195a9f00c81367295ce49e,Update README.md
1021,https://api.github.com/repos/mozilla/TTS/pulls/1,1,Development,,erogol,1402048,2018-01-24T16:59:02Z,CONTRIBUTOR,False,239,119,12,:robot: :speech_balloon: Deep learning for Text to Speech  (Discussion forum: https://discourse.mozilla.org/c/tts),Jupyter Notebook,9f80516b727bb5948e73c14fff5e50c9ebb2a6f8,Update README.md
