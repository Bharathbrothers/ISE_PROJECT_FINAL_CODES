,pullid,pulls_number,pulltitle,pullsbody,pullsuserlogin,pullsuserid,pullauthordate,author_association,merged_status,stats_addns,stats_delns,stats_changed_files,pull_repo_desc,pull_repo_lang,pull_commit_sha,pull_commit_message
0,https://api.github.com/repos/mozilla/datazilla/pulls/120,120,"Bug 1085021 - Remove ingestion reports for b2gperf data, hamachi, and tarako",,davehunt,122800,2014-10-20T09:30:11Z,MEMBER,True,41,282,1,Datazilla is a system for managing and visualizing data.,JavaScript,c7f5087480c0e2609bd72c28acf16b0f9fe95fbf,"Bug 1085021 - Remove ingestion reports for b2gperf data, hamachi, and tarako. r=jmaher"
1,https://api.github.com/repos/mozilla/datazilla/pulls/120,120,"Bug 1085021 - Remove ingestion reports for b2gperf data, hamachi, and tarako",,davehunt,122800,2014-10-20T09:30:11Z,MEMBER,True,41,282,1,Datazilla is a system for managing and visualizing data.,JavaScript,5af67520b73e1f4a6877cdf8424429cb907f7ae8,Remove startup_time from list of applications.
2,https://api.github.com/repos/mozilla/datazilla/pulls/120,120,"Bug 1085021 - Remove ingestion reports for b2gperf data, hamachi, and tarako",,davehunt,122800,2014-10-20T09:30:11Z,MEMBER,True,41,282,1,Datazilla is a system for managing and visualizing data.,JavaScript,c26a2fdf1764d768a112133b55f51368d5e07939,Add costcontrol and fix memory ingestion alerts.
3,https://api.github.com/repos/mozilla/datazilla/pulls/119,119,added dialog for failed http requests,,jeads,949498,2014-08-19T18:04:00Z,CONTRIBUTOR,True,46,10,6,Datazilla is a system for managing and visualizing data.,JavaScript,8af7c9d0b83be2f7833052ffa6315c3dde61ab86,added dialog for failed http requests
4,https://api.github.com/repos/mozilla/datazilla/pulls/118,118,Fix b2g machines,"A collection of fixes addressing Bugs 1047306 1011577 1007774 1046057 1046056 1050179 1047324
",jeads,949498,2014-08-15T18:35:29Z,CONTRIBUTOR,True,508,56,10,Datazilla is a system for managing and visualizing data.,JavaScript,41660e106b009a7f3f7b0ef2e5c7598f941d5403,Added command to reset the machine ids in the test_run table for b2g
5,https://api.github.com/repos/mozilla/datazilla/pulls/118,118,Fix b2g machines,"A collection of fixes addressing Bugs 1047306 1011577 1007774 1046057 1046056 1050179 1047324
",jeads,949498,2014-08-15T18:35:29Z,CONTRIBUTOR,True,508,56,10,Datazilla is a system for managing and visualizing data.,JavaScript,fbbda6e9735bb162f200ac126ed3817adf08777b,fixed data issues and added a target line to the performance graphs
6,https://api.github.com/repos/mozilla/datazilla/pulls/117,117,B2ghaystack integration,"Added zooming, panning, and range selection function that builds a b2ghaystack cmd in a modal window.
",jeads,949498,2014-07-22T00:05:18Z,CONTRIBUTOR,True,279,9,4,Datazilla is a system for managing and visualizing data.,JavaScript,ab43398e778c353699fd3215bb77b412d02f877b,made changes
7,https://api.github.com/repos/mozilla/datazilla/pulls/117,117,B2ghaystack integration,"Added zooming, panning, and range selection function that builds a b2ghaystack cmd in a modal window.
",jeads,949498,2014-07-22T00:05:18Z,CONTRIBUTOR,True,279,9,4,Datazilla is a system for managing and visualizing data.,JavaScript,dccf7ae2ff9bf60c437f5801711386dae2ab829a,Merge branch 'master' of ssh://github.com/mozilla/datazilla into b2ghaystack-integration
8,https://api.github.com/repos/mozilla/datazilla/pulls/117,117,B2ghaystack integration,"Added zooming, panning, and range selection function that builds a b2ghaystack cmd in a modal window.
",jeads,949498,2014-07-22T00:05:18Z,CONTRIBUTOR,True,279,9,4,Datazilla is a system for managing and visualizing data.,JavaScript,57c3ff30b478710bcbdb0c05f2ccb1f949845901,added modal and selection range functions
9,https://api.github.com/repos/mozilla/datazilla/pulls/117,117,B2ghaystack integration,"Added zooming, panning, and range selection function that builds a b2ghaystack cmd in a modal window.
",jeads,949498,2014-07-22T00:05:18Z,CONTRIBUTOR,True,279,9,4,Datazilla is a system for managing and visualizing data.,JavaScript,9c32b9a2a6af78a6c136b9ca2a7c8d1765b45d3e,Merge branch 'master' of ssh://github.com/mozilla/datazilla into b2ghaystack-integration
10,https://api.github.com/repos/mozilla/datazilla/pulls/117,117,B2ghaystack integration,"Added zooming, panning, and range selection function that builds a b2ghaystack cmd in a modal window.
",jeads,949498,2014-07-22T00:05:18Z,CONTRIBUTOR,True,279,9,4,Datazilla is a system for managing and visualizing data.,JavaScript,5bd24d2afbf51a596d1623f56dfce42ae1875cb0,added navigation controls
11,https://api.github.com/repos/mozilla/datazilla/pulls/117,117,B2ghaystack integration,"Added zooming, panning, and range selection function that builds a b2ghaystack cmd in a modal window.
",jeads,949498,2014-07-22T00:05:18Z,CONTRIBUTOR,True,279,9,4,Datazilla is a system for managing and visualizing data.,JavaScript,5d4bc5fc24532c899bacd2804b6d004db452f4e8,finished b2ghaystack modal functionality
12,https://api.github.com/repos/mozilla/datazilla/pulls/117,117,B2ghaystack integration,"Added zooming, panning, and range selection function that builds a b2ghaystack cmd in a modal window.
",jeads,949498,2014-07-22T00:05:18Z,CONTRIBUTOR,True,279,9,4,Datazilla is a system for managing and visualizing data.,JavaScript,9acd4257ae34f1c7720c3b51c34f3efdb779f450,cleaned up
13,https://api.github.com/repos/mozilla/datazilla/pulls/116,116,Test units config,"Added dynamic y-axis units and the new generated_by field.
",jeads,949498,2014-07-08T18:40:38Z,CONTRIBUTOR,True,157,9,9,Datazilla is a system for managing and visualizing data.,JavaScript,e7a678ff02229eeae5c1ebf2fc1de692160e4613,added dynamic y-axis units and the new generated_by field
14,https://api.github.com/repos/mozilla/datazilla/pulls/116,116,Test units config,"Added dynamic y-axis units and the new generated_by field.
",jeads,949498,2014-07-08T18:40:38Z,CONTRIBUTOR,True,157,9,9,Datazilla is a system for managing and visualizing data.,JavaScript,24bc7a28208203d93b5c4318981d858a412559cf,removed unused import
15,https://api.github.com/repos/mozilla/datazilla/pulls/115,115,Bug 1024924 - Enable ingestion alerts for Flame. r=jmaher,,jmaher,62588,2014-06-17T04:21:18Z,CONTRIBUTOR,True,96,4,1,Datazilla is a system for managing and visualizing data.,JavaScript,8a5df27c1266e8a7736812bbec3dc343e2fb408b,Bug 1024924 - Enable ingestion alerts for Flame. r=jmaher
16,https://api.github.com/repos/mozilla/datazilla/pulls/114,114,Bug 1012673 - disable inari from datazilla b2g ingestion alerts,"removed inari
",jmaher,62588,2014-05-19T14:01:28Z,CONTRIBUTOR,True,0,33,1,Datazilla is a system for managing and visualizing data.,JavaScript,0741e52dfdc537fed089c999b3b3ffddc9b689f2,Bug 1012673 - disable inari from datazilla b2g ingestion alerts
17,https://api.github.com/repos/mozilla/datazilla/pulls/114,114,Bug 1012673 - disable inari from datazilla b2g ingestion alerts,"removed inari
",jmaher,62588,2014-05-19T14:01:28Z,CONTRIBUTOR,True,0,33,1,Datazilla is a system for managing and visualizing data.,JavaScript,f622232850120759c1295489e002c92cf64feb5a,Bug 1012673 - disable inari from datazilla b2g ingestion alerts
18,https://api.github.com/repos/mozilla/datazilla/pulls/114,114,Bug 1012673 - disable inari from datazilla b2g ingestion alerts,"removed inari
",jmaher,62588,2014-05-19T14:01:28Z,CONTRIBUTOR,True,0,33,1,Datazilla is a system for managing and visualizing data.,JavaScript,d4d9c1ba4aecb83d3154dcfda67270e61dd9883b,Bug 1012673 - disable inari from datazilla b2g ingestion alerts
19,https://api.github.com/repos/mozilla/datazilla/pulls/113,113,Data cycling pt2,"Updated data cycling protocol to include objectstore and use nested selects to improve performance.
",jeads,949498,2014-04-08T20:28:15Z,CONTRIBUTOR,True,127,57,7,Datazilla is a system for managing and visualizing data.,JavaScript,37a3db470451152e04cac212ccc295d7cab35542,new data cycling procedure for production
20,https://api.github.com/repos/mozilla/datazilla/pulls/113,113,Data cycling pt2,"Updated data cycling protocol to include objectstore and use nested selects to improve performance.
",jeads,949498,2014-04-08T20:28:15Z,CONTRIBUTOR,True,127,57,7,Datazilla is a system for managing and visualizing data.,JavaScript,32f8c8b15759a039c9604434fb5824ff5999ec68,fixed stuff
21,https://api.github.com/repos/mozilla/datazilla/pulls/112,112,add ingestion alerts,,globau,872825,2014-02-27T07:53:16Z,CONTRIBUTOR,True,4091,11,16,Datazilla is a system for managing and visualizing data.,JavaScript,1fc6fc0c51e00282c9bba01a058510590f35d626,add ingestion alerts
22,https://api.github.com/repos/mozilla/datazilla/pulls/112,112,add ingestion alerts,,globau,872825,2014-02-27T07:53:16Z,CONTRIBUTOR,True,4091,11,16,Datazilla is a system for managing and visualizing data.,JavaScript,07e4244b639e94e6b9e9b996d193fdb39e7207c6,address review points
23,https://api.github.com/repos/mozilla/datazilla/pulls/111,111,B2g median,,globau,872825,2014-02-04T06:26:24Z,CONTRIBUTOR,False,24,3,4,Datazilla is a system for managing and visualizing data.,JavaScript,bbed9ec6a9f5cadd23666f3000f5e9e94f8246d6,Add the median to the hover panel data display
24,https://api.github.com/repos/mozilla/datazilla/pulls/111,111,B2g median,,globau,872825,2014-02-04T06:26:24Z,CONTRIBUTOR,False,24,3,4,Datazilla is a system for managing and visualizing data.,JavaScript,4df32b261d3d92257089873c2b27fe5a0d9eb93d,add median to replicate display
25,https://api.github.com/repos/mozilla/datazilla/pulls/111,111,B2g median,,globau,872825,2014-02-04T06:26:24Z,CONTRIBUTOR,False,24,3,4,Datazilla is a system for managing and visualizing data.,JavaScript,29f84cb13fea5980421cdbb819a2e2fe7f4a61d6,add avg/med/error-bars to url/history
26,https://api.github.com/repos/mozilla/datazilla/pulls/110,110,"mean, median, and error bar controls","This branch is not ready to review but should facilitate some back and forth with glob to finish the implementation.
",jeads,949498,2014-01-30T02:19:57Z,CONTRIBUTOR,True,122,25,9,Datazilla is a system for managing and visualizing data.,JavaScript,d6f35bbbc74143b3110feebdf5e115d2cc4074d0,"added adv, median, and error bar controls"
27,https://api.github.com/repos/mozilla/datazilla/pulls/110,110,"mean, median, and error bar controls","This branch is not ready to review but should facilitate some back and forth with glob to finish the implementation.
",jeads,949498,2014-01-30T02:19:57Z,CONTRIBUTOR,True,122,25,9,Datazilla is a system for managing and visualizing data.,JavaScript,2504f200aee92aa2e9f226f2415852a54253ef59,"adjusted widths, changed application to app, and converted mean/median/std to ints"
28,https://api.github.com/repos/mozilla/datazilla/pulls/110,110,"mean, median, and error bar controls","This branch is not ready to review but should facilitate some back and forth with glob to finish the implementation.
",jeads,949498,2014-01-30T02:19:57Z,CONTRIBUTOR,True,122,25,9,Datazilla is a system for managing and visualizing data.,JavaScript,8c7b18f969c8a1b48775209471488edc0bd56299,"adjusted widths, changed application to app, and converted mean/median/std to ints"
29,https://api.github.com/repos/mozilla/datazilla/pulls/109,109,added b2gtw handling,"Added handling to send the new b2gtw project to the b2g ui
",jeads,949498,2014-01-29T21:33:41Z,CONTRIBUTOR,True,10,3,4,Datazilla is a system for managing and visualizing data.,JavaScript,ac4769aac442db880b5b70104f37ff1c2caeaf84,added b2gtw handling
30,https://api.github.com/repos/mozilla/datazilla/pulls/108,108,Update hompage slider range,"Missed to files in the merge, added them back.
",jeads,949498,2013-12-13T23:13:31Z,CONTRIBUTOR,True,16,4,2,Datazilla is a system for managing and visualizing data.,JavaScript,70f1ab6c82a115599c238a30794af163f3f0ebfc,made changes
31,https://api.github.com/repos/mozilla/datazilla/pulls/107,107,Data cycling,"This branch includes a variety of updates to the b2g ui and homepage. It also includes an initial data cycling manage.py command that will be completed and added as a scheduled job in a subsequent branch.
",jeads,949498,2013-12-13T23:02:29Z,CONTRIBUTOR,True,209,69,9,Datazilla is a system for managing and visualizing data.,JavaScript,47725f33b12e05349bec279820cd9ad3141d4847,made changes
32,https://api.github.com/repos/mozilla/datazilla/pulls/107,107,Data cycling,"This branch includes a variety of updates to the b2g ui and homepage. It also includes an initial data cycling manage.py command that will be completed and added as a scheduled job in a subsequent branch.
",jeads,949498,2013-12-13T23:02:29Z,CONTRIBUTOR,True,209,69,9,Datazilla is a system for managing and visualizing data.,JavaScript,f7bb77ef5b0535cd36336acbee742158762fb693,rebuilt minified js
33,https://api.github.com/repos/mozilla/datazilla/pulls/106,106,fixed js bugs and reduced min-width in homepage ui,"This branch fixes a bug in the homepage javascript that prevents url's with either x86=false or x86_64=false parameter specifications from loading when the data exclusion causes graphs to have no data. It also fixes a bug in the url initialization logic that prevented ""Browse By Test"" selections to not load correctly.
",jeads,949498,2013-09-11T23:10:09Z,CONTRIBUTOR,True,46,26,9,Datazilla is a system for managing and visualizing data.,JavaScript,748b96f09e73417e16cbbbd5f230e753a1737e71,fixed js bugs and reduced min-width in homepage ui
34,https://api.github.com/repos/mozilla/datazilla/pulls/105,105,Remove dataviews,"This branch removes the deprecated original datazilla ui and associated web services/model methods that were adapted from bughunter.
",jeads,949498,2013-09-09T22:47:09Z,CONTRIBUTOR,True,94,5856,22,Datazilla is a system for managing and visualizing data.,JavaScript,9d81306973da6ac977de0d4cca522302e03fd5f6,removed deprecated code
35,https://api.github.com/repos/mozilla/datazilla/pulls/105,105,Remove dataviews,"This branch removes the deprecated original datazilla ui and associated web services/model methods that were adapted from bughunter.
",jeads,949498,2013-09-09T22:47:09Z,CONTRIBUTOR,True,94,5856,22,Datazilla is a system for managing and visualizing data.,JavaScript,fa0089a22ac797e37068234396ee9378efc1f2ac,removed dataviews
36,https://api.github.com/repos/mozilla/datazilla/pulls/105,105,Remove dataviews,"This branch removes the deprecated original datazilla ui and associated web services/model methods that were adapted from bughunter.
",jeads,949498,2013-09-09T22:47:09Z,CONTRIBUTOR,True,94,5856,22,Datazilla is a system for managing and visualizing data.,JavaScript,0dddb192dba0b1783b6bcad08ba923e4ac772a01,removed deprecated ui
37,https://api.github.com/repos/mozilla/datazilla/pulls/105,105,Remove dataviews,"This branch removes the deprecated original datazilla ui and associated web services/model methods that were adapted from bughunter.
",jeads,949498,2013-09-09T22:47:09Z,CONTRIBUTOR,True,94,5856,22,Datazilla is a system for managing and visualizing data.,JavaScript,b6210b14a3e8782fe5ab529c5c13b6e1c37896a9,removed deprecated ui
38,https://api.github.com/repos/mozilla/datazilla/pulls/105,105,Remove dataviews,"This branch removes the deprecated original datazilla ui and associated web services/model methods that were adapted from bughunter.
",jeads,949498,2013-09-09T22:47:09Z,CONTRIBUTOR,True,94,5856,22,Datazilla is a system for managing and visualizing data.,JavaScript,39e0e662be3b2048f74b2fd351784dd23d0aab9d,updated Bases.js path
39,https://api.github.com/repos/mozilla/datazilla/pulls/104,104,Ui zoom,"Adds zooming functionality to the graphs in the user interface.
",jeads,949498,2013-09-04T20:47:07Z,CONTRIBUTOR,True,612,9,6,Datazilla is a system for managing and visualizing data.,JavaScript,3bf6b285aa6a37a425e9d0820b3a080c1b21f58c,added zoom feature
40,https://api.github.com/repos/mozilla/datazilla/pulls/104,104,Ui zoom,"Adds zooming functionality to the graphs in the user interface.
",jeads,949498,2013-09-04T20:47:07Z,CONTRIBUTOR,True,612,9,6,Datazilla is a system for managing and visualizing data.,JavaScript,b27fca7595d738d2dac25a4bce27781faead9211,added jquery.mousewheel.js for compatibility with jquery version
41,https://api.github.com/repos/mozilla/datazilla/pulls/104,104,Ui zoom,"Adds zooming functionality to the graphs in the user interface.
",jeads,949498,2013-09-04T20:47:07Z,CONTRIBUTOR,True,612,9,6,Datazilla is a system for managing and visualizing data.,JavaScript,a76cbd0f89df6ba83a91705ca6117823bf815d86,recompiled minified js
42,https://api.github.com/repos/mozilla/datazilla/pulls/104,104,Ui zoom,"Adds zooming functionality to the graphs in the user interface.
",jeads,949498,2013-09-04T20:47:07Z,CONTRIBUTOR,True,612,9,6,Datazilla is a system for managing and visualizing data.,JavaScript,15d3533fbfafe757ceb6d84c9c58d7c31877a8ad,removed graph scrollwheel functionality
43,https://api.github.com/repos/mozilla/datazilla/pulls/103,103,Ui checkboxes,"Adds new checkbox toggles for displaying x86, x86_64, and error_bars on the displayed graphs. This branch also adds functionality enabling a user to add a series to all displayed graphs from a different product/repository.
",jeads,949498,2013-09-03T18:48:29Z,CONTRIBUTOR,True,691,110,20,Datazilla is a system for managing and visualizing data.,JavaScript,8dda3db455430894850e3f71cc8fd9ccb99ef46a,"added x86, x86_64, and error bar toggles and compare to functionality"
44,https://api.github.com/repos/mozilla/datazilla/pulls/103,103,Ui checkboxes,"Adds new checkbox toggles for displaying x86, x86_64, and error_bars on the displayed graphs. This branch also adds functionality enabling a user to add a series to all displayed graphs from a different product/repository.
",jeads,949498,2013-09-03T18:48:29Z,CONTRIBUTOR,True,691,110,20,Datazilla is a system for managing and visualizing data.,JavaScript,bb5e9cb844a4bdb1cf2e58bc12986ffdf2b0334a,added graph controls to url structure
45,https://api.github.com/repos/mozilla/datazilla/pulls/103,103,Ui checkboxes,"Adds new checkbox toggles for displaying x86, x86_64, and error_bars on the displayed graphs. This branch also adds functionality enabling a user to add a series to all displayed graphs from a different product/repository.
",jeads,949498,2013-09-03T18:48:29Z,CONTRIBUTOR,True,691,110,20,Datazilla is a system for managing and visualizing data.,JavaScript,8a538e8be3bbd08bdc635199d72a8f1153492d63,color picker plugin
46,https://api.github.com/repos/mozilla/datazilla/pulls/103,103,Ui checkboxes,"Adds new checkbox toggles for displaying x86, x86_64, and error_bars on the displayed graphs. This branch also adds functionality enabling a user to add a series to all displayed graphs from a different product/repository.
",jeads,949498,2013-09-03T18:48:29Z,CONTRIBUTOR,True,691,110,20,Datazilla is a system for managing and visualizing data.,JavaScript,b749356fc2c2e27ee2c1a8de48b2a28be6c14448,added more colorpicker stuff
47,https://api.github.com/repos/mozilla/datazilla/pulls/103,103,Ui checkboxes,"Adds new checkbox toggles for displaying x86, x86_64, and error_bars on the displayed graphs. This branch also adds functionality enabling a user to add a series to all displayed graphs from a different product/repository.
",jeads,949498,2013-09-03T18:48:29Z,CONTRIBUTOR,True,691,110,20,Datazilla is a system for managing and visualizing data.,JavaScript,4b4fa8add337505db764aaa80a15f03d5488023c,removed console statement
48,https://api.github.com/repos/mozilla/datazilla/pulls/100,100,Fix tp5 stdev,"Added generic handling for replicate filtering based the combination of project and test. Added specific handling for talos and tp50 to exclude the first replicate when computing the mean and standard deviation. 
",jeads,949498,2013-08-23T16:58:07Z,CONTRIBUTOR,True,221,89,3,Datazilla is a system for managing and visualizing data.,JavaScript,5bad4d3231c2a2eb97e5f46a930cc265f10fb0a4,"added handling for filtering replicates in the calculation of the mean, also removed some old metrics code"
49,https://api.github.com/repos/mozilla/datazilla/pulls/100,100,Fix tp5 stdev,"Added generic handling for replicate filtering based the combination of project and test. Added specific handling for talos and tp50 to exclude the first replicate when computing the mean and standard deviation. 
",jeads,949498,2013-08-23T16:58:07Z,CONTRIBUTOR,True,221,89,3,Datazilla is a system for managing and visualizing data.,JavaScript,f29e5ce810ead47f3455534bc278885227972bc5,modified sql where logic to use not equal to improve performance
50,https://api.github.com/repos/mozilla/datazilla/pulls/99,99,Homepage history,"This branch adds history for all user actions enabling url representations for all page states.
",jeads,949498,2013-08-21T00:00:05Z,CONTRIBUTOR,True,18423,196,43,Datazilla is a system for managing and visualizing data.,JavaScript,4d6bf71428b8228e23c858d9bcf6e50a5b8efbc0,made changes
51,https://api.github.com/repos/mozilla/datazilla/pulls/99,99,Homepage history,"This branch adds history for all user actions enabling url representations for all page states.
",jeads,949498,2013-08-21T00:00:05Z,CONTRIBUTOR,True,18423,196,43,Datazilla is a system for managing and visualizing data.,JavaScript,15bc8fd695d3e9f1313a3311476c63d1a6d5c635,added state management and history functionality
52,https://api.github.com/repos/mozilla/datazilla/pulls/99,99,Homepage history,"This branch adds history for all user actions enabling url representations for all page states.
",jeads,949498,2013-08-21T00:00:05Z,CONTRIBUTOR,True,18423,196,43,Datazilla is a system for managing and visualizing data.,JavaScript,2e097fdc0e13042d63ce6c2e0ed3002e133d17b7,fixed plot click bug
53,https://api.github.com/repos/mozilla/datazilla/pulls/99,99,Homepage history,"This branch adds history for all user actions enabling url representations for all page states.
",jeads,949498,2013-08-21T00:00:05Z,CONTRIBUTOR,True,18423,196,43,Datazilla is a system for managing and visualizing data.,JavaScript,ad13d9f2dbc445a6fcee031b0ac5c2ed1860b42a,made lots of changes to history management
54,https://api.github.com/repos/mozilla/datazilla/pulls/99,99,Homepage history,"This branch adds history for all user actions enabling url representations for all page states.
",jeads,949498,2013-08-21T00:00:05Z,CONTRIBUTOR,True,18423,196,43,Datazilla is a system for managing and visualizing data.,JavaScript,d983a1374b60a0eee55c515757724c15e73a589c,added new files
55,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,2ec12d2ea8c68458f68a05e090a89289e644b8c7,made changes
56,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,2faf8c5094b7cb82e83a1e0f9bfa0de509becc28,new files
57,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,e31e832a917687af04e888cb705c0bfaeedd5659,made changes
58,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,328267c41a907e30bbf82493f705ae2f2f636236,made changes
59,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,cb8c66437daf3417d5953e0840f137a4c6fabf8b,made changes
60,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,f512ac024de1ea5fd7ae31a55866b31bfd58cd5c,made changes
61,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,bdb5185dead8d340c279a829722c433654192a8b,fixed the slider
62,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,c23d477701bfe64be96b2986e0e98bcf0c81f0ee,added missing files
63,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,eef62e4d498923992ef19da0a5eec5eabf324a1d,added SelectionState class for state management
64,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,1bb017aba7449dfcaf9d6e67c4409f6bad59a4b2,new components
65,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,eae32c49413b5701a4c8ef1695da58d09f083764,made changes
66,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,d395b20f0b23ac2673c7cd085e0b12205bcf97f2,made changes
67,https://api.github.com/repos/mozilla/datazilla/pulls/97,97,Data cube,"This branch includes the etl procedures for the new test_data_all_dimensions table and associated web service methods. The UI code is also included but is not enabled in urls.py.
",jeads,949498,2013-07-26T19:52:33Z,CONTRIBUTOR,True,2938,52,31,Datazilla is a system for managing and visualizing data.,JavaScript,7aa0b3af42f654b44fb785d92de15995644f009b,removed comment
68,https://api.github.com/repos/mozilla/datazilla/pulls/95,95,B2g new details,"Adds changes to display the attributes: delay, restart, and settle_time in the detail panel when a user selects a data point.
",jeads,949498,2013-06-11T21:20:46Z,CONTRIBUTOR,True,29,7,5,Datazilla is a system for managing and visualizing data.,JavaScript,46b0ac699ed57147e32def027a2a23e08a30dc32,made changes
69,https://api.github.com/repos/mozilla/datazilla/pulls/95,95,B2g new details,"Adds changes to display the attributes: delay, restart, and settle_time in the detail panel when a user selects a data point.
",jeads,949498,2013-06-11T21:20:46Z,CONTRIBUTOR,True,29,7,5,Datazilla is a system for managing and visualizing data.,JavaScript,412a3f7fdc449eb20e83852d82595551ddea684b,made changes
70,https://api.github.com/repos/mozilla/datazilla/pulls/94,94,added device select menu,"Added handling for multiple phone devices.
",jeads,949498,2013-05-14T22:20:55Z,CONTRIBUTOR,True,144,27,11,Datazilla is a system for managing and visualizing data.,JavaScript,207f3b6bf5696763671b88b1f1c1a0870149bed9,added device select menu
71,https://api.github.com/repos/mozilla/datazilla/pulls/93,93,changed email app name to email FTU,"Mapped email app name to email FTU.
",jeads,949498,2013-04-18T21:43:24Z,CONTRIBUTOR,True,18,1,2,Datazilla is a system for managing and visualizing data.,JavaScript,7f473ea148912d96d52a5db58e3ee501e19dee6c,changed email app name to email FTU
72,https://api.github.com/repos/mozilla/datazilla/pulls/92,92,modified update_pushlog command to use pid strategy,"This branch modifies the existing `update_pushlog` command to utilize a pid strategy to send a `kill -9 pid` if it's detected in the process list when it's run. All termination events are logged to a log file, this is a work around for a bug in python's urllib which causes the program to hang when there is an interrupt in an HTTP GET. This branch also contains a fix for a long standing bug in the `datazilla/webapp/apps/datazilla/views.py set_test_data()` method returning a web service endpoint with a 0 id in it.
",jeads,949498,2013-04-16T18:05:53Z,CONTRIBUTOR,True,74,23,5,Datazilla is a system for managing and visualizing data.,JavaScript,64a4681464c1caf03b5bea795c921476af40e43c,modified update_pushlog command to use pid strategy
73,https://api.github.com/repos/mozilla/datazilla/pulls/91,91,Cache json objects,"Added new manage command for transferring production data to development. Also removed the b2g apps ftu and marketplace from the performance graph display.
",jeads,949498,2013-04-10T19:56:27Z,CONTRIBUTOR,True,180,24,5,Datazilla is a system for managing and visualizing data.,JavaScript,b73ce67cf3b1632340826616f14da28116ee3c8d,expanded exclude list
74,https://api.github.com/repos/mozilla/datazilla/pulls/91,91,Cache json objects,"Added new manage command for transferring production data to development. Also removed the b2g apps ftu and marketplace from the performance graph display.
",jeads,949498,2013-04-10T19:56:27Z,CONTRIBUTOR,True,180,24,5,Datazilla is a system for managing and visualizing data.,JavaScript,a33681b31ba8564d582d81eba30f9ae825704bce,new manage command to transfer data from production to development databases
75,https://api.github.com/repos/mozilla/datazilla/pulls/90,90,"added handling for serveral app related unhandled states, removed onchan...","Added handling for a defined app_list without a relevant app series selection.
",jeads,949498,2013-03-25T18:26:26Z,CONTRIBUTOR,True,15,11,3,Datazilla is a system for managing and visualizing data.,JavaScript,35568afdb95ad457f5d83558a75698efe51dc8b4,"added handling for serveral app related unhandled states, removed onchange app listener"
76,https://api.github.com/repos/mozilla/datazilla/pulls/89,89,Compute test results,"This branch updates django to 1.4.4, fixes a b2g UI race condition associated with the state saved on selecting all applications, and adds test support for computing metrics in the http request cycle without saving the result (not sure if this will be used yet).
",jeads,949498,2013-03-22T21:57:59Z,CONTRIBUTOR,True,251592,109436,3010,Datazilla is a system for managing and visualizing data.,JavaScript,bb7a009937308db1f82225f3d57f56fb93f0029e,new django version
77,https://api.github.com/repos/mozilla/datazilla/pulls/89,89,Compute test results,"This branch updates django to 1.4.4, fixes a b2g UI race condition associated with the state saved on selecting all applications, and adds test support for computing metrics in the http request cycle without saving the result (not sure if this will be used yet).
",jeads,949498,2013-03-22T21:57:59Z,CONTRIBUTOR,True,251592,109436,3010,Datazilla is a system for managing and visualizing data.,JavaScript,59ec1954a1050c1b2fa7621d3a94370ceef77e35,"fixed b2g issues, started inline metrics calculations"
78,https://api.github.com/repos/mozilla/datazilla/pulls/89,89,Compute test results,"This branch updates django to 1.4.4, fixes a b2g UI race condition associated with the state saved on selecting all applications, and adds test support for computing metrics in the http request cycle without saving the result (not sure if this will be used yet).
",jeads,949498,2013-03-22T21:57:59Z,CONTRIBUTOR,True,251592,109436,3010,Datazilla is a system for managing and visualizing data.,JavaScript,a560bf2256efe728ee079d10edf526f6e29fda67,added changes
79,https://api.github.com/repos/mozilla/datazilla/pulls/89,89,Compute test results,"This branch updates django to 1.4.4, fixes a b2g UI race condition associated with the state saved on selecting all applications, and adds test support for computing metrics in the http request cycle without saving the result (not sure if this will be used yet).
",jeads,949498,2013-03-22T21:57:59Z,CONTRIBUTOR,True,251592,109436,3010,Datazilla is a system for managing and visualizing data.,JavaScript,9ea056d40db7de9f9971633ecb3a9d5798cc1374,added missing jquery.history.js to minified js
80,https://api.github.com/repos/mozilla/datazilla/pulls/88,88,fixes display url bug and label area bug,"Fixes displayed url bug and increases label area to full size of label
",jeads,949498,2013-03-15T18:35:18Z,CONTRIBUTOR,True,33,26,6,Datazilla is a system for managing and visualizing data.,JavaScript,b24d709f378909fb2dde859d40596300dd2a922a,fixes display url bug and label area bug
81,https://api.github.com/repos/mozilla/datazilla/pulls/87,87,"added url based history and HTML5 labels to b2g UI, removed pushlog pane...","Added HTML5 labels and url based history and removed the `Get URL` dropdown from the b2g UI. Removed the pushlog panel from the talos UI. Added django-cors-headers to enable cross origin javascript queries for http GET only.
",jeads,949498,2013-03-12T21:57:31Z,CONTRIBUTOR,True,497,149,25,Datazilla is a system for managing and visualizing data.,JavaScript,17c0131d6c886d3450eaf74b195da3fbd6b8852c,"added url based history and HTML5 labels to b2g UI, removed pushlog panel from talos UI"
82,https://api.github.com/repos/mozilla/datazilla/pulls/87,87,"added url based history and HTML5 labels to b2g UI, removed pushlog pane...","Added HTML5 labels and url based history and removed the `Get URL` dropdown from the b2g UI. Removed the pushlog panel from the talos UI. Added django-cors-headers to enable cross origin javascript queries for http GET only.
",jeads,949498,2013-03-12T21:57:31Z,CONTRIBUTOR,True,497,149,25,Datazilla is a system for managing and visualizing data.,JavaScript,9a1e30b850395081ead7ebf230a8e347d6ea35a0,commented out pushlog creation
83,https://api.github.com/repos/mozilla/datazilla/pulls/87,87,"added url based history and HTML5 labels to b2g UI, removed pushlog pane...","Added HTML5 labels and url based history and removed the `Get URL` dropdown from the b2g UI. Removed the pushlog panel from the talos UI. Added django-cors-headers to enable cross origin javascript queries for http GET only.
",jeads,949498,2013-03-12T21:57:31Z,CONTRIBUTOR,True,497,149,25,Datazilla is a system for managing and visualizing data.,JavaScript,eff7b7fb09cb0937c44ebd555dca2c8d1eed8223,new files
84,https://api.github.com/repos/mozilla/datazilla/pulls/87,87,"added url based history and HTML5 labels to b2g UI, removed pushlog pane...","Added HTML5 labels and url based history and removed the `Get URL` dropdown from the b2g UI. Removed the pushlog panel from the talos UI. Added django-cors-headers to enable cross origin javascript queries for http GET only.
",jeads,949498,2013-03-12T21:57:31Z,CONTRIBUTOR,True,497,149,25,Datazilla is a system for managing and visualizing data.,JavaScript,36ff23d3e9681e74806df0711e2141395d3228f7,removed unecessary file
85,https://api.github.com/repos/mozilla/datazilla/pulls/86,86,added permalinks and fixed some bugs,"added permalinks and fixed some bugs for the b2g ui
",jeads,949498,2013-03-01T18:20:07Z,CONTRIBUTOR,True,428,63,13,Datazilla is a system for managing and visualizing data.,JavaScript,3927663d76824e715326c2696ef2e874d74bea41,added permalinks and fixed some bugs
86,https://api.github.com/repos/mozilla/datazilla/pulls/85,85,Socket timeout,"Added a socket default timeout to prevent `store_pushlogs` from hanging in a TCP CLOSE_WAIT state when the json_pushes web service method fails to return. Also fixed the x-axis labels and added handling for default branch options in the UI.
",jeads,949498,2013-02-13T01:51:12Z,CONTRIBUTOR,True,52,21,6,Datazilla is a system for managing and visualizing data.,JavaScript,9eff42081911eaaad562e4c88cfdacff238a1b6d,adds socket.setdefaulttimeout to store_pushlogs webservice call and adds a default branch selection to the UI
87,https://api.github.com/repos/mozilla/datazilla/pulls/85,85,Socket timeout,"Added a socket default timeout to prevent `store_pushlogs` from hanging in a TCP CLOSE_WAIT state when the json_pushes web service method fails to return. Also fixed the x-axis labels and added handling for default branch options in the UI.
",jeads,949498,2013-02-13T01:51:12Z,CONTRIBUTOR,True,52,21,6,Datazilla is a system for managing and visualizing data.,JavaScript,39aff22448bd306c07b595f4f90a3f4e8bc1c31a,fixed x-axis label bug
88,https://api.github.com/repos/mozilla/datazilla/pulls/85,85,Socket timeout,"Added a socket default timeout to prevent `store_pushlogs` from hanging in a TCP CLOSE_WAIT state when the json_pushes web service method fails to return. Also fixed the x-axis labels and added handling for default branch options in the UI.
",jeads,949498,2013-02-13T01:51:12Z,CONTRIBUTOR,True,52,21,6,Datazilla is a system for managing and visualizing data.,JavaScript,37925a5cb4a8ea9559b64dc4403d8cb9e45a7f86,make sure json_data is in scope
89,https://api.github.com/repos/mozilla/datazilla/pulls/84,84,added group by revision and branch select functionality,"Adds group by gaia/gecko revision combination to the main performance graph and a branch select menu.
",jeads,949498,2013-02-01T18:22:49Z,CONTRIBUTOR,True,287,48,14,Datazilla is a system for managing and visualizing data.,JavaScript,7346f0e03ca29208c28fd951d291c1ae4e1a38a1,added group by revision and branch select functionality
90,https://api.github.com/repos/mozilla/datazilla/pulls/83,83,B2g app summary,"New dedicated UI for b2g/gaia performance test data.  Also adds a local variable for a allowed list of projects.
",jeads,949498,2013-01-28T20:38:26Z,CONTRIBUTOR,True,1550,52,23,Datazilla is a system for managing and visualizing data.,JavaScript,e122d26dd2794ea424f7d6f63cb204f4b66dc0ed,new UI for b2g
91,https://api.github.com/repos/mozilla/datazilla/pulls/83,83,B2g app summary,"New dedicated UI for b2g/gaia performance test data.  Also adds a local variable for a allowed list of projects.
",jeads,949498,2013-01-28T20:38:26Z,CONTRIBUTOR,True,1550,52,23,Datazilla is a system for managing and visualizing data.,JavaScript,42767a3c2372dfedc09fa9177fba06b69493963e,fixed hover issue
92,https://api.github.com/repos/mozilla/datazilla/pulls/83,83,B2g app summary,"New dedicated UI for b2g/gaia performance test data.  Also adds a local variable for a allowed list of projects.
",jeads,949498,2013-01-28T20:38:26Z,CONTRIBUTOR,True,1550,52,23,Datazilla is a system for managing and visualizing data.,JavaScript,4d1954a3d1a9a24bf8a158e182ba8fef191d972a,fixed test
93,https://api.github.com/repos/mozilla/datazilla/pulls/82,82,Crossbrowser fix,"Fixed a crossbrowser ui bug, added in-application help, and also added the presentation of the threshold revision for each test metric datum displayed.
",jeads,949498,2013-01-16T22:25:24Z,CONTRIBUTOR,True,315,33,16,Datazilla is a system for managing and visualizing data.,JavaScript,45afb0ea736275ea71449e2374bdb5e753bbd1a3,fixed cross browser layout bugs
94,https://api.github.com/repos/mozilla/datazilla/pulls/82,82,Crossbrowser fix,"Fixed a crossbrowser ui bug, added in-application help, and also added the presentation of the threshold revision for each test metric datum displayed.
",jeads,949498,2013-01-16T22:25:24Z,CONTRIBUTOR,True,315,33,16,Datazilla is a system for managing and visualizing data.,JavaScript,982ee95b6f849fb2188d95466ac0937a027a22ff,added in application help
95,https://api.github.com/repos/mozilla/datazilla/pulls/82,82,Crossbrowser fix,"Fixed a crossbrowser ui bug, added in-application help, and also added the presentation of the threshold revision for each test metric datum displayed.
",jeads,949498,2013-01-16T22:25:24Z,CONTRIBUTOR,True,315,33,16,Datazilla is a system for managing and visualizing data.,JavaScript,935904f743381844c9b5047b8c103238610073de,updated minified css and js
96,https://api.github.com/repos/mozilla/datazilla/pulls/81,81,Doc update 1,"Cleaned up the readthedocs documentation and updated the readme.
",jeads,949498,2013-01-09T22:39:24Z,CONTRIBUTOR,True,228,442,8,Datazilla is a system for managing and visualizing data.,JavaScript,cb74fd68aa0f40adf6b42b069206c3527b6c0890,fixed docs
97,https://api.github.com/repos/mozilla/datazilla/pulls/81,81,Doc update 1,"Cleaned up the readthedocs documentation and updated the readme.
",jeads,949498,2013-01-09T22:39:24Z,CONTRIBUTOR,True,228,442,8,Datazilla is a system for managing and visualizing data.,JavaScript,da3e14d590be03ada01df5a41b673796f7df78ca,added link
98,https://api.github.com/repos/mozilla/datazilla/pulls/81,81,Doc update 1,"Cleaned up the readthedocs documentation and updated the readme.
",jeads,949498,2013-01-09T22:39:24Z,CONTRIBUTOR,True,228,442,8,Datazilla is a system for managing and visualizing data.,JavaScript,02d5b65af89f1750a22f906b968351ecd52138d4,"cleaned up docs, fixed web service method return structure"
99,https://api.github.com/repos/mozilla/datazilla/pulls/81,81,Doc update 1,"Cleaned up the readthedocs documentation and updated the readme.
",jeads,949498,2013-01-09T22:39:24Z,CONTRIBUTOR,True,228,442,8,Datazilla is a system for managing and visualizing data.,JavaScript,af1ff5f4dfbe381a619368a5d02ecc168d48a015,fixed text
100,https://api.github.com/repos/mozilla/datazilla/pulls/81,81,Doc update 1,"Cleaned up the readthedocs documentation and updated the readme.
",jeads,949498,2013-01-09T22:39:24Z,CONTRIBUTOR,True,228,442,8,Datazilla is a system for managing and visualizing data.,JavaScript,55cce6bb477d636249f6199f96547c94a2c05cdc,fixed test
101,https://api.github.com/repos/mozilla/datazilla/pulls/81,81,Doc update 1,"Cleaned up the readthedocs documentation and updated the readme.
",jeads,949498,2013-01-09T22:39:24Z,CONTRIBUTOR,True,228,442,8,Datazilla is a system for managing and visualizing data.,JavaScript,180ec5cebec7fe2480355395a418d6d66fe1073b,rearranged stuff
102,https://api.github.com/repos/mozilla/datazilla/pulls/80,80,Stage fix 2,"Converts the unique key on build.test_build_id to a composite key that incorporates the test_build_id, product_id, processor, and build_type.  This branch also contains some UI enhancements including carrying out a least squares fit of the trend mean data for data display in the revision pushlog.
",jeads,949498,2012-12-17T19:36:58Z,CONTRIBUTOR,True,508,251,23,Datazilla is a system for managing and visualizing data.,JavaScript,58623b3ab0e436500fb40ce5e3143ed1de931e64,lots of changes
103,https://api.github.com/repos/mozilla/datazilla/pulls/80,80,Stage fix 2,"Converts the unique key on build.test_build_id to a composite key that incorporates the test_build_id, product_id, processor, and build_type.  This branch also contains some UI enhancements including carrying out a least squares fit of the trend mean data for data display in the revision pushlog.
",jeads,949498,2012-12-17T19:36:58Z,CONTRIBUTOR,True,508,251,23,Datazilla is a system for managing and visualizing data.,JavaScript,0f87ce2f15e8207c1e7b10de532aa3e52d5e832f,removed tdhtml
104,https://api.github.com/repos/mozilla/datazilla/pulls/80,80,Stage fix 2,"Converts the unique key on build.test_build_id to a composite key that incorporates the test_build_id, product_id, processor, and build_type.  This branch also contains some UI enhancements including carrying out a least squares fit of the trend mean data for data display in the revision pushlog.
",jeads,949498,2012-12-17T19:36:58Z,CONTRIBUTOR,True,508,251,23,Datazilla is a system for managing and visualizing data.,JavaScript,1eb8605d80bd87c29704629edd8a59fe49e2aa80,fixed bug
105,https://api.github.com/repos/mozilla/datazilla/pulls/79,79,removed legacy cache code,"Removes legacy memcache usage and a set of methods from datazilla/views.py that are no longer required.
",jeads,949498,2012-12-06T20:51:08Z,CONTRIBUTOR,True,2,219,2,Datazilla is a system for managing and visualizing data.,JavaScript,beb04cceba66e3ddbf0c115f2bc932ea63056d9c,removed legacy cache code
106,https://api.github.com/repos/mozilla/datazilla/pulls/78,78,Update docs,"Updates some of the readthedocs documentation.  Also includes a bug fix for the grid layout, a grid of any size can now be accommodated. 
",jeads,949498,2012-12-06T18:31:51Z,CONTRIBUTOR,True,220,97,10,Datazilla is a system for managing and visualizing data.,JavaScript,55d3b084b63a1ce41e9406a016ff7025ce29d7d4,"fixed some bugs, cleaned up docs"
107,https://api.github.com/repos/mozilla/datazilla/pulls/78,78,Update docs,"Updates some of the readthedocs documentation.  Also includes a bug fix for the grid layout, a grid of any size can now be accommodated. 
",jeads,949498,2012-12-06T18:31:51Z,CONTRIBUTOR,True,220,97,10,Datazilla is a system for managing and visualizing data.,JavaScript,d9c550433d3bd68072e4d33b1282277db2f10617,fixed comment
108,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,025da884d008797096ca8ccfcfa37946c0226d6e,moved dataview app under apps
109,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,b7e94b5a6767c6be76b2869dc80c954e383de2c4,new developer ui components
110,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,294f7fa56882d01467ee31186b800e78d2f8f2fe,removed
111,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,6509075d35820c7c2c32830c796041fb0b56457d,added ui components
112,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,1af3e24683a62819fcb2912a3cd6e8784a0e393f,added test pages ui components
113,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,4e3aca834b1edb239ef337f2327cc22b62152099,more ui
114,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,2ab516fc1a34817b37dc351b5d074a114c4850be,Merge branch 'master' of https://github.com/mozilla/datazilla into developer-ui
115,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,41b05f0772acea00c4db9324e9897476fb4bceb2,ui changes
116,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,3553f8ee118b9e011dc715f186f2a8cd2385a8b1,Merge branch 'master' of https://github.com/mozilla/datazilla into developer-ui
117,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,10be9459f0dd2b4b1f74d8c14d583e4e404a5a85,made changes
118,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,ccd6845ad3f943709a4640b1bbfc214bad4f4f78,Merge branch 'master' of https://github.com/mozilla/datazilla into developer-ui
119,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,3c4d44cf29ec38d306116b25ba35c274ebb21309,fixed mouseover hover issue
120,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,b448a2dece018f441414e399ebf36d28e2475800,Merge branch 'master' of https://github.com/mozilla/datazilla into developer-ui
121,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,1e4842f99da3b11af80d5873d8d9b1165b554407,ui grid component
122,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,0dfac09a54738af5537017cd8d600a0892dcc073,more ui
123,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,bd1764a54d7767be4c32fdf605b8b3665de6a7c5,merged
124,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,d7adc43eee95db7161a203be3ec90eaf8d54f07d,made changes
125,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,746968315545921c2784d1b4c323084b566718f7,modified webservice
126,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,f0a0aa9a84bb3c753a1d751d7e5ffb87c3c699bf,increased loadlimit
127,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,88298abf3fa52c78bee2caa2b57f752fda8ff751,merged with master
128,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,67434ca03b901fc111e522c5532c680b99709535,made changes
129,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,815f9cb3e3756fa62136b76120c285c08a89b473,fixed hover bug
130,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,0fcf3c9c94f329011546c7b7206c48430166678c,merged
131,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,8403874388d468029204c05fd563837211380322,ui changes
132,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,212712de023dd47f3d8f5b47cbf4d9d6c03b015a,Merge branch 'master' of https://github.com/mozilla/datazilla into developer-ui
133,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,62ae872faa685991021f0d6c4d4020480e440e54,made changes
134,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,6a7259146dd6ac07a40d5a9eb8bc0748ed059793,made changes
135,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,e5f9fbd32c79cbf5b3a533603375be8e6f9a3297,made changes
136,https://api.github.com/repos/mozilla/datazilla/pulls/77,77,Developer ui,"This branch implements a new user interface designed to display per push metrics data with the intent of identifying performance regressions.
",jeads,949498,2012-12-05T18:37:30Z,CONTRIBUTOR,True,3735,258,43,Datazilla is a system for managing and visualizing data.,JavaScript,21119544ae92172f66f45039d657724abbf9d1a2,lots of changes
137,https://api.github.com/repos/mozilla/datazilla/pulls/76,76,Remove summary cache,"The populate_summary_cache command is now removed from crontab.txt.  
",jeads,949498,2012-11-21T02:20:59Z,CONTRIBUTOR,True,0,40,2,Datazilla is a system for managing and visualizing data.,JavaScript,3f8a29dc32b7132feaa1962badce9ef2dfa058f2,removed summary_cache dependencies
138,https://api.github.com/repos/mozilla/datazilla/pulls/76,76,Remove summary cache,"The populate_summary_cache command is now removed from crontab.txt.  
",jeads,949498,2012-11-21T02:20:59Z,CONTRIBUTOR,True,0,40,2,Datazilla is a system for managing and visualizing data.,JavaScript,896e75bcf2d78c440980b018bf74c82e1e8a66fa,removed unused statement
139,https://api.github.com/repos/mozilla/datazilla/pulls/75,75,added maximum allowed value for replicates,"There is a bug in some of the talos test suites that causes 63,000 replicates to be submitted to datazilla for a single page in a test suite.  This branch puts a maximum limit of 5000 replicates for all test suites.
",jeads,949498,2012-11-15T22:43:32Z,CONTRIBUTOR,True,27,12,1,Datazilla is a system for managing and visualizing data.,JavaScript,d42a37430653ff837d7956098aaad306c5050c44,added maximum allowed value for replicates
140,https://api.github.com/repos/mozilla/datazilla/pulls/74,74,"removed talos from the automated summary data generation process, disabl...","This branch turns off warnings generated on the summary cache.  The warnings are specific to the master/slave configuration on production.  It also removes the summary generation for talos.
",jeads,949498,2012-10-19T22:01:26Z,CONTRIBUTOR,True,22,11,2,Datazilla is a system for managing and visualizing data.,JavaScript,aaa544b6206ef301061e1a118690b83c8ebee7fb,"removed talos from the automated summary data generation process, disable warnings for loading the summary cache"
141,https://api.github.com/repos/mozilla/datazilla/pulls/73,73,Cache fix,"This branch fixes a bug in the selection of default projects and also limits the number of default projects to 10.
",jeads,949498,2012-10-17T18:42:16Z,CONTRIBUTOR,True,7,4,2,Datazilla is a system for managing and visualizing data.,JavaScript,75e638a6e7f7e7eb17a099a5d45a6b476f8fa061,made changes
142,https://api.github.com/repos/mozilla/datazilla/pulls/73,73,Cache fix,"This branch fixes a bug in the selection of default projects and also limits the number of default projects to 10.
",jeads,949498,2012-10-17T18:42:16Z,CONTRIBUTOR,True,7,4,2,Datazilla is a system for managing and visualizing data.,JavaScript,8adf8a27ef4cc50f81fb7e612c21c4581dc2a0a6,merged
143,https://api.github.com/repos/mozilla/datazilla/pulls/73,73,Cache fix,"This branch fixes a bug in the selection of default projects and also limits the number of default projects to 10.
",jeads,949498,2012-10-17T18:42:16Z,CONTRIBUTOR,True,7,4,2,Datazilla is a system for managing and visualizing data.,JavaScript,cf4f3940150cfe8d8b3e4113bf30333519a10807,fixed default selection bug
144,https://api.github.com/repos/mozilla/datazilla/pulls/72,72,Pushlog fix,"This branch fixes a bug in the pushlog that causes it to be out of sync with what is reported in tbpl.  It also adds some adjustments to the metrics web service to support ui development.
",jeads,949498,2012-10-16T20:23:45Z,CONTRIBUTOR,True,128,53,6,Datazilla is a system for managing and visualizing data.,JavaScript,fdd9d17907c976d5245b277b8def21f983ddfa7e,fixed pushlog bug
145,https://api.github.com/repos/mozilla/datazilla/pulls/72,72,Pushlog fix,"This branch fixes a bug in the pushlog that causes it to be out of sync with what is reported in tbpl.  It also adds some adjustments to the metrics web service to support ui development.
",jeads,949498,2012-10-16T20:23:45Z,CONTRIBUTOR,True,128,53,6,Datazilla is a system for managing and visualizing data.,JavaScript,188e280b9113f9eb543d1bc1cbceae985290f979,made changes
146,https://api.github.com/repos/mozilla/datazilla/pulls/72,72,Pushlog fix,"This branch fixes a bug in the pushlog that causes it to be out of sync with what is reported in tbpl.  It also adds some adjustments to the metrics web service to support ui development.
",jeads,949498,2012-10-16T20:23:45Z,CONTRIBUTOR,True,128,53,6,Datazilla is a system for managing and visualizing data.,JavaScript,750ff62e94ac47f3410467500e13f3b827dd92d0,modified tests
147,https://api.github.com/repos/mozilla/datazilla/pulls/72,72,Pushlog fix,"This branch fixes a bug in the pushlog that causes it to be out of sync with what is reported in tbpl.  It also adds some adjustments to the metrics web service to support ui development.
",jeads,949498,2012-10-16T20:23:45Z,CONTRIBUTOR,True,128,53,6,Datazilla is a system for managing and visualizing data.,JavaScript,993c3c05562621e98b77d17431d3ab8b6d3f6a4e,made float format changes
148,https://api.github.com/repos/mozilla/datazilla/pulls/71,71,disabled MySQLdb.Warning for objectstore.updates.mark_loading,"Disabling MySQLdb.Warning for objectstore.updates.mark_loading
",jeads,949498,2012-10-12T20:08:10Z,CONTRIBUTOR,True,30,3,1,Datazilla is a system for managing and visualizing data.,JavaScript,e39c6606e913758146200c4f460652278a303456,disabled MySQLdb.Warning for objectstore.updates.mark_loading
149,https://api.github.com/repos/mozilla/datazilla/pulls/70,70,added ORDER BY clause to unsafe UPDATE,"In SQL an UPDATE with a LIMIT but no ORDER BY clause is unsafe because the query may produce different results each time it is applied even on identical data sets.  In the case of this particular query it doesn't cause a real problem but it does produce an annoying warning message in the log.  
",jeads,949498,2012-10-11T21:18:54Z,CONTRIBUTOR,True,1,0,1,Datazilla is a system for managing and visualizing data.,JavaScript,e86ce458b4e3f97307bccca80a6bbaa05e1f4a7f,added ORDER BY clause to unsafe UPDATE
150,https://api.github.com/repos/mozilla/datazilla/pulls/69,69,fixed query load issue,"This branch adds a set of reference data constraints to a metrics model method that significantly reduces the quantity of data retrieved when walking the push log.  It also adds handling for excluding all Try branches from the metrics calculations.  The Try exceptions will be removed once we have a method of retrieving the Try comparison branch at run time.
",jeads,949498,2012-10-11T16:14:53Z,CONTRIBUTOR,True,83,11,6,Datazilla is a system for managing and visualizing data.,JavaScript,23decd3b41027b85359b6652a874fd5f11bce46d,fixed query load issue
151,https://api.github.com/repos/mozilla/datazilla/pulls/68,68,Metrics model tests,"This completes the test coverage of metrics related model and controller methods used by the web service.
",jeads,949498,2012-09-28T19:53:18Z,CONTRIBUTOR,True,135,1,2,Datazilla is a system for managing and visualizing data.,JavaScript,8b2f07b0df146ea1d93087ba6076c7cc90f04dba,added metrics tests
152,https://api.github.com/repos/mozilla/datazilla/pulls/68,68,Metrics model tests,"This completes the test coverage of metrics related model and controller methods used by the web service.
",jeads,949498,2012-09-28T19:53:18Z,CONTRIBUTOR,True,135,1,2,Datazilla is a system for managing and visualizing data.,JavaScript,6df601c5a09c6531dce10b5dc0971c5099ae9a54,added missing metrics model and controller tests
153,https://api.github.com/repos/mozilla/datazilla/pulls/67,67,added optional arg,"Adding optional project argument to a factory method.  Missed this in the original branch.
",jeads,949498,2012-09-28T15:44:51Z,CONTRIBUTOR,True,2,2,1,Datazilla is a system for managing and visualizing data.,JavaScript,f51da6fd47c9c33435d43313f7ee0e73ced94f8a,added optional arg
154,https://api.github.com/repos/mozilla/datazilla/pulls/66,66,added testdata web service unit tests,"This branch adds a complete set of unit tests for all of the `testdata` web service methods.  It also adds a new query parameter for branch version numbers and fixes a couple bugs.
",jeads,949498,2012-09-27T23:55:54Z,CONTRIBUTOR,True,596,83,8,Datazilla is a system for managing and visualizing data.,JavaScript,f2fdd748e738120e76f522a36261e0ee3586d43a,added testdata web service unit tests
155,https://api.github.com/repos/mozilla/datazilla/pulls/65,65,New docs,"This branch adds documentation for the metrics web services and the new set of data filters available.  It also fixes a bug found in one of the metrics methods.
",jeads,949498,2012-09-24T23:27:49Z,CONTRIBUTOR,True,522,64,7,Datazilla is a system for managing and visualizing data.,JavaScript,ab8451c63012f11ff933deb2c7fc125f16c2d05f,fixed bug added docs
156,https://api.github.com/repos/mozilla/datazilla/pulls/65,65,New docs,"This branch adds documentation for the metrics web services and the new set of data filters available.  It also fixes a bug found in one of the metrics methods.
",jeads,949498,2012-09-24T23:27:49Z,CONTRIBUTOR,True,522,64,7,Datazilla is a system for managing and visualizing data.,JavaScript,90ca735bd6824566dd98389a97162abb4121eb2d,fixed bug
157,https://api.github.com/repos/mozilla/datazilla/pulls/64,64,Stats to refdata,"This branch converts all the references to ""stats"" into ""refdata"" where they apply to reference data, rather than statistics.
",camd,419924,2012-09-24T21:58:14Z,CONTRIBUTOR,True,148,148,29,Datazilla is a system for managing and visualizing data.,JavaScript,1c762ea28ba7bea955a1f7156d9f9cb0e4391fa9,Update datazilla/model/sql/template_schema/schema_perftest.json
158,https://api.github.com/repos/mozilla/datazilla/pulls/64,64,Stats to refdata,"This branch converts all the references to ""stats"" into ""refdata"" where they apply to reference data, rather than statistics.
",camd,419924,2012-09-24T21:58:14Z,CONTRIBUTOR,True,148,148,29,Datazilla is a system for managing and visualizing data.,JavaScript,2513df84c00b016bf4790a38b6e33432124b4d5e,Update datazilla/model/sql/template_schema/schema_perftest.json
159,https://api.github.com/repos/mozilla/datazilla/pulls/64,64,Stats to refdata,"This branch converts all the references to ""stats"" into ""refdata"" where they apply to reference data, rather than statistics.
",camd,419924,2012-09-24T21:58:14Z,CONTRIBUTOR,True,148,148,29,Datazilla is a system for managing and visualizing data.,JavaScript,462844382f6238ea0ce37a08c823d005d3417c04,Update datazilla/model/sql/template_schema/schema_perftest.json
160,https://api.github.com/repos/mozilla/datazilla/pulls/64,64,Stats to refdata,"This branch converts all the references to ""stats"" into ""refdata"" where they apply to reference data, rather than statistics.
",camd,419924,2012-09-24T21:58:14Z,CONTRIBUTOR,True,148,148,29,Datazilla is a system for managing and visualizing data.,JavaScript,eccea32d6ac0c543c84a4892cfee94787f2d51b0,some of the stats to refdata changes
161,https://api.github.com/repos/mozilla/datazilla/pulls/64,64,Stats to refdata,"This branch converts all the references to ""stats"" into ""refdata"" where they apply to reference data, rather than statistics.
",camd,419924,2012-09-24T21:58:14Z,CONTRIBUTOR,True,148,148,29,Datazilla is a system for managing and visualizing data.,JavaScript,01c07f69ca628e405f03596690fcd1a21301dba6,finished changing stats references over to refdata
162,https://api.github.com/repos/mozilla/datazilla/pulls/64,64,Stats to refdata,"This branch converts all the references to ""stats"" into ""refdata"" where they apply to reference data, rather than statistics.
",camd,419924,2012-09-24T21:58:14Z,CONTRIBUTOR,True,148,148,29,Datazilla is a system for managing and visualizing data.,JavaScript,a88fb7a2dc2385e519076249d8d4fbdd5b36b004,fixed webapp area stats references to refdata
163,https://api.github.com/repos/mozilla/datazilla/pulls/64,64,Stats to refdata,"This branch converts all the references to ""stats"" into ""refdata"" where they apply to reference data, rather than statistics.
",camd,419924,2012-09-24T21:58:14Z,CONTRIBUTOR,True,148,148,29,Datazilla is a system for managing and visualizing data.,JavaScript,8111932c7eafb27159e222c0e86d7aedb82673a1,"Merge pull request #65 from mozilla/new-docs

New docs"
164,https://api.github.com/repos/mozilla/datazilla/pulls/64,64,Stats to refdata,"This branch converts all the references to ""stats"" into ""refdata"" where they apply to reference data, rather than statistics.
",camd,419924,2012-09-24T21:58:14Z,CONTRIBUTOR,True,148,148,29,Datazilla is a system for managing and visualizing data.,JavaScript,8096b0bd0206f6e0573b263f091e44e9d118cf12,Merge branch 'stats-to-refdata' of https://github.com/mozilla/datazilla into stats-to-refdata
165,https://api.github.com/repos/mozilla/datazilla/pulls/64,64,Stats to refdata,"This branch converts all the references to ""stats"" into ""refdata"" where they apply to reference data, rather than statistics.
",camd,419924,2012-09-24T21:58:14Z,CONTRIBUTOR,True,148,148,29,Datazilla is a system for managing and visualizing data.,JavaScript,26fb2a2402200b6669aa3b8e9ab24eaaf44a1d3f,removed stats reference
166,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,934a17e798cbb4c4fe7ab8b60771e4d3c5d55972,starting skeleton for the testdata api
167,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,3f35b15dec0083564dbdad03d7dbfac27d9a78ec,now returning the list of json blobs according to the filters
168,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,6f50f108cdd7d2e11e6c3df1892dd9d8ea4bd6ff,added support for bad json blobs
169,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,24aa4894c30fdb96dbb882f1634d689d0769b011,added statistics api for getting a list of pushlogs.  and documentation for the new apis.
170,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,4e638a24cda92676eae5b9b0af7511cf0fbb6347,"oops, not all files were committed in that last commit"
171,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,27916b082e2fe3bb15327ae9ed715e1be36062c8,added test for get_pushlogs
172,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,dec0b9d2e63f4234dfaf4899ec4d672e9b97ff90,added tests for the controller for the testdata webservice
173,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,d6ec004a251688a3aa6851f60f3698bd561b2e95,merged master with new metrics branch changes.  fixed conflicts
174,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,dc8650a9ddcbdbb43e3bea311eb90036deeb60d9,added new URL for the metrics data
175,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,451d06fcbbaab1733cd60e59bb70cff5b30fb34d,new endpoint (project)/testdata/metrics/(branch)/(revision) added.  returns dummy content for now.
176,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,e3235b226da092355776f23b7079059b9f1ee1ba,"fixed controller, added application logging"
177,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,e6bc17595c480fd1cb0eb21ddb225c826fc9c5ed,fixed tests
178,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,c5e917b0d9bb0a032e1cd65a3b068146cdc803e5,Merge branch 'ws-testdata' of https://github.com/mozilla/datazilla into metrics-web-service
179,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,21d8ce9ce782711f29668638a8ec627dacc7ea5f,fixed server error when fetching testdata/raw
180,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,5bc263470afae9212dc2b8286a994b80c98f77dd,Merge branch 'ws-testdata' of https://github.com/mozilla/datazilla into metrics-web-service
181,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,50bf3a67551d90ace1c5d74a1176e6038faffb4d,merged ws-testdata and added metrics web service methods
182,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,d342ef88c208dfca1b3a0edc0ee46e40335958ad,added default summary command
183,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,dd7f2dcf5b6bfcd4f31eb284b5c40d2347f31406,fixed bug
184,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,61364428e9ee53395e18fcf0741461354e42fec9,fixed broken tests
185,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,9d0caabfc342d944cd5cdf73456a8d959167cabf,made changes
186,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,da2fba70c867b0c78f8a828ffe9766f744a35be6,made changes
187,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,c6bb7c88e9c5c1515a6962608a385c34bf6a5ee0,new doc group
188,https://api.github.com/repos/mozilla/datazilla/pulls/63,63,Metrics web service,"This branch is not ready for revue, making a pull request to start some discussion around it.  I will need to merge the ws-testdata branch into it before adding metrics web service methods.  This branch fixes a variety of issues found in perftest_metrics.py and also adds handling for the occurrence of 0 standard deviation which causes a divide by zero error in the t-test.

The branch incorporates new edge case handling for a variety of cases found when trolling through large quantities of the development data.  These cases were missed when using the sample data in the unit tests.  It also adds an application_log table that allows us to capture application level errors in the database and provide useful debugging information.
",jeads,949498,2012-09-14T18:43:04Z,CONTRIBUTOR,True,2469,459,51,Datazilla is a system for managing and visualizing data.,JavaScript,b04def40b5b0adc81a4aa13f5a5bf61760f1c681,removed files
189,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,d2e6b28852f27ed891c7fc1c5ff7676773988157,new metrics implementation
190,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,d59c29fa8a846718724644f8607ce55517e675cd,new metrics implementation
191,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,733386fe410accfd76bc9b5494e9373e1e536e60,made changes
192,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,a7ea6e24f9414d124d88d88d8cc5ab4267c0e2f9,merged master into branch
193,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,3d2983c42ddc3bc9c4e4685bbaf8713b9b3cdf5f,changes for metrics
194,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,2a75afa5ba9bf233282de3ec7ce6445716274bef,changed a bunch of stuff
195,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,3961ce074549df1eb84f403b2a4359b8532b9b9a,made changes
196,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,05bb98a344d9e83cf9f1a7d3dd730d461f1ccad6,clean up
197,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,4ddfc11054827875d84db3ebc09444d6e937e5f7,renamed
198,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,45af9ba0ff8cb3f3025c7a4d8cab78498cdddffe,renamed
199,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,d15f4e4a2bf4b0c5a0f2f7cdd1ad302866d54c7f,tests for MetricsMethodFactory
200,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,955cda4ebf5377836da8a56f03a942d76dbc2aba,added run_metrics command tests
201,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,e5e2295f2882f9e1451a2b8e93d084207d75308d,added controller tests
202,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,c7f34f073141dcde79166386c1931a54ac72983c,added requirement for metric threshold updates
203,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,292bf37843a6018020519f097c4e48521d3bc869,added threshold_test_run_id to track the parent data used with a child
204,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,386007e43ec9cf889d9a4552a380518d903d9fc2,cleaned up
205,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,5da4ab959d6471784cae04a4ed20eeead53f1560,moved MetricsTestModel to metrics.py
206,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,09405d0c8d5648d3826c3ba1dc8c071a2726f402,made changes for exp smoothing
207,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,12fa26e58458f1bcf0bf3866dea01f5d5d6c1be6,cleaned up
208,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,6914e71e57be1c5829bc6b8932888cfe5d0db170,removed unnecessary imports
209,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,3b904c7723e8300b3be49ead103dfb432b9e43e7,prep for exp_smooth
210,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,f2825df08a5885487498abe20cd76396fb0f037a,added exp smoothing
211,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,81c41362310834c691da8ae5058ab77dde06f785,new metrics files
212,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,b0410655ec18b210e361334af03d1cf5c02a9e65,updated
213,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,dd90b008ba251f93be2302a15c174e492c3c486e,merged
214,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,942a37008659a02e8452f0b01ed00db1c259a8f3,removed run_metrics command
215,https://api.github.com/repos/mozilla/datazilla/pulls/62,62,Metrics schema,"Not ready for merge yet, but a pull request allows easier review and commenting
",carljm,61586,2012-08-28T16:59:29Z,MEMBER,True,3963,863,46,Datazilla is a system for managing and visualizing data.,JavaScript,441e05a637d7fde3bdc605a1a03f1fb20cd01147,modified interface
216,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,88c696df99f424434f1d907c05d4ac84bb7868ff,new management command to build an error report for unparseable JSON
217,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,98761ad8fa3ad21d9e0a9e689f0d708b3d3b264f,pushlog_check mgmt command to verify any pushlogs that do not have tests for the specified branch
218,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,adcbe4f613b5b48bec3d98a8047dc66b430906f6,moved most of pushlog_check work into the pushlogmodel and perftestmodel.  also fixed some logic in the management command base class and children
219,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,3118d6d9c2ef8f1b55dab93c0e8f102e182c12a2,fixed call for count of pushlogs to be simpler and faster.
220,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,b5be0c4667992a31f30fefc5cdc46bbb4d22f9d0,adding a secondary technique to check for missing talos data by query
221,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,b9fc65ca8de66a0ac750340c950535dcbe202cd4,added some docs
222,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,9d696e57e26142b4ed5b5c6fa521425ad20b2d51,made script more configurable.
223,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,9f8b5246c3f8e4937ef759844c85e37488f55410,added branch filtering support for get_pushlogs_...
224,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,37a5c421984c7d413072e7133593d5cb612b77d8,Merge branch 'master' into data-check
225,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,3f807ef3c582bf6b3ea705fd4c7aed4c4635eda6,begin creating the webservice for stats
226,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,91d1da0d88d8bc971b3021fdd9df8972beea2a5f,"finished web services for getting counts of error blobs, list of error data, and specific json blobs by id"
227,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,326da438667cefc1344cdd4e24f06e33646e395e,added perftest webservice methods
228,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,fa6eccab3d8b666ba9b9b099c6bcda0ac18a37b5,new pushlog stats webservices
229,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,13a96cebdae4e651adbc4a9dfea7a77fc153b283,trying with updated datasource
230,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,c9676bc53e89b3fb4456957a25f86bb05ebb5a73,added database size api
231,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,a68688fec7f0dcf444a2c531f1ab471c4da43d73,added docs for the endpoints
232,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,c2fb54bbe4d7e28a8a43bcb02b6b0600acee6230,added url for list of pushlog branches.  adding some tests.
233,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,45792d7e4105f4da279dde7097bcbaad9dcfab2b,fixed doc errors for webservices
234,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,01270f3c86258c1defc8498322b83e4e9a17820a,fixed another doc error with the statistics heading
235,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,d70736247e08484df8d59b7e2d24b92cb1c1d82a,made return data use utf-8
236,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,5efa98f2685faf30c02f60ff64d382ada199c137,doc fix for objectstore / perftest db_size mixup
237,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,9a790edd004f32757bb12c6f62994042c8a825ca,added show_test_runs param to perftest/runs_by_branch
238,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,91b5676580120ce03128db80a9bc05e5fdab6577,added show_test_runs consistent formatting.  and updated the docs
239,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,1a1e75eaefc848f380f683d8f9d1ccfde3a59e5a,made thes stats models inherit directly from DatazillaModelBase.  Fixed urls for pushlog stats that didn't need the project name.  Starts for some more tests.
240,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,05807fa1a56aac22d6ba14954133f8d23cb4f87f,working on a test
241,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,cf8f7ef077f7418998ebfbe0208a76ee6a3d588a,"added unit tests for the pushlog, performance test and objectstore stats controllers"
242,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,973263c8d81e219f9fd8a734561d2300a4633091,new tests now passing with 100% coverage on views and controllers.  Still need to cover a couple stats model methods.
243,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,66a64afce97674e1765dbc8fd6ba563596cf2761,fixed docs and added limit of max 80 test runs per branch returned
244,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,a126e899e5fea5a1e7d9d03d6a264e9139bb270d,fixed last test for perftest_views
245,https://api.github.com/repos/mozilla/datazilla/pulls/61,61,Data check,"State: Ready for review.

I added the limits to the ""get_test_runs"" perftest.json query.  However I wasn't able to find any way to return what the non-limited count would be.  So it doesn't do that.

The tracker story for this is:  https://www.pivotaltracker.com/story/show/33862653
",camd,419924,2012-08-10T01:22:03Z,CONTRIBUTOR,True,2725,265,57,Datazilla is a system for managing and visualizing data.,JavaScript,d4d2c6f7c85c4763160a6f64d1c6625687687593,removed unused methods in the stats model
246,https://api.github.com/repos/mozilla/datazilla/pulls/60,60,Prod changes,"Added a new column to datazilla.datasource to support read only databases and updated appropriate sql.  Also made a few changes to support https in the post_json command.
",jeads,949498,2012-08-01T19:20:50Z,CONTRIBUTOR,True,61,39,7,Datazilla is a system for managing and visualizing data.,JavaScript,e3539e54267955cd3600493dc87dc005becc73ae,"added read_only_host column to datazilla.datasource that gets passed to datasource module, updated ro sql"
247,https://api.github.com/repos/mozilla/datazilla/pulls/60,60,Prod changes,"Added a new column to datazilla.datasource to support read only databases and updated appropriate sql.  Also made a few changes to support https in the post_json command.
",jeads,949498,2012-08-01T19:20:50Z,CONTRIBUTOR,True,61,39,7,Datazilla is a system for managing and visualizing data.,JavaScript,d5ada23f7a4b7e0608934ad939a39f4fecf587d9,updated to work with https
248,https://api.github.com/repos/mozilla/datazilla/pulls/60,60,Prod changes,"Added a new column to datazilla.datasource to support read only databases and updated appropriate sql.  Also made a few changes to support https in the post_json command.
",jeads,949498,2012-08-01T19:20:50Z,CONTRIBUTOR,True,61,39,7,Datazilla is a system for managing and visualizing data.,JavaScript,1e11eccaa6185b8050c7b5bc8edd65964edee3be,updated sql to use read_only where appropriate
249,https://api.github.com/repos/mozilla/datazilla/pulls/60,60,Prod changes,"Added a new column to datazilla.datasource to support read only databases and updated appropriate sql.  Also made a few changes to support https in the post_json command.
",jeads,949498,2012-08-01T19:20:50Z,CONTRIBUTOR,True,61,39,7,Datazilla is a system for managing and visualizing data.,JavaScript,6c3ed22aad49c58c7624836ded3811c6beb44597,"added manage command to clear datasources from memcached, removed ON DUPLICATE KEY sql that was generating a warning on prod"
250,https://api.github.com/repos/mozilla/datazilla/pulls/59,59,create_project has been renamed to create_perftest_project,"Pull me!
",rniwa,285965,2012-07-26T22:47:21Z,CONTRIBUTOR,True,3,3,1,Datazilla is a system for managing and visualizing data.,JavaScript,16dd89837ffe8fb7513e0b9d0efe1864ce831a5a,create_project has been renamed to create_perftest_project
251,https://api.github.com/repos/mozilla/datazilla/pulls/58,58,View tests,"This adds 100% test coverage of `oauth_required` decorator and `set_test_data` view. Also fixes some bugs along the way, and adds some infrastructure (like a test http client with the ability to post signed OAuth data) that will be useful for future view tests.
",carljm,61586,2012-07-19T23:14:30Z,MEMBER,True,257,47,11,Datazilla is a system for managing and visualizing data.,JavaScript,c90110c4d871afac45e469133411a9d42ce10628,Remove some unused imports.
252,https://api.github.com/repos/mozilla/datazilla/pulls/58,58,View tests,"This adds 100% test coverage of `oauth_required` decorator and `set_test_data` view. Also fixes some bugs along the way, and adds some infrastructure (like a test http client with the ability to post signed OAuth data) that will be useful for future view tests.
",carljm,61586,2012-07-19T23:14:30Z,MEMBER,True,257,47,11,Datazilla is a system for managing and visualizing data.,JavaScript,36ad1f0deb5a29beb70dc04badca752927232671,Always truncate the testproj tables.
253,https://api.github.com/repos/mozilla/datazilla/pulls/58,58,View tests,"This adds 100% test coverage of `oauth_required` decorator and `set_test_data` view. Also fixes some bugs along the way, and adds some infrastructure (like a test http client with the ability to post signed OAuth data) that will be useful for future view tests.
",carljm,61586,2012-07-19T23:14:30Z,MEMBER,True,257,47,11,Datazilla is a system for managing and visualizing data.,JavaScript,478f42a16044d68e38e9d72eef6d46303f184a6e,Prevent test discovery in vendor/; allows running just py.test.
254,https://api.github.com/repos/mozilla/datazilla/pulls/58,58,View tests,"This adds 100% test coverage of `oauth_required` decorator and `set_test_data` view. Also fixes some bugs along the way, and adds some infrastructure (like a test http client with the ability to post signed OAuth data) that will be useful for future view tests.
",carljm,61586,2012-07-19T23:14:30Z,MEMBER,True,257,47,11,Datazilla is a system for managing and visualizing data.,JavaScript,b06264bae5f2779b3c6394f27be7f9ff42bb4d06,Add initial happy-path test for set_test_data view.
255,https://api.github.com/repos/mozilla/datazilla/pulls/58,58,View tests,"This adds 100% test coverage of `oauth_required` decorator and `set_test_data` view. Also fixes some bugs along the way, and adds some infrastructure (like a test http client with the ability to post signed OAuth data) that will be useful for future view tests.
",carljm,61586,2012-07-19T23:14:30Z,MEMBER,True,257,47,11,Datazilla is a system for managing and visualizing data.,JavaScript,b39a5261c36d998ed9bb4ddf6c663b9a24123981,Merge branch 'master' into view-test
256,https://api.github.com/repos/mozilla/datazilla/pulls/58,58,View tests,"This adds 100% test coverage of `oauth_required` decorator and `set_test_data` view. Also fixes some bugs along the way, and adds some infrastructure (like a test http client with the ability to post signed OAuth data) that will be useful for future view tests.
",carljm,61586,2012-07-19T23:14:30Z,MEMBER,True,257,47,11,Datazilla is a system for managing and visualizing data.,JavaScript,c8c0257294856ec7a95de08441d84b5ccc3eab06,Full coverage of oauth_required.
257,https://api.github.com/repos/mozilla/datazilla/pulls/58,58,View tests,"This adds 100% test coverage of `oauth_required` decorator and `set_test_data` view. Also fixes some bugs along the way, and adds some infrastructure (like a test http client with the ability to post signed OAuth data) that will be useful for future view tests.
",carljm,61586,2012-07-19T23:14:30Z,MEMBER,True,257,47,11,Datazilla is a system for managing and visualizing data.,JavaScript,45a5bda2f4041613847eb0d07a05f8f0ec609e53,100% coverage of both oauth_required and set_test_data.
258,https://api.github.com/repos/mozilla/datazilla/pulls/58,58,View tests,"This adds 100% test coverage of `oauth_required` decorator and `set_test_data` view. Also fixes some bugs along the way, and adds some infrastructure (like a test http client with the ability to post signed OAuth data) that will be useful for future view tests.
",carljm,61586,2012-07-19T23:14:30Z,MEMBER,True,257,47,11,Datazilla is a system for managing and visualizing data.,JavaScript,9a50c1067895a3ccd8bacfa608a2fad9247474d1,"Return 404, not 500, on bad project name."
259,https://api.github.com/repos/mozilla/datazilla/pulls/58,58,View tests,"This adds 100% test coverage of `oauth_required` decorator and `set_test_data` view. Also fixes some bugs along the way, and adds some infrastructure (like a test http client with the ability to post signed OAuth data) that will be useful for future view tests.
",carljm,61586,2012-07-19T23:14:30Z,MEMBER,True,257,47,11,Datazilla is a system for managing and visualizing data.,JavaScript,25f145b5cfa25a3e329ae6d7a2e5c6ed10573516,Add missing __init__.py
260,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,1f4eae1d20d7afda8f70e71a8203687950e94306,adding batching to populate_summary_cache management command.  updated create_perftest_project to support the cron_batch field
261,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,7527a946f700cb6237a601308ed791890a60496a,Merge branch 'master' into cron-commands
262,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,8ac802144152f69b22cb9a404be1323e956d7f55,added a new command base that handles project and cron_batch params.  The cron_batch part handles looping on the command for the batch.  Also added a param to view the projects that belong to each batch.
263,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,0387afde1004eb0d2d61fc43d11bd6d327adf0ea,make other project related tests use the ProjectCommandBase parent class.  Added a crontab.txt sample
264,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,05745f3ea0a46d509b397455725d775994d706ff,added new tests to cover base.py for batching and populate_summary_cache
265,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,0a1ff971f9a42a344db42b8097b52bbc45c0e32f,added tests for all mgmt commands
266,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,7478c8ccd6d5d3e27e361400db2945e4e74cd27d,Merge branch 'master' into cron-commands
267,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,1b941763f91e68f03b56a0484e82f80c6ca5a0e3,got test for next dataset working
268,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,14c3ef1ba8999f965c2b69160b18e337762e7c08,Merge branch 'master' into cron-commands
269,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,cec0d264b258859e8c3a1bb8856e7bf1d278efbd,fixed test_view_batches method
270,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,d6a61071e978ae6dd3b30b4d59efcbb690812e0b,"I was going to test the base directly, but I tested it through populate_summary_cache."
271,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,9df18014cea55fbd64d7b784dde41c3e1cf765e9,adding file locking to batch commands
272,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,f589f3c27c6d0aa7d6822a64136246440a901b3a,Merge branch 'master' into cron-commands
273,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,cb25cbd0b7896e26be53f9714f787bf85c1a356c,added the release lock to the finally block
274,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,48c9dd64e3c6a80e02d0ab06f81a4a0da50ffb3c,using fixes to datasource and added lockfile to vendor lib
275,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,9f51229435a1e1a9ede7bb8063669f3fe43bcefd,added file locking for batch and pushlog update processes to prevent stomping each other
276,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,bc9929e808c3da508521357bf96f7ef9b22b4908,made fixes per carl's and jeads' review comments
277,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,0ce12a5f049865b17b4f6e8e6ce784b12def1a5a,fixes to the crontab.txt file and a couple mgmt command fixes
278,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,6e41c86183c5ced0317ac52ccca848cf62874ed1,added custom name for test databases.  and implemented the rest of carljm's pull comments
279,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,59b25ce89fdb00c05243c80e7f787cbe7c4fdfc3,removed some commented code
280,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,480d96383b64aa3b685a3d8701fe4b8ca1bf3d7d,Make tests run again without externally-installed Django; change setting name to TEST_DB_PREFIX.
281,https://api.github.com/repos/mozilla/datazilla/pulls/57,57,Cron commands,"Add batching to some management commands, such as populate_summary_cache and process_objects.  Had to update the create_perftest_product to support a cron_batch value.  cron_batch is the field that determines which batch each project falls into.  When you pass that value to populate_summary_cache or process_objects, it will loop through and act on each project in that batch.  You can also pass in multiple batches.

This also contains a crontab.txt sample file that represents what I believe IT will want in their crontab.
",camd,419924,2012-07-19T20:55:21Z,CONTRIBUTOR,True,3211,353,35,Datazilla is a system for managing and visualizing data.,JavaScript,80b95117aa61990c0c343aa566860f428b9937c8,Merge branch master into cron-commands.
282,https://api.github.com/repos/mozilla/datazilla/pulls/56,56,Add test for bugfix to _set_build_data.,"When we have a bug that doesn't cause any test to fail, that indicates a hole in test coverage. Preferably ever time we fix a bug, we also add a test that fails prior to the bugfix and passes after it. This pull request adds such a test for the recent fix to _set_build_data.
",carljm,61586,2012-07-19T16:51:41Z,MEMBER,True,18,1,1,Datazilla is a system for managing and visualizing data.,JavaScript,e3f2bb0781b4662a7504d1a1ee777b4d6b51bf1b,Add test for bugfix to _set_build_data.
283,https://api.github.com/repos/mozilla/datazilla/pulls/55,55,fixed set_build_data(),"These changes fix a bug in _set_build_data() that resulted in the build.id being returned only after a new build was inserted.
",jeads,949498,2012-07-19T15:46:55Z,CONTRIBUTOR,True,21,5,2,Datazilla is a system for managing and visualizing data.,JavaScript,38be9b0988ac6bf528642787f1733bf6ef794e88,fixed set_build_data()
284,https://api.github.com/repos/mozilla/datazilla/pulls/54,54,disable oauth for talos,"It's going to be awhile before the talos production environment can support OAuth or some form of API keys.  We cannot wait to roll the changes we have to development and we cannot afford to stop ingesting data from talos tests.  To account for this I've added a conditional that disables OAuth for talos.
",jeads,949498,2012-07-18T21:27:27Z,CONTRIBUTOR,True,9,0,1,Datazilla is a system for managing and visualizing data.,JavaScript,316495ced1788357923baf1c19b1faff5d8e35c7,disable oauth for talos
285,https://api.github.com/repos/mozilla/datazilla/pulls/53,53,Perftest schema fixes,"This branch fixes several problems with the perftest schema.

1.) Moved `build.machine_id` to `test_run.machine_id`

2.) Moved `build.operating_system_id` to `machine.operating_system_id`

3.) Made `build.test_build_id` a `UNIQUE KEY`

4.) Updated `set_build_data` SQL to use `INSERT SELECT FROM DUAL WHERE NOT EXISTS` strategy

I'm not sure it's worth migrating the existing development databases to have these changes.  I'm thinking it would be easier to dump the data for talos, drop all existing perftest databases and recreate all of them using the new schema, then validate that the new incoming talos data looks as expected.  None of the other projects are currently using the development instances, everyone is waiting for the production database to become available.
",jeads,949498,2012-07-17T20:12:06Z,CONTRIBUTOR,True,94,68,5,Datazilla is a system for managing and visualizing data.,JavaScript,ff4d4813b6d9d9576429696d951379e497032436,"moved build.machine_id, build.operating_system_id to test_run.machine_id and machine.operating_system_id also changed the set_build_data() to use INSERT INTO SELECT FROM DUAL..."
286,https://api.github.com/repos/mozilla/datazilla/pulls/53,53,Perftest schema fixes,"This branch fixes several problems with the perftest schema.

1.) Moved `build.machine_id` to `test_run.machine_id`

2.) Moved `build.operating_system_id` to `machine.operating_system_id`

3.) Made `build.test_build_id` a `UNIQUE KEY`

4.) Updated `set_build_data` SQL to use `INSERT SELECT FROM DUAL WHERE NOT EXISTS` strategy

I'm not sure it's worth migrating the existing development databases to have these changes.  I'm thinking it would be easier to dump the data for talos, drop all existing perftest databases and recreate all of them using the new schema, then validate that the new incoming talos data looks as expected.  None of the other projects are currently using the development instances, everyone is waiting for the production database to become available.
",jeads,949498,2012-07-17T20:12:06Z,CONTRIBUTOR,True,94,68,5,Datazilla is a system for managing and visualizing data.,JavaScript,07ead80e896171f3ffd420e7d291050b5583268f,build id must be unique
287,https://api.github.com/repos/mozilla/datazilla/pulls/53,53,Perftest schema fixes,"This branch fixes several problems with the perftest schema.

1.) Moved `build.machine_id` to `test_run.machine_id`

2.) Moved `build.operating_system_id` to `machine.operating_system_id`

3.) Made `build.test_build_id` a `UNIQUE KEY`

4.) Updated `set_build_data` SQL to use `INSERT SELECT FROM DUAL WHERE NOT EXISTS` strategy

I'm not sure it's worth migrating the existing development databases to have these changes.  I'm thinking it would be easier to dump the data for talos, drop all existing perftest databases and recreate all of them using the new schema, then validate that the new incoming talos data looks as expected.  None of the other projects are currently using the development instances, everyone is waiting for the production database to become available.
",jeads,949498,2012-07-17T20:12:06Z,CONTRIBUTOR,True,94,68,5,Datazilla is a system for managing and visualizing data.,JavaScript,ac89e269c7875540387b270fc5bd4e0f55eccda2,Increment a counter rather than using random test build IDs in tests.
288,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,4cb4c0c962d120ad5accd85f8fb02eaaced6d868,fixed reference data cache bug
289,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,b3efd2f95c3c01605ac4f715df444ee8c2ee1ff6,fixed test_collection population strategy to avoid failed inserts
290,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,7a5b637e54b0897fd07d4e096798e87d410ef062,added reference data and default project caching
291,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,87a48dbbecb580eb0df72aed57a6072ee61ff7b5,added new methods for updating the reference data cache
292,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,1168db801b8445359b2831933e8381ac031ba41c,added INSERT INTO ... WHERE NOT EXISTS to replace duplicate key inserts
293,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,90046f3248b833a2c10401cbf71a488813971a3e,added default_product column
294,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,e6bd14491c5b35f6dfa4c66559f7e2d2648e8ac7,made get_cache_key name more specific
295,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,dffa656474237bf6e68650a0203a996044a08912,removed reference data cache code
296,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,4289479817029cf09cbb602db3a72f84b9e1fee6,modified placeholder params to work with new SQL
297,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,a6c0af8667e524ef43d7fcb3a665d782622b7daa,removed INSERT ON DUPLICATE KEY statements for all reference data and replaced with INSERT SELECT WHERE NOT EXISTS statements
298,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,b100a422a086bdfa774ed2394d97c2933cadfc64,reference data generated from perftest default test data
299,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,4b8831d9d10bef9fb5666ebd8d32c4a992407fc7,added set method for default product
300,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,ffc2fa951670c08155f355f3f6507e721277de7c,added sql for default product set method
301,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,51ce9acc1f9829f9b6f01b1fdbdc3c79965530de,added test methods for reference data and setting the default product
302,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,6b9151d0ae0638c48848ecc65b2b689b00c30c2d,added reference data retrieval method
303,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,c1b87bb16ca569e924b3e7cda6b9e46aaeb518c8,cleaned up comments
304,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,d8d7bed4cf430bece64eac3bf4bf0e20faa71546,cleaned up comment
305,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,20804b4e09707c480341102f00127c7a9bc98959,made cache_ref_data() returned the compressed json data
306,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,5d70ad143d15a43b66e3ccd0aa172de9fd0378d0,cleaned up
307,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,2de35bd6102d57e4c5afe6307e95e28e6788b9f2,"Merge pull request #53 from mozilla/perftest-schema-fixes

Perftest schema fixes"
308,https://api.github.com/repos/mozilla/datazilla/pulls/52,52,Ui sql fixes,"This branch fixes the following issues:

1.) The UI was using cached reference data that was only loaded when the server was started, this means that any new reference data inserted after that would not be visible in the cache.  To fix this the following changes were made: 
     - `PerformanceTestModel.get_test_reference_data()` was modified to cache reference data.
     -  An explicit method to cache data was added and is now called in the manage command `populate_summary_cache`.  Any time cached summary data is modified the reference data cache is updated.

2.) The manage command, `populate_test_collections`, was failing on data integrity errors caused by inserting duplicate keys.
     - The method was modified to only insert product test collections that have not already been inserted.

3.) The UI needs to specify a default branch when it first loads.  This branch is different for different projects.  A column, `default_product`, was added to the `product` table to be used as a boolean indicating which product is the default.  get/set methods were added to `PerformanceTestModel` to support its use.  When this branch is rolled the following alter statement needs to be run on all `perftest` databases:

`ALTER TABLE`*_perftest_1`.`product`ADD COLUMN`default_product`TINYINT NOT NULL DEFAULT 0  AFTER`version`;

The default product is cached in memcached for rapid retrieval.

4.) All of the methods in `PerformanceTestModel` that insert reference data used an `ON DUPLICATE KEY UPDATE` strategy.  In MySQL this causes the AUTO_INCREMENT to increment on every update which creates large gaps in the id column.  This will be a problem if we exceed the max size of an int and it's also really ugly.  To fix this all `ON DUPLICATE KEY UPDATE` SQL methods were modified to work as `INSERT INTO ... SELECT FROM DUAL WHERE NOT EXIST` statements.  This will keep our ids consecutive and we won't have to worry about exceeding an int.  
",jeads,949498,2012-07-17T00:21:52Z,CONTRIBUTOR,True,330,111,10,Datazilla is a system for managing and visualizing data.,JavaScript,db575a8c6321f760590995eef55f11e4dafe646b,"fixed merge conflict, merged perftest schema change branch"
309,https://api.github.com/repos/mozilla/datazilla/pulls/51,51,Fix malformed HTTP request in post_json management command.,"Also removed a couple unused imports and variables.
",carljm,61586,2012-07-13T23:25:36Z,MEMBER,True,13,10,2,Datazilla is a system for managing and visualizing data.,JavaScript,7c04d426e3306579041a71081e7fa7e6a004821e,Fix malformed HTTP request in post_json management command.
310,https://api.github.com/repos/mozilla/datazilla/pulls/51,51,Fix malformed HTTP request in post_json management command.,"Also removed a couple unused imports and variables.
",carljm,61586,2012-07-13T23:25:36Z,MEMBER,True,13,10,2,Datazilla is a system for managing and visualizing data.,JavaScript,bad01840538d2369bb3f46be9b9e7bb2b295849c,403 instead of 500 if no OAuth creds are provided.
311,https://api.github.com/repos/mozilla/datazilla/pulls/50,50,"Remove all SQL, model methods, and management commands related to old test_data table.",,carljm,61586,2012-07-13T16:54:32Z,MEMBER,True,0,205,4,Datazilla is a system for managing and visualizing data.,JavaScript,7826bc33b5a7613f748ea46d5a687bff74479454,"Remove all SQL, model methods, and management commands related to old test_data table."
312,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,b60e1e08cd23557d8284561be36093045d7469aa,new schema template for creating the pushlog database.  updated datazilla model to reference it in its sources.
313,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,452594e7572cf314ed055aee4cd8a25afe7483dc,Merge branch 'master' into push-log-store
314,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,9f15a4eb323a9742b92e7170efe57908b525f1e6,update_pushlog mgmt command is retrieving json data via cmd line params
315,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,e224115c04d3516d023d67300d0c37358bff670b,"entering items into the push_log table, and skipping duplicates.  next need to do nodes and files"
316,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,021b286685ebcd3c6bc03f8ca9f7d1878e3843ff,"code to add records is there, but getting an integrity error adding to nodes: fk violation"
317,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,c00ff0b7bdc6662ec4145b5d8600c4ba46d20ee6,successfully avoiding dups on import by handling the exceptions
318,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,ec3d55d7425eaf1925ec27e72f8889a1beaa4a77,updated vendor/datasource.  renamed schema_repo to schema_pushlog since that's more appropriate
319,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,3f3007aa0f6969ab23ba094698e5ba5eb93342fa,Merge branch 'master' into push-log-store
320,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,52664639833d02ea8a3aca6051b53b4b4dfa82b3,separated DatazillaModel into PushLogModel and PerformanceTestModel
321,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,4ae99a6cbebeea361d41ac115a3a1ea24df25468,"pushlog import working with files.  Though we will strip out file support for now, because it needs a many to many, and don't have time to implement yet."
322,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,e8bfa44f71db45fb2e3c40bbda56a1993ea0439b,removed file data import.  stops at changesets for now
323,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,00c6eae7d1a47290117daaaf5133b1de03926630,merged master in
324,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,5fcc7fbee934c0fab11d8adae027778881f7bb4f,added new unit tests for pushlog
325,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,fa71f3e77816a7ba269adc425c730f64c27de422,fixed error with truncating
326,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,558b36f4b132e71900ac85cddbd46e8cab114dae,merged from master
327,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,a917a46082ba9e5ceca363da35ef6d98b3b6edab,add changeset dup test
328,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,36578c3090890f586ae277f2a9c07a081a7cad4e,added tests for management commands and more tests for PushLogModel
329,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,73bf15b2fcb78d157b9ecf50a398075be642de40,removed unused import
330,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,54e5cc0106d3e20acf7af0c063e10c3f38e54a88,Merge branch 'master' into push-log-store-no-files
331,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,11500909f1a04efd553a719b1c040d347e4f02a4,make push_log and pushlog references all be just pushlog.  added data checks to unit tests
332,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,e7161a5301a7cf5431cb0afc65801790b351585b,added test for empty json for a branch
333,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,114ca09d3bc84852899c1e745e1f470ad7a718e6,fixed other references to DatazillaModel
334,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,5a5f9e83a3512ae55c21ff1c8f528abfb3e282e9,removed thunderbird branches and harcoded autoincrement values
335,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,7021770d092b1bd73283b6ff679fea9ba310ba7e,made the println in PushLogModel honor the settings.DEBUG setting.
336,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,e7044b070d8e8385fc4234b26f174b0610e98b1d,Merge branch 'push-log-store-no-files' of github.com:mozilla/datazilla into push-log-store-no-files
337,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,557dae5d701847cdfa96106845ad09267bb5e94d,fixed tests to not rely on Firefox being branch id of 1
338,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,4431d585745e29861a24ba656fefaa156eb79123,Fix test hang.
339,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,ef7723662ec1917518fe1295fdef27c395b72943,fixed class level setting of PROJECT where it could have been unintentionally used by multiple instances.  Also added project param to the update pushlogs.
340,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,52b9c58761c4e665544608f9c44195534a950d03,Merge branch 'push-log-store-no-files' of github.com:mozilla/datazilla into push-log-store-no-files
341,https://api.github.com/repos/mozilla/datazilla/pulls/49,49,Push log store no files,"This feature handles importing pushlog data for our various branches.  There are two management commands create_pushlog which creates all the database tables for our current setup (hg) and update_pushlog which takes parameters to specify the date range of pushlogs to be imported.
",camd,419924,2012-07-11T18:47:29Z,CONTRIBUTOR,True,1192,55,25,Datazilla is a system for managing and visualizing data.,JavaScript,59aa3439c05645b23442175b16d964f01d922ce1,"added project name support to create_pushlog, and added a test for it"
342,https://api.github.com/repos/mozilla/datazilla/pulls/48,48,Added a conditional that ignores options named extensions,"We are going to need to add a new table to perftest to store addon/extensions explicitly.  Extensions will be a new reference data type that will be used by several different projects.  I've created a pivotal tracker story for this here https://www.pivotaltracker.com/story/show/32202781 .  There is also a bugzilla bug, https://bugzilla.mozilla.org/show_bug.cgi?id=769479 describing the required modifications to the JSON structure.  

I tested posting sample JSON that has the structure referenced in the bugzilla bug.  It generates a data truncation error, this error is caught and the error_flag for the JSON object is assigned a `Y`.  Once the talos patch in the bugzilla bug is pushed out, these data truncation errors will prevent valid JSON objects from being loaded into the perftest schema.  

To prevent these errors in the interim, while we implement extensions handling, I've added a conditional that ignores options named `extensions`.  This will need to be pushed out on s4n4 so that we can still receive talos data.  
",jeads,949498,2012-07-03T23:09:43Z,CONTRIBUTOR,True,64,0,3,Datazilla is a system for managing and visualizing data.,JavaScript,77eba4fa1671067bc51765a990a3981f60c2fc16,Added a conditional that ignores options names extensions
343,https://api.github.com/repos/mozilla/datazilla/pulls/48,48,Added a conditional that ignores options named extensions,"We are going to need to add a new table to perftest to store addon/extensions explicitly.  Extensions will be a new reference data type that will be used by several different projects.  I've created a pivotal tracker story for this here https://www.pivotaltracker.com/story/show/32202781 .  There is also a bugzilla bug, https://bugzilla.mozilla.org/show_bug.cgi?id=769479 describing the required modifications to the JSON structure.  

I tested posting sample JSON that has the structure referenced in the bugzilla bug.  It generates a data truncation error, this error is caught and the error_flag for the JSON object is assigned a `Y`.  Once the talos patch in the bugzilla bug is pushed out, these data truncation errors will prevent valid JSON objects from being loaded into the perftest schema.  

To prevent these errors in the interim, while we implement extensions handling, I've added a conditional that ignores options named `extensions`.  This will need to be pushed out on s4n4 so that we can still receive talos data.  
",jeads,949498,2012-07-03T23:09:43Z,CONTRIBUTOR,True,64,0,3,Datazilla is a system for managing and visualizing data.,JavaScript,57c9d9d78bdc01b19168409f7dd176f37cc776bc,added a test for the extensions option
344,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,56ed31e19c323611ddd2597a542b7c3fd2b8dc4f,added consumer_key and consumer_secret to datasource model
345,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,424a308a1a406659d5705e9348599b216816eb84,New manage command to post json data using OAuth consumer key/secret
346,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,2e054ed2d21356521df6a57a00216773b4457322,added oauth2 module
347,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,d089235ec702af47c8446297ec605d962c1c639f,added oauth2 module
348,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,4d32b85054919c1c9d28e970cb276a22ba6d18ac,cleaned up
349,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,8a77ac1dcc5cc30c1079bc01ac3eff2a59d595eb,added oauth_required decorator
350,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,e846fa900b006766b4db23348013e7620833b9da,added debug option handling
351,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,80264d0d50c513b5807a751c6f76b9efd7f1825b,Fixed lots of stuff
352,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,3bd0a04465c83fdeff8733f5344959aced91f67b,added oauth key/secret creation to create_project
353,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,d558fb9000a594779768d4015f89a456a8d0ad70,added null=True for key and secret columns
354,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,de3a5b8513489f24434ed2ada092e1213b556a15,added try/except around verify_request
355,https://api.github.com/repos/mozilla/datazilla/pulls/47,47,Twolegged oauth,"This branch implements two legged OAuth 1.0 in the following way.

1.) Added two columns to datazilla.datasource: consumer_key and consumer_secret.  These columns will contain NULL for non-objectstore contenttypes.  The columns hold the OAuth consumer key/secret combination for a given project's objectstore.

2.) In models.DataSource consumer_key and consumer_secret were added as attributes.

3.) Added a decorator to views.py, oauth_required, that implements a two legged OAuth service provider.  It accesses the key/secret associated with the given project through  `dm.sources['objectstore'].datasource`

4.) Added a new manage command, post_json, that implements the OAuth consumer.  It takes options for the consumer key/secret but defaults to using settings.OAUTH_CONSUMER_KEY and settings.OAUTH_CONSUMER_SECRET.  These can be set in local.py.  To test, copy the key/secret from your test project in datazilla.datasource to local.py.   The following example illustrates how to use the command:

`python manage.py post_json --project jeads --host s4n2.qa.phx1.mozilla.com --file /home/jeads/sample_data.json`

NOTE: you will need to restart memcached for these new attributes to be available.

5.) Added python-oauth2 (Which actually implements oauth 1.0) to requirements/pure.txt and ran bin/generate-vendor-lib.py to populate the related vendor files.

I have a couple open ended questions which might require some conversation to answer.

Where should the code that implements the construction of the oauth consumer key/secret live?
The most convenient place would be in the create_project manage.py command but this would leave the process exposed.  There are a couple pieces of random data in the key/secret so maybe it's not a problem...

Once we agree on this branch we should update https://github.com/mozilla/datazilla_client to add support for the OAuth consumers.  We will need to contact groups intending to use datazilla and confirm that they can install oauth2 in their production environments.  We will also need to send them their project's consumer key/secret data.

We will also need to add special handling to talos if python-oauth2 cannot be distributed in the production environment.
",jeads,949498,2012-07-02T17:30:34Z,CONTRIBUTOR,True,1238,3,18,Datazilla is a system for managing and visualizing data.,JavaScript,adea331145c8a560db9eeb7190195f5a7fefc927,removed unnecessary comment
356,https://api.github.com/repos/mozilla/datazilla/pulls/46,46,Remove AppEngine code.,"If what I saw on IRC today is accurate, we no longer need this code.
",carljm,61586,2012-06-30T01:29:14Z,MEMBER,True,3,275,4,Datazilla is a system for managing and visualizing data.,JavaScript,261f1df44fa5918ee759b1c94c1fc03ecdc4e1ef,Remove AppEngine code.
357,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,f2de6bf641048783b2f7cbc7cb3128c250417e3b,Functions for easily generating sample input JSON.
358,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,a115f8ba6a853f06c727e820500ec55a24b659b6,"Test for DatazillaModel.claim_objects, with support code for custom test SQL."
359,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,f73dadb100e20425bd703d4ac32904d89bee6216,Test for mark_object_complete.
360,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,70dbb49735fbcaa753d26820aec6c492c77fd6d1,Merge branch 'master' into objectstore-tests
361,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,43a7f399343441df77de767d218e67bb0642f511,Merge branch 'master' into objectstore-tests
362,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,a3486c85fdf9e5f4f9e00095523fb76687b1e7e4,"Give store_test_data() a nicer API, don't require error info."
363,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,79cf35e14430436943222930b15a7dd6d2cd4cf2,Measure branch coverage.
364,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,41c6ec6d1a286926cf79f17b77503c326784f4e3,Tests for DatazillaModel._get_or_create_test_id.
365,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,c5d7950fffd9f4c1d3cbea2f2087a538af410552,Tests for DatazillaModel._get_or_create_option_ids.
366,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,1894762a91adb573970af8959c0be046b58a9c6f,Tests for DatazillaModel._get_or_create_os_id.
367,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,deb0eae7c895ac798c1ff3b8b16ba0ad11360928,Tests for DatazillaModel._get_or_create_product_id.
368,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,69dbf89e3ccda1c8caaf3a5d098b35d544cc45f1,Tests for DatazillaModel._get_or_create_machine_id.
369,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,9a4365d78d776a673fabdaf70168492e35e012ec,Tests for DatazillaModel._set_build_data.
370,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,da03d4951c4ca2e6435e4e3026668b5c943d1ccf,Collect all missing-data error catching into a single generic TestData class.
371,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,f3488f289fdec2e4b8f7275db94af9fa518d91c8,Tests for DatazillaModel._set_test_run_data.
372,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,8a81bf67bbe6cba0c466e0f7b28fb770c68f8da3,Tests for DatazillaModel._set_option_data.
373,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,304d197537481c8f3bd9609e75a6628bc6196f1c,Tests for DatazillaModel._set_test_values
374,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,1544bc304aa667de7bbcf3eb3c55d318a7ba6e54,Tests for DatazillaModel._set_test_aux_data
375,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,58e80fe0ff62501c9d0f1dc0d450ae033abdf64a,Tests for DatazillaModel.load_test_data.
376,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,8bc8b55a1d2099ff0c8383c35c490ef3c04533f5,Tests for DatazillaModel.process_objects.
377,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,08c66ea85f6bcd162a30b79abb670092bcf5d449,Handle arbitrary unknown errors in data loading.
378,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,b1d5af7c0e581a3c04afbe810b6a8b1e1b25829b,Merge branch 'master' into objectstore-tests
379,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,7fa98a9d3501cc5f3c93a6b09f5998108f067e99,Fix set_test_data view error handling.
380,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,69345590eb33d58392e54ed8d9cd8f714b692913,"Avoid startswith in test assertion, error output is not useful."
381,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,d3f0b85635ae707e97270ef6ac0982c40d300aae,new version of datasource
382,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,e7b10e02fe22886c90839051bd686eccaca3dd4d,Merge branch 'objectstore-tests' of https://github.com/mozilla/datazilla into objectstore-tests
383,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,707eebee195bf8dcd366a0f942eea0f2fd391377,Ensure cache is isolated early enough in test-run process.
384,https://api.github.com/repos/mozilla/datazilla/pulls/45,45,Tests and process_objects error handling,"This pull request adds full error handling for the process_objects method (updating rows in the objectstore with error flag ""Y"" and an error msg on any error), and adds complete test coverage for the entire data-ingestion process, bringing our line/branch test coverage for DatazillaModel from 30% up to 85%.
",carljm,61586,2012-06-28T03:58:48Z,MEMBER,True,1127,331,14,Datazilla is a system for managing and visualizing data.,JavaScript,088d95630b9e4e68122cd92707933ff6be6ea0bd,updated get_page_id() and get_aux_id() to the new naming convention
385,https://api.github.com/repos/mozilla/datazilla/pulls/44,44,Sanitize json,"This branch was originally intended to sanitize json but it turns out this is ultimately being done in the UI.  There was one change I made in this branch that removes an unused conditional and also removes an explicit call to escape_string and replaces it with a cast to an int.  The only parameters accepted from the UI are integers.
",jeads,949498,2012-06-27T23:51:28Z,CONTRIBUTOR,True,2,6,1,Datazilla is a system for managing and visualizing data.,JavaScript,78ef0f3d68c6eb512b6e856850f995a9ff804f21,removed unused POST conditional and added an explicit cast to an int for default table signals
386,https://api.github.com/repos/mozilla/datazilla/pulls/44,44,Sanitize json,"This branch was originally intended to sanitize json but it turns out this is ultimately being done in the UI.  There was one change I made in this branch that removes an unused conditional and also removes an explicit call to escape_string and replaces it with a cast to an int.  The only parameters accepted from the UI are integers.
",jeads,949498,2012-06-27T23:51:28Z,CONTRIBUTOR,True,2,6,1,Datazilla is a system for managing and visualizing data.,JavaScript,3ab7ef9c2277242c38b0919701390b4f0801dad2,added conditional for key
387,https://api.github.com/repos/mozilla/datazilla/pulls/44,44,Sanitize json,"This branch was originally intended to sanitize json but it turns out this is ultimately being done in the UI.  There was one change I made in this branch that removes an unused conditional and also removes an explicit call to escape_string and replaces it with a cast to an int.  The only parameters accepted from the UI are integers.
",jeads,949498,2012-06-27T23:51:28Z,CONTRIBUTOR,True,2,6,1,Datazilla is a system for managing and visualizing data.,JavaScript,3879412254dd0ce9c1436c1b2004307faf4fd069,added conditional for key
388,https://api.github.com/repos/mozilla/datazilla/pulls/43,43,Handle objectstore errors,"Once the objectstore was rolled out this morning and talos objects were being stored several bugs were found.  The web service method that stores the objects was not storing any captured errors from json deserialization, it was also always returning a success message even when errors were generated.  This caused objects with malformed json to be stored.  When the process_objects command was run it breaks on the malformed json and leaves the unprocessed objects in a loading state.  When a connection id is recycled process_objects continues to break leaving well formed json objects permanently in the loading state.

To fix this, I modified views.set_test_data() to explicitly capture/store the error flag and message.  The object retrieval/marking sql statements used by process_objects were modified to only operate on objects with an error_flag of `N` so that json generating an error is never processed by process_objects.

Another change made was converting the timestamp column to an int to match perftest.  This is the time format that talos and most of the other Mozilla database applications I've seen use.  I would like to stay consistent with our handling of time across all content types in datazilla.  This change will require rolling out a new object store table, to do this I will run the following SQL statement on all objectstore databases:

DROP TABLE IF EXISTS objectstore;

  CREATE TABLE objectstore (
    id int(11) NOT NULL AUTO_INCREMENT,
    test_run_id int(11) NULL,
    date_loaded int(11) NOT NULL,
    processed_flag enum('ready','loading','complete') DEFAULT 'ready',
    error_flag enum('N','Y') DEFAULT 'N',
    error_msg mediumtext,
    json_blob blob,
    worker_id int(11),
    PRIMARY KEY (id),
    KEY test_run_id_key (test_run_id),
    KEY processed_flag_key (processed_flag),
    KEY error_flag_key (error_flag),
    KEY worker_id_key (worker_id)
 ) ENGINE=Aria DEFAULT CHARSET=utf8;
",jeads,949498,2012-06-26T17:15:19Z,CONTRIBUTOR,True,30,20,4,Datazilla is a system for managing and visualizing data.,JavaScript,f08ab9768758ad808f8f23e604f948d9f2af7f26,modified store_test_data to store the error flag and message explicitly and also converted the timestamp column to an int to match perftest
389,https://api.github.com/repos/mozilla/datazilla/pulls/43,43,Handle objectstore errors,"Once the objectstore was rolled out this morning and talos objects were being stored several bugs were found.  The web service method that stores the objects was not storing any captured errors from json deserialization, it was also always returning a success message even when errors were generated.  This caused objects with malformed json to be stored.  When the process_objects command was run it breaks on the malformed json and leaves the unprocessed objects in a loading state.  When a connection id is recycled process_objects continues to break leaving well formed json objects permanently in the loading state.

To fix this, I modified views.set_test_data() to explicitly capture/store the error flag and message.  The object retrieval/marking sql statements used by process_objects were modified to only operate on objects with an error_flag of `N` so that json generating an error is never processed by process_objects.

Another change made was converting the timestamp column to an int to match perftest.  This is the time format that talos and most of the other Mozilla database applications I've seen use.  I would like to stay consistent with our handling of time across all content types in datazilla.  This change will require rolling out a new object store table, to do this I will run the following SQL statement on all objectstore databases:

DROP TABLE IF EXISTS objectstore;

  CREATE TABLE objectstore (
    id int(11) NOT NULL AUTO_INCREMENT,
    test_run_id int(11) NULL,
    date_loaded int(11) NOT NULL,
    processed_flag enum('ready','loading','complete') DEFAULT 'ready',
    error_flag enum('N','Y') DEFAULT 'N',
    error_msg mediumtext,
    json_blob blob,
    worker_id int(11),
    PRIMARY KEY (id),
    KEY test_run_id_key (test_run_id),
    KEY processed_flag_key (processed_flag),
    KEY error_flag_key (error_flag),
    KEY worker_id_key (worker_id)
 ) ENGINE=Aria DEFAULT CHARSET=utf8;
",jeads,949498,2012-06-26T17:15:19Z,CONTRIBUTOR,True,30,20,4,Datazilla is a system for managing and visualizing data.,JavaScript,787ba6c7d3b760fa5b7e9d85bdf5322f900ca539,"added the error flag and message to store json, also added error flag constraint to the where clase on object retrieval methods"
390,https://api.github.com/repos/mozilla/datazilla/pulls/43,43,Handle objectstore errors,"Once the objectstore was rolled out this morning and talos objects were being stored several bugs were found.  The web service method that stores the objects was not storing any captured errors from json deserialization, it was also always returning a success message even when errors were generated.  This caused objects with malformed json to be stored.  When the process_objects command was run it breaks on the malformed json and leaves the unprocessed objects in a loading state.  When a connection id is recycled process_objects continues to break leaving well formed json objects permanently in the loading state.

To fix this, I modified views.set_test_data() to explicitly capture/store the error flag and message.  The object retrieval/marking sql statements used by process_objects were modified to only operate on objects with an error_flag of `N` so that json generating an error is never processed by process_objects.

Another change made was converting the timestamp column to an int to match perftest.  This is the time format that talos and most of the other Mozilla database applications I've seen use.  I would like to stay consistent with our handling of time across all content types in datazilla.  This change will require rolling out a new object store table, to do this I will run the following SQL statement on all objectstore databases:

DROP TABLE IF EXISTS objectstore;

  CREATE TABLE objectstore (
    id int(11) NOT NULL AUTO_INCREMENT,
    test_run_id int(11) NULL,
    date_loaded int(11) NOT NULL,
    processed_flag enum('ready','loading','complete') DEFAULT 'ready',
    error_flag enum('N','Y') DEFAULT 'N',
    error_msg mediumtext,
    json_blob blob,
    worker_id int(11),
    PRIMARY KEY (id),
    KEY test_run_id_key (test_run_id),
    KEY processed_flag_key (processed_flag),
    KEY error_flag_key (error_flag),
    KEY worker_id_key (worker_id)
 ) ENGINE=Aria DEFAULT CHARSET=utf8;
",jeads,949498,2012-06-26T17:15:19Z,CONTRIBUTOR,True,30,20,4,Datazilla is a system for managing and visualizing data.,JavaScript,a72d717b919e70aaf47927d139cc80dee23ffbb2,changed the objectstore table to use an int instead of timestamp to match perftest
391,https://api.github.com/repos/mozilla/datazilla/pulls/43,43,Handle objectstore errors,"Once the objectstore was rolled out this morning and talos objects were being stored several bugs were found.  The web service method that stores the objects was not storing any captured errors from json deserialization, it was also always returning a success message even when errors were generated.  This caused objects with malformed json to be stored.  When the process_objects command was run it breaks on the malformed json and leaves the unprocessed objects in a loading state.  When a connection id is recycled process_objects continues to break leaving well formed json objects permanently in the loading state.

To fix this, I modified views.set_test_data() to explicitly capture/store the error flag and message.  The object retrieval/marking sql statements used by process_objects were modified to only operate on objects with an error_flag of `N` so that json generating an error is never processed by process_objects.

Another change made was converting the timestamp column to an int to match perftest.  This is the time format that talos and most of the other Mozilla database applications I've seen use.  I would like to stay consistent with our handling of time across all content types in datazilla.  This change will require rolling out a new object store table, to do this I will run the following SQL statement on all objectstore databases:

DROP TABLE IF EXISTS objectstore;

  CREATE TABLE objectstore (
    id int(11) NOT NULL AUTO_INCREMENT,
    test_run_id int(11) NULL,
    date_loaded int(11) NOT NULL,
    processed_flag enum('ready','loading','complete') DEFAULT 'ready',
    error_flag enum('N','Y') DEFAULT 'N',
    error_msg mediumtext,
    json_blob blob,
    worker_id int(11),
    PRIMARY KEY (id),
    KEY test_run_id_key (test_run_id),
    KEY processed_flag_key (processed_flag),
    KEY error_flag_key (error_flag),
    KEY worker_id_key (worker_id)
 ) ENGINE=Aria DEFAULT CHARSET=utf8;
",jeads,949498,2012-06-26T17:15:19Z,CONTRIBUTOR,True,30,20,4,Datazilla is a system for managing and visualizing data.,JavaScript,cbed9b2b0519a30fedfb45f604671164b6282d4e,fixed broken error handling in set_test_data
392,https://api.github.com/repos/mozilla/datazilla/pulls/43,43,Handle objectstore errors,"Once the objectstore was rolled out this morning and talos objects were being stored several bugs were found.  The web service method that stores the objects was not storing any captured errors from json deserialization, it was also always returning a success message even when errors were generated.  This caused objects with malformed json to be stored.  When the process_objects command was run it breaks on the malformed json and leaves the unprocessed objects in a loading state.  When a connection id is recycled process_objects continues to break leaving well formed json objects permanently in the loading state.

To fix this, I modified views.set_test_data() to explicitly capture/store the error flag and message.  The object retrieval/marking sql statements used by process_objects were modified to only operate on objects with an error_flag of `N` so that json generating an error is never processed by process_objects.

Another change made was converting the timestamp column to an int to match perftest.  This is the time format that talos and most of the other Mozilla database applications I've seen use.  I would like to stay consistent with our handling of time across all content types in datazilla.  This change will require rolling out a new object store table, to do this I will run the following SQL statement on all objectstore databases:

DROP TABLE IF EXISTS objectstore;

  CREATE TABLE objectstore (
    id int(11) NOT NULL AUTO_INCREMENT,
    test_run_id int(11) NULL,
    date_loaded int(11) NOT NULL,
    processed_flag enum('ready','loading','complete') DEFAULT 'ready',
    error_flag enum('N','Y') DEFAULT 'N',
    error_msg mediumtext,
    json_blob blob,
    worker_id int(11),
    PRIMARY KEY (id),
    KEY test_run_id_key (test_run_id),
    KEY processed_flag_key (processed_flag),
    KEY error_flag_key (error_flag),
    KEY worker_id_key (worker_id)
 ) ENGINE=Aria DEFAULT CHARSET=utf8;
",jeads,949498,2012-06-26T17:15:19Z,CONTRIBUTOR,True,30,20,4,Datazilla is a system for managing and visualizing data.,JavaScript,d50a864b0fac4c6fd82cdc7b27a6923fe3b05053,cleaned up the try/except logic with an else clause
393,https://api.github.com/repos/mozilla/datazilla/pulls/42,42,Rollout objectstore,"The following series of operations will need to be performed to roll out the new objectstore to the development environment.

1.) Execute the following alter statements on the perftest databases:

`ALTER TABLE test_run ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_run ADD KEY status_key (status);`

`ALTER TABLE test_value ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_value ADD KEY status_key (status);`

 `ALTER TABLE test_aux_data ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_aux_data ADD KEY status_key (status);`

 `ALTER TABLE test_option_values ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_option_values ADD KEY status_key (status);` 

These statements add a `status` column to the core data tables.  This will allow us to ignore data using sql without having to perform physical deletions.

2.) Install httpd, memcached, wsgi, and datazilla on s4n1 (completed)

3.) The url that talos is using for data submission looks like this:
`http://10.8.73.29/views/api/load_test`

The `views` string in this url, is used as the project identifier in the current version of datazilla.  I added a conditional to `views.py` that forces the the project to be `talos` if `views` is used as the project name.  This will give us compatibility with the old url structure talos is using.  Once the new url format is rolled out this conditional should be removed.

4.) Change existing talos project name to 'talosv1' in datazilla.datasource and drop the unused talos objectstore database.  This will point at the graphs_exp database, we can eventually drop this database entirely but should transfer data from the last month to the new talos database beforehand so we have data to develop with.  This might not be necessary, depends on how fast we accumulate data.

NOTE: As of this weekend we ran out of disk space on s4n4.  This was from the talos data in graphs_exp exceeding the VM's capacity.  I physically deleted all test_run data with an id <= 350,000.  This should account for ~1/2 of the data.  This requires rebuilding the index to get MySQL to free up the disk space.  I mysqldumped graphs_exp after the physical deletion and will manually load it after this upgrade is complete.  I deleted all data tables in graphs_exp after the mysqldump was complete so that all other projects are functional.  We might get away with just loading the contents of the test_data table in graphs_exp and then use this to transfer objects from, this would save a lot of space in our development environment.

5.) Create a new project called 'talos'.

6.) Start httpd on s4n1.  Confirm data ingestion in the talos objectstore.

7.) Install cron to run process_objects for all dev projects on s4n4: talos, b2g, camd, carljm, jeads, jetperf, xperf, peptest, secreview, stoneridge.

8.) update datazilla repo on s4n3 and update the memcache.

10.) Remove the test_data table from all development databases.

11.) POST json data to each project and confirm that the object is transferred to the corresponding project's `perftest` database to confirm success.
",jeads,949498,2012-06-25T23:21:53Z,CONTRIBUTOR,True,32,73,6,Datazilla is a system for managing and visualizing data.,JavaScript,52ef8661936250debba80c5786430f4c57b10c4f,Added a status column to the core data tables to be used for marking rows active/deleted.
394,https://api.github.com/repos/mozilla/datazilla/pulls/42,42,Rollout objectstore,"The following series of operations will need to be performed to roll out the new objectstore to the development environment.

1.) Execute the following alter statements on the perftest databases:

`ALTER TABLE test_run ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_run ADD KEY status_key (status);`

`ALTER TABLE test_value ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_value ADD KEY status_key (status);`

 `ALTER TABLE test_aux_data ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_aux_data ADD KEY status_key (status);`

 `ALTER TABLE test_option_values ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_option_values ADD KEY status_key (status);` 

These statements add a `status` column to the core data tables.  This will allow us to ignore data using sql without having to perform physical deletions.

2.) Install httpd, memcached, wsgi, and datazilla on s4n1 (completed)

3.) The url that talos is using for data submission looks like this:
`http://10.8.73.29/views/api/load_test`

The `views` string in this url, is used as the project identifier in the current version of datazilla.  I added a conditional to `views.py` that forces the the project to be `talos` if `views` is used as the project name.  This will give us compatibility with the old url structure talos is using.  Once the new url format is rolled out this conditional should be removed.

4.) Change existing talos project name to 'talosv1' in datazilla.datasource and drop the unused talos objectstore database.  This will point at the graphs_exp database, we can eventually drop this database entirely but should transfer data from the last month to the new talos database beforehand so we have data to develop with.  This might not be necessary, depends on how fast we accumulate data.

NOTE: As of this weekend we ran out of disk space on s4n4.  This was from the talos data in graphs_exp exceeding the VM's capacity.  I physically deleted all test_run data with an id <= 350,000.  This should account for ~1/2 of the data.  This requires rebuilding the index to get MySQL to free up the disk space.  I mysqldumped graphs_exp after the physical deletion and will manually load it after this upgrade is complete.  I deleted all data tables in graphs_exp after the mysqldump was complete so that all other projects are functional.  We might get away with just loading the contents of the test_data table in graphs_exp and then use this to transfer objects from, this would save a lot of space in our development environment.

5.) Create a new project called 'talos'.

6.) Start httpd on s4n1.  Confirm data ingestion in the talos objectstore.

7.) Install cron to run process_objects for all dev projects on s4n4: talos, b2g, camd, carljm, jeads, jetperf, xperf, peptest, secreview, stoneridge.

8.) update datazilla repo on s4n3 and update the memcache.

10.) Remove the test_data table from all development databases.

11.) POST json data to each project and confirm that the object is transferred to the corresponding project's `perftest` database to confirm success.
",jeads,949498,2012-06-25T23:21:53Z,CONTRIBUTOR,True,32,73,6,Datazilla is a system for managing and visualizing data.,JavaScript,f5b44520e7fb01128d01e788a912da505b52a76d,changed the object store loading url to api/load_test
395,https://api.github.com/repos/mozilla/datazilla/pulls/42,42,Rollout objectstore,"The following series of operations will need to be performed to roll out the new objectstore to the development environment.

1.) Execute the following alter statements on the perftest databases:

`ALTER TABLE test_run ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_run ADD KEY status_key (status);`

`ALTER TABLE test_value ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_value ADD KEY status_key (status);`

 `ALTER TABLE test_aux_data ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_aux_data ADD KEY status_key (status);`

 `ALTER TABLE test_option_values ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_option_values ADD KEY status_key (status);` 

These statements add a `status` column to the core data tables.  This will allow us to ignore data using sql without having to perform physical deletions.

2.) Install httpd, memcached, wsgi, and datazilla on s4n1 (completed)

3.) The url that talos is using for data submission looks like this:
`http://10.8.73.29/views/api/load_test`

The `views` string in this url, is used as the project identifier in the current version of datazilla.  I added a conditional to `views.py` that forces the the project to be `talos` if `views` is used as the project name.  This will give us compatibility with the old url structure talos is using.  Once the new url format is rolled out this conditional should be removed.

4.) Change existing talos project name to 'talosv1' in datazilla.datasource and drop the unused talos objectstore database.  This will point at the graphs_exp database, we can eventually drop this database entirely but should transfer data from the last month to the new talos database beforehand so we have data to develop with.  This might not be necessary, depends on how fast we accumulate data.

NOTE: As of this weekend we ran out of disk space on s4n4.  This was from the talos data in graphs_exp exceeding the VM's capacity.  I physically deleted all test_run data with an id <= 350,000.  This should account for ~1/2 of the data.  This requires rebuilding the index to get MySQL to free up the disk space.  I mysqldumped graphs_exp after the physical deletion and will manually load it after this upgrade is complete.  I deleted all data tables in graphs_exp after the mysqldump was complete so that all other projects are functional.  We might get away with just loading the contents of the test_data table in graphs_exp and then use this to transfer objects from, this would save a lot of space in our development environment.

5.) Create a new project called 'talos'.

6.) Start httpd on s4n1.  Confirm data ingestion in the talos objectstore.

7.) Install cron to run process_objects for all dev projects on s4n4: talos, b2g, camd, carljm, jeads, jetperf, xperf, peptest, secreview, stoneridge.

8.) update datazilla repo on s4n3 and update the memcache.

10.) Remove the test_data table from all development databases.

11.) POST json data to each project and confirm that the object is transferred to the corresponding project's `perftest` database to confirm success.
",jeads,949498,2012-06-25T23:21:53Z,CONTRIBUTOR,True,32,73,6,Datazilla is a system for managing and visualizing data.,JavaScript,d642fd51646aaf4f2d471175a35e49883ccdeb98,added a conditional that recognizes views to provide backword compatibility with the url talos is currently using
396,https://api.github.com/repos/mozilla/datazilla/pulls/42,42,Rollout objectstore,"The following series of operations will need to be performed to roll out the new objectstore to the development environment.

1.) Execute the following alter statements on the perftest databases:

`ALTER TABLE test_run ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_run ADD KEY status_key (status);`

`ALTER TABLE test_value ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_value ADD KEY status_key (status);`

 `ALTER TABLE test_aux_data ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_aux_data ADD KEY status_key (status);`

 `ALTER TABLE test_option_values ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_option_values ADD KEY status_key (status);` 

These statements add a `status` column to the core data tables.  This will allow us to ignore data using sql without having to perform physical deletions.

2.) Install httpd, memcached, wsgi, and datazilla on s4n1 (completed)

3.) The url that talos is using for data submission looks like this:
`http://10.8.73.29/views/api/load_test`

The `views` string in this url, is used as the project identifier in the current version of datazilla.  I added a conditional to `views.py` that forces the the project to be `talos` if `views` is used as the project name.  This will give us compatibility with the old url structure talos is using.  Once the new url format is rolled out this conditional should be removed.

4.) Change existing talos project name to 'talosv1' in datazilla.datasource and drop the unused talos objectstore database.  This will point at the graphs_exp database, we can eventually drop this database entirely but should transfer data from the last month to the new talos database beforehand so we have data to develop with.  This might not be necessary, depends on how fast we accumulate data.

NOTE: As of this weekend we ran out of disk space on s4n4.  This was from the talos data in graphs_exp exceeding the VM's capacity.  I physically deleted all test_run data with an id <= 350,000.  This should account for ~1/2 of the data.  This requires rebuilding the index to get MySQL to free up the disk space.  I mysqldumped graphs_exp after the physical deletion and will manually load it after this upgrade is complete.  I deleted all data tables in graphs_exp after the mysqldump was complete so that all other projects are functional.  We might get away with just loading the contents of the test_data table in graphs_exp and then use this to transfer objects from, this would save a lot of space in our development environment.

5.) Create a new project called 'talos'.

6.) Start httpd on s4n1.  Confirm data ingestion in the talos objectstore.

7.) Install cron to run process_objects for all dev projects on s4n4: talos, b2g, camd, carljm, jeads, jetperf, xperf, peptest, secreview, stoneridge.

8.) update datazilla repo on s4n3 and update the memcache.

10.) Remove the test_data table from all development databases.

11.) POST json data to each project and confirm that the object is transferred to the corresponding project's `perftest` database to confirm success.
",jeads,949498,2012-06-25T23:21:53Z,CONTRIBUTOR,True,32,73,6,Datazilla is a system for managing and visualizing data.,JavaScript,031fa1dc1c1c5397c76d850cf51eeeb7d1889b96,removed menu options that are no longer supported
397,https://api.github.com/repos/mozilla/datazilla/pulls/42,42,Rollout objectstore,"The following series of operations will need to be performed to roll out the new objectstore to the development environment.

1.) Execute the following alter statements on the perftest databases:

`ALTER TABLE test_run ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_run ADD KEY status_key (status);`

`ALTER TABLE test_value ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_value ADD KEY status_key (status);`

 `ALTER TABLE test_aux_data ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_aux_data ADD KEY status_key (status);`

 `ALTER TABLE test_option_values ADD COLUMN status tinyint NOT NULL DEFAULT 1;`
 `ALTER TABLE test_option_values ADD KEY status_key (status);` 

These statements add a `status` column to the core data tables.  This will allow us to ignore data using sql without having to perform physical deletions.

2.) Install httpd, memcached, wsgi, and datazilla on s4n1 (completed)

3.) The url that talos is using for data submission looks like this:
`http://10.8.73.29/views/api/load_test`

The `views` string in this url, is used as the project identifier in the current version of datazilla.  I added a conditional to `views.py` that forces the the project to be `talos` if `views` is used as the project name.  This will give us compatibility with the old url structure talos is using.  Once the new url format is rolled out this conditional should be removed.

4.) Change existing talos project name to 'talosv1' in datazilla.datasource and drop the unused talos objectstore database.  This will point at the graphs_exp database, we can eventually drop this database entirely but should transfer data from the last month to the new talos database beforehand so we have data to develop with.  This might not be necessary, depends on how fast we accumulate data.

NOTE: As of this weekend we ran out of disk space on s4n4.  This was from the talos data in graphs_exp exceeding the VM's capacity.  I physically deleted all test_run data with an id <= 350,000.  This should account for ~1/2 of the data.  This requires rebuilding the index to get MySQL to free up the disk space.  I mysqldumped graphs_exp after the physical deletion and will manually load it after this upgrade is complete.  I deleted all data tables in graphs_exp after the mysqldump was complete so that all other projects are functional.  We might get away with just loading the contents of the test_data table in graphs_exp and then use this to transfer objects from, this would save a lot of space in our development environment.

5.) Create a new project called 'talos'.

6.) Start httpd on s4n1.  Confirm data ingestion in the talos objectstore.

7.) Install cron to run process_objects for all dev projects on s4n4: talos, b2g, camd, carljm, jeads, jetperf, xperf, peptest, secreview, stoneridge.

8.) update datazilla repo on s4n3 and update the memcache.

10.) Remove the test_data table from all development databases.

11.) POST json data to each project and confirm that the object is transferred to the corresponding project's `perftest` database to confirm success.
",jeads,949498,2012-06-25T23:21:53Z,CONTRIBUTOR,True,32,73,6,Datazilla is a system for managing and visualizing data.,JavaScript,07897b5af9a2a1c9eb875b1f882762b20a5a2229,added status column to test_run
398,https://api.github.com/repos/mozilla/datazilla/pulls/41,41,Management commands,"This pull request just converts the `populate_summary_cache.py` and `populate_test_collections.py` scripts to be Django management commands. Really the only significant benefit of this is consistency for IT if we are asking them to put scripts into cron or run them for us on a stage/prod instance; if all our stuff is management commands it makes the path handling consistent, if they're raw scripts IT has to make sure to set PYTHONPATH appropriately when running them. There are some other minor consistency benefits but that's the primary one.
",carljm,61586,2012-06-20T19:33:15Z,MEMBER,True,195,178,7,Datazilla is a system for managing and visualizing data.,JavaScript,86e500ca6a8ea2c9c79afcad9eaace2ef810bed9,Converted populate_summary_cache to a management command.
399,https://api.github.com/repos/mozilla/datazilla/pulls/41,41,Management commands,"This pull request just converts the `populate_summary_cache.py` and `populate_test_collections.py` scripts to be Django management commands. Really the only significant benefit of this is consistency for IT if we are asking them to put scripts into cron or run them for us on a stage/prod instance; if all our stuff is management commands it makes the path handling consistent, if they're raw scripts IT has to make sure to set PYTHONPATH appropriately when running them. There are some other minor consistency benefits but that's the primary one.
",carljm,61586,2012-06-20T19:33:15Z,MEMBER,True,195,178,7,Datazilla is a system for managing and visualizing data.,JavaScript,446a778a25debe83f222d245309b418f88760caf,Convert populate_test_collections to be a management command.
400,https://api.github.com/repos/mozilla/datazilla/pulls/40,40,Move generic SQL out of contenttype-specific SQL files and into shared generic-SQL procs file.,"We had trouble with this before because we were trying to name the generic procs file `sql.json` which shadows a proc file of that same name in datasource itself. In the long run it might be good to figure out if datasource could avoid squatting on the procs-file namespace at all somehow, or at least raise a clear error if someone instantiating a datahub gives it a procs file of the same name as a built-in one - but for now just using a different name works fine.
",carljm,61586,2012-06-20T00:43:18Z,MEMBER,True,3,9,4,Datazilla is a system for managing and visualizing data.,JavaScript,90a4ac4cf98bdcba3035ef8e9169ce8c04628a11,Move generic SQL out of contenttype-specific SQL files and into shared generic-SQL procs file.
401,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,db30baf2a3a104f14c2a2d3353ebcd72116cfc50,"just need to lock the transaction and we're good I thnk, that and test this"
402,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,a82b73ffa91283ac53ea51dd44cf81c07ff2673b,needs testing but feature seems somewhat functional
403,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,7e68dd077e4de0640abdf1eeb051006fd850133a,removed some comments
404,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,af8b7fbb98b5d0562ffa3a76aef899a0aa588474,"still debugging, boilerplate code is done"
405,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,a5c1f020f9e0fd2cdec8d339129594c0cea6d338,it works with newest datasource
406,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,43fde48e08ddf84431fec26a9c40091f4b89ea69,made sure transfer_objects's use of load_test_data doesn't get broken
407,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,718fa5eb66668f57b430c84ffe5e1596b558b52c,removed unnecessary comment
408,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,0f93c9c240e52afad1b9e824c3b0eb9c05d06839,process_objects manage.py task
409,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,57b305023ded70acffddab83d733ae8e8774b2b3,Merge branch 'objectstore-feature' of github.com:mozilla/datazilla into objectstore-feature
410,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,343a4cf48f2692fc5bba56323ae69a7a1894e4d5,"made style modifications, moved logic into datazillamodel, created stub for verification (another story)"
411,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,bc5da8ee0af4e33cf5c7da5bc5c92667df10cf13,fixes and renames for pull request
412,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,785d623dc7cde1a62f7169c500fe955c5acb188f,"formatting, changed datazillamodel to always use self.debug rather than settings.debug, added transfer_objects"
413,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,88012746e88e73a49599bd21e44621ede2803c1f,added changes for pull request
414,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,ab56f3b751332cc9af56605753b9a2884f591fe4,added a sanity check
415,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,c748558d5dc989f5d6f81e0a9c9544df309f56cb,changed case
416,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,d5746039f2f6c54d3364b5d9ba970738afc863a5,Merge branch 'management-commands' of https://github.com/mozilla/datazilla
417,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,eedb6d999605ffd4f4275a6610a3f614617bd4bd,Merge branch 'master' of https://github.com/mozilla/datazilla
418,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,e8860c2558405ce81f195dff2f91e5af7df5f5a9,Merge branch 'master' into objectstore-feature
419,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,36920b55c27e68e905c714a754b1bc6ff926a39f,Allow process_objects to clean up after itself.
420,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,a031a8aab5aab31a76c607956b251e383f0cdcb4,Merge branch 'objectstore-feature' of https://github.com/mozilla/datazilla into objectstore-feature
421,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,ee63b6dee40ac19f6c23c595e5b0c59f3d04ad26,modified process_objects() so that mark_object_complete() stores the corresponding test_run_id
422,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,21fa7bb2b808ae087b02c046a940389cff545d78,added test_run_id to objectstore sql
423,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,ec90ca0789436b117b4f75518781cb78ad1bfe9e,added indexes to appropriate columns and test_run_id to the objectstore schema
424,https://api.github.com/repos/mozilla/datazilla/pulls/39,39,Objectstore feature,"- Added process_objects manage task which moves objects from the objectstore into the correct perftest database for a project.
- Bumped version of datasource required in pure.txt
",samliu,135933,2012-06-14T22:47:23Z,MEMBER,True,4624,4357,20,Datazilla is a system for managing and visualizing data.,JavaScript,8f2a5d296b91c20b045f0a1b51dd9c1f91436afe,Clearer variable names in process_objects.
425,https://api.github.com/repos/mozilla/datazilla/pulls/38,38,Invalidate datasource cache,"This pull request invalidates the cached list of datasources anytime a new one is added (e.g. via `create_project`). This means that the new datasource will be usable without requiring a memcached restart.

This pull request depends on the previous ""cache wrapper"" pull request, and contains its changes as well, so the diff here will be smaller after that one is merged.
",carljm,61586,2012-06-14T04:27:08Z,MEMBER,True,180,30,8,Datazilla is a system for managing and visualizing data.,JavaScript,82aa41b0051106bb23bc3b3fea437792bd37f5e6,Fix issues with Django memcache backend.
426,https://api.github.com/repos/mozilla/datazilla/pulls/38,38,Invalidate datasource cache,"This pull request invalidates the cached list of datasources anytime a new one is added (e.g. via `create_project`). This means that the new datasource will be usable without requiring a memcached restart.

This pull request depends on the previous ""cache wrapper"" pull request, and contains its changes as well, so the diff here will be smaller after that one is merged.
",carljm,61586,2012-06-14T04:27:08Z,MEMBER,True,180,30,8,Datazilla is a system for managing and visualizing data.,JavaScript,69d412e6b986b8cc25e48cbc0cae2bc2639ba611,Go back to using Django cache API now that issues with it are addressed.
427,https://api.github.com/repos/mozilla/datazilla/pulls/38,38,Invalidate datasource cache,"This pull request invalidates the cached list of datasources anytime a new one is added (e.g. via `create_project`). This means that the new datasource will be usable without requiring a memcached restart.

This pull request depends on the previous ""cache wrapper"" pull request, and contains its changes as well, so the diff here will be smaller after that one is merged.
",carljm,61586,2012-06-14T04:27:08Z,MEMBER,True,180,30,8,Datazilla is a system for managing and visualizing data.,JavaScript,e35edb4cbb59a4f91f7495a23fadd41129a4ba94,Add cache version.
428,https://api.github.com/repos/mozilla/datazilla/pulls/38,38,Invalidate datasource cache,"This pull request invalidates the cached list of datasources anytime a new one is added (e.g. via `create_project`). This means that the new datasource will be usable without requiring a memcached restart.

This pull request depends on the previous ""cache wrapper"" pull request, and contains its changes as well, so the diff here will be smaller after that one is merged.
",carljm,61586,2012-06-14T04:27:08Z,MEMBER,True,180,30,8,Datazilla is a system for managing and visualizing data.,JavaScript,02416443ae6f97593e254c4a4c883a2e6a8895ee,Add tests for datasource list caching.
429,https://api.github.com/repos/mozilla/datazilla/pulls/37,37,Cache wrapper,"This pull request fixes the issues that cropped up last time I tried to switch to using Django's cache backend API rather than memcache.Client directly:
1. Ability to cache forever, and make this the default.
2. `.set()` returns the return value from the client library so we can error-check.

I had been thinking I'd just write our own thin cache wrapper (in order to allow global cache key prefixing, so tests can run deterministically with a clean cache), but this turned out to be even easier. It also allows us to easily swap in the compiled pylibmc in place of the pure-Python python-memcached if we ever need to squeeze more performance out of the cache.
",carljm,61586,2012-06-14T00:41:39Z,MEMBER,True,41,18,5,Datazilla is a system for managing and visualizing data.,JavaScript,82aa41b0051106bb23bc3b3fea437792bd37f5e6,Fix issues with Django memcache backend.
430,https://api.github.com/repos/mozilla/datazilla/pulls/37,37,Cache wrapper,"This pull request fixes the issues that cropped up last time I tried to switch to using Django's cache backend API rather than memcache.Client directly:
1. Ability to cache forever, and make this the default.
2. `.set()` returns the return value from the client library so we can error-check.

I had been thinking I'd just write our own thin cache wrapper (in order to allow global cache key prefixing, so tests can run deterministically with a clean cache), but this turned out to be even easier. It also allows us to easily swap in the compiled pylibmc in place of the pure-Python python-memcached if we ever need to squeeze more performance out of the cache.
",carljm,61586,2012-06-14T00:41:39Z,MEMBER,True,41,18,5,Datazilla is a system for managing and visualizing data.,JavaScript,69d412e6b986b8cc25e48cbc0cae2bc2639ba611,Go back to using Django cache API now that issues with it are addressed.
431,https://api.github.com/repos/mozilla/datazilla/pulls/37,37,Cache wrapper,"This pull request fixes the issues that cropped up last time I tried to switch to using Django's cache backend API rather than memcache.Client directly:
1. Ability to cache forever, and make this the default.
2. `.set()` returns the return value from the client library so we can error-check.

I had been thinking I'd just write our own thin cache wrapper (in order to allow global cache key prefixing, so tests can run deterministically with a clean cache), but this turned out to be even easier. It also allows us to easily swap in the compiled pylibmc in place of the pure-Python python-memcached if we ever need to squeeze more performance out of the cache.
",carljm,61586,2012-06-14T00:41:39Z,MEMBER,True,41,18,5,Datazilla is a system for managing and visualizing data.,JavaScript,e35edb4cbb59a4f91f7495a23fadd41129a4ba94,Add cache version.
432,https://api.github.com/repos/mozilla/datazilla/pulls/36,36,Engine select feature,"With this pull request:
- The create_project management command supports `--perftest_type` and `--objectstore_type` arguments, which should be like ""MySQL-InnoDB"" or ""MySQL-Aria"".
- The ""type"" column in the ""datasource"" table should now contain a similarly-formatted type, though for backwards-compatibility ""MySQL"" is still supported (and assumed to mean ""MySQL-InnoDB"").
- The SQL schema files now have a `.sql.tmpl` extension because they are no longer valid SQL; they contain `{engine}` placeholders which must be replaced before use. `DataSource.create_database` performs this replacement (by removing the ""MySQL-"" prefix from the datasource type and using the rest as the engine name).
- The default type for all databases is ""MySQL-InnoDB"", which means the tests can now run against any vanilla MySQL server (as long as it is compiled with InnoDB support).
",carljm,61586,2012-06-12T22:56:21Z,MEMBER,True,125,62,5,Datazilla is a system for managing and visualizing data.,JavaScript,9448a0a6c210cf98c6f8213f79fa35b84501ff70,Add engine type selection to SQLDataSource.create().
433,https://api.github.com/repos/mozilla/datazilla/pulls/36,36,Engine select feature,"With this pull request:
- The create_project management command supports `--perftest_type` and `--objectstore_type` arguments, which should be like ""MySQL-InnoDB"" or ""MySQL-Aria"".
- The ""type"" column in the ""datasource"" table should now contain a similarly-formatted type, though for backwards-compatibility ""MySQL"" is still supported (and assumed to mean ""MySQL-InnoDB"").
- The SQL schema files now have a `.sql.tmpl` extension because they are no longer valid SQL; they contain `{engine}` placeholders which must be replaced before use. `DataSource.create_database` performs this replacement (by removing the ""MySQL-"" prefix from the datasource type and using the rest as the engine name).
- The default type for all databases is ""MySQL-InnoDB"", which means the tests can now run against any vanilla MySQL server (as long as it is compiled with InnoDB support).
",carljm,61586,2012-06-12T22:56:21Z,MEMBER,True,125,62,5,Datazilla is a system for managing and visualizing data.,JavaScript,3e27e6bcf2693583ed66899123d729763883d078,Remove dedicated engine column; overload type column instead.
434,https://api.github.com/repos/mozilla/datazilla/pulls/36,36,Engine select feature,"With this pull request:
- The create_project management command supports `--perftest_type` and `--objectstore_type` arguments, which should be like ""MySQL-InnoDB"" or ""MySQL-Aria"".
- The ""type"" column in the ""datasource"" table should now contain a similarly-formatted type, though for backwards-compatibility ""MySQL"" is still supported (and assumed to mean ""MySQL-InnoDB"").
- The SQL schema files now have a `.sql.tmpl` extension because they are no longer valid SQL; they contain `{engine}` placeholders which must be replaced before use. `DataSource.create_database` performs this replacement (by removing the ""MySQL-"" prefix from the datasource type and using the rest as the engine name).
- The default type for all databases is ""MySQL-InnoDB"", which means the tests can now run against any vanilla MySQL server (as long as it is compiled with InnoDB support).
",carljm,61586,2012-06-12T22:56:21Z,MEMBER,True,125,62,5,Datazilla is a system for managing and visualizing data.,JavaScript,7eaa8f14a49b182655a050707325295d8b0ea9ca,Create_project management command supports --perftest_type and --objectstore_type.
435,https://api.github.com/repos/mozilla/datazilla/pulls/36,36,Engine select feature,"With this pull request:
- The create_project management command supports `--perftest_type` and `--objectstore_type` arguments, which should be like ""MySQL-InnoDB"" or ""MySQL-Aria"".
- The ""type"" column in the ""datasource"" table should now contain a similarly-formatted type, though for backwards-compatibility ""MySQL"" is still supported (and assumed to mean ""MySQL-InnoDB"").
- The SQL schema files now have a `.sql.tmpl` extension because they are no longer valid SQL; they contain `{engine}` placeholders which must be replaced before use. `DataSource.create_database` performs this replacement (by removing the ""MySQL-"" prefix from the datasource type and using the rest as the engine name).
- The default type for all databases is ""MySQL-InnoDB"", which means the tests can now run against any vanilla MySQL server (as long as it is compiled with InnoDB support).
",carljm,61586,2012-06-12T22:56:21Z,MEMBER,True,125,62,5,Datazilla is a system for managing and visualizing data.,JavaScript,df76774a8ffdd8f0b8edb212b811fa4fa8cf7489,Add back-compat handling for a type of just 'MySQL'.
436,https://api.github.com/repos/mozilla/datazilla/pulls/35,35,Loadtestdata refactor,"I did some research and decided to go ahead and refactor `load_test_data()` to make use of MySQL's `INSERT ... ON DUPLICATE KEY UPDATE` for all reference data.  I was concerned about taking this approach because of the frequency of updates but I think there is a compelling argument for it and we need to get rid of the call to `get_reference_data()`. 

This branch removes the call to `get_reference_data()` from `load_test_data()`.  All of the `get_*_id()` methods have been converted to use an `ON DUPLICATE KEY UPDATE` strategy.  The reference data is first inserted and the associated id is then selected.

 I used the `manage.py` command, `transfer_data`, to test every line of code changed.  I inserted several thousand data structures into `test_1_perftest` to test entries into a database already containing data and I also created a new project, jeads, to test the insertion of data into an empty schema.

I identified some `UNIQUE KEY` indexes that needed the test_id incorporated in them in the reference data tables and a `VARCHAR()` field that needed to be reduced in size to facilitate a joint `UNIQUE KEY`.  These changes are reflected in schema_perftest.sql.  I also ran the following SQL statements to update the existing development databases with the schema changes:

`ALTER TABLE test ADD UNIQUE (name, version)`
`ALTER TABLE pages CHANGE COLUMN url url VARCHAR(255) CHARACTER SET 'utf8' COLLATE 'utf8_bin' NOT NULL`
`ALTER TABLE pages ADD UNIQUE (test_id, url)`
`ALTER TABLE aux_data DROP INDEX name_UNIQUE, ADD UNIQUE INDEX test_id_name_UNIQUE (test_id, name)`

These statements were run on all databases on s4n3 and s4n4 that have a contenttype of perftest.

I think another improvement to load_test_data() that should be implemented is `START TRANSACTION` at the beginning of the function and a single `COMMIT` at the end.  This should be implemented in a try/except, if any errors are raised we could do an explicit `ROLLBACK`.  Before implementing this I would like to confirm this is the correct approach for TokuDB.  This will prevent partial data being loaded when a data structure is provided that is incomplete but well formed json.  This should be researched carefully before implementing.
",jeads,949498,2012-06-09T21:41:55Z,CONTRIBUTOR,True,237,83,3,Datazilla is a system for managing and visualizing data.,JavaScript,479150d7c82973799f904002f6a661820b06a455,Removed get_reference_data() call from load_test_data() and modified all get_*_id() methods to use an INSERT ... ON DUPLICATE KEY UPDATE strategy.
437,https://api.github.com/repos/mozilla/datazilla/pulls/35,35,Loadtestdata refactor,"I did some research and decided to go ahead and refactor `load_test_data()` to make use of MySQL's `INSERT ... ON DUPLICATE KEY UPDATE` for all reference data.  I was concerned about taking this approach because of the frequency of updates but I think there is a compelling argument for it and we need to get rid of the call to `get_reference_data()`. 

This branch removes the call to `get_reference_data()` from `load_test_data()`.  All of the `get_*_id()` methods have been converted to use an `ON DUPLICATE KEY UPDATE` strategy.  The reference data is first inserted and the associated id is then selected.

 I used the `manage.py` command, `transfer_data`, to test every line of code changed.  I inserted several thousand data structures into `test_1_perftest` to test entries into a database already containing data and I also created a new project, jeads, to test the insertion of data into an empty schema.

I identified some `UNIQUE KEY` indexes that needed the test_id incorporated in them in the reference data tables and a `VARCHAR()` field that needed to be reduced in size to facilitate a joint `UNIQUE KEY`.  These changes are reflected in schema_perftest.sql.  I also ran the following SQL statements to update the existing development databases with the schema changes:

`ALTER TABLE test ADD UNIQUE (name, version)`
`ALTER TABLE pages CHANGE COLUMN url url VARCHAR(255) CHARACTER SET 'utf8' COLLATE 'utf8_bin' NOT NULL`
`ALTER TABLE pages ADD UNIQUE (test_id, url)`
`ALTER TABLE aux_data DROP INDEX name_UNIQUE, ADD UNIQUE INDEX test_id_name_UNIQUE (test_id, name)`

These statements were run on all databases on s4n3 and s4n4 that have a contenttype of perftest.

I think another improvement to load_test_data() that should be implemented is `START TRANSACTION` at the beginning of the function and a single `COMMIT` at the end.  This should be implemented in a try/except, if any errors are raised we could do an explicit `ROLLBACK`.  Before implementing this I would like to confirm this is the correct approach for TokuDB.  This will prevent partial data being loaded when a data structure is provided that is incomplete but well formed json.  This should be researched carefully before implementing.
",jeads,949498,2012-06-09T21:41:55Z,CONTRIBUTOR,True,237,83,3,Datazilla is a system for managing and visualizing data.,JavaScript,f64b49e00676a7ceb8f7ef5d8e4b69a91b2d2bcb,"Added new UNIQUE KEYS to test, pages, aux_data, reduced the VARCHAR size of pages.url to facilitate a UNIQUE KEY"
438,https://api.github.com/repos/mozilla/datazilla/pulls/35,35,Loadtestdata refactor,"I did some research and decided to go ahead and refactor `load_test_data()` to make use of MySQL's `INSERT ... ON DUPLICATE KEY UPDATE` for all reference data.  I was concerned about taking this approach because of the frequency of updates but I think there is a compelling argument for it and we need to get rid of the call to `get_reference_data()`. 

This branch removes the call to `get_reference_data()` from `load_test_data()`.  All of the `get_*_id()` methods have been converted to use an `ON DUPLICATE KEY UPDATE` strategy.  The reference data is first inserted and the associated id is then selected.

 I used the `manage.py` command, `transfer_data`, to test every line of code changed.  I inserted several thousand data structures into `test_1_perftest` to test entries into a database already containing data and I also created a new project, jeads, to test the insertion of data into an empty schema.

I identified some `UNIQUE KEY` indexes that needed the test_id incorporated in them in the reference data tables and a `VARCHAR()` field that needed to be reduced in size to facilitate a joint `UNIQUE KEY`.  These changes are reflected in schema_perftest.sql.  I also ran the following SQL statements to update the existing development databases with the schema changes:

`ALTER TABLE test ADD UNIQUE (name, version)`
`ALTER TABLE pages CHANGE COLUMN url url VARCHAR(255) CHARACTER SET 'utf8' COLLATE 'utf8_bin' NOT NULL`
`ALTER TABLE pages ADD UNIQUE (test_id, url)`
`ALTER TABLE aux_data DROP INDEX name_UNIQUE, ADD UNIQUE INDEX test_id_name_UNIQUE (test_id, name)`

These statements were run on all databases on s4n3 and s4n4 that have a contenttype of perftest.

I think another improvement to load_test_data() that should be implemented is `START TRANSACTION` at the beginning of the function and a single `COMMIT` at the end.  This should be implemented in a try/except, if any errors are raised we could do an explicit `ROLLBACK`.  Before implementing this I would like to confirm this is the correct approach for TokuDB.  This will prevent partial data being loaded when a data structure is provided that is incomplete but well formed json.  This should be researched carefully before implementing.
",jeads,949498,2012-06-09T21:41:55Z,CONTRIBUTOR,True,237,83,3,Datazilla is a system for managing and visualizing data.,JavaScript,0a17e99d4285b55cba385a7023ab6b26029c2950,"Added new UNIQUE KEYS to test, pages, aux_data, reduced the VARCHAR size of pages.url to facilitate a UNIQUE KEY"
439,https://api.github.com/repos/mozilla/datazilla/pulls/34,34,database setup and teardown for tests,"This pull request makes the tests pass again! (As long as you have your `DATAZILLA_DATABASE_*` settings pointed to a MariaDB host, since the objectstore schema requires Aria - at this point there's no configuration for running the tests with one contenttype created on one host and another on a different host). At the moment there is no data loaded into the test databases, so the tests aren't exercising much, but that will change with the next pull request.

The test runner creates a test_datazilla database with a datasource table, then creates a project called ""testproj"" and the databases for both content types. In between each test it truncates all the tables for both testproj contenttypes, so that each test is isolated from database modifications made by other tests. Any test that needs a `DatazillaModel` instance (which is likely most tests) can just accept a `dm` parameter and it will get passed a `DatazillaModel` instance pointing to ""testproj"". At the end of the test run all test databases are torn down.

In the future once we have a significant number of tests, the speed can be improved by having an option to run each test within a transaction and rollback at the end of the transaction (and monkeypatch the datasource transaction stuff to never commit for the duration of the test). This provides per-test isolation without needing to truncate tables, and is much faster; this is the technique used by the Django test runner. Tests which explicitly need to test transactional behavior would still use the truncate technique.
",carljm,61586,2012-06-08T23:24:12Z,MEMBER,True,116,63,5,Datazilla is a system for managing and visualizing data.,JavaScript,849d7289e2af3003e81ae8db10e76b9f5a33b7b5,Convert existing tests to PEP8 style.
440,https://api.github.com/repos/mozilla/datazilla/pulls/34,34,database setup and teardown for tests,"This pull request makes the tests pass again! (As long as you have your `DATAZILLA_DATABASE_*` settings pointed to a MariaDB host, since the objectstore schema requires Aria - at this point there's no configuration for running the tests with one contenttype created on one host and another on a different host). At the moment there is no data loaded into the test databases, so the tests aren't exercising much, but that will change with the next pull request.

The test runner creates a test_datazilla database with a datasource table, then creates a project called ""testproj"" and the databases for both content types. In between each test it truncates all the tables for both testproj contenttypes, so that each test is isolated from database modifications made by other tests. Any test that needs a `DatazillaModel` instance (which is likely most tests) can just accept a `dm` parameter and it will get passed a `DatazillaModel` instance pointing to ""testproj"". At the end of the test run all test databases are torn down.

In the future once we have a significant number of tests, the speed can be improved by having an option to run each test within a transaction and rollback at the end of the transaction (and monkeypatch the datasource transaction stuff to never commit for the duration of the test). This provides per-test isolation without needing to truncate tables, and is much faster; this is the technique used by the Django test runner. Tests which explicitly need to test transactional behavior would still use the truncate technique.
",carljm,61586,2012-06-08T23:24:12Z,MEMBER,True,116,63,5,Datazilla is a system for managing and visualizing data.,JavaScript,123d9f01567ab85548af0346a66c5f90cf7edd63,Merge branch 'sep-data-loading' into test-dbs
441,https://api.github.com/repos/mozilla/datazilla/pulls/34,34,database setup and teardown for tests,"This pull request makes the tests pass again! (As long as you have your `DATAZILLA_DATABASE_*` settings pointed to a MariaDB host, since the objectstore schema requires Aria - at this point there's no configuration for running the tests with one contenttype created on one host and another on a different host). At the moment there is no data loaded into the test databases, so the tests aren't exercising much, but that will change with the next pull request.

The test runner creates a test_datazilla database with a datasource table, then creates a project called ""testproj"" and the databases for both content types. In between each test it truncates all the tables for both testproj contenttypes, so that each test is isolated from database modifications made by other tests. Any test that needs a `DatazillaModel` instance (which is likely most tests) can just accept a `dm` parameter and it will get passed a `DatazillaModel` instance pointing to ""testproj"". At the end of the test run all test databases are torn down.

In the future once we have a significant number of tests, the speed can be improved by having an option to run each test within a transaction and rollback at the end of the transaction (and monkeypatch the datasource transaction stuff to never commit for the duration of the test). This provides per-test isolation without needing to truncate tables, and is much faster; this is the technique used by the Django test runner. Tests which explicitly need to test transactional behavior would still use the truncate technique.
",carljm,61586,2012-06-08T23:24:12Z,MEMBER,True,116,63,5,Datazilla is a system for managing and visualizing data.,JavaScript,a1f2cebe64b9d5fd7f5a729fad3adec785e22aa4,Tests pass again.
442,https://api.github.com/repos/mozilla/datazilla/pulls/34,34,database setup and teardown for tests,"This pull request makes the tests pass again! (As long as you have your `DATAZILLA_DATABASE_*` settings pointed to a MariaDB host, since the objectstore schema requires Aria - at this point there's no configuration for running the tests with one contenttype created on one host and another on a different host). At the moment there is no data loaded into the test databases, so the tests aren't exercising much, but that will change with the next pull request.

The test runner creates a test_datazilla database with a datasource table, then creates a project called ""testproj"" and the databases for both content types. In between each test it truncates all the tables for both testproj contenttypes, so that each test is isolated from database modifications made by other tests. Any test that needs a `DatazillaModel` instance (which is likely most tests) can just accept a `dm` parameter and it will get passed a `DatazillaModel` instance pointing to ""testproj"". At the end of the test run all test databases are torn down.

In the future once we have a significant number of tests, the speed can be improved by having an option to run each test within a transaction and rollback at the end of the transaction (and monkeypatch the datasource transaction stuff to never commit for the duration of the test). This provides per-test isolation without needing to truncate tables, and is much faster; this is the technique used by the Django test runner. Tests which explicitly need to test transactional behavior would still use the truncate technique.
",carljm,61586,2012-06-08T23:24:12Z,MEMBER,True,116,63,5,Datazilla is a system for managing and visualizing data.,JavaScript,d378326a809ebf106e919f19aee8faead8a13486,Merge branch master into test-dbs.
443,https://api.github.com/repos/mozilla/datazilla/pulls/33,33,Added objectstore json and sql files,,samliu,135933,2012-06-06T18:21:11Z,MEMBER,True,51,0,2,Datazilla is a system for managing and visualizing data.,JavaScript,9c7249b498dc680f636d17d7863f5f5f1bed0fd4,added sql structures
444,https://api.github.com/repos/mozilla/datazilla/pulls/32,32,Underscore,"1.) Converted all python files in datazilla to use the underscore convention.

2.) Reverted back to using the memcache module directly instead of using django's cache plugin.

3.) Reduced the key size in the cached json structures: standard_deviation->std and average->avg
",jeads,949498,2012-06-05T15:48:47Z,CONTRIBUTOR,True,1052,1044,22,Datazilla is a system for managing and visualizing data.,JavaScript,61ba49f8542cd4c8b82546297977d537aee472c9,converted naming convention from camelCase to underscores
445,https://api.github.com/repos/mozilla/datazilla/pulls/32,32,Underscore,"1.) Converted all python files in datazilla to use the underscore convention.

2.) Reverted back to using the memcache module directly instead of using django's cache plugin.

3.) Reduced the key size in the cached json structures: standard_deviation->std and average->avg
",jeads,949498,2012-06-05T15:48:47Z,CONTRIBUTOR,True,1052,1044,22,Datazilla is a system for managing and visualizing data.,JavaScript,fda6da4d92590d5070359aa8b2695afd8fa9e3f7,converted naming convention from camelCase to underscores
446,https://api.github.com/repos/mozilla/datazilla/pulls/32,32,Underscore,"1.) Converted all python files in datazilla to use the underscore convention.

2.) Reverted back to using the memcache module directly instead of using django's cache plugin.

3.) Reduced the key size in the cached json structures: standard_deviation->std and average->avg
",jeads,949498,2012-06-05T15:48:47Z,CONTRIBUTOR,True,1052,1044,22,Datazilla is a system for managing and visualizing data.,JavaScript,5d76ad8863e91be50ae6cce0cf1c832cb1f08eed,reduced the key size in the cached json structures and reverted back to using the memcache module directly
447,https://api.github.com/repos/mozilla/datazilla/pulls/31,31,Test setup,"This branch contains a number of changes; the only thing they have in common is that I ran across all of them as dependencies for getting a reproducible isolated test suite in place (and related cleanups). Summarized:
1. Use Django's cache interface (an extremely light wrapper) rather than python-memcached directly. No actual API change, but it allows us to automatically prefix all memcached keys, which means that test runs can be sure they aren't reusing data from an existing memcached instance, necessary to ensure reproducible test runs.
2. Split the previously-massive `datazilla/model/models.py` into two files: the Django ORM stuff for loading datasets from the datasources table now goes in `datazilla/model/sql/models.py`, and the base `DatazillaModel` class goes in `datazilla/model/base.py` (though it's still imported in `__init__.py` so its import path `from datazilla.model import DatazillaModel` doesn't change).
3. Moved the transfer_data management command from `datazilla/model` to `datazilla/controller/admin`, since it seems to match the definition of the type of thing you'd originally intended to put in `datazilla/controller`.
4. Added SQLDataSource `create` and `create_next_dataset` methods which can create a new project (both the row in the datasource table and the new database itself, with empty schema) and create the next dataset in sequence for an existing project, respectively.
5. Created `pytest_sessionstart` and `pytest_sessionfinish` hook functions that set up and tear down the test environment, including a temporary test-only database.

Next up (in a different pull request) - adding pytest funcargs (test resources) for a full test-only project database, with isolation between tests, in order to allow the existing tests to pass again.
",carljm,61586,2012-06-04T16:05:48Z,MEMBER,True,458,286,23,Datazilla is a system for managing and visualizing data.,JavaScript,31fc021af4acf204d31ef13d34b2109066681fd8,Tests add vendor lib automatically.
448,https://api.github.com/repos/mozilla/datazilla/pulls/31,31,Test setup,"This branch contains a number of changes; the only thing they have in common is that I ran across all of them as dependencies for getting a reproducible isolated test suite in place (and related cleanups). Summarized:
1. Use Django's cache interface (an extremely light wrapper) rather than python-memcached directly. No actual API change, but it allows us to automatically prefix all memcached keys, which means that test runs can be sure they aren't reusing data from an existing memcached instance, necessary to ensure reproducible test runs.
2. Split the previously-massive `datazilla/model/models.py` into two files: the Django ORM stuff for loading datasets from the datasources table now goes in `datazilla/model/sql/models.py`, and the base `DatazillaModel` class goes in `datazilla/model/base.py` (though it's still imported in `__init__.py` so its import path `from datazilla.model import DatazillaModel` doesn't change).
3. Moved the transfer_data management command from `datazilla/model` to `datazilla/controller/admin`, since it seems to match the definition of the type of thing you'd originally intended to put in `datazilla/controller`.
4. Added SQLDataSource `create` and `create_next_dataset` methods which can create a new project (both the row in the datasource table and the new database itself, with empty schema) and create the next dataset in sequence for an existing project, respectively.
5. Created `pytest_sessionstart` and `pytest_sessionfinish` hook functions that set up and tear down the test environment, including a temporary test-only database.

Next up (in a different pull request) - adding pytest funcargs (test resources) for a full test-only project database, with isolation between tests, in order to allow the existing tests to pass again.
",carljm,61586,2012-06-04T16:05:48Z,MEMBER,True,458,286,23,Datazilla is a system for managing and visualizing data.,JavaScript,155920aa29392a459c2f5fca014922fd9024842d,Setup and teardown test isolation environment; makes existing tests fail.
449,https://api.github.com/repos/mozilla/datazilla/pulls/31,31,Test setup,"This branch contains a number of changes; the only thing they have in common is that I ran across all of them as dependencies for getting a reproducible isolated test suite in place (and related cleanups). Summarized:
1. Use Django's cache interface (an extremely light wrapper) rather than python-memcached directly. No actual API change, but it allows us to automatically prefix all memcached keys, which means that test runs can be sure they aren't reusing data from an existing memcached instance, necessary to ensure reproducible test runs.
2. Split the previously-massive `datazilla/model/models.py` into two files: the Django ORM stuff for loading datasets from the datasources table now goes in `datazilla/model/sql/models.py`, and the base `DatazillaModel` class goes in `datazilla/model/base.py` (though it's still imported in `__init__.py` so its import path `from datazilla.model import DatazillaModel` doesn't change).
3. Moved the transfer_data management command from `datazilla/model` to `datazilla/controller/admin`, since it seems to match the definition of the type of thing you'd originally intended to put in `datazilla/controller`.
4. Added SQLDataSource `create` and `create_next_dataset` methods which can create a new project (both the row in the datasource table and the new database itself, with empty schema) and create the next dataset in sequence for an existing project, respectively.
5. Created `pytest_sessionstart` and `pytest_sessionfinish` hook functions that set up and tear down the test environment, including a temporary test-only database.

Next up (in a different pull request) - adding pytest funcargs (test resources) for a full test-only project database, with isolation between tests, in order to allow the existing tests to pass again.
",carljm,61586,2012-06-04T16:05:48Z,MEMBER,True,458,286,23,Datazilla is a system for managing and visualizing data.,JavaScript,4d49ae932f193cad5a65bc489fc5a2c45b361dd4,Some reorganization to break up the massive models.py.
450,https://api.github.com/repos/mozilla/datazilla/pulls/31,31,Test setup,"This branch contains a number of changes; the only thing they have in common is that I ran across all of them as dependencies for getting a reproducible isolated test suite in place (and related cleanups). Summarized:
1. Use Django's cache interface (an extremely light wrapper) rather than python-memcached directly. No actual API change, but it allows us to automatically prefix all memcached keys, which means that test runs can be sure they aren't reusing data from an existing memcached instance, necessary to ensure reproducible test runs.
2. Split the previously-massive `datazilla/model/models.py` into two files: the Django ORM stuff for loading datasets from the datasources table now goes in `datazilla/model/sql/models.py`, and the base `DatazillaModel` class goes in `datazilla/model/base.py` (though it's still imported in `__init__.py` so its import path `from datazilla.model import DatazillaModel` doesn't change).
3. Moved the transfer_data management command from `datazilla/model` to `datazilla/controller/admin`, since it seems to match the definition of the type of thing you'd originally intended to put in `datazilla/controller`.
4. Added SQLDataSource `create` and `create_next_dataset` methods which can create a new project (both the row in the datasource table and the new database itself, with empty schema) and create the next dataset in sequence for an existing project, respectively.
5. Created `pytest_sessionstart` and `pytest_sessionfinish` hook functions that set up and tear down the test environment, including a temporary test-only database.

Next up (in a different pull request) - adding pytest funcargs (test resources) for a full test-only project database, with isolation between tests, in order to allow the existing tests to pass again.
",carljm,61586,2012-06-04T16:05:48Z,MEMBER,True,458,286,23,Datazilla is a system for managing and visualizing data.,JavaScript,f951404ef6b866bba81503611bf015bb391a39d5,Rename template schema; dataset number isn't inherent to the template schema itself.
451,https://api.github.com/repos/mozilla/datazilla/pulls/31,31,Test setup,"This branch contains a number of changes; the only thing they have in common is that I ran across all of them as dependencies for getting a reproducible isolated test suite in place (and related cleanups). Summarized:
1. Use Django's cache interface (an extremely light wrapper) rather than python-memcached directly. No actual API change, but it allows us to automatically prefix all memcached keys, which means that test runs can be sure they aren't reusing data from an existing memcached instance, necessary to ensure reproducible test runs.
2. Split the previously-massive `datazilla/model/models.py` into two files: the Django ORM stuff for loading datasets from the datasources table now goes in `datazilla/model/sql/models.py`, and the base `DatazillaModel` class goes in `datazilla/model/base.py` (though it's still imported in `__init__.py` so its import path `from datazilla.model import DatazillaModel` doesn't change).
3. Moved the transfer_data management command from `datazilla/model` to `datazilla/controller/admin`, since it seems to match the definition of the type of thing you'd originally intended to put in `datazilla/controller`.
4. Added SQLDataSource `create` and `create_next_dataset` methods which can create a new project (both the row in the datasource table and the new database itself, with empty schema) and create the next dataset in sequence for an existing project, respectively.
5. Created `pytest_sessionstart` and `pytest_sessionfinish` hook functions that set up and tear down the test environment, including a temporary test-only database.

Next up (in a different pull request) - adding pytest funcargs (test resources) for a full test-only project database, with isolation between tests, in order to allow the existing tests to pass again.
",carljm,61586,2012-06-04T16:05:48Z,MEMBER,True,458,286,23,Datazilla is a system for managing and visualizing data.,JavaScript,9c566164913871203d3be48dcd500d785e435e11,"Update datasource table schema, add functions for automatic creation of new databases."
452,https://api.github.com/repos/mozilla/datazilla/pulls/31,31,Test setup,"This branch contains a number of changes; the only thing they have in common is that I ran across all of them as dependencies for getting a reproducible isolated test suite in place (and related cleanups). Summarized:
1. Use Django's cache interface (an extremely light wrapper) rather than python-memcached directly. No actual API change, but it allows us to automatically prefix all memcached keys, which means that test runs can be sure they aren't reusing data from an existing memcached instance, necessary to ensure reproducible test runs.
2. Split the previously-massive `datazilla/model/models.py` into two files: the Django ORM stuff for loading datasets from the datasources table now goes in `datazilla/model/sql/models.py`, and the base `DatazillaModel` class goes in `datazilla/model/base.py` (though it's still imported in `__init__.py` so its import path `from datazilla.model import DatazillaModel` doesn't change).
3. Moved the transfer_data management command from `datazilla/model` to `datazilla/controller/admin`, since it seems to match the definition of the type of thing you'd originally intended to put in `datazilla/controller`.
4. Added SQLDataSource `create` and `create_next_dataset` methods which can create a new project (both the row in the datasource table and the new database itself, with empty schema) and create the next dataset in sequence for an existing project, respectively.
5. Created `pytest_sessionstart` and `pytest_sessionfinish` hook functions that set up and tear down the test environment, including a temporary test-only database.

Next up (in a different pull request) - adding pytest funcargs (test resources) for a full test-only project database, with isolation between tests, in order to allow the existing tests to pass again.
",carljm,61586,2012-06-04T16:05:48Z,MEMBER,True,458,286,23,Datazilla is a system for managing and visualizing data.,JavaScript,5b865c9244e1885220e4d01ad504f8f1db6bbd0a,Default settings suitable for local dev.
453,https://api.github.com/repos/mozilla/datazilla/pulls/31,31,Test setup,"This branch contains a number of changes; the only thing they have in common is that I ran across all of them as dependencies for getting a reproducible isolated test suite in place (and related cleanups). Summarized:
1. Use Django's cache interface (an extremely light wrapper) rather than python-memcached directly. No actual API change, but it allows us to automatically prefix all memcached keys, which means that test runs can be sure they aren't reusing data from an existing memcached instance, necessary to ensure reproducible test runs.
2. Split the previously-massive `datazilla/model/models.py` into two files: the Django ORM stuff for loading datasets from the datasources table now goes in `datazilla/model/sql/models.py`, and the base `DatazillaModel` class goes in `datazilla/model/base.py` (though it's still imported in `__init__.py` so its import path `from datazilla.model import DatazillaModel` doesn't change).
3. Moved the transfer_data management command from `datazilla/model` to `datazilla/controller/admin`, since it seems to match the definition of the type of thing you'd originally intended to put in `datazilla/controller`.
4. Added SQLDataSource `create` and `create_next_dataset` methods which can create a new project (both the row in the datasource table and the new database itself, with empty schema) and create the next dataset in sequence for an existing project, respectively.
5. Created `pytest_sessionstart` and `pytest_sessionfinish` hook functions that set up and tear down the test environment, including a temporary test-only database.

Next up (in a different pull request) - adding pytest funcargs (test resources) for a full test-only project database, with isolation between tests, in order to allow the existing tests to pass again.
",carljm,61586,2012-06-04T16:05:48Z,MEMBER,True,458,286,23,Datazilla is a system for managing and visualizing data.,JavaScript,eb05fa6a9f85c06f898cf2de2816668876fca973,Split SQLDataset .create_next_dataset() from .create().
454,https://api.github.com/repos/mozilla/datazilla/pulls/31,31,Test setup,"This branch contains a number of changes; the only thing they have in common is that I ran across all of them as dependencies for getting a reproducible isolated test suite in place (and related cleanups). Summarized:
1. Use Django's cache interface (an extremely light wrapper) rather than python-memcached directly. No actual API change, but it allows us to automatically prefix all memcached keys, which means that test runs can be sure they aren't reusing data from an existing memcached instance, necessary to ensure reproducible test runs.
2. Split the previously-massive `datazilla/model/models.py` into two files: the Django ORM stuff for loading datasets from the datasources table now goes in `datazilla/model/sql/models.py`, and the base `DatazillaModel` class goes in `datazilla/model/base.py` (though it's still imported in `__init__.py` so its import path `from datazilla.model import DatazillaModel` doesn't change).
3. Moved the transfer_data management command from `datazilla/model` to `datazilla/controller/admin`, since it seems to match the definition of the type of thing you'd originally intended to put in `datazilla/controller`.
4. Added SQLDataSource `create` and `create_next_dataset` methods which can create a new project (both the row in the datasource table and the new database itself, with empty schema) and create the next dataset in sequence for an existing project, respectively.
5. Created `pytest_sessionstart` and `pytest_sessionfinish` hook functions that set up and tear down the test environment, including a temporary test-only database.

Next up (in a different pull request) - adding pytest funcargs (test resources) for a full test-only project database, with isolation between tests, in order to allow the existing tests to pass again.
",carljm,61586,2012-06-04T16:05:48Z,MEMBER,True,458,286,23,Datazilla is a system for managing and visualizing data.,JavaScript,862385b4e8640cc96c32a2335a34c2d5803ae137,Merge from master.
455,https://api.github.com/repos/mozilla/datazilla/pulls/31,31,Test setup,"This branch contains a number of changes; the only thing they have in common is that I ran across all of them as dependencies for getting a reproducible isolated test suite in place (and related cleanups). Summarized:
1. Use Django's cache interface (an extremely light wrapper) rather than python-memcached directly. No actual API change, but it allows us to automatically prefix all memcached keys, which means that test runs can be sure they aren't reusing data from an existing memcached instance, necessary to ensure reproducible test runs.
2. Split the previously-massive `datazilla/model/models.py` into two files: the Django ORM stuff for loading datasets from the datasources table now goes in `datazilla/model/sql/models.py`, and the base `DatazillaModel` class goes in `datazilla/model/base.py` (though it's still imported in `__init__.py` so its import path `from datazilla.model import DatazillaModel` doesn't change).
3. Moved the transfer_data management command from `datazilla/model` to `datazilla/controller/admin`, since it seems to match the definition of the type of thing you'd originally intended to put in `datazilla/controller`.
4. Added SQLDataSource `create` and `create_next_dataset` methods which can create a new project (both the row in the datasource table and the new database itself, with empty schema) and create the next dataset in sequence for an existing project, respectively.
5. Created `pytest_sessionstart` and `pytest_sessionfinish` hook functions that set up and tear down the test environment, including a temporary test-only database.

Next up (in a different pull request) - adding pytest funcargs (test resources) for a full test-only project database, with isolation between tests, in order to allow the existing tests to pass again.
",carljm,61586,2012-06-04T16:05:48Z,MEMBER,True,458,286,23,Datazilla is a system for managing and visualizing data.,JavaScript,45dd86af83006658bb8957df3d0ce359b913b869,Fix reference to runtests.sh in docs.
456,https://api.github.com/repos/mozilla/datazilla/pulls/31,31,Test setup,"This branch contains a number of changes; the only thing they have in common is that I ran across all of them as dependencies for getting a reproducible isolated test suite in place (and related cleanups). Summarized:
1. Use Django's cache interface (an extremely light wrapper) rather than python-memcached directly. No actual API change, but it allows us to automatically prefix all memcached keys, which means that test runs can be sure they aren't reusing data from an existing memcached instance, necessary to ensure reproducible test runs.
2. Split the previously-massive `datazilla/model/models.py` into two files: the Django ORM stuff for loading datasets from the datasources table now goes in `datazilla/model/sql/models.py`, and the base `DatazillaModel` class goes in `datazilla/model/base.py` (though it's still imported in `__init__.py` so its import path `from datazilla.model import DatazillaModel` doesn't change).
3. Moved the transfer_data management command from `datazilla/model` to `datazilla/controller/admin`, since it seems to match the definition of the type of thing you'd originally intended to put in `datazilla/controller`.
4. Added SQLDataSource `create` and `create_next_dataset` methods which can create a new project (both the row in the datasource table and the new database itself, with empty schema) and create the next dataset in sequence for an existing project, respectively.
5. Created `pytest_sessionstart` and `pytest_sessionfinish` hook functions that set up and tear down the test environment, including a temporary test-only database.

Next up (in a different pull request) - adding pytest funcargs (test resources) for a full test-only project database, with isolation between tests, in order to allow the existing tests to pass again.
",carljm,61586,2012-06-04T16:05:48Z,MEMBER,True,458,286,23,Datazilla is a system for managing and visualizing data.,JavaScript,14b78eb11e3de472e01a88de4ed42113c475c687,Merge branch 'master' into test-setup
457,https://api.github.com/repos/mozilla/datazilla/pulls/30,30,Fix transfer data,"There was a bug in the new manage.py method transfer_data. When making calls to DatazillaModel while stepping through an iterator from datasource, where two DatazillaModels are being used to communicate to two different databases, the MySQL-python execute function blocks between the two databases even when commit is called after each transaction.  I'm not sure why this happens, I could be misinterpreting the symptoms but I think I found a reasonable fix.  I used the data_iter.sqlChunks attribute which holds a list of all of the sql statements to execute in a chunking operation. Data is retrieved from the source, disconnect is called, and then data is loaded into the target. This solved the blocking problem. I also modified the execute function in datasource so it takes a new option called chunk_total, which allows the caller to specify a total number of rows to return in a chunking transaction. This is cleaner than having callers deal with it.

I fixed a bug in datasource that prevents debug_show from being set to False explicitly. You can now actually turn off debugging through local.py by setting DEBUG to False.

I added a new option to the execute function in datasource, executemany. When set to True, it uses MySQL-python's executemany for multi-row inserts. You can pass a list of lists of mixed types (strings, ints, floats) that will be passed to executemany, this is way more efficient than doing individual row inserts. I updated DatazillaModel._setTestAuxData() and DatazillaModel._setTestValues() which were the worst row level insert offenders. This gives a decent performance boost and reduces inefficient database operation code. Now we just need to cache the reference data and loadTestData will be a reasonable method!

I fixed populate_test_collections.py so it will now work with the new version of models.py.

Also, I was transferring data to mariadb over the weekend and the data transfer job died when I had to restart memcached. This was caused by the active_status column being removed from the database. I updated DataSource and DataSourceManager in models.py so they don't reference active_status. This is a critical update that needs to be pushed to s4n4 so the web service will not break if we restart memcached.
",jeads,949498,2012-06-04T02:12:41Z,CONTRIBUTOR,True,154,50,7,Datazilla is a system for managing and visualizing data.,JavaScript,7a26839a851c9ad1ac8bc53b02f443cf6cab0ae8,modified so it would work with the new models.py structure
458,https://api.github.com/repos/mozilla/datazilla/pulls/30,30,Fix transfer data,"There was a bug in the new manage.py method transfer_data. When making calls to DatazillaModel while stepping through an iterator from datasource, where two DatazillaModels are being used to communicate to two different databases, the MySQL-python execute function blocks between the two databases even when commit is called after each transaction.  I'm not sure why this happens, I could be misinterpreting the symptoms but I think I found a reasonable fix.  I used the data_iter.sqlChunks attribute which holds a list of all of the sql statements to execute in a chunking operation. Data is retrieved from the source, disconnect is called, and then data is loaded into the target. This solved the blocking problem. I also modified the execute function in datasource so it takes a new option called chunk_total, which allows the caller to specify a total number of rows to return in a chunking transaction. This is cleaner than having callers deal with it.

I fixed a bug in datasource that prevents debug_show from being set to False explicitly. You can now actually turn off debugging through local.py by setting DEBUG to False.

I added a new option to the execute function in datasource, executemany. When set to True, it uses MySQL-python's executemany for multi-row inserts. You can pass a list of lists of mixed types (strings, ints, floats) that will be passed to executemany, this is way more efficient than doing individual row inserts. I updated DatazillaModel._setTestAuxData() and DatazillaModel._setTestValues() which were the worst row level insert offenders. This gives a decent performance boost and reduces inefficient database operation code. Now we just need to cache the reference data and loadTestData will be a reasonable method!

I fixed populate_test_collections.py so it will now work with the new version of models.py.

Also, I was transferring data to mariadb over the weekend and the data transfer job died when I had to restart memcached. This was caused by the active_status column being removed from the database. I updated DataSource and DataSourceManager in models.py so they don't reference active_status. This is a critical update that needs to be pushed to s4n4 so the web service will not break if we restart memcached.
",jeads,949498,2012-06-04T02:12:41Z,CONTRIBUTOR,True,154,50,7,Datazilla is a system for managing and visualizing data.,JavaScript,4eb725d8c16d97f1b29dfa2ca98d2c3990eb7c16,Fixed execute blocking bug and made use of the new chunk_total option for execute
459,https://api.github.com/repos/mozilla/datazilla/pulls/30,30,Fix transfer data,"There was a bug in the new manage.py method transfer_data. When making calls to DatazillaModel while stepping through an iterator from datasource, where two DatazillaModels are being used to communicate to two different databases, the MySQL-python execute function blocks between the two databases even when commit is called after each transaction.  I'm not sure why this happens, I could be misinterpreting the symptoms but I think I found a reasonable fix.  I used the data_iter.sqlChunks attribute which holds a list of all of the sql statements to execute in a chunking operation. Data is retrieved from the source, disconnect is called, and then data is loaded into the target. This solved the blocking problem. I also modified the execute function in datasource so it takes a new option called chunk_total, which allows the caller to specify a total number of rows to return in a chunking transaction. This is cleaner than having callers deal with it.

I fixed a bug in datasource that prevents debug_show from being set to False explicitly. You can now actually turn off debugging through local.py by setting DEBUG to False.

I added a new option to the execute function in datasource, executemany. When set to True, it uses MySQL-python's executemany for multi-row inserts. You can pass a list of lists of mixed types (strings, ints, floats) that will be passed to executemany, this is way more efficient than doing individual row inserts. I updated DatazillaModel._setTestAuxData() and DatazillaModel._setTestValues() which were the worst row level insert offenders. This gives a decent performance boost and reduces inefficient database operation code. Now we just need to cache the reference data and loadTestData will be a reasonable method!

I fixed populate_test_collections.py so it will now work with the new version of models.py.

Also, I was transferring data to mariadb over the weekend and the data transfer job died when I had to restart memcached. This was caused by the active_status column being removed from the database. I updated DataSource and DataSourceManager in models.py so they don't reference active_status. This is a critical update that needs to be pushed to s4n4 so the web service will not break if we restart memcached.
",jeads,949498,2012-06-04T02:12:41Z,CONTRIBUTOR,True,154,50,7,Datazilla is a system for managing and visualizing data.,JavaScript,079995aeef54e088b6802885b371b5b1c7b1cd4d,"Fixed getTestId bug, modifed setTestValues and setTestAuxData to use executemany to improve efficiency"
460,https://api.github.com/repos/mozilla/datazilla/pulls/30,30,Fix transfer data,"There was a bug in the new manage.py method transfer_data. When making calls to DatazillaModel while stepping through an iterator from datasource, where two DatazillaModels are being used to communicate to two different databases, the MySQL-python execute function blocks between the two databases even when commit is called after each transaction.  I'm not sure why this happens, I could be misinterpreting the symptoms but I think I found a reasonable fix.  I used the data_iter.sqlChunks attribute which holds a list of all of the sql statements to execute in a chunking operation. Data is retrieved from the source, disconnect is called, and then data is loaded into the target. This solved the blocking problem. I also modified the execute function in datasource so it takes a new option called chunk_total, which allows the caller to specify a total number of rows to return in a chunking transaction. This is cleaner than having callers deal with it.

I fixed a bug in datasource that prevents debug_show from being set to False explicitly. You can now actually turn off debugging through local.py by setting DEBUG to False.

I added a new option to the execute function in datasource, executemany. When set to True, it uses MySQL-python's executemany for multi-row inserts. You can pass a list of lists of mixed types (strings, ints, floats) that will be passed to executemany, this is way more efficient than doing individual row inserts. I updated DatazillaModel._setTestAuxData() and DatazillaModel._setTestValues() which were the worst row level insert offenders. This gives a decent performance boost and reduces inefficient database operation code. Now we just need to cache the reference data and loadTestData will be a reasonable method!

I fixed populate_test_collections.py so it will now work with the new version of models.py.

Also, I was transferring data to mariadb over the weekend and the data transfer job died when I had to restart memcached. This was caused by the active_status column being removed from the database. I updated DataSource and DataSourceManager in models.py so they don't reference active_status. This is a critical update that needs to be pushed to s4n4 so the web service will not break if we restart memcached.
",jeads,949498,2012-06-04T02:12:41Z,CONTRIBUTOR,True,154,50,7,Datazilla is a system for managing and visualizing data.,JavaScript,cd3905b7b5f9763ed627a8cf9b55376cfdb505e6,added new version of datasource
461,https://api.github.com/repos/mozilla/datazilla/pulls/30,30,Fix transfer data,"There was a bug in the new manage.py method transfer_data. When making calls to DatazillaModel while stepping through an iterator from datasource, where two DatazillaModels are being used to communicate to two different databases, the MySQL-python execute function blocks between the two databases even when commit is called after each transaction.  I'm not sure why this happens, I could be misinterpreting the symptoms but I think I found a reasonable fix.  I used the data_iter.sqlChunks attribute which holds a list of all of the sql statements to execute in a chunking operation. Data is retrieved from the source, disconnect is called, and then data is loaded into the target. This solved the blocking problem. I also modified the execute function in datasource so it takes a new option called chunk_total, which allows the caller to specify a total number of rows to return in a chunking transaction. This is cleaner than having callers deal with it.

I fixed a bug in datasource that prevents debug_show from being set to False explicitly. You can now actually turn off debugging through local.py by setting DEBUG to False.

I added a new option to the execute function in datasource, executemany. When set to True, it uses MySQL-python's executemany for multi-row inserts. You can pass a list of lists of mixed types (strings, ints, floats) that will be passed to executemany, this is way more efficient than doing individual row inserts. I updated DatazillaModel._setTestAuxData() and DatazillaModel._setTestValues() which were the worst row level insert offenders. This gives a decent performance boost and reduces inefficient database operation code. Now we just need to cache the reference data and loadTestData will be a reasonable method!

I fixed populate_test_collections.py so it will now work with the new version of models.py.

Also, I was transferring data to mariadb over the weekend and the data transfer job died when I had to restart memcached. This was caused by the active_status column being removed from the database. I updated DataSource and DataSourceManager in models.py so they don't reference active_status. This is a critical update that needs to be pushed to s4n4 so the web service will not break if we restart memcached.
",jeads,949498,2012-06-04T02:12:41Z,CONTRIBUTOR,True,154,50,7,Datazilla is a system for managing and visualizing data.,JavaScript,e08a615829fe97f7a9d942af6cc0b321b91eeb8b,"Fixed debug_show bug, added new execute option executemany for batch sql execution, added execute option chunk_total for specifying total number of records to chunk through"
462,https://api.github.com/repos/mozilla/datazilla/pulls/29,29,Fixed sphinx docs,"They weren't compiling before
",samliu,135933,2012-06-01T17:40:49Z,MEMBER,True,1,3,2,Datazilla is a system for managing and visualizing data.,JavaScript,e97af970e27f32b0ab440a9fb4e2b64512f18d3d,added missing images
463,https://api.github.com/repos/mozilla/datazilla/pulls/29,29,Fixed sphinx docs,"They weren't compiling before
",samliu,135933,2012-06-01T17:40:49Z,MEMBER,True,1,3,2,Datazilla is a system for managing and visualizing data.,JavaScript,06213660c66131cf947a598fff5ca16c3a68319e,fixed sphinx compilation bug
464,https://api.github.com/repos/mozilla/datazilla/pulls/28,28,Moved readme to sphinx documentation,,samliu,135933,2012-06-01T01:36:38Z,MEMBER,True,896,563,8,Datazilla is a system for managing and visualizing data.,JavaScript,44590c7c5e41fd819d5239d752d5ea3811eebd3b,"moved readme to sphinx docs, fixed links, etc"
465,https://api.github.com/repos/mozilla/datazilla/pulls/28,28,Moved readme to sphinx documentation,,samliu,135933,2012-06-01T01:36:38Z,MEMBER,True,896,563,8,Datazilla is a system for managing and visualizing data.,JavaScript,aa808c722caf31f90302ec7007ce424ffeee94db,gitignore build folder
466,https://api.github.com/repos/mozilla/datazilla/pulls/27,27,Model reorg,"This branch accomplishes many of the things we discussed last week. I'll enumerate more specifically in a comment, but I want to get the pull request in place so you can start reviewing...
",carljm,61586,2012-05-29T21:19:14Z,MEMBER,True,396,424,16,Datazilla is a system for managing and visualizing data.,JavaScript,7947c202ce774fcb44ea2605eba5e4c0b01a340f,Reorganized model layer.
467,https://api.github.com/repos/mozilla/datazilla/pulls/27,27,Model reorg,"This branch accomplishes many of the things we discussed last week. I'll enumerate more specifically in a comment, but I want to get the pull request in place so you can start reviewing...
",carljm,61586,2012-05-29T21:19:14Z,MEMBER,True,396,424,16,Datazilla is a system for managing and visualizing data.,JavaScript,45a1bdf78073107dc6e1d992faeed151f27e0cc3,Merge from master to model-reorg.
468,https://api.github.com/repos/mozilla/datazilla/pulls/27,27,Model reorg,"This branch accomplishes many of the things we discussed last week. I'll enumerate more specifically in a comment, but I want to get the pull request in place so you can start reviewing...
",carljm,61586,2012-05-29T21:19:14Z,MEMBER,True,396,424,16,Datazilla is a system for managing and visualizing data.,JavaScript,3185ac6c29b048c8bfcd2e01d4042fb6bce1a5dc,Update appengine-specific model layer code to new structure.
469,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,ed0fec7219bb2c0dc73f0bf2150a59eeb20fbb30,added a method to chunk throught test_data
470,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,1f63bb055ab25d177b457ee571385569d796b5ab,added to sql statement for test_data
471,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,25db95694d23e10ab336a7a2f79d832b747467cb,removed unnecessary unique constraint on operating_system.name
472,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,6ce2eaaef99ca0f49d6e72232cb28873f9490fe3,fixed broken paths that did not reflect the recent directory modifications in datazilla
473,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,7940c43bc381673bd7d216f03a85db637e4f2b75,updated datasource with the chunk_min option
474,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,3beeb6975bd20f504058872c7cb113f280553264,new command to transfer data between projects
475,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,b8eb62afcf462bc3d67193530b020ddb3e250254,updates from running bin/generate-vendor-lib.py after updating requirements/pure.txt to include a new datasource commit
476,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,59f53fe1153780ac8c74a0eef2b97cf589ecfd76,cleaned up white space
477,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,345c5c35027d4bfe34515ec2540b3f0f821d3ad3,new model directory for manage.py commands
478,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,baaa47020e51e52e5d98bfa77844f203f9734c7f,moved to model/management/commands
479,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,26bffe87018345f74800e414e5faaf1b1261de07,added datazilla.model as an installed app
480,https://api.github.com/repos/mozilla/datazilla/pulls/26,26,Data transfer,"Added a new manage.py command called transfer_data.  You can take a look at the options with: manage.py transfer_data --help

The following command:

python manage.py transfer_data --source talos --target test --records 10 --start 20000 --debug

Will write out 10 json structures to stdout starting at id 20000. The json data is pulled from the talos project's test_data table.  I used this command to transfer 10000 records to the test database.  When the --debug flag is removed the data transfer is actually carried out.

This command required adding a new option to datasource, ""chunk_min"", that allows a user to specify a minimum id to start chunking from.  The updates in /vendor were from running bin/generate-vendor-lib.py with the new datasource commit hash.

This data transfer into the test database validates the foreign keys on the test database.  There was one UNIQUE key on the operating_system.name column that needed to be removed, there is already a UNIQUE key on (name, version) other than that, there were no data integrity errors found in the 10,000 records transferred.

Jeads
",jeads,949498,2012-05-25T21:50:14Z,CONTRIBUTOR,True,506,332,17,Datazilla is a system for managing and visualizing data.,JavaScript,3cf7d0dc1faab715d513e557c9b7e68b222f0a2f,new datasource file generated by generate-vendor-lib.py
481,https://api.github.com/repos/mozilla/datazilla/pulls/25,25,Add the initial support of Datazilla on App Engine with Cloud SQL,"Improve the condition for USE_APP_ENGINE so that it works on remote servers, and deploy it in Model.py now that we pull settings there. Also remove the assignment of SECRET_KEY in base.py since this is done in the local setting instead now.

Remove the unnecessary import of url.

Add the initial support of Datazilla on App Engine with Cloud SQL. Added app.yaml and appengine.py to launch Datazilla on App Engine because App Engine requires app.yaml to be at the top level directory, and there are few configuration tricks we have to use. Added datazilla/settings/appengine.py for App Engine and Cloud SQL specific settings and datazilla/model/appengine/model.py to talk with datasource's CloudSQLHub.
",rniwa,285965,2012-05-23T17:27:32Z,CONTRIBUTOR,True,318,3,7,Datazilla is a system for managing and visualizing data.,JavaScript,0b9ebe8972baa76b1b9b55d86c1ff0a01cca23b2,"Improve the condition for USE_APP_ENGINE so that it works on remote servers,
and deploy it in Model.py now that we pull settings there.

Also remove the assignment of SECRET_KEY in base.py since this is done in
the local setting instead now."
482,https://api.github.com/repos/mozilla/datazilla/pulls/25,25,Add the initial support of Datazilla on App Engine with Cloud SQL,"Improve the condition for USE_APP_ENGINE so that it works on remote servers, and deploy it in Model.py now that we pull settings there. Also remove the assignment of SECRET_KEY in base.py since this is done in the local setting instead now.

Remove the unnecessary import of url.

Add the initial support of Datazilla on App Engine with Cloud SQL. Added app.yaml and appengine.py to launch Datazilla on App Engine because App Engine requires app.yaml to be at the top level directory, and there are few configuration tricks we have to use. Added datazilla/settings/appengine.py for App Engine and Cloud SQL specific settings and datazilla/model/appengine/model.py to talk with datasource's CloudSQLHub.
",rniwa,285965,2012-05-23T17:27:32Z,CONTRIBUTOR,True,318,3,7,Datazilla is a system for managing and visualizing data.,JavaScript,0a1f089a1116c39124b0127f4f923a57ed32c8a3,Remove the unnecessary import of url.
483,https://api.github.com/repos/mozilla/datazilla/pulls/25,25,Add the initial support of Datazilla on App Engine with Cloud SQL,"Improve the condition for USE_APP_ENGINE so that it works on remote servers, and deploy it in Model.py now that we pull settings there. Also remove the assignment of SECRET_KEY in base.py since this is done in the local setting instead now.

Remove the unnecessary import of url.

Add the initial support of Datazilla on App Engine with Cloud SQL. Added app.yaml and appengine.py to launch Datazilla on App Engine because App Engine requires app.yaml to be at the top level directory, and there are few configuration tricks we have to use. Added datazilla/settings/appengine.py for App Engine and Cloud SQL specific settings and datazilla/model/appengine/model.py to talk with datasource's CloudSQLHub.
",rniwa,285965,2012-05-23T17:27:32Z,CONTRIBUTOR,True,318,3,7,Datazilla is a system for managing and visualizing data.,JavaScript,9676357a90d25841094dc143b0bfe6fcd231c6ff,"Add the initial support of Datazilla on App Engine with Cloud SQL.

Added app.yaml and appengine.py to launch Datazilla on App Engine because App Engine requires app.yaml
to be at the top level directory, and there are few configuration tricks we have to use.

Added datazilla/settings/appengine.py for App Engine and Cloud SQL specific settings and
datazilla/model/appengine/model.py to talk with datasource's CloudSQLHub."
484,https://api.github.com/repos/mozilla/datazilla/pulls/25,25,Add the initial support of Datazilla on App Engine with Cloud SQL,"Improve the condition for USE_APP_ENGINE so that it works on remote servers, and deploy it in Model.py now that we pull settings there. Also remove the assignment of SECRET_KEY in base.py since this is done in the local setting instead now.

Remove the unnecessary import of url.

Add the initial support of Datazilla on App Engine with Cloud SQL. Added app.yaml and appengine.py to launch Datazilla on App Engine because App Engine requires app.yaml to be at the top level directory, and there are few configuration tricks we have to use. Added datazilla/settings/appengine.py for App Engine and Cloud SQL specific settings and datazilla/model/appengine/model.py to talk with datasource's CloudSQLHub.
",rniwa,285965,2012-05-23T17:27:32Z,CONTRIBUTOR,True,318,3,7,Datazilla is a system for managing and visualizing data.,JavaScript,3397a760f484470fc87e1773fc1279fc59dc0e0c,"Address Carl's comments. Namely remove a bunch of junk from appengine.py,
rename DATAZILLA_DEBUG to DEBUG in datazilla/settings/appengine.py, and
revert the change in datazilla/settings/base.py.

Also fix a bug in datazilla/model/appengine/model.p that we used to use
settings.DATAZILLA_DATABASE_NAME as the default database name instead of
the correct settings.CLOUDSQL_DATABASE."
485,https://api.github.com/repos/mozilla/datazilla/pulls/25,25,Add the initial support of Datazilla on App Engine with Cloud SQL,"Improve the condition for USE_APP_ENGINE so that it works on remote servers, and deploy it in Model.py now that we pull settings there. Also remove the assignment of SECRET_KEY in base.py since this is done in the local setting instead now.

Remove the unnecessary import of url.

Add the initial support of Datazilla on App Engine with Cloud SQL. Added app.yaml and appengine.py to launch Datazilla on App Engine because App Engine requires app.yaml to be at the top level directory, and there are few configuration tricks we have to use. Added datazilla/settings/appengine.py for App Engine and Cloud SQL specific settings and datazilla/model/appengine/model.py to talk with datasource's CloudSQLHub.
",rniwa,285965,2012-05-23T17:27:32Z,CONTRIBUTOR,True,318,3,7,Datazilla is a system for managing and visualizing data.,JavaScript,fcb1eab42b52c8c3190dd5dbf465d6ee66c80552,Merge branch 'master' into appengine
486,https://api.github.com/repos/mozilla/datazilla/pulls/25,25,Add the initial support of Datazilla on App Engine with Cloud SQL,"Improve the condition for USE_APP_ENGINE so that it works on remote servers, and deploy it in Model.py now that we pull settings there. Also remove the assignment of SECRET_KEY in base.py since this is done in the local setting instead now.

Remove the unnecessary import of url.

Add the initial support of Datazilla on App Engine with Cloud SQL. Added app.yaml and appengine.py to launch Datazilla on App Engine because App Engine requires app.yaml to be at the top level directory, and there are few configuration tricks we have to use. Added datazilla/settings/appengine.py for App Engine and Cloud SQL specific settings and datazilla/model/appengine/model.py to talk with datasource's CloudSQLHub.
",rniwa,285965,2012-05-23T17:27:32Z,CONTRIBUTOR,True,318,3,7,Datazilla is a system for managing and visualizing data.,JavaScript,2206ea2b6ac18ede3280f9c76acf2f95de930121,Remove app.yaml and the top-level appengine.py for now per IRC discussion
487,https://api.github.com/repos/mozilla/datazilla/pulls/24,24,Improve the condition for USE_APP_ENGINE so that it works on remote servers,"and deploy it in Model.py now that we pull settings there.

Also remove the assignment of SECRET_KEY in base.py since this is done in
the local setting instead now.
",rniwa,285965,2012-05-23T17:23:49Z,CONTRIBUTOR,False,5,6,2,Datazilla is a system for managing and visualizing data.,JavaScript,0b9ebe8972baa76b1b9b55d86c1ff0a01cca23b2,"Improve the condition for USE_APP_ENGINE so that it works on remote servers,
and deploy it in Model.py now that we pull settings there.

Also remove the assignment of SECRET_KEY in base.py since this is done in
the local setting instead now."
488,https://api.github.com/repos/mozilla/datazilla/pulls/23,23,Settings cleanup,"Some minor cleanups I missed in the settings switchover. The only real impact this has is that you want to define `DEBUG` in your `settings/local.py` rather than `DATAZILLA_DEBUG` - once you're already in a datazilla local-settings file, there's no reason to maintain the extra indirection of `DATAZILLA_DEBUG`.

If you're using the env-var defaults rather than `settings/local.py`, the name of the env var is still `DATAZILLA_DEBUG`.
",carljm,61586,2012-05-22T21:13:56Z,MEMBER,True,3,4,2,Datazilla is a system for managing and visualizing data.,JavaScript,71b2c6c510f59390a76d562eaa7d090fba2c3971,Remove the DATAZILLA_DEBUG level of indirection from the settings; that's only needed for the env var.
489,https://api.github.com/repos/mozilla/datazilla/pulls/23,23,Settings cleanup,"Some minor cleanups I missed in the settings switchover. The only real impact this has is that you want to define `DEBUG` in your `settings/local.py` rather than `DATAZILLA_DEBUG` - once you're already in a datazilla local-settings file, there's no reason to maintain the extra indirection of `DATAZILLA_DEBUG`.

If you're using the env-var defaults rather than `settings/local.py`, the name of the env var is still `DATAZILLA_DEBUG`.
",carljm,61586,2012-05-22T21:13:56Z,MEMBER,True,3,4,2,Datazilla is a system for managing and visualizing data.,JavaScript,e49983a2560e5e75fd029434566b24fbd23b801d,Update README for envvars -> Django settings change.
490,https://api.github.com/repos/mozilla/datazilla/pulls/22,22,Fix test.sh script.,"With the switch to config in Django I forgot to update the `test.sh` script to set a default `DJANGO_SETTINGS_MODULE` value if none is set. This fixes that.
",carljm,61586,2012-05-22T20:11:38Z,MEMBER,True,4,0,1,Datazilla is a system for managing and visualizing data.,JavaScript,885fdd70d9cec3fc79d53af79f2edd01d35bd8ad,Set a default DJANGO_SETTINGS_MODULE in test.sh.
491,https://api.github.com/repos/mozilla/datazilla/pulls/21,21,Add WSGI application and sample Apache config.,"This pull request includes the changes from the vendor-dependencies and django-config pull requests, so should be merged after those (and once those are merged, its diff will be a lot smaller!)

This pull request adds a WSGI application module compatible with Apache/mod_wsgi, removes sample config files that are no longer relevant, and adds sample configs for both nginx proxying to a WSGI app server and Apache/mod_wsgi. It also fleshes out / updates the Installation / Deployment section of the README to assume the use of WSGI rather than FastCGI.

Tested and verified that the sample configs both work; with nginx proxying (just for testing purposes) to `./manage.py runserver 0:8080` and Apache handling double-duty on both static files and WSGI.

I suppose it would be best if we both convert our dev environments to use Apache/mod_wsgi at this point, so we match what IT will be using. `yum install httpd mod_wsgi` followed by adding the sample config (with `ServerName` changed) to the end of `/etc/httpd/conf/httpd.conf` was enough to make it work for me. In order to reload the Python code, you don't actually have to restart Apache, you can just touch the `datazilla/wsgi.py` file. Alternatively, you can set `MaxRequestsPerChild 1` in the Apache config and it will always reload the code after every request (this is only sensible for development, of course).
",carljm,61586,2012-05-19T03:49:42Z,MEMBER,True,496,459,155,Datazilla is a system for managing and visualizing data.,JavaScript,722374afed2fec4b070299158ab5d48ce4b03613,Don't require config via environment variables.
492,https://api.github.com/repos/mozilla/datazilla/pulls/21,21,Add WSGI application and sample Apache config.,"This pull request includes the changes from the vendor-dependencies and django-config pull requests, so should be merged after those (and once those are merged, its diff will be a lot smaller!)

This pull request adds a WSGI application module compatible with Apache/mod_wsgi, removes sample config files that are no longer relevant, and adds sample configs for both nginx proxying to a WSGI app server and Apache/mod_wsgi. It also fleshes out / updates the Installation / Deployment section of the README to assume the use of WSGI rather than FastCGI.

Tested and verified that the sample configs both work; with nginx proxying (just for testing purposes) to `./manage.py runserver 0:8080` and Apache handling double-duty on both static files and WSGI.

I suppose it would be best if we both convert our dev environments to use Apache/mod_wsgi at this point, so we match what IT will be using. `yum install httpd mod_wsgi` followed by adding the sample config (with `ServerName` changed) to the end of `/etc/httpd/conf/httpd.conf` was enough to make it work for me. In order to reload the Python code, you don't actually have to restart Apache, you can just touch the `datazilla/wsgi.py` file. Alternatively, you can set `MaxRequestsPerChild 1` in the Apache config and it will always reload the code after every request (this is only sensible for development, of course).
",carljm,61586,2012-05-19T03:49:42Z,MEMBER,True,496,459,155,Datazilla is a system for managing and visualizing data.,JavaScript,1e40e806f00400e6e28605886bcedb7101cfd014,Merge branch vendor-deps into branch wsgi.
493,https://api.github.com/repos/mozilla/datazilla/pulls/21,21,Add WSGI application and sample Apache config.,"This pull request includes the changes from the vendor-dependencies and django-config pull requests, so should be merged after those (and once those are merged, its diff will be a lot smaller!)

This pull request adds a WSGI application module compatible with Apache/mod_wsgi, removes sample config files that are no longer relevant, and adds sample configs for both nginx proxying to a WSGI app server and Apache/mod_wsgi. It also fleshes out / updates the Installation / Deployment section of the README to assume the use of WSGI rather than FastCGI.

Tested and verified that the sample configs both work; with nginx proxying (just for testing purposes) to `./manage.py runserver 0:8080` and Apache handling double-duty on both static files and WSGI.

I suppose it would be best if we both convert our dev environments to use Apache/mod_wsgi at this point, so we match what IT will be using. `yum install httpd mod_wsgi` followed by adding the sample config (with `ServerName` changed) to the end of `/etc/httpd/conf/httpd.conf` was enough to make it work for me. In order to reload the Python code, you don't actually have to restart Apache, you can just touch the `datazilla/wsgi.py` file. Alternatively, you can set `MaxRequestsPerChild 1` in the Apache config and it will always reload the code after every request (this is only sensible for development, of course).
",carljm,61586,2012-05-19T03:49:42Z,MEMBER,True,496,459,155,Datazilla is a system for managing and visualizing data.,JavaScript,5f4b7228120b47838a49137d34ae37708f110bfc,Update README and switch sample nginx config to proxy to WSGI.
494,https://api.github.com/repos/mozilla/datazilla/pulls/21,21,Add WSGI application and sample Apache config.,"This pull request includes the changes from the vendor-dependencies and django-config pull requests, so should be merged after those (and once those are merged, its diff will be a lot smaller!)

This pull request adds a WSGI application module compatible with Apache/mod_wsgi, removes sample config files that are no longer relevant, and adds sample configs for both nginx proxying to a WSGI app server and Apache/mod_wsgi. It also fleshes out / updates the Installation / Deployment section of the README to assume the use of WSGI rather than FastCGI.

Tested and verified that the sample configs both work; with nginx proxying (just for testing purposes) to `./manage.py runserver 0:8080` and Apache handling double-duty on both static files and WSGI.

I suppose it would be best if we both convert our dev environments to use Apache/mod_wsgi at this point, so we match what IT will be using. `yum install httpd mod_wsgi` followed by adding the sample config (with `ServerName` changed) to the end of `/etc/httpd/conf/httpd.conf` was enough to make it work for me. In order to reload the Python code, you don't actually have to restart Apache, you can just touch the `datazilla/wsgi.py` file. Alternatively, you can set `MaxRequestsPerChild 1` in the Apache config and it will always reload the code after every request (this is only sensible for development, of course).
",carljm,61586,2012-05-19T03:49:42Z,MEMBER,True,496,459,155,Datazilla is a system for managing and visualizing data.,JavaScript,a23fede8bc7226f0cdc109515ed9975df4754d3b,Add wsgi module and sample Apache config.
495,https://api.github.com/repos/mozilla/datazilla/pulls/21,21,Add WSGI application and sample Apache config.,"This pull request includes the changes from the vendor-dependencies and django-config pull requests, so should be merged after those (and once those are merged, its diff will be a lot smaller!)

This pull request adds a WSGI application module compatible with Apache/mod_wsgi, removes sample config files that are no longer relevant, and adds sample configs for both nginx proxying to a WSGI app server and Apache/mod_wsgi. It also fleshes out / updates the Installation / Deployment section of the README to assume the use of WSGI rather than FastCGI.

Tested and verified that the sample configs both work; with nginx proxying (just for testing purposes) to `./manage.py runserver 0:8080` and Apache handling double-duty on both static files and WSGI.

I suppose it would be best if we both convert our dev environments to use Apache/mod_wsgi at this point, so we match what IT will be using. `yum install httpd mod_wsgi` followed by adding the sample config (with `ServerName` changed) to the end of `/etc/httpd/conf/httpd.conf` was enough to make it work for me. In order to reload the Python code, you don't actually have to restart Apache, you can just touch the `datazilla/wsgi.py` file. Alternatively, you can set `MaxRequestsPerChild 1` in the Apache config and it will always reload the code after every request (this is only sensible for development, of course).
",carljm,61586,2012-05-19T03:49:42Z,MEMBER,True,496,459,155,Datazilla is a system for managing and visualizing data.,JavaScript,7ae907a15f8a5d6931feb8ff3580cdaf4a0114d2,Mention the sample configs in the README.
496,https://api.github.com/repos/mozilla/datazilla/pulls/20,20,Don't require config via environment variables.,"This pull request makes it possible to configure datazilla entirely via `settings/local.py`, which is how IT is accustomed to configuring Django projects.

It doesn't remove the ability to configure via env vars; in fact, if no `local.py` is present, the same env vars that are used now will still provide the fallback defaults for the same settings.

Since Django settings are now the canonical source for configuration of all of datazilla, not just the webapp portion, I moved the settings out to `datazilla/settings/base.py`. I added a `datazilla/settings/local.sample.py` which can be coped to `datazilla/settings/local.py` and modified as needed for local configuration (the latter is git-ignored).

In the process of reviewing the settings, I noticed that `MEDIA_URL` and `STATIC_URL` were being used incorrectly. In the Django world, ""media"" is user-uploaded files (which Datazilla does not have), and ""static assets"" are CSS, JS, etc that is packaged with the project. In order to reduce terminology confusion for any future coders familiar with Django working on this project, I renamed `datazilla/webapp/media` to `datazilla/webapp/static` and made the adjustments throughout CSS and JS files to refer to other assets at the URL path `/static/...` rather than `/media/...`. This requires a minor change to the Nginx config file, which I've made to the sample nginx config.

As usual, feel free to comment if I've missed something or something here isn't acceptable!
",carljm,61586,2012-05-19T02:01:05Z,MEMBER,True,265,252,143,Datazilla is a system for managing and visualizing data.,JavaScript,722374afed2fec4b070299158ab5d48ce4b03613,Don't require config via environment variables.
497,https://api.github.com/repos/mozilla/datazilla/pulls/19,19,Add vendor library for pure-Python dependencies.,"This is a massive pull request because it adds all of our pure-Python dependencies (including e.g. Django) into the `vendor/` directory, as IT requires for deployment. If you don't like having all these in the main repo, we can also make `vendor/` a submodule; we do that in MozTrap, but it definitely complicates the process of updating or adding dependencies, and I'm not sure it's worth it in the end.

This also adds the script `bin/generate-vendor-lib.py` which will remove and recreate the `vendor/` directory based on the pip requirements listed in `requirements/pure.txt`. This would be kind of unsafe (if anything goes wrong, it could blow away `vendor/` entirely), but that's ok in this case because git's got our back, and we should never be making manual changes in `vendor/`. This script should only need to be run if you change the requirements listed in `requirements/pure.txt`.

`requirements/compiled.txt` lists the compiled requirements which IT will install via yum packages; this is basically just documentation for them.

`requirements/dev.txt` contains dependencies that IT doesn't need to care about, that are only useful for development (currently that means py.test and the coverage stuff). We can use `pip install -r requirements/dev.txt` (in addition to installing the compiled deps) to create a development environment.

The last thing needed here is to make the vendor library available on `sys.path`. This is the part where there's no really elegant solution currently available. Basically, every entry point into the codebase needs to import and call the function `datazilla.vendor.add_vendor_lib`, which performs the necessary `sys.path` munging. Currently the entry points which do this are `manage.py` and the two scripts in `datazilla/controller/admin/`. At some point (once I've converted the configuration to be entirely Django settings based and thus the whole codebase is Django-dependent anyway), I think we should convert the two `controller/admin` scripts to be `manage.py` subcommands, which will reduce the number of entry points we have to worry about. The WSGI application entry point, when I add that, will also need to call `datazilla.vendor.add_vendor_lib`.
",carljm,61586,2012-05-18T22:47:33Z,MEMBER,True,524313,11,3271,Datazilla is a system for managing and visualizing data.,JavaScript,d166d0073f711296991ac2f6f75770e267aa1dbc,Pin datasource to a particular git revision.
498,https://api.github.com/repos/mozilla/datazilla/pulls/19,19,Add vendor library for pure-Python dependencies.,"This is a massive pull request because it adds all of our pure-Python dependencies (including e.g. Django) into the `vendor/` directory, as IT requires for deployment. If you don't like having all these in the main repo, we can also make `vendor/` a submodule; we do that in MozTrap, but it definitely complicates the process of updating or adding dependencies, and I'm not sure it's worth it in the end.

This also adds the script `bin/generate-vendor-lib.py` which will remove and recreate the `vendor/` directory based on the pip requirements listed in `requirements/pure.txt`. This would be kind of unsafe (if anything goes wrong, it could blow away `vendor/` entirely), but that's ok in this case because git's got our back, and we should never be making manual changes in `vendor/`. This script should only need to be run if you change the requirements listed in `requirements/pure.txt`.

`requirements/compiled.txt` lists the compiled requirements which IT will install via yum packages; this is basically just documentation for them.

`requirements/dev.txt` contains dependencies that IT doesn't need to care about, that are only useful for development (currently that means py.test and the coverage stuff). We can use `pip install -r requirements/dev.txt` (in addition to installing the compiled deps) to create a development environment.

The last thing needed here is to make the vendor library available on `sys.path`. This is the part where there's no really elegant solution currently available. Basically, every entry point into the codebase needs to import and call the function `datazilla.vendor.add_vendor_lib`, which performs the necessary `sys.path` munging. Currently the entry points which do this are `manage.py` and the two scripts in `datazilla/controller/admin/`. At some point (once I've converted the configuration to be entirely Django settings based and thus the whole codebase is Django-dependent anyway), I think we should convert the two `controller/admin` scripts to be `manage.py` subcommands, which will reduce the number of entry points we have to worry about. The WSGI application entry point, when I add that, will also need to call `datazilla.vendor.add_vendor_lib`.
",carljm,61586,2012-05-18T22:47:33Z,MEMBER,True,524313,11,3271,Datazilla is a system for managing and visualizing data.,JavaScript,a05d9ffc6e34d54e7d38f74c5c4d5fb19381dc41,Give manage.py executable bit.
499,https://api.github.com/repos/mozilla/datazilla/pulls/19,19,Add vendor library for pure-Python dependencies.,"This is a massive pull request because it adds all of our pure-Python dependencies (including e.g. Django) into the `vendor/` directory, as IT requires for deployment. If you don't like having all these in the main repo, we can also make `vendor/` a submodule; we do that in MozTrap, but it definitely complicates the process of updating or adding dependencies, and I'm not sure it's worth it in the end.

This also adds the script `bin/generate-vendor-lib.py` which will remove and recreate the `vendor/` directory based on the pip requirements listed in `requirements/pure.txt`. This would be kind of unsafe (if anything goes wrong, it could blow away `vendor/` entirely), but that's ok in this case because git's got our back, and we should never be making manual changes in `vendor/`. This script should only need to be run if you change the requirements listed in `requirements/pure.txt`.

`requirements/compiled.txt` lists the compiled requirements which IT will install via yum packages; this is basically just documentation for them.

`requirements/dev.txt` contains dependencies that IT doesn't need to care about, that are only useful for development (currently that means py.test and the coverage stuff). We can use `pip install -r requirements/dev.txt` (in addition to installing the compiled deps) to create a development environment.

The last thing needed here is to make the vendor library available on `sys.path`. This is the part where there's no really elegant solution currently available. Basically, every entry point into the codebase needs to import and call the function `datazilla.vendor.add_vendor_lib`, which performs the necessary `sys.path` munging. Currently the entry points which do this are `manage.py` and the two scripts in `datazilla/controller/admin/`. At some point (once I've converted the configuration to be entirely Django settings based and thus the whole codebase is Django-dependent anyway), I think we should convert the two `controller/admin` scripts to be `manage.py` subcommands, which will reduce the number of entry points we have to worry about. The WSGI application entry point, when I add that, will also need to call `datazilla.vendor.add_vendor_lib`.
",carljm,61586,2012-05-18T22:47:33Z,MEMBER,True,524313,11,3271,Datazilla is a system for managing and visualizing data.,JavaScript,0fa146c6b1c81ac29a6a06510649df02936e5e54,Split requirements file into compiled and pure-Python.
500,https://api.github.com/repos/mozilla/datazilla/pulls/19,19,Add vendor library for pure-Python dependencies.,"This is a massive pull request because it adds all of our pure-Python dependencies (including e.g. Django) into the `vendor/` directory, as IT requires for deployment. If you don't like having all these in the main repo, we can also make `vendor/` a submodule; we do that in MozTrap, but it definitely complicates the process of updating or adding dependencies, and I'm not sure it's worth it in the end.

This also adds the script `bin/generate-vendor-lib.py` which will remove and recreate the `vendor/` directory based on the pip requirements listed in `requirements/pure.txt`. This would be kind of unsafe (if anything goes wrong, it could blow away `vendor/` entirely), but that's ok in this case because git's got our back, and we should never be making manual changes in `vendor/`. This script should only need to be run if you change the requirements listed in `requirements/pure.txt`.

`requirements/compiled.txt` lists the compiled requirements which IT will install via yum packages; this is basically just documentation for them.

`requirements/dev.txt` contains dependencies that IT doesn't need to care about, that are only useful for development (currently that means py.test and the coverage stuff). We can use `pip install -r requirements/dev.txt` (in addition to installing the compiled deps) to create a development environment.

The last thing needed here is to make the vendor library available on `sys.path`. This is the part where there's no really elegant solution currently available. Basically, every entry point into the codebase needs to import and call the function `datazilla.vendor.add_vendor_lib`, which performs the necessary `sys.path` munging. Currently the entry points which do this are `manage.py` and the two scripts in `datazilla/controller/admin/`. At some point (once I've converted the configuration to be entirely Django settings based and thus the whole codebase is Django-dependent anyway), I think we should convert the two `controller/admin` scripts to be `manage.py` subcommands, which will reduce the number of entry points we have to worry about. The WSGI application entry point, when I add that, will also need to call `datazilla.vendor.add_vendor_lib`.
",carljm,61586,2012-05-18T22:47:33Z,MEMBER,True,524313,11,3271,Datazilla is a system for managing and visualizing data.,JavaScript,df1e6aa1bd6f55ee4248e2499f1010f034806c98,Added vendor library for pure-Python dependencies.
501,https://api.github.com/repos/mozilla/datazilla/pulls/19,19,Add vendor library for pure-Python dependencies.,"This is a massive pull request because it adds all of our pure-Python dependencies (including e.g. Django) into the `vendor/` directory, as IT requires for deployment. If you don't like having all these in the main repo, we can also make `vendor/` a submodule; we do that in MozTrap, but it definitely complicates the process of updating or adding dependencies, and I'm not sure it's worth it in the end.

This also adds the script `bin/generate-vendor-lib.py` which will remove and recreate the `vendor/` directory based on the pip requirements listed in `requirements/pure.txt`. This would be kind of unsafe (if anything goes wrong, it could blow away `vendor/` entirely), but that's ok in this case because git's got our back, and we should never be making manual changes in `vendor/`. This script should only need to be run if you change the requirements listed in `requirements/pure.txt`.

`requirements/compiled.txt` lists the compiled requirements which IT will install via yum packages; this is basically just documentation for them.

`requirements/dev.txt` contains dependencies that IT doesn't need to care about, that are only useful for development (currently that means py.test and the coverage stuff). We can use `pip install -r requirements/dev.txt` (in addition to installing the compiled deps) to create a development environment.

The last thing needed here is to make the vendor library available on `sys.path`. This is the part where there's no really elegant solution currently available. Basically, every entry point into the codebase needs to import and call the function `datazilla.vendor.add_vendor_lib`, which performs the necessary `sys.path` munging. Currently the entry points which do this are `manage.py` and the two scripts in `datazilla/controller/admin/`. At some point (once I've converted the configuration to be entirely Django settings based and thus the whole codebase is Django-dependent anyway), I think we should convert the two `controller/admin` scripts to be `manage.py` subcommands, which will reduce the number of entry points we have to worry about. The WSGI application entry point, when I add that, will also need to call `datazilla.vendor.add_vendor_lib`.
",carljm,61586,2012-05-18T22:47:33Z,MEMBER,True,524313,11,3271,Datazilla is a system for managing and visualizing data.,JavaScript,5cb72b0eadedbf0eda9fd272ed5ac5fdabece92d,Merge from master into branch vendor-deps.
502,https://api.github.com/repos/mozilla/datazilla/pulls/19,19,Add vendor library for pure-Python dependencies.,"This is a massive pull request because it adds all of our pure-Python dependencies (including e.g. Django) into the `vendor/` directory, as IT requires for deployment. If you don't like having all these in the main repo, we can also make `vendor/` a submodule; we do that in MozTrap, but it definitely complicates the process of updating or adding dependencies, and I'm not sure it's worth it in the end.

This also adds the script `bin/generate-vendor-lib.py` which will remove and recreate the `vendor/` directory based on the pip requirements listed in `requirements/pure.txt`. This would be kind of unsafe (if anything goes wrong, it could blow away `vendor/` entirely), but that's ok in this case because git's got our back, and we should never be making manual changes in `vendor/`. This script should only need to be run if you change the requirements listed in `requirements/pure.txt`.

`requirements/compiled.txt` lists the compiled requirements which IT will install via yum packages; this is basically just documentation for them.

`requirements/dev.txt` contains dependencies that IT doesn't need to care about, that are only useful for development (currently that means py.test and the coverage stuff). We can use `pip install -r requirements/dev.txt` (in addition to installing the compiled deps) to create a development environment.

The last thing needed here is to make the vendor library available on `sys.path`. This is the part where there's no really elegant solution currently available. Basically, every entry point into the codebase needs to import and call the function `datazilla.vendor.add_vendor_lib`, which performs the necessary `sys.path` munging. Currently the entry points which do this are `manage.py` and the two scripts in `datazilla/controller/admin/`. At some point (once I've converted the configuration to be entirely Django settings based and thus the whole codebase is Django-dependent anyway), I think we should convert the two `controller/admin` scripts to be `manage.py` subcommands, which will reduce the number of entry points we have to worry about. The WSGI application entry point, when I add that, will also need to call `datazilla.vendor.add_vendor_lib`.
",carljm,61586,2012-05-18T22:47:33Z,MEMBER,True,524313,11,3271,Datazilla is a system for managing and visualizing data.,JavaScript,56c9a6e40e7b2ff7b94a1e41a274b16a12f0e67e,Add egg-info metadata to vendor lib.
503,https://api.github.com/repos/mozilla/datazilla/pulls/19,19,Add vendor library for pure-Python dependencies.,"This is a massive pull request because it adds all of our pure-Python dependencies (including e.g. Django) into the `vendor/` directory, as IT requires for deployment. If you don't like having all these in the main repo, we can also make `vendor/` a submodule; we do that in MozTrap, but it definitely complicates the process of updating or adding dependencies, and I'm not sure it's worth it in the end.

This also adds the script `bin/generate-vendor-lib.py` which will remove and recreate the `vendor/` directory based on the pip requirements listed in `requirements/pure.txt`. This would be kind of unsafe (if anything goes wrong, it could blow away `vendor/` entirely), but that's ok in this case because git's got our back, and we should never be making manual changes in `vendor/`. This script should only need to be run if you change the requirements listed in `requirements/pure.txt`.

`requirements/compiled.txt` lists the compiled requirements which IT will install via yum packages; this is basically just documentation for them.

`requirements/dev.txt` contains dependencies that IT doesn't need to care about, that are only useful for development (currently that means py.test and the coverage stuff). We can use `pip install -r requirements/dev.txt` (in addition to installing the compiled deps) to create a development environment.

The last thing needed here is to make the vendor library available on `sys.path`. This is the part where there's no really elegant solution currently available. Basically, every entry point into the codebase needs to import and call the function `datazilla.vendor.add_vendor_lib`, which performs the necessary `sys.path` munging. Currently the entry points which do this are `manage.py` and the two scripts in `datazilla/controller/admin/`. At some point (once I've converted the configuration to be entirely Django settings based and thus the whole codebase is Django-dependent anyway), I think we should convert the two `controller/admin` scripts to be `manage.py` subcommands, which will reduce the number of entry points we have to worry about. The WSGI application entry point, when I add that, will also need to call `datazilla.vendor.add_vendor_lib`.
",carljm,61586,2012-05-18T22:47:33Z,MEMBER,True,524313,11,3271,Datazilla is a system for managing and visualizing data.,JavaScript,c02d387339717089465a7c62998761eb44d13058,Split out dev requirements.
504,https://api.github.com/repos/mozilla/datazilla/pulls/19,19,Add vendor library for pure-Python dependencies.,"This is a massive pull request because it adds all of our pure-Python dependencies (including e.g. Django) into the `vendor/` directory, as IT requires for deployment. If you don't like having all these in the main repo, we can also make `vendor/` a submodule; we do that in MozTrap, but it definitely complicates the process of updating or adding dependencies, and I'm not sure it's worth it in the end.

This also adds the script `bin/generate-vendor-lib.py` which will remove and recreate the `vendor/` directory based on the pip requirements listed in `requirements/pure.txt`. This would be kind of unsafe (if anything goes wrong, it could blow away `vendor/` entirely), but that's ok in this case because git's got our back, and we should never be making manual changes in `vendor/`. This script should only need to be run if you change the requirements listed in `requirements/pure.txt`.

`requirements/compiled.txt` lists the compiled requirements which IT will install via yum packages; this is basically just documentation for them.

`requirements/dev.txt` contains dependencies that IT doesn't need to care about, that are only useful for development (currently that means py.test and the coverage stuff). We can use `pip install -r requirements/dev.txt` (in addition to installing the compiled deps) to create a development environment.

The last thing needed here is to make the vendor library available on `sys.path`. This is the part where there's no really elegant solution currently available. Basically, every entry point into the codebase needs to import and call the function `datazilla.vendor.add_vendor_lib`, which performs the necessary `sys.path` munging. Currently the entry points which do this are `manage.py` and the two scripts in `datazilla/controller/admin/`. At some point (once I've converted the configuration to be entirely Django settings based and thus the whole codebase is Django-dependent anyway), I think we should convert the two `controller/admin` scripts to be `manage.py` subcommands, which will reduce the number of entry points we have to worry about. The WSGI application entry point, when I add that, will also need to call `datazilla.vendor.add_vendor_lib`.
",carljm,61586,2012-05-18T22:47:33Z,MEMBER,True,524313,11,3271,Datazilla is a system for managing and visualizing data.,JavaScript,fcda833f8629531735ffbfefdebb09cf039d7d36,Add bin/generate-vendor-lib script.
505,https://api.github.com/repos/mozilla/datazilla/pulls/19,19,Add vendor library for pure-Python dependencies.,"This is a massive pull request because it adds all of our pure-Python dependencies (including e.g. Django) into the `vendor/` directory, as IT requires for deployment. If you don't like having all these in the main repo, we can also make `vendor/` a submodule; we do that in MozTrap, but it definitely complicates the process of updating or adding dependencies, and I'm not sure it's worth it in the end.

This also adds the script `bin/generate-vendor-lib.py` which will remove and recreate the `vendor/` directory based on the pip requirements listed in `requirements/pure.txt`. This would be kind of unsafe (if anything goes wrong, it could blow away `vendor/` entirely), but that's ok in this case because git's got our back, and we should never be making manual changes in `vendor/`. This script should only need to be run if you change the requirements listed in `requirements/pure.txt`.

`requirements/compiled.txt` lists the compiled requirements which IT will install via yum packages; this is basically just documentation for them.

`requirements/dev.txt` contains dependencies that IT doesn't need to care about, that are only useful for development (currently that means py.test and the coverage stuff). We can use `pip install -r requirements/dev.txt` (in addition to installing the compiled deps) to create a development environment.

The last thing needed here is to make the vendor library available on `sys.path`. This is the part where there's no really elegant solution currently available. Basically, every entry point into the codebase needs to import and call the function `datazilla.vendor.add_vendor_lib`, which performs the necessary `sys.path` munging. Currently the entry points which do this are `manage.py` and the two scripts in `datazilla/controller/admin/`. At some point (once I've converted the configuration to be entirely Django settings based and thus the whole codebase is Django-dependent anyway), I think we should convert the two `controller/admin` scripts to be `manage.py` subcommands, which will reduce the number of entry points we have to worry about. The WSGI application entry point, when I add that, will also need to call `datazilla.vendor.add_vendor_lib`.
",carljm,61586,2012-05-18T22:47:33Z,MEMBER,True,524313,11,3271,Datazilla is a system for managing and visualizing data.,JavaScript,8cb8eeacae35811d8dec7ef0dabcae4d33cd72db,Give controller/admin scripts access to vendor lib.
506,https://api.github.com/repos/mozilla/datazilla/pulls/18,18,"Add test runner script, with coverage measurement","This pull request makes it possible to run `./test.sh` from the repo root to run all tests in the repo. It discovers tests according to [these rules](http://pytest.org/latest/goodpractises.html#test-discovery), except I added a config file to modify those rules so it looks in files named `*Test.py` to match our non-standard module-naming conventions.

(In order for this to work, you have to have `pytest` installed, which you can do by running `pip install -r requirements.txt`).

The test-running script also outputs HTML coverage data to the `htmlcov/` directory in the repo (which is git-ignored). Since we're working on VMs, you can't just view this report locally, so you'll have to add an nginx config stanza for it - I added this in the sample nginx config in `webapp/conf/etc/nginx/conf.d/datazilla.conf`, just so you have a convenient place to copy it from (although that nginx config will likely go away soon).
",carljm,61586,2012-05-17T21:43:15Z,MEMBER,True,98,74,7,Datazilla is a system for managing and visualizing data.,JavaScript,14181e160a0b7674ecc2883c8a55d9d695cf7344,Flesh out requirements.txt
507,https://api.github.com/repos/mozilla/datazilla/pulls/18,18,"Add test runner script, with coverage measurement","This pull request makes it possible to run `./test.sh` from the repo root to run all tests in the repo. It discovers tests according to [these rules](http://pytest.org/latest/goodpractises.html#test-discovery), except I added a config file to modify those rules so it looks in files named `*Test.py` to match our non-standard module-naming conventions.

(In order for this to work, you have to have `pytest` installed, which you can do by running `pip install -r requirements.txt`).

The test-running script also outputs HTML coverage data to the `htmlcov/` directory in the repo (which is git-ignored). Since we're working on VMs, you can't just view this report locally, so you'll have to add an nginx config stanza for it - I added this in the sample nginx config in `webapp/conf/etc/nginx/conf.d/datazilla.conf`, just so you have a convenient place to copy it from (although that nginx config will likely go away soon).
",carljm,61586,2012-05-17T21:43:15Z,MEMBER,True,98,74,7,Datazilla is a system for managing and visualizing data.,JavaScript,9da3371c29d48aa15afe9c893a57d37e66bd1117,Setup for running tests with py.test.
508,https://api.github.com/repos/mozilla/datazilla/pulls/18,18,"Add test runner script, with coverage measurement","This pull request makes it possible to run `./test.sh` from the repo root to run all tests in the repo. It discovers tests according to [these rules](http://pytest.org/latest/goodpractises.html#test-discovery), except I added a config file to modify those rules so it looks in files named `*Test.py` to match our non-standard module-naming conventions.

(In order for this to work, you have to have `pytest` installed, which you can do by running `pip install -r requirements.txt`).

The test-running script also outputs HTML coverage data to the `htmlcov/` directory in the repo (which is git-ignored). Since we're working on VMs, you can't just view this report locally, so you'll have to add an nginx config stanza for it - I added this in the sample nginx config in `webapp/conf/etc/nginx/conf.d/datazilla.conf`, just so you have a convenient place to copy it from (although that nginx config will likely go away soon).
",carljm,61586,2012-05-17T21:43:15Z,MEMBER,True,98,74,7,Datazilla is a system for managing and visualizing data.,JavaScript,9c98c023ccc4d50dda768100dbf568b74c825f97,Merge branch 'complete-requirements' into test-runner
509,https://api.github.com/repos/mozilla/datazilla/pulls/18,18,"Add test runner script, with coverage measurement","This pull request makes it possible to run `./test.sh` from the repo root to run all tests in the repo. It discovers tests according to [these rules](http://pytest.org/latest/goodpractises.html#test-discovery), except I added a config file to modify those rules so it looks in files named `*Test.py` to match our non-standard module-naming conventions.

(In order for this to work, you have to have `pytest` installed, which you can do by running `pip install -r requirements.txt`).

The test-running script also outputs HTML coverage data to the `htmlcov/` directory in the repo (which is git-ignored). Since we're working on VMs, you can't just view this report locally, so you'll have to add an nginx config stanza for it - I added this in the sample nginx config in `webapp/conf/etc/nginx/conf.d/datazilla.conf`, just so you have a convenient place to copy it from (although that nginx config will likely go away soon).
",carljm,61586,2012-05-17T21:43:15Z,MEMBER,True,98,74,7,Datazilla is a system for managing and visualizing data.,JavaScript,9f4942566ba8530285869da7634ca513a0962bac,Add pytest and pytest-cov to requirements.
510,https://api.github.com/repos/mozilla/datazilla/pulls/18,18,"Add test runner script, with coverage measurement","This pull request makes it possible to run `./test.sh` from the repo root to run all tests in the repo. It discovers tests according to [these rules](http://pytest.org/latest/goodpractises.html#test-discovery), except I added a config file to modify those rules so it looks in files named `*Test.py` to match our non-standard module-naming conventions.

(In order for this to work, you have to have `pytest` installed, which you can do by running `pip install -r requirements.txt`).

The test-running script also outputs HTML coverage data to the `htmlcov/` directory in the repo (which is git-ignored). Since we're working on VMs, you can't just view this report locally, so you'll have to add an nginx config stanza for it - I added this in the sample nginx config in `webapp/conf/etc/nginx/conf.d/datazilla.conf`, just so you have a convenient place to copy it from (although that nginx config will likely go away soon).
",carljm,61586,2012-05-17T21:43:15Z,MEMBER,True,98,74,7,Datazilla is a system for managing and visualizing data.,JavaScript,64d37448de99efb5f03c82eb889cab5fc90ec279,Add README instructions.
511,https://api.github.com/repos/mozilla/datazilla/pulls/18,18,"Add test runner script, with coverage measurement","This pull request makes it possible to run `./test.sh` from the repo root to run all tests in the repo. It discovers tests according to [these rules](http://pytest.org/latest/goodpractises.html#test-discovery), except I added a config file to modify those rules so it looks in files named `*Test.py` to match our non-standard module-naming conventions.

(In order for this to work, you have to have `pytest` installed, which you can do by running `pip install -r requirements.txt`).

The test-running script also outputs HTML coverage data to the `htmlcov/` directory in the repo (which is git-ignored). Since we're working on VMs, you can't just view this report locally, so you'll have to add an nginx config stanza for it - I added this in the sample nginx config in `webapp/conf/etc/nginx/conf.d/datazilla.conf`, just so you have a convenient place to copy it from (although that nginx config will likely go away soon).
",carljm,61586,2012-05-17T21:43:15Z,MEMBER,True,98,74,7,Datazilla is a system for managing and visualizing data.,JavaScript,3f105d8b137db7f517402db0da7bb3d68f9dbaf9,Add htmlcov stanza to sample nginx config.
512,https://api.github.com/repos/mozilla/datazilla/pulls/17,17,Make import paths more reliable by making the top-level datazilla package explicit in the repo.,"There's also one other change here that may require some discussion/explanation. Python always puts the current directory of the script file that it is running onto `sys.path`. This means that in general, putting script files inside an import hierarchy can cause problems, because it means suddenly anything adjacent to or beneath that script file can be imported under two different names. For a specific example, if ""manage.py"" is located at ""datazilla/webapp/manage.py"" and is executed as a script (e.g. ""python ./manage.py""), now the ""settings.py"" adjacent to it can be imported either as ""datazilla.webapp.settings"" or as just ""settings"", because sys.path has both `$TOPLEVEL` and `$TOPLEVEL/datazilla/webapp` on `sys.path`. This can cause subtle and difficult-to-debug problems like unexpectedly shadowed top-level module names, and module-level code that is only supposed to execute once being executed twice, so it's best avoided altogether by ensuring that only one top-level directory in the codebase is ever placed on sys.path, and any scripts intended for direct execution are placed in that directory as well.

So in this pull request, I've yanked `manage.py` out to the top level, which solves this potential problem and also allows removing the `--python-path` directive from the `runfcgi` invocation (because the directory `manage.py` is in automatically goes on `sys.path`). We also have the same problem with the scripts in `admin/controller` - we may want to move those out as well, though I didn't do that yet.

If you'd like to keep these scripts separated deeper in the file-structure, we may want to talk about some alternative approaches; let me know.
",carljm,61586,2012-05-14T23:34:27Z,MEMBER,True,12,18,174,Datazilla is a system for managing and visualizing data.,JavaScript,ff798941bf9b7f4e88ed34015deece49ae0ab574,Moved everything within an explicit top-level 'datazilla' Python package.
513,https://api.github.com/repos/mozilla/datazilla/pulls/17,17,Make import paths more reliable by making the top-level datazilla package explicit in the repo.,"There's also one other change here that may require some discussion/explanation. Python always puts the current directory of the script file that it is running onto `sys.path`. This means that in general, putting script files inside an import hierarchy can cause problems, because it means suddenly anything adjacent to or beneath that script file can be imported under two different names. For a specific example, if ""manage.py"" is located at ""datazilla/webapp/manage.py"" and is executed as a script (e.g. ""python ./manage.py""), now the ""settings.py"" adjacent to it can be imported either as ""datazilla.webapp.settings"" or as just ""settings"", because sys.path has both `$TOPLEVEL` and `$TOPLEVEL/datazilla/webapp` on `sys.path`. This can cause subtle and difficult-to-debug problems like unexpectedly shadowed top-level module names, and module-level code that is only supposed to execute once being executed twice, so it's best avoided altogether by ensuring that only one top-level directory in the codebase is ever placed on sys.path, and any scripts intended for direct execution are placed in that directory as well.

So in this pull request, I've yanked `manage.py` out to the top level, which solves this potential problem and also allows removing the `--python-path` directive from the `runfcgi` invocation (because the directory `manage.py` is in automatically goes on `sys.path`). We also have the same problem with the scripts in `admin/controller` - we may want to move those out as well, though I didn't do that yet.

If you'd like to keep these scripts separated deeper in the file-structure, we may want to talk about some alternative approaches; let me know.
",carljm,61586,2012-05-14T23:34:27Z,MEMBER,True,12,18,174,Datazilla is a system for managing and visualizing data.,JavaScript,eba5d6284b666ecf98a28e617cf3b3e59e64c115,Move manage.py to top level and update it to better version.
514,https://api.github.com/repos/mozilla/datazilla/pulls/16,16,Reindent to four-space indents.,,carljm,61586,2012-05-12T01:13:32Z,MEMBER,True,897,903,9,Datazilla is a system for managing and visualizing data.,JavaScript,d7359bffad7d361f43c003349c0bed4ad44b5ea9,Reindent to four-space indents.
515,https://api.github.com/repos/mozilla/datazilla/pulls/14,14,Add requirements.txt.,"A pip requirements.txt file is a semi-standard way to both document and make easily installable the Python-level library dependencies of a project. By running `pip install -r requirements.txt` (probably with a virtualenv active, else you'd need to prepend ""sudo"") you can easily install the listed requirements. It also standardizes the exact versions required to avoid the ""we're all using slightly different versions of the libraries"" problem. Eventually I think we should put datasource on PyPI instead of installing it direct from github, but that can wait. Also, this requirements.txt won't actually work as written (it'll break on datasource) until you merge my setup.py fixes to datasource.
",carljm,61586,2012-05-09T00:05:40Z,MEMBER,True,3,0,1,Datazilla is a system for managing and visualizing data.,JavaScript,06339fc392f94df38fde8576e6939f731418ae2d,Add requirements.txt.
516,https://api.github.com/repos/mozilla/datazilla/pulls/13,13,Fix name of column in README table to match actual schema.,,carljm,61586,2012-05-08T23:29:40Z,MEMBER,True,1,1,1,Datazilla is a system for managing and visualizing data.,JavaScript,4f8bda6a2258497b68b9afc9c1d28c9367a69ff8,Fix name of column in README table to match actual schema.
517,https://api.github.com/repos/mozilla/datazilla/pulls/10,10,Remove url from the list of modules to import in webapp/url.py,"It's not used anywhere.
",rniwa,285965,2012-05-08T18:57:24Z,CONTRIBUTOR,False,1,1,1,Datazilla is a system for managing and visualizing data.,JavaScript,d147130a5bddc7eee96be0b0ddd92f53b557e742,Remove url from the list of modules to import in webapp/url.py
518,https://api.github.com/repos/mozilla/datazilla/pulls/9,9,Prepare Mode.py and settings.py for the WebKit/Chromium App Engine port.,"Move Model.py to sql/model.py and replace it by a wrapper Model.
appengine/model.py is to be added in follow up patches.

Also modified settings.py to work inside the App Engine.
",rniwa,285965,2012-05-08T18:50:37Z,CONTRIBUTOR,True,131,112,3,Datazilla is a system for managing and visualizing data.,JavaScript,075cb91402562ac39fbaf9c7fd66c8fa3bc37676,"Prepare Mode.py and settings.py for the WebKit/Chromium App Engine port.

Move Model.py to sql/model.py and replace it by a wrapper Model.
appengine/model.py is to be added in follow up patches.

Also modified settings.py to work inside the App Engine."
519,https://api.github.com/repos/mozilla/datazilla/pulls/8,8,Prepare Mode.py and settings.py for the WebKit/Chromium App Engine port.,"Move Model.py to sql/model.py and replace it by a wrapper Model.
appengine/model.py is to be added in follow up patches.

Also modified settings.py to work inside the App Engine.
",rniwa,285965,2012-05-08T16:31:54Z,CONTRIBUTOR,False,131,112,3,Datazilla is a system for managing and visualizing data.,JavaScript,075cb91402562ac39fbaf9c7fd66c8fa3bc37676,"Prepare Mode.py and settings.py for the WebKit/Chromium App Engine port.

Move Model.py to sql/model.py and replace it by a wrapper Model.
appengine/model.py is to be added in follow up patches.

Also modified settings.py to work inside the App Engine."
520,https://api.github.com/repos/mozilla/datazilla/pulls/6,6,Make setSummaryCache use setData instead of dhub.execute.,"Also renamed the existing setData to setDataAndGetId and extracted new setData,
which doesn't obtain the id of the inserted entity.
",rniwa,285965,2012-05-07T22:24:02Z,CONTRIBUTOR,True,48,49,2,Datazilla is a system for managing and visualizing data.,JavaScript,d441718e08d2b12c2eedfa2bf41206a92cdd41e3,"Make setSummaryCache use setData instead of dhub.execute.
Also renamed the existing setData to setDataAndGetId and extracted new setData,
which doesn't obtain the id of the inserted entity."
521,https://api.github.com/repos/mozilla/datazilla/pulls/5,5,Remove url from the list of modules to import in webapp/url.py,,rniwa,285965,2012-05-07T22:05:03Z,CONTRIBUTOR,False,1,1,1,Datazilla is a system for managing and visualizing data.,JavaScript,d147130a5bddc7eee96be0b0ddd92f53b557e742,Remove url from the list of modules to import in webapp/url.py
522,https://api.github.com/repos/mozilla/datazilla/pulls/4,4,Rename getSummaryCacheData and getAllSummaryCacheData to getSummaryCache...,"... and getAllSummaryCache to match set\* equivalents. Also use placeholder instead of replace in set_summary_cache
",rniwa,285965,2012-05-07T21:52:51Z,CONTRIBUTOR,True,5,5,3,Datazilla is a system for managing and visualizing data.,JavaScript,2a753adf70d1b2cece79f7bdd2974ff729c40ecd,Rename getSummaryCacheData and getAllSummaryCacheData to getSummaryCache and getAllSummaryCache to match set* equivalents. Also use placeholder instead of replace in set_summary_cache
523,https://api.github.com/repos/mozilla/datazilla/pulls/3,3,Ignore .pyc files,"Need to ignore .pyc files.
",rniwa,285965,2012-05-06T22:55:16Z,CONTRIBUTOR,True,1,0,1,Datazilla is a system for managing and visualizing data.,JavaScript,9cf7447ca9fecf0ac54081c9f97103b18f1a8b54,Ignore .pyc files
