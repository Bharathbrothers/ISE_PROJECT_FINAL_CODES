,pullid,pulls_number,pulltitle,pullsbody,pullsuserlogin,pullsuserid,pullauthordate,author_association,merged_status,stats_addns,stats_delns,stats_changed_files,pull_repo_desc,pull_repo_lang,pull_commit_sha,pull_commit_message
0,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/130,130,chore(deps): bump y18n from 3.2.1 to 3.2.2,"Bumps [y18n](https://github.com/yargs/y18n) from 3.2.1 to 3.2.2.
<details>
<summary>Commits</summary>
<ul>
<li>See full diff in <a href=""https://github.com/yargs/y18n/commits"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~oss-bot"">oss-bot</a>, a new releaser for y18n since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=y18n&package-manager=npm_and_yarn&previous-version=3.2.1&new-version=3.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2021-03-31T20:21:22Z,CONTRIBUTOR,False,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,3e25ec3e449b405b4ae238df419d05ad15136841,"chore(deps): bump y18n from 3.2.1 to 3.2.2

Bumps [y18n](https://github.com/yargs/y18n) from 3.2.1 to 3.2.2.
- [Release notes](https://github.com/yargs/y18n/releases)
- [Changelog](https://github.com/yargs/y18n/blob/master/CHANGELOG.md)
- [Commits](https://github.com/yargs/y18n/commits)

Signed-off-by: dependabot[bot] <support@github.com>"
1,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/129,129,chore(deps): bump ini from 1.3.5 to 1.3.8,"Bumps [ini](https://github.com/isaacs/ini) from 1.3.5 to 1.3.8.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/npm/ini/commit/a2c5da86604bc2238fe393c5ff083bf23a9910eb""><code>a2c5da8</code></a> 1.3.8</li>
<li><a href=""https://github.com/npm/ini/commit/af5c6bb5dca6f0248c153aa87e25bddfc515ff6e""><code>af5c6bb</code></a> Do not use Object.create(null)</li>
<li><a href=""https://github.com/npm/ini/commit/8b648a1ac49e1b3b7686ea957e0b95e544bc6ec1""><code>8b648a1</code></a> don't test where our devdeps don't even work</li>
<li><a href=""https://github.com/npm/ini/commit/c74c8af35f32b801a7e82a8309eab792a95932f6""><code>c74c8af</code></a> 1.3.7</li>
<li><a href=""https://github.com/npm/ini/commit/024b8b55ac1c980c6225607b007714c54eb501ba""><code>024b8b5</code></a> update deps, add linting</li>
<li><a href=""https://github.com/npm/ini/commit/032fbaf5f0b98fce70c8cc380e0d05177a9c9073""><code>032fbaf</code></a> Use Object.create(null) to avoid default object property hazards</li>
<li><a href=""https://github.com/npm/ini/commit/2da90391ef70db41d10f013e3a87f9a8c5d01a72""><code>2da9039</code></a> 1.3.6</li>
<li><a href=""https://github.com/npm/ini/commit/cfea636f534b5ca7550d2c28b7d1a95d936d56c6""><code>cfea636</code></a> better git push script, before publish instead of after</li>
<li><a href=""https://github.com/npm/ini/commit/56d2805e07ccd94e2ba0984ac9240ff02d44b6f1""><code>56d2805</code></a> do not allow invalid hazardous string as section name</li>
<li>See full diff in <a href=""https://github.com/isaacs/ini/compare/v1.3.5...v1.3.8"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~isaacs"">isaacs</a>, a new releaser for ini since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ini&package-manager=npm_and_yarn&previous-version=1.3.5&new-version=1.3.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2021-01-28T22:51:12Z,CONTRIBUTOR,False,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,3e1ca4996b77f4dc9de7f4e142e9efe6a4e08ca2,"chore(deps): bump ini from 1.3.5 to 1.3.8

Bumps [ini](https://github.com/isaacs/ini) from 1.3.5 to 1.3.8.
- [Release notes](https://github.com/isaacs/ini/releases)
- [Commits](https://github.com/isaacs/ini/compare/v1.3.5...v1.3.8)

Signed-off-by: dependabot[bot] <support@github.com>"
2,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/127,127,chore(deps): bump ini from 1.3.5 to 1.3.8 in /pubsub,"Bumps [ini](https://github.com/isaacs/ini) from 1.3.5 to 1.3.8.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/npm/ini/commit/a2c5da86604bc2238fe393c5ff083bf23a9910eb""><code>a2c5da8</code></a> 1.3.8</li>
<li><a href=""https://github.com/npm/ini/commit/af5c6bb5dca6f0248c153aa87e25bddfc515ff6e""><code>af5c6bb</code></a> Do not use Object.create(null)</li>
<li><a href=""https://github.com/npm/ini/commit/8b648a1ac49e1b3b7686ea957e0b95e544bc6ec1""><code>8b648a1</code></a> don't test where our devdeps don't even work</li>
<li><a href=""https://github.com/npm/ini/commit/c74c8af35f32b801a7e82a8309eab792a95932f6""><code>c74c8af</code></a> 1.3.7</li>
<li><a href=""https://github.com/npm/ini/commit/024b8b55ac1c980c6225607b007714c54eb501ba""><code>024b8b5</code></a> update deps, add linting</li>
<li><a href=""https://github.com/npm/ini/commit/032fbaf5f0b98fce70c8cc380e0d05177a9c9073""><code>032fbaf</code></a> Use Object.create(null) to avoid default object property hazards</li>
<li><a href=""https://github.com/npm/ini/commit/2da90391ef70db41d10f013e3a87f9a8c5d01a72""><code>2da9039</code></a> 1.3.6</li>
<li><a href=""https://github.com/npm/ini/commit/cfea636f534b5ca7550d2c28b7d1a95d936d56c6""><code>cfea636</code></a> better git push script, before publish instead of after</li>
<li><a href=""https://github.com/npm/ini/commit/56d2805e07ccd94e2ba0984ac9240ff02d44b6f1""><code>56d2805</code></a> do not allow invalid hazardous string as section name</li>
<li>See full diff in <a href=""https://github.com/isaacs/ini/compare/v1.3.5...v1.3.8"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~isaacs"">isaacs</a>, a new releaser for ini since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ini&package-manager=npm_and_yarn&previous-version=1.3.5&new-version=1.3.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2020-12-13T06:37:03Z,CONTRIBUTOR,False,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,0060a069e7319c9c34b4709f543f2f30b814fee3,"chore(deps): bump ini from 1.3.5 to 1.3.8 in /pubsub

Bumps [ini](https://github.com/isaacs/ini) from 1.3.5 to 1.3.8.
- [Release notes](https://github.com/isaacs/ini/releases)
- [Commits](https://github.com/isaacs/ini/compare/v1.3.5...v1.3.8)

Signed-off-by: dependabot[bot] <support@github.com>"
3,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/126,126,Clean up unused scripts,,jbuck,578466,2020-12-02T18:28:04Z,MEMBER,True,1021,4165,28,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,407a07cf2b41f0fe78e310818205891d7ac5e4d8,Clean up unused scripts
4,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/126,126,Clean up unused scripts,,jbuck,578466,2020-12-02T18:28:04Z,MEMBER,True,1021,4165,28,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,014b3df9fe579586ac940f8f1bd82dbf2253e533,Clean up CI
5,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/126,126,Clean up unused scripts,,jbuck,578466,2020-12-02T18:28:04Z,MEMBER,True,1021,4165,28,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,5166a01da5294a8940eb7a61c9e346e484b26755,Oops
6,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/125,125,chore(deps): bump lodash from 4.17.14 to 4.17.20,"Bumps [lodash](https://github.com/lodash/lodash) from 4.17.14 to 4.17.20.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/lodash/lodash/commit/ded9bc66583ed0b4e3b7dc906206d40757b4a90a""><code>ded9bc6</code></a> Bump to v4.17.20.</li>
<li><a href=""https://github.com/lodash/lodash/commit/63150ef7645ac07961b63a86490f419f356429aa""><code>63150ef</code></a> Documentation fixes.</li>
<li><a href=""https://github.com/lodash/lodash/commit/00f0f62a979d2f5fa0287c06eae70cf9a62d8794""><code>00f0f62</code></a> test.js: Remove trailing comma.</li>
<li><a href=""https://github.com/lodash/lodash/commit/846e434c7a5b5692c55ebf5715ed677b70a32389""><code>846e434</code></a> Temporarily use a custom fork of <code>lodash-cli</code>.</li>
<li><a href=""https://github.com/lodash/lodash/commit/5d046f39cbd27f573914768e3b36eeefcc4f1229""><code>5d046f3</code></a> Re-enable Travis tests on <code>4.17</code> branch.</li>
<li><a href=""https://github.com/lodash/lodash/commit/aa816b36d402a1ad9385142ce7188f17dae514fd""><code>aa816b3</code></a> Remove <code>/npm-package</code>.</li>
<li><a href=""https://github.com/lodash/lodash/commit/d7fbc52ee0466a6d248f047b5d5c3e6d1e099056""><code>d7fbc52</code></a> Bump to v4.17.19</li>
<li><a href=""https://github.com/lodash/lodash/commit/2e1c0f22f425e9c013815b2cd7c2ebd51f49a8d6""><code>2e1c0f2</code></a> Add npm-package</li>
<li><a href=""https://github.com/lodash/lodash/commit/1b6c282299f4e0271f932b466c67f0f822aa308e""><code>1b6c282</code></a> Bump to v4.17.18</li>
<li><a href=""https://github.com/lodash/lodash/commit/a370ac81408de2da77a82b3c4b61a01a3b9c2fac""><code>a370ac8</code></a> Bump to v4.17.17</li>
<li>Additional commits viewable in <a href=""https://github.com/lodash/lodash/compare/4.17.14...4.17.20"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~bnjmnt4n"">bnjmnt4n</a>, a new releaser for lodash since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=lodash&package-manager=npm_and_yarn&previous-version=4.17.14&new-version=4.17.20)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2020-10-20T15:59:38Z,CONTRIBUTOR,False,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,dc185c843ddcc1633bc84c3919eee76a43518a7c,"chore(deps): bump lodash from 4.17.14 to 4.17.20

Bumps [lodash](https://github.com/lodash/lodash) from 4.17.14 to 4.17.20.
- [Release notes](https://github.com/lodash/lodash/releases)
- [Commits](https://github.com/lodash/lodash/compare/4.17.14...4.17.20)

Signed-off-by: dependabot[bot] <support@github.com>"
7,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/124,124,chore(deps): bump acorn from 6.1.1 to 6.4.2,"Bumps [acorn](https://github.com/acornjs/acorn) from 6.1.1 to 6.4.2.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/acornjs/acorn/commit/f6b83edda8f4f0af57f9335cbdea8e5155133631""><code>f6b83ed</code></a> Mark version 6.4.2</li>
<li><a href=""https://github.com/acornjs/acorn/commit/f51895bfee3047d808d7afdaad498526f040e787""><code>f51895b</code></a> Fix potentially-exponential regular expression in use-strict-scanning</li>
<li><a href=""https://github.com/acornjs/acorn/commit/9a2e9b6678e243d66846b91179d650d28453e70c""><code>9a2e9b6</code></a> Mark version 6.4.1</li>
<li><a href=""https://github.com/acornjs/acorn/commit/90a9548ea0ce351b54f956e2c4ed27cca9631284""><code>90a9548</code></a> More rigorously check surrogate pairs in regexp validator</li>
<li><a href=""https://github.com/acornjs/acorn/commit/df0cf1a3e2b1a51a26c14984dc0f5412b7151b10""><code>df0cf1a</code></a> Mark version 6.4.0</li>
<li><a href=""https://github.com/acornjs/acorn/commit/53034126864b492da4e278628bb972cb2a9313d4""><code>5303412</code></a> Also export Parser via Parser.acorn</li>
<li><a href=""https://github.com/acornjs/acorn/commit/efe273e70123449a458157dbf578afaf109a49ab""><code>efe273e</code></a> give token types and etc to plugins</li>
<li><a href=""https://github.com/acornjs/acorn/commit/ac6decb94a3aa4eee99230fdaf5883dfaafe8479""><code>ac6decb</code></a> Mark version 6.3.0</li>
<li><a href=""https://github.com/acornjs/acorn/commit/7e9817d17639d95cc6dbacfde734a0626b2a7dea""><code>7e9817d</code></a> Allow sourceType: module even with ecmaVersion &lt; 6</li>
<li><a href=""https://github.com/acornjs/acorn/commit/e2b8cc087386eccc2ad6fd4a02b4257833557cb3""><code>e2b8cc0</code></a> Fix broken parsing of new expressions when allowReserved==&quot;never&quot;</li>
<li>Additional commits viewable in <a href=""https://github.com/acornjs/acorn/compare/6.1.1...6.4.2"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=acorn&package-manager=npm_and_yarn&previous-version=6.1.1&new-version=6.4.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2020-10-20T15:59:17Z,CONTRIBUTOR,False,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,8a9ac1f076b1948ea36311c136ee03e11dd4accf,"chore(deps): bump acorn from 6.1.1 to 6.4.2

Bumps [acorn](https://github.com/acornjs/acorn) from 6.1.1 to 6.4.2.
- [Release notes](https://github.com/acornjs/acorn/releases)
- [Commits](https://github.com/acornjs/acorn/compare/6.1.1...6.4.2)

Signed-off-by: dependabot[bot] <support@github.com>"
8,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/123,123,chore(deps): bump node-fetch from 2.6.0 to 2.6.1 in /pubsub,"Bumps [node-fetch](https://github.com/bitinn/node-fetch) from 2.6.0 to 2.6.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/bitinn/node-fetch/releases"">node-fetch's releases</a>.</em></p>
<blockquote>
<h2>v2.6.1</h2>
<p><strong>This is an important security release. It is strongly recommended to update as soon as possible.</strong></p>
<p>See <a href=""https://github.com/node-fetch/node-fetch/blob/master/docs/CHANGELOG.md#v261"">CHANGELOG</a> for details.</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/node-fetch/node-fetch/blob/master/docs/CHANGELOG.md"">node-fetch's changelog</a>.</em></p>
<blockquote>
<h2>v2.6.1</h2>
<p><strong>This is an important security release. It is strongly recommended to update as soon as possible.</strong></p>
<ul>
<li>Fix: honor the <code>size</code> option after following a redirect.</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/node-fetch/node-fetch/commit/b5e2e41b2b50bf2997720d6125accaf0dd68c0ab""><code>b5e2e41</code></a> update version number</li>
<li><a href=""https://github.com/node-fetch/node-fetch/commit/2358a6c2563d1730a0cdaccc197c611949f6a334""><code>2358a6c</code></a> Honor the <code>size</code> option after following a redirect and revert data uri support</li>
<li><a href=""https://github.com/node-fetch/node-fetch/commit/8c197f8982a238b3c345c64b17bfa92e16b4f7c4""><code>8c197f8</code></a> docs: Fix typos and grammatical errors in README.md (<a href=""https://github-redirect.dependabot.com/bitinn/node-fetch/issues/686"">#686</a>)</li>
<li><a href=""https://github.com/node-fetch/node-fetch/commit/1e99050f944ac435fce26a9549eadcc2419a968a""><code>1e99050</code></a> fix: Change error message thrown with redirect mode set to error (<a href=""https://github-redirect.dependabot.com/bitinn/node-fetch/issues/653"">#653</a>)</li>
<li><a href=""https://github.com/node-fetch/node-fetch/commit/244e6f63d42025465796e3ca4ce813bf2c31fc5b""><code>244e6f6</code></a> docs: Show backers in README</li>
<li><a href=""https://github.com/node-fetch/node-fetch/commit/6a5d192034a0f438551dffb6d2d8df2c00921d16""><code>6a5d192</code></a> fix: Properly parse meta tag when parameters are reversed (<a href=""https://github-redirect.dependabot.com/bitinn/node-fetch/issues/682"">#682</a>)</li>
<li><a href=""https://github.com/node-fetch/node-fetch/commit/47a24a03eb49a49d81b768892aee10074ed54a91""><code>47a24a0</code></a> chore: Add opencollective badge</li>
<li><a href=""https://github.com/node-fetch/node-fetch/commit/7b136627c537cb24430b0310638c9177a85acee1""><code>7b13662</code></a> chore: Add funding link</li>
<li><a href=""https://github.com/node-fetch/node-fetch/commit/5535c2ed478d418969ecfd60c16453462de2a53f""><code>5535c2e</code></a> fix: Check for global.fetch before binding it (<a href=""https://github-redirect.dependabot.com/bitinn/node-fetch/issues/674"">#674</a>)</li>
<li><a href=""https://github.com/node-fetch/node-fetch/commit/1d5778ad0d910dbd1584fb407a186f5a0bc1ea22""><code>1d5778a</code></a> docs: Add Discord badge</li>
<li>Additional commits viewable in <a href=""https://github.com/bitinn/node-fetch/compare/v2.6.0...v2.6.1"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~akepinski"">akepinski</a>, a new releaser for node-fetch since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=node-fetch&package-manager=npm_and_yarn&previous-version=2.6.0&new-version=2.6.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2020-09-11T16:30:57Z,CONTRIBUTOR,False,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,e3ebafa3a90f654a3f3b75cfea7d847bcb94fd05,"chore(deps): bump node-fetch from 2.6.0 to 2.6.1 in /pubsub

Bumps [node-fetch](https://github.com/bitinn/node-fetch) from 2.6.0 to 2.6.1.
- [Release notes](https://github.com/bitinn/node-fetch/releases)
- [Changelog](https://github.com/node-fetch/node-fetch/blob/master/docs/CHANGELOG.md)
- [Commits](https://github.com/bitinn/node-fetch/compare/v2.6.0...v2.6.1)

Signed-off-by: dependabot[bot] <support@github.com>"
9,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/122,122,chore(deps): bump lodash from 4.17.14 to 4.17.19 in /pubsub,"Bumps [lodash](https://github.com/lodash/lodash) from 4.17.14 to 4.17.19.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/lodash/lodash/releases"">lodash's releases</a>.</em></p>
<blockquote>
<h2>4.17.16</h2>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/lodash/lodash/commit/d7fbc52ee0466a6d248f047b5d5c3e6d1e099056""><code>d7fbc52</code></a> Bump to v4.17.19</li>
<li><a href=""https://github.com/lodash/lodash/commit/2e1c0f22f425e9c013815b2cd7c2ebd51f49a8d6""><code>2e1c0f2</code></a> Add npm-package</li>
<li><a href=""https://github.com/lodash/lodash/commit/1b6c282299f4e0271f932b466c67f0f822aa308e""><code>1b6c282</code></a> Bump to v4.17.18</li>
<li><a href=""https://github.com/lodash/lodash/commit/a370ac81408de2da77a82b3c4b61a01a3b9c2fac""><code>a370ac8</code></a> Bump to v4.17.17</li>
<li><a href=""https://github.com/lodash/lodash/commit/1144918f3578a84fcc4986da9b806e63a6175cbb""><code>1144918</code></a> Rebuild lodash and docs</li>
<li><a href=""https://github.com/lodash/lodash/commit/3a3b0fd339c2109563f7e8167dc95265ed82ef3e""><code>3a3b0fd</code></a> Bump to v4.17.16</li>
<li><a href=""https://github.com/lodash/lodash/commit/c84fe82760fb2d3e03a63379b297a1cc1a2fce12""><code>c84fe82</code></a> fix(zipObjectDeep): prototype pollution (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4759"">#4759</a>)</li>
<li><a href=""https://github.com/lodash/lodash/commit/e7b28ea6cb17b4ca021e7c9d66218c8c89782f32""><code>e7b28ea</code></a> Sanitize sourceURL so it cannot affect evaled code (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4518"">#4518</a>)</li>
<li><a href=""https://github.com/lodash/lodash/commit/0cec225778d4ac26c2bac95031ecc92a94f08bbb""><code>0cec225</code></a> Fix lodash.isEqual for circular references (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4320"">#4320</a>) (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4515"">#4515</a>)</li>
<li><a href=""https://github.com/lodash/lodash/commit/94c3a8133cb4fcdb50db72b4fd14dd884b195cd5""><code>94c3a81</code></a> Document matches* shorthands for over* methods (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4510"">#4510</a>) (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4514"">#4514</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/lodash/lodash/compare/4.17.14...4.17.19"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~mathias"">mathias</a>, a new releaser for lodash since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=lodash&package-manager=npm_and_yarn&previous-version=4.17.14&new-version=4.17.19)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2020-07-17T04:35:18Z,CONTRIBUTOR,False,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,b5ae69e568a8e1323f62502598bffc3984f54dce,"chore(deps): bump lodash from 4.17.14 to 4.17.19 in /pubsub

Bumps [lodash](https://github.com/lodash/lodash) from 4.17.14 to 4.17.19.
- [Release notes](https://github.com/lodash/lodash/releases)
- [Commits](https://github.com/lodash/lodash/compare/4.17.14...4.17.19)

Signed-off-by: dependabot[bot] <support@github.com>"
10,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/121,121,chore(deps): bump lodash from 4.17.14 to 4.17.19,"Bumps [lodash](https://github.com/lodash/lodash) from 4.17.14 to 4.17.19.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/lodash/lodash/releases"">lodash's releases</a>.</em></p>
<blockquote>
<h2>4.17.16</h2>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/lodash/lodash/commit/d7fbc52ee0466a6d248f047b5d5c3e6d1e099056""><code>d7fbc52</code></a> Bump to v4.17.19</li>
<li><a href=""https://github.com/lodash/lodash/commit/2e1c0f22f425e9c013815b2cd7c2ebd51f49a8d6""><code>2e1c0f2</code></a> Add npm-package</li>
<li><a href=""https://github.com/lodash/lodash/commit/1b6c282299f4e0271f932b466c67f0f822aa308e""><code>1b6c282</code></a> Bump to v4.17.18</li>
<li><a href=""https://github.com/lodash/lodash/commit/a370ac81408de2da77a82b3c4b61a01a3b9c2fac""><code>a370ac8</code></a> Bump to v4.17.17</li>
<li><a href=""https://github.com/lodash/lodash/commit/1144918f3578a84fcc4986da9b806e63a6175cbb""><code>1144918</code></a> Rebuild lodash and docs</li>
<li><a href=""https://github.com/lodash/lodash/commit/3a3b0fd339c2109563f7e8167dc95265ed82ef3e""><code>3a3b0fd</code></a> Bump to v4.17.16</li>
<li><a href=""https://github.com/lodash/lodash/commit/c84fe82760fb2d3e03a63379b297a1cc1a2fce12""><code>c84fe82</code></a> fix(zipObjectDeep): prototype pollution (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4759"">#4759</a>)</li>
<li><a href=""https://github.com/lodash/lodash/commit/e7b28ea6cb17b4ca021e7c9d66218c8c89782f32""><code>e7b28ea</code></a> Sanitize sourceURL so it cannot affect evaled code (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4518"">#4518</a>)</li>
<li><a href=""https://github.com/lodash/lodash/commit/0cec225778d4ac26c2bac95031ecc92a94f08bbb""><code>0cec225</code></a> Fix lodash.isEqual for circular references (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4320"">#4320</a>) (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4515"">#4515</a>)</li>
<li><a href=""https://github.com/lodash/lodash/commit/94c3a8133cb4fcdb50db72b4fd14dd884b195cd5""><code>94c3a81</code></a> Document matches* shorthands for over* methods (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4510"">#4510</a>) (<a href=""https://github-redirect.dependabot.com/lodash/lodash/issues/4514"">#4514</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/lodash/lodash/compare/4.17.14...4.17.19"">compare view</a></li>
</ul>
</details>
<details>
<summary>Maintainer changes</summary>
<p>This version was pushed to npm by <a href=""https://www.npmjs.com/~mathias"">mathias</a>, a new releaser for lodash since your current version.</p>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=lodash&package-manager=npm_and_yarn&previous-version=4.17.14&new-version=4.17.19)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2020-07-16T00:47:20Z,CONTRIBUTOR,False,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,15467b6717e8f5c33d4d8bc72c6b5926caf8da16,"chore(deps): bump lodash from 4.17.14 to 4.17.19

Bumps [lodash](https://github.com/lodash/lodash) from 4.17.14 to 4.17.19.
- [Release notes](https://github.com/lodash/lodash/releases)
- [Commits](https://github.com/lodash/lodash/compare/4.17.14...4.17.19)

Signed-off-by: dependabot[bot] <support@github.com>"
11,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/120,120,chore(deps): bump acorn from 6.1.1 to 6.4.1,"Bumps [acorn](https://github.com/acornjs/acorn) from 6.1.1 to 6.4.1.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/acornjs/acorn/commit/9a2e9b6678e243d66846b91179d650d28453e70c""><code>9a2e9b6</code></a> Mark version 6.4.1</li>
<li><a href=""https://github.com/acornjs/acorn/commit/90a9548ea0ce351b54f956e2c4ed27cca9631284""><code>90a9548</code></a> More rigorously check surrogate pairs in regexp validator</li>
<li><a href=""https://github.com/acornjs/acorn/commit/df0cf1a3e2b1a51a26c14984dc0f5412b7151b10""><code>df0cf1a</code></a> Mark version 6.4.0</li>
<li><a href=""https://github.com/acornjs/acorn/commit/53034126864b492da4e278628bb972cb2a9313d4""><code>5303412</code></a> Also export Parser via Parser.acorn</li>
<li><a href=""https://github.com/acornjs/acorn/commit/efe273e70123449a458157dbf578afaf109a49ab""><code>efe273e</code></a> give token types and etc to plugins</li>
<li><a href=""https://github.com/acornjs/acorn/commit/ac6decb94a3aa4eee99230fdaf5883dfaafe8479""><code>ac6decb</code></a> Mark version 6.3.0</li>
<li><a href=""https://github.com/acornjs/acorn/commit/7e9817d17639d95cc6dbacfde734a0626b2a7dea""><code>7e9817d</code></a> Allow sourceType: module even with ecmaVersion &lt; 6</li>
<li><a href=""https://github.com/acornjs/acorn/commit/e2b8cc087386eccc2ad6fd4a02b4257833557cb3""><code>e2b8cc0</code></a> Fix broken parsing of new expressions when allowReserved==&quot;never&quot;</li>
<li><a href=""https://github.com/acornjs/acorn/commit/1555c528855b10320ce98b4154906d7898c92990""><code>1555c52</code></a> Update acorn.d.ts</li>
<li><a href=""https://github.com/acornjs/acorn/commit/77c20fa2c2f490e646b67e6a0ff7e75fb54ab6c8""><code>77c20fa</code></a> Mark version 6.2.1</li>
<li>Additional commits viewable in <a href=""https://github.com/acornjs/acorn/compare/6.1.1...6.4.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=acorn&package-manager=npm_and_yarn&previous-version=6.1.1&new-version=6.4.1)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2020-03-13T21:41:01Z,CONTRIBUTOR,False,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,75994b8e2f997bd5316580172a6ae98a0f085f7b,"chore(deps): bump acorn from 6.1.1 to 6.4.1

Bumps [acorn](https://github.com/acornjs/acorn) from 6.1.1 to 6.4.1.
- [Release notes](https://github.com/acornjs/acorn/releases)
- [Commits](https://github.com/acornjs/acorn/compare/6.1.1...6.4.1)

Signed-off-by: dependabot[bot] <support@github.com>"
12,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/119,119,Add README with a first pass at documenting amplitude processing flow,"Here's a first attempt at some docs, covering the little bit that I think I understand. Comments and improvements welcome, feel free to add commits or suggest and I'll add.",jaredhirsch,96396,2019-12-03T01:33:43Z,MEMBER,False,84,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,dbd7f05758e5109c0c6d11854d22151f91c9db78,Add README with a first pass at documenting amplitude processing flow
13,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/115,115,Add synchronous pull version,,jbuck,578466,2019-11-29T22:51:02Z,MEMBER,True,222,0,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,6ea19381fe98f0c07f4458e8f33da6e39dc30c08,Add synchronous pull version
14,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/115,115,Add synchronous pull version,,jbuck,578466,2019-11-29T22:51:02Z,MEMBER,True,222,0,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,85611ca63d4bb670f6cf5f22e275905c0cda38f7,Remove unused env vars
15,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/115,115,Add synchronous pull version,,jbuck,578466,2019-11-29T22:51:02Z,MEMBER,True,222,0,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,e87688e287fef7e9f53ca9e44c1ffdc556d3b6c7,Update startup error message
16,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/114,114,Add C++ grpc library,,jbuck,578466,2019-11-28T16:27:12Z,MEMBER,True,602,1,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,68837b4f91d56e0bcf198bd757a93e16e33e8885,Add C++ grpc library
17,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/114,114,Add C++ grpc library,,jbuck,578466,2019-11-28T16:27:12Z,MEMBER,True,602,1,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,8dc4ef953835a2a878507439325a39815040df81,Add config option to switch between C++/JS GRPC libraries
18,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/113,113,"Update pubsub client, use default options",,jbuck,578466,2019-11-27T21:39:44Z,MEMBER,True,160,892,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,bf84da528ee50eb2fcf514d473a97a299123ed6c,"Update pubsub client, use default options"
19,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/113,113,"Update pubsub client, use default options",,jbuck,578466,2019-11-27T21:39:44Z,MEMBER,True,160,892,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,10d8f92ea38f17c84100759964e3d82e238b8c7e,Switch some flow control options
20,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/113,113,"Update pubsub client, use default options",,jbuck,578466,2019-11-27T21:39:44Z,MEMBER,True,160,892,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,94af487a2346245410b11a3ffd764cd3017c7ce9,Add back old settings
21,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/113,113,"Update pubsub client, use default options",,jbuck,578466,2019-11-27T21:39:44Z,MEMBER,True,160,892,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,1c0f04dec2c37059012945802bb49bb2803eed4a,restart fixes
22,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/113,113,"Update pubsub client, use default options",,jbuck,578466,2019-11-27T21:39:44Z,MEMBER,True,160,892,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,d5c3a5cae93e1631e8bf5ade74e9ffc77e0e65b7,Try catch it
23,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/109,109,Try using batch API,,jbuck,578466,2019-11-27T19:16:32Z,MEMBER,True,19,10,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,332bb64d18f8912a3b04d7ad413fb479d885105d,Try using batch API
24,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/109,109,Try using batch API,,jbuck,578466,2019-11-27T19:16:32Z,MEMBER,True,19,10,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,45abbbd792ba60f2d5764d42efa202a23ffb5a16,s/HTTP/BATCH
25,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/109,109,Try using batch API,,jbuck,578466,2019-11-27T19:16:32Z,MEMBER,True,19,10,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,9234acd98fb0dba626f8ceb088bf4925163ac4d4,Minimal changes
26,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/109,109,Try using batch API,,jbuck,578466,2019-11-27T19:16:32Z,MEMBER,True,19,10,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,ed6ce71f20d491b029fbb4c4dcea2dfa3de08e3c,Add server response
27,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/109,109,Try using batch API,,jbuck,578466,2019-11-27T19:16:32Z,MEMBER,True,19,10,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,1be62960eb3a79f5de706a3f2c13d49879671edd,Minimize changes
28,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/109,109,Try using batch API,,jbuck,578466,2019-11-27T19:16:32Z,MEMBER,True,19,10,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,754cb19a07c5da868eac40ce0ccbabae7020a6d2,m
29,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/108,108,Add support for routing 'identify' events to the batch API.,"This change allows the 'identify' amplitude events to be split between
the identify API and the batch API.

The BATCH_API_PERCENTAGE env var (int 0 - 100, default 75) is used to
decide which API to use to handle a particular event.

Other new config values added in this patch:

* BATCH_API_MAX_EVENTS_PER_BATCH, number of events per batch API
submission (default 10)

* BATCH_API_WORKER_COUNT, number of batch API queue workers per
fxa-amplitude-send instance (default 1)

Fixes #107.

I'm working on unit tests that can run locally, even if node-parquet doesn't install on MacOS Sierra 🙄, but there's no reason to block on that.",jaredhirsch,96396,2019-11-27T18:48:45Z,MEMBER,False,45,10,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,6a07bc1c82f80178884495aabc91bb65933f42f4,"Add support for routing 'identify' events to the batch API.

This change allows the 'identify' amplitude events to be split between
the identify API and the batch API.

The BATCH_API_PERCENTAGE env var (int 0 - 100, default 75) is used to
decide which API to use to handle a particular event.

Other new config values added in this patch:

* BATCH_API_MAX_EVENTS_PER_BATCH, number of events per batch API
submission (default 10)

* BATCH_API_WORKER_COUNT, number of batch API queue workers per
fxa-amplitude-send instance (default 1)

Fixes #107."
30,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/108,108,Add support for routing 'identify' events to the batch API.,"This change allows the 'identify' amplitude events to be split between
the identify API and the batch API.

The BATCH_API_PERCENTAGE env var (int 0 - 100, default 75) is used to
decide which API to use to handle a particular event.

Other new config values added in this patch:

* BATCH_API_MAX_EVENTS_PER_BATCH, number of events per batch API
submission (default 10)

* BATCH_API_WORKER_COUNT, number of batch API queue workers per
fxa-amplitude-send instance (default 1)

Fixes #107.

I'm working on unit tests that can run locally, even if node-parquet doesn't install on MacOS Sierra 🙄, but there's no reason to block on that.",jaredhirsch,96396,2019-11-27T18:48:45Z,MEMBER,False,45,10,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,b3618f8aa9925d240fb2ee9426100360600fa7b5,Set event_type for batch events
31,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/108,108,Add support for routing 'identify' events to the batch API.,"This change allows the 'identify' amplitude events to be split between
the identify API and the batch API.

The BATCH_API_PERCENTAGE env var (int 0 - 100, default 75) is used to
decide which API to use to handle a particular event.

Other new config values added in this patch:

* BATCH_API_MAX_EVENTS_PER_BATCH, number of events per batch API
submission (default 10)

* BATCH_API_WORKER_COUNT, number of batch API queue workers per
fxa-amplitude-send instance (default 1)

Fixes #107.

I'm working on unit tests that can run locally, even if node-parquet doesn't install on MacOS Sierra 🙄, but there's no reason to block on that.",jaredhirsch,96396,2019-11-27T18:48:45Z,MEMBER,False,45,10,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,ed174e5c4f3b3c3ec35acfc24aa97fca0787ebe9,"The batch API request must use JSON header and format, not form-encoded"
32,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/105,105,Update to latest beta pubsub,,jbuck,578466,2019-11-26T20:43:32Z,MEMBER,False,140,884,2,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,21942608dc7a32a9e985836fc46ce057f84e31f7,Update to latest beta pubsub
33,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/104,104,Changes to support configurable queue workers and batch size,"Note that this only needs to land if our first option, asking amplitude corp to allow batch duplicates to the Identify API without rate limiting, doesn't work out.

* Move Amplitude API worker count and batch size to env vars.
* Remove the old WORKER_COUNT env var in favor of separate worker counts
for each of the HTTP and Identify APIs.

Refs https://github.com/mozilla/fxa/issues/3484.",jaredhirsch,96396,2019-11-26T19:12:23Z,MEMBER,True,10,7,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,31fe0a33030552c3478ae49c4170807306486fb2,"Changes to support configurable queue workers and batch size

* Move Amplitude API worker count and batch size to env vars.
* Remove the old WORKER_COUNT env var in favor of separate worker counts
for each of the HTTP and Identify APIs.

Refs https://github.com/mozilla/fxa/issues/3484."
34,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/103,103,Add pino dependencies,,jbuck,578466,2019-11-26T17:52:58Z,MEMBER,True,68,14,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,557d0bd41d011ae83697fff965a3ea96e85149a4,Changes from prod
35,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/103,103,Add pino dependencies,,jbuck,578466,2019-11-26T17:52:58Z,MEMBER,True,68,14,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,21878945081f7d8f23be98b32328a092ab8ed53c,Add pino dependencies
36,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/102,102,filter out malformed messages from event array,,jbuck,578466,2019-11-26T08:55:11Z,MEMBER,False,332,1132,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,557d0bd41d011ae83697fff965a3ea96e85149a4,Changes from prod
37,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/102,102,filter out malformed messages from event array,,jbuck,578466,2019-11-26T08:55:11Z,MEMBER,False,332,1132,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,6098a16a6c4bf50330eee9e18caf493df55c0747,a jbuck special
38,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/102,102,filter out malformed messages from event array,,jbuck,578466,2019-11-26T08:55:11Z,MEMBER,False,332,1132,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,05b52b614e4b04bb16e3f7374571fc7079b5736e,env fixes
39,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/102,102,filter out malformed messages from event array,,jbuck,578466,2019-11-26T08:55:11Z,MEMBER,False,332,1132,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,fc41ffc9b44ab3e28cd16b06528512eec72dc416,filter out malformed messages from event array
40,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/100,100,chore(deps): bump eslint-utils from 1.3.1 to 1.4.2,"Bumps [eslint-utils](https://github.com/mysticatea/eslint-utils) from 1.3.1 to 1.4.2.
<details>
<summary>Commits</summary>

- [`4e1bc07`](https://github.com/mysticatea/eslint-utils/commit/4e1bc077c2a6bb00538d66b69a63c24de3463bed) 1.4.2
- [`e4cb014`](https://github.com/mysticatea/eslint-utils/commit/e4cb01498df6096b66edb0c78965ee6f47d3ac77) 🐛 add null test
- [`230a4e2`](https://github.com/mysticatea/eslint-utils/commit/230a4e2275cde169cbfbb95cd2e4de2152fae0a2) 1.4.1
- [`08158db`](https://github.com/mysticatea/eslint-utils/commit/08158db1c98fd71cf0f32ddefbc147e2620e724c) 🐛 fix getStaticValue security issue
- [`587cca2`](https://github.com/mysticatea/eslint-utils/commit/587cca2f82c245f5fc4a8b9fb2cf6b35c0d02552) 🐛 fix getStringIfConstant to handle literals correctly
- [`c119e83`](https://github.com/mysticatea/eslint-utils/commit/c119e832952c8c653bd4f21e39eb9f7ce48e5947) 🐛 fix getStaticValue to handle bigint correctly
- [`531b16f`](https://github.com/mysticatea/eslint-utils/commit/531b16fa686b80a8cc450eb87525115233ce6064) 🔖 1.4.0
- [`276303d`](https://github.com/mysticatea/eslint-utils/commit/276303d826bf94b9e6d6cdf5697cb1feb54c89ca) ⚒ upgrade rollup
- [`cb518c7`](https://github.com/mysticatea/eslint-utils/commit/cb518c70ee037722f802d808bbbe93da83f07fb3) 🐛 fix hasSideEffect false negative
- [`aac472e`](https://github.com/mysticatea/eslint-utils/commit/aac472e815551688d23cc8fd88f9044dbf276804) 🐛 fix isParenthesized had false positive on ImportExpression (fixes [#1](https://github-redirect.dependabot.com/mysticatea/eslint-utils/issues/1))
- Additional commits viewable in [compare view](https://github.com/mysticatea/eslint-utils/compare/v1.3.1...v1.4.2)
</details>
<br />

[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=eslint-utils&package-manager=npm_and_yarn&previous-version=1.3.1&new-version=1.4.2)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2019-10-18T14:29:55Z,CONTRIBUTOR,False,7,4,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,6b53e42208d8ab71e6e7bcd77d854cdf18358b45,"chore(deps): bump eslint-utils from 1.3.1 to 1.4.2

Bumps [eslint-utils](https://github.com/mysticatea/eslint-utils) from 1.3.1 to 1.4.2.
- [Release notes](https://github.com/mysticatea/eslint-utils/releases)
- [Commits](https://github.com/mysticatea/eslint-utils/compare/v1.3.1...v1.4.2)

Signed-off-by: dependabot[bot] <support@github.com>"
41,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/98,98,chore(deps): bump lodash from 4.17.11 to 4.17.14,"Bumps [lodash](https://github.com/lodash/lodash) from 4.17.11 to 4.17.14.
<details>
<summary>Commits</summary>

- [`be87d30`](https://github.com/lodash/lodash/commit/be87d303941222b97c482755afc0f4a77ce46c30) Bump to v4.17.14.
- [`a6fe6b1`](https://github.com/lodash/lodash/commit/a6fe6b1e174fd02b5e60eb2664405f4c1262c300) Rebuild lodash and docs.
- [`e371828`](https://github.com/lodash/lodash/commit/e37182845f16715a0d1c391c8662d83c55609cee) Bump to v4.17.13.
- [`357e899`](https://github.com/lodash/lodash/commit/357e899e685872b4af5403ecc4b2a928f961ae63) Rebuild lodash and docs.
- [`fd9a062`](https://github.com/lodash/lodash/commit/fd9a062d57646450b61f74029315abd4cc834b08) Bump to v4.17.12.
- [`e77d681`](https://github.com/lodash/lodash/commit/e77d68121ff00ba86b53eed5893d35adfe94c9dd) Rebuild lodash and docs.
- [`629d186`](https://github.com/lodash/lodash/commit/629d1865793182cd967196716f4beff223aa4a91) Update OpenJS references.
- [`2406eac`](https://github.com/lodash/lodash/commit/2406eac542b2a1282be8d812a6d8a45433ade80a) Fix minified build.
- [`17a34bc`](https://github.com/lodash/lodash/commit/17a34bc5854bb982ef333bfe7ae469f4dfcee0ec) Fix test bootstrap for core build.
- [`53838a3`](https://github.com/lodash/lodash/commit/53838a38f8e4f6204ef2f837fecc4e07d09afe77) Fix tests in older browsers.
- Additional commits viewable in [compare view](https://github.com/lodash/lodash/compare/4.17.11...4.17.14)
</details>
<br />

[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=lodash&package-manager=npm_and_yarn&previous-version=4.17.11&new-version=4.17.14)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2019-07-15T10:12:28Z,CONTRIBUTOR,True,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,1543da10d6d484c7ae085a0204704fd6287edd9c,"chore(deps): bump lodash from 4.17.11 to 4.17.14

Bumps [lodash](https://github.com/lodash/lodash) from 4.17.11 to 4.17.14.
- [Release notes](https://github.com/lodash/lodash/releases)
- [Commits](https://github.com/lodash/lodash/compare/4.17.11...4.17.14)

Signed-off-by: dependabot[bot] <support@github.com>"
42,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/97,97,chore(deps): bump lodash.merge from 4.6.1 to 4.6.2 in /pubsub,"Bumps [lodash.merge](https://github.com/lodash/lodash) from 4.6.1 to 4.6.2.
<details>
<summary>Commits</summary>

- See full diff in [compare view](https://github.com/lodash/lodash/commits)
</details>
<br />

[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=lodash.merge&package-manager=npm_and_yarn&previous-version=4.6.1&new-version=4.6.2)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2019-07-15T10:12:13Z,CONTRIBUTOR,True,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,ee1951db09652973caeec241c7930213fda07ff1,"chore(deps): bump lodash.merge from 4.6.1 to 4.6.2 in /pubsub

Bumps [lodash.merge](https://github.com/lodash/lodash) from 4.6.1 to 4.6.2.
- [Release notes](https://github.com/lodash/lodash/releases)
- [Commits](https://github.com/lodash/lodash/commits)

Signed-off-by: dependabot[bot] <support@github.com>"
43,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/96,96,chore(deps): bump lodash from 4.17.11 to 4.17.14 in /pubsub,"Bumps [lodash](https://github.com/lodash/lodash) from 4.17.11 to 4.17.14.
<details>
<summary>Commits</summary>

- [`be87d30`](https://github.com/lodash/lodash/commit/be87d303941222b97c482755afc0f4a77ce46c30) Bump to v4.17.14.
- [`a6fe6b1`](https://github.com/lodash/lodash/commit/a6fe6b1e174fd02b5e60eb2664405f4c1262c300) Rebuild lodash and docs.
- [`e371828`](https://github.com/lodash/lodash/commit/e37182845f16715a0d1c391c8662d83c55609cee) Bump to v4.17.13.
- [`357e899`](https://github.com/lodash/lodash/commit/357e899e685872b4af5403ecc4b2a928f961ae63) Rebuild lodash and docs.
- [`fd9a062`](https://github.com/lodash/lodash/commit/fd9a062d57646450b61f74029315abd4cc834b08) Bump to v4.17.12.
- [`e77d681`](https://github.com/lodash/lodash/commit/e77d68121ff00ba86b53eed5893d35adfe94c9dd) Rebuild lodash and docs.
- [`629d186`](https://github.com/lodash/lodash/commit/629d1865793182cd967196716f4beff223aa4a91) Update OpenJS references.
- [`2406eac`](https://github.com/lodash/lodash/commit/2406eac542b2a1282be8d812a6d8a45433ade80a) Fix minified build.
- [`17a34bc`](https://github.com/lodash/lodash/commit/17a34bc5854bb982ef333bfe7ae469f4dfcee0ec) Fix test bootstrap for core build.
- [`53838a3`](https://github.com/lodash/lodash/commit/53838a38f8e4f6204ef2f837fecc4e07d09afe77) Fix tests in older browsers.
- Additional commits viewable in [compare view](https://github.com/lodash/lodash/compare/4.17.11...4.17.14)
</details>
<br />

[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=lodash&package-manager=npm_and_yarn&previous-version=4.17.11&new-version=4.17.14)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/fxa-amplitude-send/network/alerts).

</details>",dependabot[bot],49699333,2019-07-15T10:11:48Z,CONTRIBUTOR,True,3,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,778b5bfa950eca62fbb4866662e38e67f0feed1a,"chore(deps): bump lodash from 4.17.11 to 4.17.14 in /pubsub

Bumps [lodash](https://github.com/lodash/lodash) from 4.17.11 to 4.17.14.
- [Release notes](https://github.com/lodash/lodash/releases)
- [Commits](https://github.com/lodash/lodash/compare/4.17.11...4.17.14)

Signed-off-by: dependabot[bot] <support@github.com>"
44,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/95,95,fix(pubsub): Try options to do things,"Needs to be merged after #94 .

The reason messages stayed on each process forever was that `flowControl.maxExtension` was set to `Infinity` [by default](https://github.com/googleapis/nodejs-pubsub/issues/637). This patch sets it to a reasonable value, and also smears nacks() over a random 5 minute period to avoid rate-limiting kicking in. So far this has been working pretty well!",jbuck,578466,2019-06-07T21:42:15Z,MEMBER,False,68,14,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,d15e4d6f39ff6dd0d41f88926194b1720a0c28f1,feat(logging): Add structured logging
45,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/95,95,fix(pubsub): Try options to do things,"Needs to be merged after #94 .

The reason messages stayed on each process forever was that `flowControl.maxExtension` was set to `Infinity` [by default](https://github.com/googleapis/nodejs-pubsub/issues/637). This patch sets it to a reasonable value, and also smears nacks() over a random 5 minute period to avoid rate-limiting kicking in. So far this has been working pretty well!",jbuck,578466,2019-06-07T21:42:15Z,MEMBER,False,68,14,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,eee4ca4e2832a176e6e55e6ed30f91c1726c8782,fix(pubsub): Try options to do things
46,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/94,94,feat(logging): Add structured logging,,jbuck,578466,2019-06-07T20:54:37Z,MEMBER,False,60,13,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,d15e4d6f39ff6dd0d41f88926194b1720a0c28f1,feat(logging): Add structured logging
47,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/93,93,Some debugging hackery to better understand pubsub weirdness,"@jbuck, as discussed just now. Make sense?

Fwiw, even just in my local testing I can see the warnings for those old messages, so they're definitely being read from the queue. They're exclusively `fxa_activity - access_token_checked` events from what I can make out, which may be a coincidence due to event volume or may point to a deeper issue with the structure of those events or something. Any thoughts?
",philbooth,64367,2019-06-05T17:02:19Z,CONTRIBUTOR,True,28,1,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,9daadec9c3f0b7fb34bc8efadabb30b0c19f1a8b,feat(pubsub): abort script if messages appear to stall
48,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/93,93,Some debugging hackery to better understand pubsub weirdness,"@jbuck, as discussed just now. Make sense?

Fwiw, even just in my local testing I can see the warnings for those old messages, so they're definitely being read from the queue. They're exclusively `fxa_activity - access_token_checked` events from what I can make out, which may be a coincidence due to event volume or may point to a deeper issue with the structure of those events or something. Any thoughts?
",philbooth,64367,2019-06-05T17:02:19Z,CONTRIBUTOR,True,28,1,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,6214a58c2f57c3e81b7d4363d78ba479c04ae282,feat(pubsub): log a warning when really old messages arrive
49,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/92,92,fix(pubsub): Add 5 second timeout to HTTP request,,jbuck,578466,2019-06-03T17:19:17Z,MEMBER,True,144,107,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,a22919ea84c106318f092da4851c07acaffb3e67,fix(pubsub): Add 5 second timeout to HTTP request
50,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/92,92,fix(pubsub): Add 5 second timeout to HTTP request,,jbuck,578466,2019-06-03T17:19:17Z,MEMBER,True,144,107,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,a1716f31aa9a52df20a4c3de97531a83c912f664,chore(pubsub): Update to latest version of client library
51,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/92,92,fix(pubsub): Add 5 second timeout to HTTP request,,jbuck,578466,2019-06-03T17:19:17Z,MEMBER,True,144,107,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,be4271579172ba4cd4afb57fef9c9207f55d8f7e,fix(pubsub): Switch all logging to stdout
52,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/91,91,fix(scripts): fix undefined dereference in marketing import,"Noticed this while working on #90.

As per [the docs](https://caolan.github.io/async/global.html#AsyncFunction), `async.cargo` does not pass a `callback` argument to `async` functions:

> Wherever we accept a Node-style async function, we also directly accept an ES2017 `async` function. In this case, the `async` function will not be passed a final callback argument, and any thrown error will be used as the `err` argument of the implicit callback, and the return value will be used as the `result` value.

The marketing script was attempting to call `callback()`, which is actually `undefined`. It wasn't affecting the import itself because the request has already succeeded at that point, but it meant the script wasn't exiting gracefully.

Also did an `npm audit fix`.

@jbuck r?",philbooth,64367,2019-05-01T09:09:24Z,CONTRIBUTOR,True,175,173,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,8ddf7cc298172f301b6076535d66dd1a378e6953,fix(deps): npm audit fix
53,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/91,91,fix(scripts): fix undefined dereference in marketing import,"Noticed this while working on #90.

As per [the docs](https://caolan.github.io/async/global.html#AsyncFunction), `async.cargo` does not pass a `callback` argument to `async` functions:

> Wherever we accept a Node-style async function, we also directly accept an ES2017 `async` function. In this case, the `async` function will not be passed a final callback argument, and any thrown error will be used as the `err` argument of the implicit callback, and the return value will be used as the `result` value.

The marketing script was attempting to call `callback()`, which is actually `undefined`. It wasn't affecting the import itself because the request has already succeeded at that point, but it meant the script wasn't exiting gracefully.

Also did an `npm audit fix`.

@jbuck r?",philbooth,64367,2019-05-01T09:09:24Z,CONTRIBUTOR,True,175,173,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,2434d47e21098b30a419a247374606e41a8d86bd,fix(scripts): fix undefined dereference in marketing import
54,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/90,90,feat(scripts): implement a pubsub import script,"Fixes #89. Fixes mozilla/fxa#866.

Ports the existing main import script to node and slaps a pubsub-friendly interface on it. ~~Still in progress/untested. Doesn't yet include @shane-tomlinson's logic for ignoring configured client ids.~~",philbooth,64367,2019-04-29T19:57:25Z,CONTRIBUTOR,True,2096,101,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,c3c7cb749996c650923a2996451375309da584b0,feat(scripts): implement an fxa pubsub import script
55,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/90,90,feat(scripts): implement a pubsub import script,"Fixes #89. Fixes mozilla/fxa#866.

Ports the existing main import script to node and slaps a pubsub-friendly interface on it. ~~Still in progress/untested. Doesn't yet include @shane-tomlinson's logic for ignoring configured client ids.~~",philbooth,64367,2019-04-29T19:57:25Z,CONTRIBUTOR,True,2096,101,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,57ba435a5d3a39974642cf5fc26aef3e76ad8d0b,feat(scripts): ignore specified events in fxa pubsub import script
56,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/90,90,feat(scripts): implement a pubsub import script,"Fixes #89. Fixes mozilla/fxa#866.

Ports the existing main import script to node and slaps a pubsub-friendly interface on it. ~~Still in progress/untested. Doesn't yet include @shane-tomlinson's logic for ignoring configured client ids.~~",philbooth,64367,2019-04-29T19:57:25Z,CONTRIBUTOR,True,2096,101,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,4dc83ea4aa55d819f22773c07070f84393efdd72,refactor(pubsub): pull events from pubsub instead of using a cloud func
57,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/90,90,feat(scripts): implement a pubsub import script,"Fixes #89. Fixes mozilla/fxa#866.

Ports the existing main import script to node and slaps a pubsub-friendly interface on it. ~~Still in progress/untested. Doesn't yet include @shane-tomlinson's logic for ignoring configured client ids.~~",philbooth,64367,2019-04-29T19:57:25Z,CONTRIBUTOR,True,2096,101,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,a58a83a302bd061a77a5675f6156d5347084f51e,refactor(pubsub): move pubsub script and deps to their own directory
58,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/90,90,feat(scripts): implement a pubsub import script,"Fixes #89. Fixes mozilla/fxa#866.

Ports the existing main import script to node and slaps a pubsub-friendly interface on it. ~~Still in progress/untested. Doesn't yet include @shane-tomlinson's logic for ignoring configured client ids.~~",philbooth,64367,2019-04-29T19:57:25Z,CONTRIBUTOR,True,2096,101,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,9be92bcf3b14b665c6055c1fcea9c738d0705b17,feat(pubsub): postpone message.ack until both payloads are sent
59,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/90,90,feat(scripts): implement a pubsub import script,"Fixes #89. Fixes mozilla/fxa#866.

Ports the existing main import script to node and slaps a pubsub-friendly interface on it. ~~Still in progress/untested. Doesn't yet include @shane-tomlinson's logic for ignoring configured client ids.~~",philbooth,64367,2019-04-29T19:57:25Z,CONTRIBUTOR,True,2096,101,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,4906c16df8f7ddc1d47e8dbfd5e8c7488f35e252,fix(pubsub): stop generating unique subscriptions on every run
60,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/90,90,feat(scripts): implement a pubsub import script,"Fixes #89. Fixes mozilla/fxa#866.

Ports the existing main import script to node and slaps a pubsub-friendly interface on it. ~~Still in progress/untested. Doesn't yet include @shane-tomlinson's logic for ignoring configured client ids.~~",philbooth,64367,2019-04-29T19:57:25Z,CONTRIBUTOR,True,2096,101,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,86a4fd5082e62f287b12488448f20a7f80b8ea3b,feat(docker): Add Dockerfile for pubsub script
61,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/90,90,feat(scripts): implement a pubsub import script,"Fixes #89. Fixes mozilla/fxa#866.

Ports the existing main import script to node and slaps a pubsub-friendly interface on it. ~~Still in progress/untested. Doesn't yet include @shane-tomlinson's logic for ignoring configured client ids.~~",philbooth,64367,2019-04-29T19:57:25Z,CONTRIBUTOR,True,2096,101,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,25500699a9adcadbda7d74edfd4850289f6f8992,chore(pubsub): set default worker count to 1
62,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/90,90,feat(scripts): implement a pubsub import script,"Fixes #89. Fixes mozilla/fxa#866.

Ports the existing main import script to node and slaps a pubsub-friendly interface on it. ~~Still in progress/untested. Doesn't yet include @shane-tomlinson's logic for ignoring configured client ids.~~",philbooth,64367,2019-04-29T19:57:25Z,CONTRIBUTOR,True,2096,101,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,52d00916ab1ed40762661145989cb698c049d74d,fix(pubsub): tolerate already-deleted messages during clean-up
63,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/88,88,Add Mozilla Code of Conduct,"Fixes #87


As of January 1 2019, Mozilla requires that all GitHub projects include this [CODE_OF_CONDUCT.md](https://github.com/mozilla/repo-templates/blob/master/templates/CODE_OF_CONDUCT.md) file in the project root. The file has two parts:

1. Required Text - All text under the headings *Community Participation Guidelines and How to Report*, are required, and should not be altered.
2. Optional Text - The Project Specific Etiquette heading provides a space to speak more specifically about ways people can work effectively and inclusively together. Some examples of those can be found on the [Firefox Debugger](https://github.com/devtools-html/debugger.html/blob/master/CODE_OF_CONDUCT.md) project, and [Common Voice](https://github.com/mozilla/voice-web/blob/master/CODE_OF_CONDUCT.md). (The optional part is commented out in the [raw template file](https://raw.githubusercontent.com/mozilla/repo-templates/blob/master/templates/CODE_OF_CONDUCT.md), and will not be visible until you modify and uncomment that part.)

If you have any questions about this file, or Code of Conduct policies and procedures, please see [Mozilla-GitHub-Standards](https://wiki.mozilla.org/GitHub/Repository_Requirements) or email Mozilla-GitHub-Standards+CoC@mozilla.com.

_(Message COC002)_",Mozilla-GitHub-Standards,48073334,2019-03-30T06:40:48Z,CONTRIBUTOR,True,15,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,329b68ef5ddeaa1a2fac52b104af29ae466a68ec,"Add Mozilla Code of Conduct file

Fixes #87.

_(Message COC002)_"
64,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/85,85,WIP GCP support,,jbuck,578466,2019-02-14T01:15:38Z,MEMBER,False,746,21,5,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,2e68a27b45a40c71f135c990a2cf332cb98a2ace,WIP
65,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/84,84,Ensure that Debian stretch is being used and add required library,Fixes #83 ,jbuck,578466,2019-02-06T16:15:38Z,MEMBER,True,5,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,a83559932e7b96805875e6de737e8e64b02e706b,Ensure that Debian stretch is being used and add required library
66,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/82,82,Enable CircleCI integration,,jbuck,578466,2019-02-04T20:03:57Z,MEMBER,True,77,16,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,575361c22a4d5215b22b5ec2cff53b5ef697f047,Enable CircleCI integration
67,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/81,81,feat(sync): add retry and backoff logic to sync amplitude import,"See discussion at https://github.com/mozilla/fxa-activity-metrics/issues/125#issuecomment-459163068.

@jbuck, this is not properly tested but what I had in mind for backing off in the face of 429s from Amplitude. 30 seconds seems like an excessive interval I know, but it's what they mandate in [the docs](https://amplitude.zendesk.com/hc/en-us/articles/204771828-HTTP-API).

r?",philbooth,64367,2019-01-31T10:56:08Z,CONTRIBUTOR,True,32,9,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,37cacb3e621d87b7c95730f8f3a9d1fa2a960ec1,feat(sync): add retry and backoff logic to sync amplitude import
68,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/81,81,feat(sync): add retry and backoff logic to sync amplitude import,"See discussion at https://github.com/mozilla/fxa-activity-metrics/issues/125#issuecomment-459163068.

@jbuck, this is not properly tested but what I had in mind for backing off in the face of 429s from Amplitude. 30 seconds seems like an excessive interval I know, but it's what they mandate in [the docs](https://amplitude.zendesk.com/hc/en-us/articles/204771828-HTTP-API).

r?",philbooth,64367,2019-01-31T10:56:08Z,CONTRIBUTOR,True,32,9,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,a233401f458ac6fd26b46dc693fd324e157faf78,fix(sync): serialise requests to the amplitude api
69,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/79,79,feat(scripts): convert the sync import scripts to be docker-friendly,"Fixes #68.

@jbuck, I haven't tested this out yet, but it's what I have in mind to get the sync import working with the existing `Dockerfile-nodejs`.

The invocation in `cloudops-deployment` would look something like:

```
docker run -e AWS_REGION -e FXA_AMPLITUDE_API_KEY -e SYNC_INSERTID_HMAC_KEY -e SQS_QUEUE_URL --network=host --rm ${marketing_amplitude_send_docker_image} node bin/sync.js events
```

Just fyi.",philbooth,64367,2018-12-21T14:11:10Z,CONTRIBUTOR,True,129,141,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,a6020e09a8af694ae7d171506130ceaa341d2210,feat(scripts): convert the sync import scripts to be docker-friendly
70,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/78,78,fix(scripts): fix lint errors in marketing scripts,"FIxes #77.

@mozilla/fxa-devs r?",philbooth,64367,2018-12-21T14:01:59Z,CONTRIBUTOR,True,515,580,6,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,0cd18aeeb250b88bdcc50ccf050427145717b085,chore(scripts): add MPL preamble
71,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/78,78,fix(scripts): fix lint errors in marketing scripts,"FIxes #77.

@mozilla/fxa-devs r?",philbooth,64367,2018-12-21T14:01:59Z,CONTRIBUTOR,True,515,580,6,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,823a05300c4ff8d2214b9159c746d6d16d913504,fix(scripts): fix lint errors in marketing scripts
72,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/71,71,Add nodejs docker image,,jbuck,578466,2018-07-18T18:53:43Z,MEMBER,True,19,0,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,9751a8bb3a0c349f0e323f0fd0f6a4a49ce1aaa8,Add nodejs docker image
73,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/69,69,Sprinkle some async/await all over the place,,jbuck,578466,2018-07-09T22:24:38Z,MEMBER,True,457,365,5,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,7c6158aca17bcf8711d114c4544e35f3f9d7e879,Split local filesystem & SQS/S3 inputs
74,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/69,69,Sprinkle some async/await all over the place,,jbuck,578466,2018-07-09T22:24:38Z,MEMBER,True,457,365,5,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,fe34e4fac4112616fdc40e8022a9763ba3877bfd,Sprinkle some async/await all over the place
75,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/69,69,Sprinkle some async/await all over the place,,jbuck,578466,2018-07-09T22:24:38Z,MEMBER,True,457,365,5,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,d3e8319f5fd53e33ec6766b29977cb3f00efef27,Use async for handling multiple HTTP requests in flight
76,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/69,69,Sprinkle some async/await all over the place,,jbuck,578466,2018-07-09T22:24:38Z,MEMBER,True,457,365,5,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,67ce2904f51d48ded54faaf3530d20517ab72c32,Review fixes
77,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/57,57,feat(fxa): map content server flow data to amplitude,"Between 14-Mar-2018 and 19-Mar-2018, the content server instances ran out of disk IOPS because of increased logging caused by heavy traffic from Fx 59. One outcome of this is that we're missing a bunch of events in Amplitude. In order to backfill the lost events, this PR adds a new script that recreates Amplitude events from flow events, which we happen to have lying around in S3.

The transformation process is not perfect. For instance, we don't have the `device_id` property in the flow data, and it's used to calculate the `insert_id` when present. Since the `insert_id` is what Amplitude uses to deduplicate events, this is a pretty important caveat.

So, in order for this script to be useful, we need one of the following things to be true:

* We know that the events that made it to Amplitude did not contain a `device_id`, ensuring that the recreated events will have a consistent `insert_id`. My hunch is that this is true for many content server events but not all, although I can't be certain.

* We've been able to somehow delete from Amplitude all content server events for the days that we are re-importing. Seems tricky, although maybe it's possible if we ask them.

* We are able to deduplicate the events ourselves pre-import, by comparing the uid, timestamp and event type for each event to the events that made it in to Amplitude. This one is doable, but the work is for a different script.",philbooth,64367,2018-03-20T16:39:57Z,CONTRIBUTOR,False,425,62,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,aa03c22b5792029449c39f7790602ac8de4cf7c0,"feat(fxa): map content server flow data to amplitude

Between 14-Mar-2018 and 19-Mar-2018, the content server instances ran
out of disk IOPS because of increased logging caused by heavy traffic
from Fx 59. In order to backfill the lost events, this change adds a
new script that recreates Amplitude events from flow events, which we
keep around in an S3 bucket.

The transformation process is not perfect. For instance, we don't have
the device_id property in the flow data, and it's used to calculate the
insert_id when present. Since the insert_id is what Amplitude uses to
deduplicate events, this is a pretty important caveat.

So, in order for this script to be useful, we need one of the following
things to be true:

* We know that the events that made it to Amplitude did not contain a
  device_id. My hunch is that this is true for most content server
  events, but I can't be certain.

* We can ask Amplitude to delete all content server events for the days
  that we are re-importing. Seems unlikely, although we haven't asked
  the question.

* We are able to deduplicate the events ourselves, by comparing the uid,
  timestamp and event type to the events that made it to Amplitde. This
  one should definitely be true, but that is for a different script."
78,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/47,47,feat(sync): send sync_complete event to amplitude,"Fixes #45.

Seems to work okay, but I'm going to hold off merging for a while because this is a much bigger data set and I wonder if we're going to hit any rate-limits.

It's using the submission data for the `time` property, which means every event will have the same timestamp for each day. There is a timestamp in the data but it's generated client-side, so is dependent on the system time on client machines. I figure accuracy trumps precision, but happy to change that if it's wrong.
",philbooth,64367,2018-02-23T13:57:10Z,CONTRIBUTOR,True,518,376,8,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,1785888998f92ca5d5f2ecbece4aeaeb539871de,feat(sync): send sync_complete event to amplitude
79,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/41,41,Changes to make reading from many files more easily,"@philbooth I made some changes to the script here to make it easier to run this script on a larger corpus of data. It does have some problems still when running on an entire day's worth of data:

```
$ node ~/bin/check-events.js fxa-content/2018/01/17/* fxa-auth/2018/01/17/*

<--- Last few GCs --->

[540:0x25e94c0]   273831 ms: Mark-sweep 1355.1 (1418.9) -> 1355.1 (1419.4) MB, 1295.8 / 0.0 ms  allocation failure GC in old space requested
[540:0x25e94c0]   275133 ms: Mark-sweep 1355.1 (1419.4) -> 1355.1 (1387.4) MB, 1302.3 / 0.0 ms  last resort GC in old space requested
[540:0x25e94c0]   276424 ms: Mark-sweep 1355.1 (1387.4) -> 1355.1 (1387.4) MB, 1291.1 / 0.0 ms  last resort GC in old space requested


<--- JS stacktrace --->

==== JS stack trace =========================================

Security context: 0x330b38525501 <JSObject>
    1: stringSlice(aka stringSlice) [buffer.js:590] [bytecode=0x3c418ef68c71 offset=94](this=0x1eab3ce022d1 <undefined>,buf=0x30aa42202251 <Uint8Array map = 0x34beddb45331>,encoding=0x330b38534ea9 <String[4]: utf8>,start=0,end=20246089)
    2: toString [buffer.js:664] [bytecode=0x3c418ef688b9 offset=148](this=0x30aa42202251 <Uint8Array map = 0x34beddb45331>,encoding=0x330b38534ea9 <String[4]: ut...

FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory
 1: node::Abort() [node]
 2: 0x11f155c [node]
 3: v8::Utils::ReportOOMFailure(char const*, bool) [node]
 4: v8::internal::V8::FatalProcessOutOfMemory(char const*, bool) [node]
 5: v8::internal::Factory::NewRawTwoByteString(int, v8::internal::PretenureFlag) [node]
 6: v8::internal::Factory::NewStringFromUtf8(v8::internal::Vector<char const>, v8::internal::PretenureFlag) [node]
 7: v8::String::NewFromUtf8(v8::Isolate*, char const*, v8::NewStringType, int) [node]
 8: node::StringBytes::Encode(v8::Isolate*, char const*, unsigned long, node::encoding, v8::Local<v8::Value>*) [node]
 9: 0x120b392 [node]
10: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) [node]
11: 0xb7e37c [node]
12: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) [node]
13: 0x3c3eed842fd
Aborted

```

But it works pretty well when only using an hours worth of data. I'm not sure removing the time changes is the right path, I just did it to have it work.",jbuck,578466,2018-01-26T21:49:35Z,MEMBER,True,16,49,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,d1b423f3769b0d4cafcfe752054401edfc08c3e9,testing
80,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/41,41,Changes to make reading from many files more easily,"@philbooth I made some changes to the script here to make it easier to run this script on a larger corpus of data. It does have some problems still when running on an entire day's worth of data:

```
$ node ~/bin/check-events.js fxa-content/2018/01/17/* fxa-auth/2018/01/17/*

<--- Last few GCs --->

[540:0x25e94c0]   273831 ms: Mark-sweep 1355.1 (1418.9) -> 1355.1 (1419.4) MB, 1295.8 / 0.0 ms  allocation failure GC in old space requested
[540:0x25e94c0]   275133 ms: Mark-sweep 1355.1 (1419.4) -> 1355.1 (1387.4) MB, 1302.3 / 0.0 ms  last resort GC in old space requested
[540:0x25e94c0]   276424 ms: Mark-sweep 1355.1 (1387.4) -> 1355.1 (1387.4) MB, 1291.1 / 0.0 ms  last resort GC in old space requested


<--- JS stacktrace --->

==== JS stack trace =========================================

Security context: 0x330b38525501 <JSObject>
    1: stringSlice(aka stringSlice) [buffer.js:590] [bytecode=0x3c418ef68c71 offset=94](this=0x1eab3ce022d1 <undefined>,buf=0x30aa42202251 <Uint8Array map = 0x34beddb45331>,encoding=0x330b38534ea9 <String[4]: utf8>,start=0,end=20246089)
    2: toString [buffer.js:664] [bytecode=0x3c418ef688b9 offset=148](this=0x30aa42202251 <Uint8Array map = 0x34beddb45331>,encoding=0x330b38534ea9 <String[4]: ut...

FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory
 1: node::Abort() [node]
 2: 0x11f155c [node]
 3: v8::Utils::ReportOOMFailure(char const*, bool) [node]
 4: v8::internal::V8::FatalProcessOutOfMemory(char const*, bool) [node]
 5: v8::internal::Factory::NewRawTwoByteString(int, v8::internal::PretenureFlag) [node]
 6: v8::internal::Factory::NewStringFromUtf8(v8::internal::Vector<char const>, v8::internal::PretenureFlag) [node]
 7: v8::String::NewFromUtf8(v8::Isolate*, char const*, v8::NewStringType, int) [node]
 8: node::StringBytes::Encode(v8::Isolate*, char const*, unsigned long, node::encoding, v8::Local<v8::Value>*) [node]
 9: 0x120b392 [node]
10: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) [node]
11: 0xb7e37c [node]
12: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) [node]
13: 0x3c3eed842fd
Aborted

```

But it works pretty well when only using an hours worth of data. I'm not sure removing the time changes is the right path, I just did it to have it work.",jbuck,578466,2018-01-26T21:49:35Z,MEMBER,True,16,49,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,6447d760b3ac80fa85087cf41f2c08b41f66fde7,testing
81,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/41,41,Changes to make reading from many files more easily,"@philbooth I made some changes to the script here to make it easier to run this script on a larger corpus of data. It does have some problems still when running on an entire day's worth of data:

```
$ node ~/bin/check-events.js fxa-content/2018/01/17/* fxa-auth/2018/01/17/*

<--- Last few GCs --->

[540:0x25e94c0]   273831 ms: Mark-sweep 1355.1 (1418.9) -> 1355.1 (1419.4) MB, 1295.8 / 0.0 ms  allocation failure GC in old space requested
[540:0x25e94c0]   275133 ms: Mark-sweep 1355.1 (1419.4) -> 1355.1 (1387.4) MB, 1302.3 / 0.0 ms  last resort GC in old space requested
[540:0x25e94c0]   276424 ms: Mark-sweep 1355.1 (1387.4) -> 1355.1 (1387.4) MB, 1291.1 / 0.0 ms  last resort GC in old space requested


<--- JS stacktrace --->

==== JS stack trace =========================================

Security context: 0x330b38525501 <JSObject>
    1: stringSlice(aka stringSlice) [buffer.js:590] [bytecode=0x3c418ef68c71 offset=94](this=0x1eab3ce022d1 <undefined>,buf=0x30aa42202251 <Uint8Array map = 0x34beddb45331>,encoding=0x330b38534ea9 <String[4]: utf8>,start=0,end=20246089)
    2: toString [buffer.js:664] [bytecode=0x3c418ef688b9 offset=148](this=0x30aa42202251 <Uint8Array map = 0x34beddb45331>,encoding=0x330b38534ea9 <String[4]: ut...

FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory
 1: node::Abort() [node]
 2: 0x11f155c [node]
 3: v8::Utils::ReportOOMFailure(char const*, bool) [node]
 4: v8::internal::V8::FatalProcessOutOfMemory(char const*, bool) [node]
 5: v8::internal::Factory::NewRawTwoByteString(int, v8::internal::PretenureFlag) [node]
 6: v8::internal::Factory::NewStringFromUtf8(v8::internal::Vector<char const>, v8::internal::PretenureFlag) [node]
 7: v8::String::NewFromUtf8(v8::Isolate*, char const*, v8::NewStringType, int) [node]
 8: node::StringBytes::Encode(v8::Isolate*, char const*, unsigned long, node::encoding, v8::Local<v8::Value>*) [node]
 9: 0x120b392 [node]
10: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) [node]
11: 0xb7e37c [node]
12: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) [node]
13: 0x3c3eed842fd
Aborted

```

But it works pretty well when only using an hours worth of data. I'm not sure removing the time changes is the right path, I just did it to have it work.",jbuck,578466,2018-01-26T21:49:35Z,MEMBER,True,16,49,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,4dace3e697590be0f3f66ed9c9535be040b0646b,testing
82,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/41,41,Changes to make reading from many files more easily,"@philbooth I made some changes to the script here to make it easier to run this script on a larger corpus of data. It does have some problems still when running on an entire day's worth of data:

```
$ node ~/bin/check-events.js fxa-content/2018/01/17/* fxa-auth/2018/01/17/*

<--- Last few GCs --->

[540:0x25e94c0]   273831 ms: Mark-sweep 1355.1 (1418.9) -> 1355.1 (1419.4) MB, 1295.8 / 0.0 ms  allocation failure GC in old space requested
[540:0x25e94c0]   275133 ms: Mark-sweep 1355.1 (1419.4) -> 1355.1 (1387.4) MB, 1302.3 / 0.0 ms  last resort GC in old space requested
[540:0x25e94c0]   276424 ms: Mark-sweep 1355.1 (1387.4) -> 1355.1 (1387.4) MB, 1291.1 / 0.0 ms  last resort GC in old space requested


<--- JS stacktrace --->

==== JS stack trace =========================================

Security context: 0x330b38525501 <JSObject>
    1: stringSlice(aka stringSlice) [buffer.js:590] [bytecode=0x3c418ef68c71 offset=94](this=0x1eab3ce022d1 <undefined>,buf=0x30aa42202251 <Uint8Array map = 0x34beddb45331>,encoding=0x330b38534ea9 <String[4]: utf8>,start=0,end=20246089)
    2: toString [buffer.js:664] [bytecode=0x3c418ef688b9 offset=148](this=0x30aa42202251 <Uint8Array map = 0x34beddb45331>,encoding=0x330b38534ea9 <String[4]: ut...

FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory
 1: node::Abort() [node]
 2: 0x11f155c [node]
 3: v8::Utils::ReportOOMFailure(char const*, bool) [node]
 4: v8::internal::V8::FatalProcessOutOfMemory(char const*, bool) [node]
 5: v8::internal::Factory::NewRawTwoByteString(int, v8::internal::PretenureFlag) [node]
 6: v8::internal::Factory::NewStringFromUtf8(v8::internal::Vector<char const>, v8::internal::PretenureFlag) [node]
 7: v8::String::NewFromUtf8(v8::Isolate*, char const*, v8::NewStringType, int) [node]
 8: node::StringBytes::Encode(v8::Isolate*, char const*, unsigned long, node::encoding, v8::Local<v8::Value>*) [node]
 9: 0x120b392 [node]
10: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) [node]
11: 0xb7e37c [node]
12: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) [node]
13: 0x3c3eed842fd
Aborted

```

But it works pretty well when only using an hours worth of data. I'm not sure removing the time changes is the right path, I just did it to have it work.",jbuck,578466,2018-01-26T21:49:35Z,MEMBER,True,16,49,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,aab95cb24418dd041c16bb6fc559c7603b47edd5,testing
83,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/41,41,Changes to make reading from many files more easily,"@philbooth I made some changes to the script here to make it easier to run this script on a larger corpus of data. It does have some problems still when running on an entire day's worth of data:

```
$ node ~/bin/check-events.js fxa-content/2018/01/17/* fxa-auth/2018/01/17/*

<--- Last few GCs --->

[540:0x25e94c0]   273831 ms: Mark-sweep 1355.1 (1418.9) -> 1355.1 (1419.4) MB, 1295.8 / 0.0 ms  allocation failure GC in old space requested
[540:0x25e94c0]   275133 ms: Mark-sweep 1355.1 (1419.4) -> 1355.1 (1387.4) MB, 1302.3 / 0.0 ms  last resort GC in old space requested
[540:0x25e94c0]   276424 ms: Mark-sweep 1355.1 (1387.4) -> 1355.1 (1387.4) MB, 1291.1 / 0.0 ms  last resort GC in old space requested


<--- JS stacktrace --->

==== JS stack trace =========================================

Security context: 0x330b38525501 <JSObject>
    1: stringSlice(aka stringSlice) [buffer.js:590] [bytecode=0x3c418ef68c71 offset=94](this=0x1eab3ce022d1 <undefined>,buf=0x30aa42202251 <Uint8Array map = 0x34beddb45331>,encoding=0x330b38534ea9 <String[4]: utf8>,start=0,end=20246089)
    2: toString [buffer.js:664] [bytecode=0x3c418ef688b9 offset=148](this=0x30aa42202251 <Uint8Array map = 0x34beddb45331>,encoding=0x330b38534ea9 <String[4]: ut...

FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory
 1: node::Abort() [node]
 2: 0x11f155c [node]
 3: v8::Utils::ReportOOMFailure(char const*, bool) [node]
 4: v8::internal::V8::FatalProcessOutOfMemory(char const*, bool) [node]
 5: v8::internal::Factory::NewRawTwoByteString(int, v8::internal::PretenureFlag) [node]
 6: v8::internal::Factory::NewStringFromUtf8(v8::internal::Vector<char const>, v8::internal::PretenureFlag) [node]
 7: v8::String::NewFromUtf8(v8::Isolate*, char const*, v8::NewStringType, int) [node]
 8: node::StringBytes::Encode(v8::Isolate*, char const*, unsigned long, node::encoding, v8::Local<v8::Value>*) [node]
 9: 0x120b392 [node]
10: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) [node]
11: 0xb7e37c [node]
12: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) [node]
13: 0x3c3eed842fd
Aborted

```

But it works pretty well when only using an hours worth of data. I'm not sure removing the time changes is the right path, I just did it to have it work.",jbuck,578466,2018-01-26T21:49:35Z,MEMBER,True,16,49,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,e1b9f7376351ff6ee5241b85572f6bcb5e81ba3d,testing
84,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,56ee15bd4ef08c755cd4a56099bc1b178f489256,feat(debug): add a script to check raw event logs for potential issues
85,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,5c3de1652b2cbbc848db98700d0cebd3b7b3b3eb,fix(debug): apply fixes from our debugging session
86,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,de1a5b2619ed7688c89f4eadda5dce2e3aac70a3,fix(debug): make missingDeviceAndSessionIds mutually exclusive
87,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,4d9136d1bb328047b82185dc7283db735f7f01c1,feat(debug): split stats into separate content and auth arrays
88,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,132ea7aa2652c37b5cd4f4e1608a345b944ceb73,refactor(debug): extract some common boilerplate code to functions
89,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,eb0eab11460aba898dfffa10ee02c21c07208dc3,feat(debug): check for conflicting user_ids
90,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,4793a4b4268fb038fa0bd67286838f778249d0bc,feat(debug): check for missing user_ids
91,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,467d1ebe9b0b02ef64e0c0545d392f87888d3f5c,feat(debug): report percentages
92,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,11378c7f57b26f73f5d17061cba6d3f4e3d25c82,fix(debug): report content and auth stats on separate lines
93,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,d987fad48f448f7d27447cde6aefed4748fddf82,fix(debug): add check for missing user_id and session_id
94,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,d39a3856033afb5e9c794c860595b99d327958e8,fix(debug): fix variable name / undefined reference
95,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/39,39,feat(debug): add a script to check raw event logs for potential issues,"Not sure whether we want to merge this or not, it depends whether it helps us debug #27.

Anyway, the idea is that we can run this against raw logs from a time when the problem exists and a time when the problem doesn't exist, and it will help us zero in on specific events that have issues. There's no logic for downloading from S3 or unzipping the data, so those steps are pre-requisites to running the script.

Once you have the logs in a directory somewhere, `cd` into it and run this script. It takes two arguments, a `from` time and an `until` time, both in the format `YYYY-MM-DD-hh-mm`. The script will process all log files for that time range in the current working directory, reporting:

* The total count of events processed across all files
* The count of those that were content server events
* The count of those that were auth server events
* The count that were missing a `device_id` property
* The count that were missing a `session_id` property
* The count that had a `session_id` property greater than the timestamp of the log file
* The count that had a `time` property greater than the timestamp of the log file
* The count of auth server events where the `device_id` for a particular user and session doesn't match the value from the content server events
* The count of auth server events where the `session_id` for a particular user and device doesn't match the value from the content server events

Those are based on the hypotheses put forward in #27, we can add further checks as we think of them.

There is also a `VERBOSE` mode that can be triggered by flipping the switch on line 10 (we can change that to a command line switch if this is going to stick around). Running in that mode will output all of the flagged events, the file they came from and their line number in the file.

My thinking regarding usage is to run in non-verbose mode across a wide range of data and gradually try to zero in on a smaller window that shows a problem. Then, when it's been pinned down to just a few log files, we can flip on `VERBOSE` mode and take a look at the specific events.

No idea if this will help us get to the bottom of things, me and @jbuck have a debug session to try it out shortly. Hopefully it works!
",philbooth,64367,2018-01-25T15:11:18Z,CONTRIBUTOR,True,245,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,75877cc938af1da301e108426b6987ce414024d9,"Changes to make reading from many files more easily

https://github.com/mozilla/fxa-amplitude-send/pull/41
r=philbooth"
96,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/38,38,feat(marketing): add script for sending marketing events from csv data,"@rfk, @jbuck, this is a script to process the marketing email event CSV format and send it to Amplitude. There's a fair amount of duplication with the proposed sync script for #36, so we should be able to extract the common stuff as they land.

Should be nothing too surprising hopefully, the only small gotcha was the CSV we received was UTF-16 encoded, so I've added an encoding detection/transform step before piping data to the CSV parser. Happily, unlike the parquet parser, this one operates on a stream so we don't have to download the entire file before processing it.

I'm sticking a `WIP` label on this until we actually have the automated exports dumping to S3 and can verify that part of the code (the S3 bit is untested so far).

Co-authored with @jbuck.",philbooth,64367,2018-01-14T12:29:56Z,CONTRIBUTOR,True,488,122,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,0e1495f362bc9b0fd53d5fe85a9778fc9504ee9a,feat(marketing): add script for sending marketing events from csv data
97,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/38,38,feat(marketing): add script for sending marketing events from csv data,"@rfk, @jbuck, this is a script to process the marketing email event CSV format and send it to Amplitude. There's a fair amount of duplication with the proposed sync script for #36, so we should be able to extract the common stuff as they land.

Should be nothing too surprising hopefully, the only small gotcha was the CSV we received was UTF-16 encoded, so I've added an encoding detection/transform step before piping data to the CSV parser. Happily, unlike the parquet parser, this one operates on a stream so we don't have to download the entire file before processing it.

I'm sticking a `WIP` label on this until we actually have the automated exports dumping to S3 and can verify that part of the code (the S3 bit is untested so far).

Co-authored with @jbuck.",philbooth,64367,2018-01-14T12:29:56Z,CONTRIBUTOR,True,488,122,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,0744b310ad34a61639d85222d0b3db4633f021da,fix(marketing): hash the user_id before sending
98,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/38,38,feat(marketing): add script for sending marketing events from csv data,"@rfk, @jbuck, this is a script to process the marketing email event CSV format and send it to Amplitude. There's a fair amount of duplication with the proposed sync script for #36, so we should be able to extract the common stuff as they land.

Should be nothing too surprising hopefully, the only small gotcha was the CSV we received was UTF-16 encoded, so I've added an encoding detection/transform step before piping data to the CSV parser. Happily, unlike the parquet parser, this one operates on a stream so we don't have to download the entire file before processing it.

I'm sticking a `WIP` label on this until we actually have the automated exports dumping to S3 and can verify that part of the code (the S3 bit is untested so far).

Co-authored with @jbuck.",philbooth,64367,2018-01-14T12:29:56Z,CONTRIBUTOR,True,488,122,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,c8cb29285a376200e475d36ddad06b8d90b40927,Switch event type format parser to match data
99,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/38,38,feat(marketing): add script for sending marketing events from csv data,"@rfk, @jbuck, this is a script to process the marketing email event CSV format and send it to Amplitude. There's a fair amount of duplication with the proposed sync script for #36, so we should be able to extract the common stuff as they land.

Should be nothing too surprising hopefully, the only small gotcha was the CSV we received was UTF-16 encoded, so I've added an encoding detection/transform step before piping data to the CSV parser. Happily, unlike the parquet parser, this one operates on a stream so we don't have to download the entire file before processing it.

I'm sticking a `WIP` label on this until we actually have the automated exports dumping to S3 and can verify that part of the code (the S3 bit is untested so far).

Co-authored with @jbuck.",philbooth,64367,2018-01-14T12:29:56Z,CONTRIBUTOR,True,488,122,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,4ab571b1ce05f8446437b488e33e127aad21c4ea,Switch to moment for date & time parsing
100,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/38,38,feat(marketing): add script for sending marketing events from csv data,"@rfk, @jbuck, this is a script to process the marketing email event CSV format and send it to Amplitude. There's a fair amount of duplication with the proposed sync script for #36, so we should be able to extract the common stuff as they land.

Should be nothing too surprising hopefully, the only small gotcha was the CSV we received was UTF-16 encoded, so I've added an encoding detection/transform step before piping data to the CSV parser. Happily, unlike the parquet parser, this one operates on a stream so we don't have to download the entire file before processing it.

I'm sticking a `WIP` label on this until we actually have the automated exports dumping to S3 and can verify that part of the code (the S3 bit is untested so far).

Co-authored with @jbuck.",philbooth,64367,2018-01-14T12:29:56Z,CONTRIBUTOR,True,488,122,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,511e1073d3c5e6e3f0bc9b6d80f358d94cfd6e66,fix(marketing): fix lint errors
101,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/38,38,feat(marketing): add script for sending marketing events from csv data,"@rfk, @jbuck, this is a script to process the marketing email event CSV format and send it to Amplitude. There's a fair amount of duplication with the proposed sync script for #36, so we should be able to extract the common stuff as they land.

Should be nothing too surprising hopefully, the only small gotcha was the CSV we received was UTF-16 encoded, so I've added an encoding detection/transform step before piping data to the CSV parser. Happily, unlike the parquet parser, this one operates on a stream so we don't have to download the entire file before processing it.

I'm sticking a `WIP` label on this until we actually have the automated exports dumping to S3 and can verify that part of the code (the S3 bit is untested so far).

Co-authored with @jbuck.",philbooth,64367,2018-01-14T12:29:56Z,CONTRIBUTOR,True,488,122,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,a2ebbaa93b4ff8dfb5b7d453cd265f875d34b8db,fix(marketing): prefer underscores to hyphens in event names
102,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/38,38,feat(marketing): add script for sending marketing events from csv data,"@rfk, @jbuck, this is a script to process the marketing email event CSV format and send it to Amplitude. There's a fair amount of duplication with the proposed sync script for #36, so we should be able to extract the common stuff as they land.

Should be nothing too surprising hopefully, the only small gotcha was the CSV we received was UTF-16 encoded, so I've added an encoding detection/transform step before piping data to the CSV parser. Happily, unlike the parquet parser, this one operates on a stream so we don't have to download the entire file before processing it.

I'm sticking a `WIP` label on this until we actually have the automated exports dumping to S3 and can verify that part of the code (the S3 bit is untested so far).

Co-authored with @jbuck.",philbooth,64367,2018-01-14T12:29:56Z,CONTRIBUTOR,True,488,122,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,f897609b5e47970d500f6b775533e2a1750b2ce1,Ensure correct timezone when parsing
103,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/38,38,feat(marketing): add script for sending marketing events from csv data,"@rfk, @jbuck, this is a script to process the marketing email event CSV format and send it to Amplitude. There's a fair amount of duplication with the proposed sync script for #36, so we should be able to extract the common stuff as they land.

Should be nothing too surprising hopefully, the only small gotcha was the CSV we received was UTF-16 encoded, so I've added an encoding detection/transform step before piping data to the CSV parser. Happily, unlike the parquet parser, this one operates on a stream so we don't have to download the entire file before processing it.

I'm sticking a `WIP` label on this until we actually have the automated exports dumping to S3 and can verify that part of the code (the S3 bit is untested so far).

Co-authored with @jbuck.",philbooth,64367,2018-01-14T12:29:56Z,CONTRIBUTOR,True,488,122,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,3a1b91b25e92439fe64b90aa9334909f1f5d14dd,Add DNS caching
104,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/38,38,feat(marketing): add script for sending marketing events from csv data,"@rfk, @jbuck, this is a script to process the marketing email event CSV format and send it to Amplitude. There's a fair amount of duplication with the proposed sync script for #36, so we should be able to extract the common stuff as they land.

Should be nothing too surprising hopefully, the only small gotcha was the CSV we received was UTF-16 encoded, so I've added an encoding detection/transform step before piping data to the CSV parser. Happily, unlike the parquet parser, this one operates on a stream so we don't have to download the entire file before processing it.

I'm sticking a `WIP` label on this until we actually have the automated exports dumping to S3 and can verify that part of the code (the S3 bit is untested so far).

Co-authored with @jbuck.",philbooth,64367,2018-01-14T12:29:56Z,CONTRIBUTOR,True,488,122,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,f0f766266e89fbd449a0eda25150b47f9f96cc21,Bail on any errors & only exit after requests are done
105,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/38,38,feat(marketing): add script for sending marketing events from csv data,"@rfk, @jbuck, this is a script to process the marketing email event CSV format and send it to Amplitude. There's a fair amount of duplication with the proposed sync script for #36, so we should be able to extract the common stuff as they land.

Should be nothing too surprising hopefully, the only small gotcha was the CSV we received was UTF-16 encoded, so I've added an encoding detection/transform step before piping data to the CSV parser. Happily, unlike the parquet parser, this one operates on a stream so we don't have to download the entire file before processing it.

I'm sticking a `WIP` label on this until we actually have the automated exports dumping to S3 and can verify that part of the code (the S3 bit is untested so far).

Co-authored with @jbuck.",philbooth,64367,2018-01-14T12:29:56Z,CONTRIBUTOR,True,488,122,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,24fcf5a4379f4172fd5c39c276a7a9c2048f074d,chore(marketing): fix lint errors
106,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/38,38,feat(marketing): add script for sending marketing events from csv data,"@rfk, @jbuck, this is a script to process the marketing email event CSV format and send it to Amplitude. There's a fair amount of duplication with the proposed sync script for #36, so we should be able to extract the common stuff as they land.

Should be nothing too surprising hopefully, the only small gotcha was the CSV we received was UTF-16 encoded, so I've added an encoding detection/transform step before piping data to the CSV parser. Happily, unlike the parquet parser, this one operates on a stream so we don't have to download the entire file before processing it.

I'm sticking a `WIP` label on this until we actually have the automated exports dumping to S3 and can verify that part of the code (the S3 bit is untested so far).

Co-authored with @jbuck.",philbooth,64367,2018-01-14T12:29:56Z,CONTRIBUTOR,True,488,122,4,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,5b7293681dc6cd77595b4c56c51b0c31affcd3f5,Merge branch 'master' into phil/marketing
107,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/37,37,fix(zlib): flush the zlib decompressor,"Fixes #35.

@jbuck r? (when you're back on FxA stuff and have time)",philbooth,64367,2018-01-11T12:16:56Z,CONTRIBUTOR,True,5,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,eebf68d5bfd37ce049f6836b8f1d734e4b007d22,fix(zlib): flush the zlib decompressor
108,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/36,36,feat(sync): send sync telemetry events to amplitude,"Fixes #24.

This is still a WIP because I need a little bit of assistance from @jbuck to polish it off. Opened for early review now though as I'm on PTO again next week until the second week of January. And maybe there is some common code here with @jbuck's work on porting the main script to node, which we can extract to some kind of helper module to eliminate duplication. Plus boilerplate like linter the settings etc should be something we agree on for all the scripts (obviously).

The main guts of the script works correctly, I've used it to successfully send events to our dev Amplitude project. The s3 part is untested because I didn't know what to set for `FXA_AWS_ACCESS_KEY` and `FXA_AWS_SECRET_KEY`, or where to find them (sorry).

Some other noteworthy points:

* Using Python didn't work because pyarrow fails with `pyarrow.lib.ArrowNotImplementedError` when you try to access `event_map_values`. We need that column and node-parquet reads it correctly.

* Four events are implemented: `sync - tab_sent`, `sync - tab_received`, `sync - repair_triggered` and `sync - repair_success`. I think those are the only ones we can determine from telemetry data, others are going to have to come from the server side (which may be a good thing given the timestamp situation).

* Only the desktop client sends telemetry pings, which is presumably responsible for e.g. there being more tab_sent than there are tab_received.

* We have no precise timestamp for the events, because the event time uses monotonic timestamps based relative to when the Firefox process started. We can't extrapolate an absolute event time from those so instead, I'm using the `serverTime` telemetry property. That corresponds to the most recent value for the `X-Weave-Timestamp` header when the event occurred, which will sometimes be stale but it's the best we can do.

* I'm not sending `device_id` yet, because there's no way to link it with the `device_id` we're sending for FxA stuff (yet).

* I'm not sending a `session_id`, even though Sync's flowid is kind of almost synonymous-ish, because Amplitude needs `session_id` to be a timestamp.

* `app_version` is set to the  Firefox version, whereas the FxA events set it to train number. Is that going to cause any problems for people making charts?

* `ua_version` doesn't exactly match up with the FxA events, because the version string from Sync telemetry is more detailed than I'm sending for FxA. We can fix that one way or the other if it's a problem.

@jbuck r?

/cc @rfk",philbooth,64367,2017-12-15T15:18:29Z,CONTRIBUTOR,True,2206,0,8,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,b213d6e4c9b0b3503ac1599e5cc73fcc815fc233,feat(sync): send sync telemetry events to amplitude
109,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/36,36,feat(sync): send sync telemetry events to amplitude,"Fixes #24.

This is still a WIP because I need a little bit of assistance from @jbuck to polish it off. Opened for early review now though as I'm on PTO again next week until the second week of January. And maybe there is some common code here with @jbuck's work on porting the main script to node, which we can extract to some kind of helper module to eliminate duplication. Plus boilerplate like linter the settings etc should be something we agree on for all the scripts (obviously).

The main guts of the script works correctly, I've used it to successfully send events to our dev Amplitude project. The s3 part is untested because I didn't know what to set for `FXA_AWS_ACCESS_KEY` and `FXA_AWS_SECRET_KEY`, or where to find them (sorry).

Some other noteworthy points:

* Using Python didn't work because pyarrow fails with `pyarrow.lib.ArrowNotImplementedError` when you try to access `event_map_values`. We need that column and node-parquet reads it correctly.

* Four events are implemented: `sync - tab_sent`, `sync - tab_received`, `sync - repair_triggered` and `sync - repair_success`. I think those are the only ones we can determine from telemetry data, others are going to have to come from the server side (which may be a good thing given the timestamp situation).

* Only the desktop client sends telemetry pings, which is presumably responsible for e.g. there being more tab_sent than there are tab_received.

* We have no precise timestamp for the events, because the event time uses monotonic timestamps based relative to when the Firefox process started. We can't extrapolate an absolute event time from those so instead, I'm using the `serverTime` telemetry property. That corresponds to the most recent value for the `X-Weave-Timestamp` header when the event occurred, which will sometimes be stale but it's the best we can do.

* I'm not sending `device_id` yet, because there's no way to link it with the `device_id` we're sending for FxA stuff (yet).

* I'm not sending a `session_id`, even though Sync's flowid is kind of almost synonymous-ish, because Amplitude needs `session_id` to be a timestamp.

* `app_version` is set to the  Firefox version, whereas the FxA events set it to train number. Is that going to cause any problems for people making charts?

* `ua_version` doesn't exactly match up with the FxA events, because the version string from Sync telemetry is more detailed than I'm sending for FxA. We can fix that one way or the other if it's a problem.

@jbuck r?

/cc @rfk",philbooth,64367,2017-12-15T15:18:29Z,CONTRIBUTOR,True,2206,0,8,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,40384c9bd02e062482841520a8eaebbff81059fb,fix(sync): implement schema changes from 2018-01-30
110,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/36,36,feat(sync): send sync telemetry events to amplitude,"Fixes #24.

This is still a WIP because I need a little bit of assistance from @jbuck to polish it off. Opened for early review now though as I'm on PTO again next week until the second week of January. And maybe there is some common code here with @jbuck's work on porting the main script to node, which we can extract to some kind of helper module to eliminate duplication. Plus boilerplate like linter the settings etc should be something we agree on for all the scripts (obviously).

The main guts of the script works correctly, I've used it to successfully send events to our dev Amplitude project. The s3 part is untested because I didn't know what to set for `FXA_AWS_ACCESS_KEY` and `FXA_AWS_SECRET_KEY`, or where to find them (sorry).

Some other noteworthy points:

* Using Python didn't work because pyarrow fails with `pyarrow.lib.ArrowNotImplementedError` when you try to access `event_map_values`. We need that column and node-parquet reads it correctly.

* Four events are implemented: `sync - tab_sent`, `sync - tab_received`, `sync - repair_triggered` and `sync - repair_success`. I think those are the only ones we can determine from telemetry data, others are going to have to come from the server side (which may be a good thing given the timestamp situation).

* Only the desktop client sends telemetry pings, which is presumably responsible for e.g. there being more tab_sent than there are tab_received.

* We have no precise timestamp for the events, because the event time uses monotonic timestamps based relative to when the Firefox process started. We can't extrapolate an absolute event time from those so instead, I'm using the `serverTime` telemetry property. That corresponds to the most recent value for the `X-Weave-Timestamp` header when the event occurred, which will sometimes be stale but it's the best we can do.

* I'm not sending `device_id` yet, because there's no way to link it with the `device_id` we're sending for FxA stuff (yet).

* I'm not sending a `session_id`, even though Sync's flowid is kind of almost synonymous-ish, because Amplitude needs `session_id` to be a timestamp.

* `app_version` is set to the  Firefox version, whereas the FxA events set it to train number. Is that going to cause any problems for people making charts?

* `ua_version` doesn't exactly match up with the FxA events, because the version string from Sync telemetry is more detailed than I'm sending for FxA. We can fix that one way or the other if it's a problem.

@jbuck r?

/cc @rfk",philbooth,64367,2017-12-15T15:18:29Z,CONTRIBUTOR,True,2206,0,8,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,da091b292a6de0ccb19501cc7e291972dbe55459,feat(sync): add rudimentary state for cron
111,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/36,36,feat(sync): send sync telemetry events to amplitude,"Fixes #24.

This is still a WIP because I need a little bit of assistance from @jbuck to polish it off. Opened for early review now though as I'm on PTO again next week until the second week of January. And maybe there is some common code here with @jbuck's work on porting the main script to node, which we can extract to some kind of helper module to eliminate duplication. Plus boilerplate like linter the settings etc should be something we agree on for all the scripts (obviously).

The main guts of the script works correctly, I've used it to successfully send events to our dev Amplitude project. The s3 part is untested because I didn't know what to set for `FXA_AWS_ACCESS_KEY` and `FXA_AWS_SECRET_KEY`, or where to find them (sorry).

Some other noteworthy points:

* Using Python didn't work because pyarrow fails with `pyarrow.lib.ArrowNotImplementedError` when you try to access `event_map_values`. We need that column and node-parquet reads it correctly.

* Four events are implemented: `sync - tab_sent`, `sync - tab_received`, `sync - repair_triggered` and `sync - repair_success`. I think those are the only ones we can determine from telemetry data, others are going to have to come from the server side (which may be a good thing given the timestamp situation).

* Only the desktop client sends telemetry pings, which is presumably responsible for e.g. there being more tab_sent than there are tab_received.

* We have no precise timestamp for the events, because the event time uses monotonic timestamps based relative to when the Firefox process started. We can't extrapolate an absolute event time from those so instead, I'm using the `serverTime` telemetry property. That corresponds to the most recent value for the `X-Weave-Timestamp` header when the event occurred, which will sometimes be stale but it's the best we can do.

* I'm not sending `device_id` yet, because there's no way to link it with the `device_id` we're sending for FxA stuff (yet).

* I'm not sending a `session_id`, even though Sync's flowid is kind of almost synonymous-ish, because Amplitude needs `session_id` to be a timestamp.

* `app_version` is set to the  Firefox version, whereas the FxA events set it to train number. Is that going to cause any problems for people making charts?

* `ua_version` doesn't exactly match up with the FxA events, because the version string from Sync telemetry is more detailed than I'm sending for FxA. We can fix that one way or the other if it's a problem.

@jbuck r?

/cc @rfk",philbooth,64367,2017-12-15T15:18:29Z,CONTRIBUTOR,True,2206,0,8,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,b8c297df08a7cf6fc0b496770c08aac2c495c1d1,refactor(lint): inherit eslint rules from fxa/server
112,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/36,36,feat(sync): send sync telemetry events to amplitude,"Fixes #24.

This is still a WIP because I need a little bit of assistance from @jbuck to polish it off. Opened for early review now though as I'm on PTO again next week until the second week of January. And maybe there is some common code here with @jbuck's work on porting the main script to node, which we can extract to some kind of helper module to eliminate duplication. Plus boilerplate like linter the settings etc should be something we agree on for all the scripts (obviously).

The main guts of the script works correctly, I've used it to successfully send events to our dev Amplitude project. The s3 part is untested because I didn't know what to set for `FXA_AWS_ACCESS_KEY` and `FXA_AWS_SECRET_KEY`, or where to find them (sorry).

Some other noteworthy points:

* Using Python didn't work because pyarrow fails with `pyarrow.lib.ArrowNotImplementedError` when you try to access `event_map_values`. We need that column and node-parquet reads it correctly.

* Four events are implemented: `sync - tab_sent`, `sync - tab_received`, `sync - repair_triggered` and `sync - repair_success`. I think those are the only ones we can determine from telemetry data, others are going to have to come from the server side (which may be a good thing given the timestamp situation).

* Only the desktop client sends telemetry pings, which is presumably responsible for e.g. there being more tab_sent than there are tab_received.

* We have no precise timestamp for the events, because the event time uses monotonic timestamps based relative to when the Firefox process started. We can't extrapolate an absolute event time from those so instead, I'm using the `serverTime` telemetry property. That corresponds to the most recent value for the `X-Weave-Timestamp` header when the event occurred, which will sometimes be stale but it's the best we can do.

* I'm not sending `device_id` yet, because there's no way to link it with the `device_id` we're sending for FxA stuff (yet).

* I'm not sending a `session_id`, even though Sync's flowid is kind of almost synonymous-ish, because Amplitude needs `session_id` to be a timestamp.

* `app_version` is set to the  Firefox version, whereas the FxA events set it to train number. Is that going to cause any problems for people making charts?

* `ua_version` doesn't exactly match up with the FxA events, because the version string from Sync telemetry is more detailed than I'm sending for FxA. We can fix that one way or the other if it's a problem.

@jbuck r?

/cc @rfk",philbooth,64367,2017-12-15T15:18:29Z,CONTRIBUTOR,True,2206,0,8,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,eb66bd517f17dd3fec7bbea96f0f9e2fb19ee7aa,fix(sync): parse schema from input data
113,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/18,18,Sketch of using a pool of worker threads for sending,"@philbooth I couldn't find the code I used for sending events in the demo integration, I think I must have deleted it :-(

Nontheless, here's a sketch of what it looked like.  Untested, but I've use this pattern successfully in the past so hopefully it can be a useful starting point.

Another option here would be to try to use some of the new async I/O stuff that's in Python 3, if it's easier to migrate this to python3 than to do a full-on port to nodejs.",rfk,34695,2017-10-04T05:00:15Z,MEMBER,True,82,14,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,932df34fcdb24c3ac51d74137358bb1dd1a282ee,Sketch of using a pool of worker threads for sending
114,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/18,18,Sketch of using a pool of worker threads for sending,"@philbooth I couldn't find the code I used for sending events in the demo integration, I think I must have deleted it :-(

Nontheless, here's a sketch of what it looked like.  Untested, but I've use this pattern successfully in the past so hopefully it can be a useful starting point.

Another option here would be to try to use some of the new async I/O stuff that's in Python 3, if it's easier to migrate this to python3 than to do a full-on port to nodejs.",rfk,34695,2017-10-04T05:00:15Z,MEMBER,True,82,14,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,17decb588f745c9b6fe48632dd303d806e785ac0,wip: missing argument to process
115,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/18,18,Sketch of using a pool of worker threads for sending,"@philbooth I couldn't find the code I used for sending events in the demo integration, I think I must have deleted it :-(

Nontheless, here's a sketch of what it looked like.  Untested, but I've use this pattern successfully in the past so hopefully it can be a useful starting point.

Another option here would be to try to use some of the new async I/O stuff that's in Python 3, if it's easier to migrate this to python3 than to do a full-on port to nodejs.",rfk,34695,2017-10-04T05:00:15Z,MEMBER,True,82,14,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,c0f22127b1c78f50703f88ede785fa838b3e39d6,wip: missing argument to process_compressed
116,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/18,18,Sketch of using a pool of worker threads for sending,"@philbooth I couldn't find the code I used for sending events in the demo integration, I think I must have deleted it :-(

Nontheless, here's a sketch of what it looked like.  Untested, but I've use this pattern successfully in the past so hopefully it can be a useful starting point.

Another option here would be to try to use some of the new async I/O stuff that's in Python 3, if it's easier to migrate this to python3 than to do a full-on port to nodejs.",rfk,34695,2017-10-04T05:00:15Z,MEMBER,True,82,14,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,62d0569f001ff6ed0036933edb6ca465b92f5493,wip: read thread count from env
117,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/16,16,fix(logs): silence some of the log noise,@jbuck r?,philbooth,64367,2017-10-02T16:58:28Z,CONTRIBUTOR,True,0,2,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,501740633be5ea12e1b80509845945d3e48efc24,fix(logs): silence some of the log noise
118,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/15,15,feat(fn): send to the identify api off the main thread,"@jbuck, here's a better approach to fixing the Lambda timeouts for when you get in on Monday.

For our schema, it's mostly fine for failed requests to the Identify API to be non-fatal because we only use `$append` and we have plenty of duplication that will trigger retries for us. So we can treat those requests as fire-and-forget and move the slowness off the main thread.

Doing this also means we can reinstate the sleeps between event batches that ensure we stay on the right side of the HTTP API rate limit.

In hindsight, I should have realised that the Idenitfy API would be slower than the HTTP API. The latter is expressly advertised as handling 1000 events per second per project, whereas the docs for the former make no such claims. Lumping our requests to both of them into the same thread was silly of me.

r?",philbooth,64367,2017-09-30T09:57:14Z,CONTRIBUTOR,False,20,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,98177f7a4f2e84fb3669e2d7947baf69d4d28398,feat(fn): send to the identify api off the main thread
119,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/15,15,feat(fn): send to the identify api off the main thread,"@jbuck, here's a better approach to fixing the Lambda timeouts for when you get in on Monday.

For our schema, it's mostly fine for failed requests to the Identify API to be non-fatal because we only use `$append` and we have plenty of duplication that will trigger retries for us. So we can treat those requests as fire-and-forget and move the slowness off the main thread.

Doing this also means we can reinstate the sleeps between event batches that ensure we stay on the right side of the HTTP API rate limit.

In hindsight, I should have realised that the Idenitfy API would be slower than the HTTP API. The latter is expressly advertised as handling 1000 events per second per project, whereas the docs for the former make no such claims. Lumping our requests to both of them into the same thread was silly of me.

r?",philbooth,64367,2017-09-30T09:57:14Z,CONTRIBUTOR,False,20,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,1e9956ac56d91984355294863310c848e4b3faed,"fix(fn): reinstate sleep between event batches

This reverts commit bb21ab24ba09c037580757cefcc755c043ce0bbf."
120,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/15,15,feat(fn): send to the identify api off the main thread,"@jbuck, here's a better approach to fixing the Lambda timeouts for when you get in on Monday.

For our schema, it's mostly fine for failed requests to the Identify API to be non-fatal because we only use `$append` and we have plenty of duplication that will trigger retries for us. So we can treat those requests as fire-and-forget and move the slowness off the main thread.

Doing this also means we can reinstate the sleeps between event batches that ensure we stay on the right side of the HTTP API rate limit.

In hindsight, I should have realised that the Idenitfy API would be slower than the HTTP API. The latter is expressly advertised as handling 1000 events per second per project, whereas the docs for the former make no such claims. Lumping our requests to both of them into the same thread was silly of me.

r?",philbooth,64367,2017-09-30T09:57:14Z,CONTRIBUTOR,False,20,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,27c61e4b174428bb8fcb86c1cd21d773290042ee,Merge branch 'master' into phil/concurrent-identify
121,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/14,14,fix(sleep): Don't sleep in-between batch sends,,jbuck,578466,2017-09-29T19:01:09Z,MEMBER,True,0,10,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,890c14e3d6a43b867581a226264eb50cb06e4099,fix(sleep): Don't sleep in-between batch sends
122,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/13,13,fix(fn): don't send identify data to the http api,"Fixes #12.

Splits out `$append` verbs for sending to the Identify API, leaving everything else to continue as before to the HTTP API. There is some rudimentary batching logic which keeps batch size for the Identify API less than or equal to batch size for the HTTP API.

@jbuck r? / want to give it a try in stage?",philbooth,64367,2017-09-29T14:22:47Z,CONTRIBUTOR,True,51,25,2,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,8bfc95e0a94519206d6a4346c87875bb9a611229,chore(fn): move zlib magic closer to explaining comment
123,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/13,13,fix(fn): don't send identify data to the http api,"Fixes #12.

Splits out `$append` verbs for sending to the Identify API, leaving everything else to continue as before to the HTTP API. There is some rudimentary batching logic which keeps batch size for the Identify API less than or equal to batch size for the HTTP API.

@jbuck r? / want to give it a try in stage?",philbooth,64367,2017-09-29T14:22:47Z,CONTRIBUTOR,True,51,25,2,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,3addb85b30d231ae8cae5d6f0b4f13ae82c65cd5,fix(fn): don't send identify data to the http api
124,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/13,13,fix(fn): don't send identify data to the http api,"Fixes #12.

Splits out `$append` verbs for sending to the Identify API, leaving everything else to continue as before to the HTTP API. There is some rudimentary batching logic which keeps batch size for the Identify API less than or equal to batch size for the HTTP API.

@jbuck r? / want to give it a try in stage?",philbooth,64367,2017-09-29T14:22:47Z,CONTRIBUTOR,True,51,25,2,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,d85f96a9c1c1be99749ae24443157d749710112a,fix(fn): group identify payloads in to batches
125,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/13,13,fix(fn): don't send identify data to the http api,"Fixes #12.

Splits out `$append` verbs for sending to the Identify API, leaving everything else to continue as before to the HTTP API. There is some rudimentary batching logic which keeps batch size for the Identify API less than or equal to batch size for the HTTP API.

@jbuck r? / want to give it a try in stage?",philbooth,64367,2017-09-29T14:22:47Z,CONTRIBUTOR,True,51,25,2,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,b1e1507c5daf0025519818cdb7c027e257cdf72a,fix(fn): don't send to identify api unless there is data
126,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/11,11,Faster Docker build,,jbuck,578466,2017-09-25T18:19:37Z,MEMBER,True,4,3,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,87040dc22d1ee0976c5359fd5ed653d3fb3f65f0,Faster Docker build
127,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/10,10,Fixes for S3,,jbuck,578466,2017-09-25T18:18:45Z,MEMBER,True,10,5,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,29de886fc645549ec96a4ae2a0c1e5f51bc1f1f5,Fixes for S3
128,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/10,10,Fixes for S3,,jbuck,578466,2017-09-25T18:18:45Z,MEMBER,True,10,5,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,416cb0cfda4d9a7a9b72dc95014e58fbe22863a3,"wip: jbuck, does this work?"
129,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/4,4,Add KMS decryption for sensitive environment variables,,jbuck,578466,2017-09-22T03:33:19Z,MEMBER,True,17,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,22667a2c66d1f40f0dc2c2237f02039a84a046cd,KMS environment variable decryption
130,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/4,4,Add KMS decryption for sensitive environment variables,,jbuck,578466,2017-09-22T03:33:19Z,MEMBER,True,17,0,1,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,c19718b0c928e344fc71ddf20aad74aaa6fe07b2,wip: fix key error
131,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/3,3,Build zip suitable for AWS Lambda consumption,,jbuck,578466,2017-09-22T03:15:31Z,MEMBER,True,22,1,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,d72c74105aac5d00a466107e19a3c72879d01245,Build zip suitable for AWS Lambda consumption
132,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/3,3,Build zip suitable for AWS Lambda consumption,,jbuck,578466,2017-09-22T03:15:31Z,MEMBER,True,22,1,3,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,9493fe7f2d0e30855047c73283e5b68ec49d9956,chore(build): make package phony target
133,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,727ac5b9e55204d6a4eb27a41819e39e529c88b0,feat(fn): send events to amplitude
134,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,c53ac04c120ea1ec29da13697303861e53649f9e,fix(fn): remove unused environment variables
135,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,797f5cb0d952ef45109a7793605647e30c589501,fix(fn): migrate to boto3's excellent and user-friendly api
136,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,7a4f1ffc988f125f80b83269c68ce2c5c0d361dd,fix(fn): assert message contains one record inside handler
137,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,12733f7b74d30d455f72b3c8047ce4812e393e78,fix(fn): pop events from the end of the list
138,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,91501be33bc4e56ee0cf7fea50a1d15b2860ed8f,fix(fn): ditch threading timer in favour of time.sleep
139,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,3f59c9c0d2bf37be8de1cdad161705698e4a24d9,"fix(fn): reinstate message loop inside handler function

This reverts commit 7a4f1ffc988f125f80b83269c68ce2c5c0d361dd."
140,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,48a2295958b2120f0a8033e357a9895584ebc189,fix(fn): remove errant whitespace
141,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,8dbf6abc0a7ec54d8eb484da2ca9dabbe33e698c,fix(fn): clear batch after sending
142,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,877c3a1577a9840965aa7c1df0454e9e35791369,fix(fn): read events from stdin if not passed on command line
143,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,548c744a5251e21beca3abcd552e7cd9a13d45d5,fix(fn): prefer response.raise_for_status to manual exception
144,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,f707d8efb9e187e7938ed42c73f8e641c54e89f0,chore(fn): include some temporary debug logging
145,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,13ab2dfa2c11358eba67c1ca2b8532383dc2e800,chore(fn): add todo comment
146,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,b506058d0ecd7398eff896ac67676dd76abbb279,"feat(fn): crude, inefficient zlib decompression"
147,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,957da1ed6d8f5b869b7d945abe29c01e1c8a67a0,fix(fn): send data to amplitude while downloading/decompressing
148,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,83adaed7185cdb65aa486376566634744ff208a6,fix(fn): postpone incomplete batches while downloading is in progress
149,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,ca2d1eb5f21042165fcd9fcd2dc32e8a8cfc330b,"fix(fn): fix stupid, stupid runtime errors"
150,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,d827a2dabc040ad447fcc7d1461ebf000cef3764,fix(fn): wbits=0 didn't work for me locally
151,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,3fe7c4b65ee370f224e96f84e7a0a26088ad759b,feat(fn): accept path to gzipped data on cmdline
152,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,88599ae8ea525f0336a5ed484d858ee95c1a8263,chore(fn): more temporary debug logging
153,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,3021adfffa7864f507e39ff053c7669b679fd3f2,fix(fn): unpack events before checking them
154,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,29db2ed15e443700824f7651790cf6bf8c3c0b54,fix(fn): tolerate malformed events
155,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,5dd770d847d59c914373482189c561c4ba95845c,fix(fn): handle all the different packing formats
156,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,95838c039a51fde4988c6ce466e060383d88703f,fix(fn): move magic number to named variable
157,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/2,2,feat(fn): send events to amplitude,"Fixes mozilla/fxa-auth-server#2044. Fixes mozilla/fxa-content-server#5350.

This is my second attempt at a logging 2.0 function that sends data to Amplitude, superceding #1. Differences from the previous PR are:

* The `handler` function now expects an [AWS event message](http://docs.aws.amazon.com/AmazonS3/latest/dev/notification-content-structure.html) rather than a log line.
* The `handler` function is responsible for reading log lines from S3.
* A separate `process` function is broken out for easier testing/back-filling from the command line.
* Events include an `insert_id` to enable Amplitude deduplication in case of errors.
* Events are sent in batches of 10 per request to the Amplitude API.
* Batches are dispatched at intervals of at least 10 milliseconds to hopefully avoid rate-limiting (more on that inline).

@jbuck r?
",philbooth,64367,2017-09-18T12:12:56Z,CONTRIBUTOR,True,203,10,7,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,e3368716b8323556aa6d9816b4660a7d5127c8a5,fix(tests): update fixture data for recent formatting fixes
158,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/1,1,feat(fn): basic sending to Amplitude with no error handling,"This is my first stab at a logging 2.0 function that does basic per-event sending to Amplitude. Tested against the `FxAccts_Dev` project using the fixture data in this PR, it works okay as far as it goes. But it doesn't try to do any error handling yet because I'm still not sure about a couple of things.

Firstly, regarding rate-limits, [the docs say](https://amplitude.zendesk.com/hc/en-us/articles/204771828-HTTP-API#upload-limit):

> Limit your upload to 100 batches/sec and 1000 events/sec. You can batch events into an upload but we recommend not sending more than 10 events per batch. Thus, we expect at most 100 batches to be sent per second, and so the 1000 events/sec limit still applies as we do not recommend sending more than 10 events per batch. Note: This applies to customers on our Starter Plan only. 
>
> For paying customers, please reach out to us if you need to send more than 1000 events/sec. There is no hard limit on the Amplitude Enterprise plan. However, please note that we will throttle requests for individual devices that exceed 60 events/second as stated in the below HTTP status codes section.

I take a couple of things from this:

1. Assuming that doing so is straightforward, it makes sense for us to batch events in to groups of 10. @jbuck, is it possible for logging 2.0 to invoke us in batches of 10 log lines rather than for every line individually?

2. Based on some very sketchy back-of-a-fag-packet figuring-out, I think we'll definitely hit the rate limit in prod if we don't batch events, but we probably won't if we send batches of 10. Either way, I guess it's a good idea to begin that conversation with them about rate limits on the Enterprise plan. @davismtl?

Next, for sane error handling, we really want to include an `insert_id` with each request, but doing that requires statefulness and I'm not sure how to approach that within the context of logging 2.0 / AWS Lambda. Also, if we start wading into murkier waters of retry logic and exponential backoff, I'm not sure what limits there are for the lifetime of a logging 2.0 function invocation and how we should handle any timeouts arriving thereof. Do we need to guarantee all data is sent to Amplitude or is some level of lossage acceptable? @jbuck, @rfk, any wisdom to impart here?

Finally, code reviews for what's here so far are welcome, @mozilla/fxa-devs r?",philbooth,64367,2017-09-12T11:37:58Z,CONTRIBUTOR,False,63,6,6,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,7e5219240130bc67c9fd21f0fc0022f7e1a51f9e,feat(fn): basic sending with no error handling
159,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/1,1,feat(fn): basic sending to Amplitude with no error handling,"This is my first stab at a logging 2.0 function that does basic per-event sending to Amplitude. Tested against the `FxAccts_Dev` project using the fixture data in this PR, it works okay as far as it goes. But it doesn't try to do any error handling yet because I'm still not sure about a couple of things.

Firstly, regarding rate-limits, [the docs say](https://amplitude.zendesk.com/hc/en-us/articles/204771828-HTTP-API#upload-limit):

> Limit your upload to 100 batches/sec and 1000 events/sec. You can batch events into an upload but we recommend not sending more than 10 events per batch. Thus, we expect at most 100 batches to be sent per second, and so the 1000 events/sec limit still applies as we do not recommend sending more than 10 events per batch. Note: This applies to customers on our Starter Plan only. 
>
> For paying customers, please reach out to us if you need to send more than 1000 events/sec. There is no hard limit on the Amplitude Enterprise plan. However, please note that we will throttle requests for individual devices that exceed 60 events/second as stated in the below HTTP status codes section.

I take a couple of things from this:

1. Assuming that doing so is straightforward, it makes sense for us to batch events in to groups of 10. @jbuck, is it possible for logging 2.0 to invoke us in batches of 10 log lines rather than for every line individually?

2. Based on some very sketchy back-of-a-fag-packet figuring-out, I think we'll definitely hit the rate limit in prod if we don't batch events, but we probably won't if we send batches of 10. Either way, I guess it's a good idea to begin that conversation with them about rate limits on the Enterprise plan. @davismtl?

Next, for sane error handling, we really want to include an `insert_id` with each request, but doing that requires statefulness and I'm not sure how to approach that within the context of logging 2.0 / AWS Lambda. Also, if we start wading into murkier waters of retry logic and exponential backoff, I'm not sure what limits there are for the lifetime of a logging 2.0 function invocation and how we should handle any timeouts arriving thereof. Do we need to guarantee all data is sent to Amplitude or is some level of lossage acceptable? @jbuck, @rfk, any wisdom to impart here?

Finally, code reviews for what's here so far are welcome, @mozilla/fxa-devs r?",philbooth,64367,2017-09-12T11:37:58Z,CONTRIBUTOR,False,63,6,6,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,250194ceda3a6538fca76a4252ee0cc71f843ee7,fix(fn): remove redundant fxa_uid user property
160,https://api.github.com/repos/mozilla/fxa-amplitude-send/pulls/1,1,feat(fn): basic sending to Amplitude with no error handling,"This is my first stab at a logging 2.0 function that does basic per-event sending to Amplitude. Tested against the `FxAccts_Dev` project using the fixture data in this PR, it works okay as far as it goes. But it doesn't try to do any error handling yet because I'm still not sure about a couple of things.

Firstly, regarding rate-limits, [the docs say](https://amplitude.zendesk.com/hc/en-us/articles/204771828-HTTP-API#upload-limit):

> Limit your upload to 100 batches/sec and 1000 events/sec. You can batch events into an upload but we recommend not sending more than 10 events per batch. Thus, we expect at most 100 batches to be sent per second, and so the 1000 events/sec limit still applies as we do not recommend sending more than 10 events per batch. Note: This applies to customers on our Starter Plan only. 
>
> For paying customers, please reach out to us if you need to send more than 1000 events/sec. There is no hard limit on the Amplitude Enterprise plan. However, please note that we will throttle requests for individual devices that exceed 60 events/second as stated in the below HTTP status codes section.

I take a couple of things from this:

1. Assuming that doing so is straightforward, it makes sense for us to batch events in to groups of 10. @jbuck, is it possible for logging 2.0 to invoke us in batches of 10 log lines rather than for every line individually?

2. Based on some very sketchy back-of-a-fag-packet figuring-out, I think we'll definitely hit the rate limit in prod if we don't batch events, but we probably won't if we send batches of 10. Either way, I guess it's a good idea to begin that conversation with them about rate limits on the Enterprise plan. @davismtl?

Next, for sane error handling, we really want to include an `insert_id` with each request, but doing that requires statefulness and I'm not sure how to approach that within the context of logging 2.0 / AWS Lambda. Also, if we start wading into murkier waters of retry logic and exponential backoff, I'm not sure what limits there are for the lifetime of a logging 2.0 function invocation and how we should handle any timeouts arriving thereof. Do we need to guarantee all data is sent to Amplitude or is some level of lossage acceptable? @jbuck, @rfk, any wisdom to impart here?

Finally, code reviews for what's here so far are welcome, @mozilla/fxa-devs r?",philbooth,64367,2017-09-12T11:37:58Z,CONTRIBUTOR,False,63,6,6,Data pipeline scripts for importing Firefox Accounts event data to Amplitude.,JavaScript,48ab6628c3a0048b24102399b0a5e0cd9dfc6930,feat(fn): add insert_id to event
