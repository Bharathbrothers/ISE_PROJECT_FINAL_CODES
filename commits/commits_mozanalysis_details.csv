,reponame,commitid,commitmsg,commitauthor,commitauthordate,comauthorlogin,shaauthorlogin,stats_total,stats_addns,stats_delns
0,mozanalysis,4da5c25c7bed32087d3b692a2338f0dc8ee02ca8,Add search ads metric,benmiroglio,2019-03-12T22:32:55Z,benmiroglio,benmiroglio,43,43,0
1,mozanalysis,505951a34f71e1ea3a2a66a2794cf7ca4a4d57b6,"Merge pull request #28 from mozilla/tests-refactor

Tests refactor",Rob Hudson,2019-02-07T17:27:13Z,robhudson,robhudson,102,52,50
2,mozanalysis,55e2fd5fa41652f2d82775370e240069d5df870e,Made spark context global,Rob Hudson,2019-02-07T17:05:40Z,robhudson,robhudson,51,26,25
3,mozanalysis,f17703f81f384d342ee3afe328aa0f5ea307723d,python black reformatting,Rob Hudson,2019-02-06T23:11:31Z,robhudson,robhudson,51,26,25
4,mozanalysis,7319175bc905220fa6d249f2d61a994b85ac6ec7,"Add the `contrib` namespace, and two util fns. (#26)

The contrib namespace is a place for code that is being re-used
across multiple reports/investigations, and may or may not be ready
for others to start using it yet. One day this code dreams of being
promoted out of contrib and into the main package. Until then,
others are welcome to look at and even use your code, but should
not be surprised when breaking changes are silently made. If they
want reliability, then they should ask for/help with its promotion
out of contrib.",Felix Lawrence,2019-01-31T23:29:45Z,felixlawrence,felixlawrence,217,216,1
5,mozanalysis,d95cb0244dd68ac0a9a1ce2f72e30abf71f08001,"Merge pull request #25 from mozilla/stats-docs

Add `mozanalysis.stats` to docs",Rob Hudson,2019-01-23T19:19:11Z,robhudson,robhudson,26,16,10
6,mozanalysis,884a5ec60f47f91c220ccd2c57fba55b75bfdf88,Add `mozanalysis.stats` docs,Rob Hudson,2019-01-23T19:08:59Z,robhudson,robhudson,26,16,10
7,mozanalysis,6bf84e221932594e1ddacff4357990aefed03ab5,"Merge pull request #24 from mozilla/docs

Add docs",Rob Hudson,2019-01-17T22:04:48Z,robhudson,robhudson,650,579,71
8,mozanalysis,4538813ec466e5b0883ae7558b3d4d76b424d3b1,Add docs deploy via CircleCI config,Rob Hudson,2019-01-17T19:01:02Z,robhudson,robhudson,286,276,10
9,mozanalysis,60f37a192a59615c365ca6839c8b9466cfee968c,"Don't unpersist persisted datasets (#23)

In order to avoid persisting DataFrames unnecessarily or unpersisting
DataFrames that users wanted to touch interactively after calling
analyze(), try to leave the cache state of DataFrames the way we found
it when analyze() was invoked.

`is_cached` is an undocumented DataFrame property, so be defensive about
accessing it in case a future Spark version removes it.",Tim D. Smith,2019-01-14T20:31:18Z,tdsmith,tdsmith,22,21,1
10,mozanalysis,682f78f71e8ce9d7279053024bf259c1fd89ca74,"Build UDF API docs

pyspark needs to be importable, so add the testing extra.
We'll also use the napoleon extension, to be able to write Google-style
docstrings.",Tim Smith,2019-01-11T19:29:05Z,tdsmith,tdsmith,7,7,0
11,mozanalysis,9534f4cd3e06c17d7bba5b10a8eaf04ee20ea2bc,Fix up formatting of UDF docstrings,Tim Smith,2019-01-11T19:28:41Z,tdsmith,tdsmith,139,72,67
12,mozanalysis,c3840253d1ecf31d8962d13efbb296a7cf790821,Continue adding skeleton documentation,Tim Smith,2019-01-11T19:30:16Z,tdsmith,tdsmith,27,22,5
13,mozanalysis,a7623f51cec87227835eec46eb72324130515f29,"Start adding documentation

Run sphinx-quickstart and add sphinx to tox.",Tim Smith,2019-01-05T01:38:09Z,tdsmith,tdsmith,215,214,1
14,mozanalysis,600948d96676e54a2033aeb6cd198c09f6f84b8b,Fix release number,Rob Hudson,2018-12-05T16:44:01Z,robhudson,robhudson,2,1,1
15,mozanalysis,fca9cb81318ab91ec633b104c6bc0ee695923cb5,Update changelog for 2018.12.1 release,Rob Hudson,2018-12-05T16:24:39Z,robhudson,robhudson,11,11,0
16,mozanalysis,a4ca99278f5f65a019879f887867830a37c89809,Run through Python formatting with black,Rob Hudson,2018-12-05T16:17:30Z,robhudson,robhudson,29,13,16
17,mozanalysis,a0169d484c618b2e24352497409bccbc01674e08,"Merge pull request #19 from tdsmith/intensity-definition

Fix intensity definition",Rob Hudson,2018-12-05T16:09:42Z,robhudson,robhudson,8,4,4
18,mozanalysis,fd9c19452862cf9b5fd72b60f0e37e8d1027e585,Update tests,Tim Smith,2018-12-05T15:54:52Z,tdsmith,tdsmith,6,3,3
19,mozanalysis,268b2852ef1dde738bea6a476726abcd299d8710,"Fix intensity definition

Per e.g.
https://metrics.mozilla.com/protected/sguha/shield_bootstrap.html,
intensity should be active_hours / total_hours, so that it ends up
generally being a fraction on [0, 1].",Tim Smith,2018-12-05T04:50:10Z,tdsmith,tdsmith,2,1,1
20,mozanalysis,ed09cb999cc28fded5b13b858e8ddb30d92fe4ef,"Merge pull request #18 from tdsmith/udfs

Add some UDFs",Rob Hudson,2018-11-27T22:49:33Z,robhudson,robhudson,312,311,1
21,mozanalysis,05ca0f6c6be9623ba49563f2ece893366cdc3302,Empty commit,Tim Smith,2018-11-27T22:40:27Z,tdsmith,tdsmith,0,0,0
22,mozanalysis,65f72358f868e0b125efca22b980be94e5d1fdf6,Add tests for histogram threshold UDF,Tim Smith,2018-11-23T17:29:58Z,tdsmith,tdsmith,35,35,0
23,mozanalysis,072b4b693c275784ef57e3c9ef5a9f7a3dac49c8,"Add UDF for thresholding histograms

Computes the fraction of values in a histogram equal to or exceeding a particular value.",Tim Smith,2018-11-23T17:16:54Z,tdsmith,tdsmith,86,85,1
24,mozanalysis,f425515c5cf8719c4c0407e9b508482e82676da6,Test the histogram UDFs together,Tim Smith,2018-11-22T00:43:43Z,tdsmith,tdsmith,19,7,12
25,mozanalysis,d8bb69a290e16a8933822e01ad6e263461b787d5,Add some UDFs,Tim Smith,2018-11-22T00:12:04Z,tdsmith,tdsmith,198,197,1
26,mozanalysis,32337021b401f88d53c58f08c27f4d33830fd2e4,"Merge pull request #17 from tdsmith/tidy-tests

Make the tests a little more concise?",Rob Hudson,2018-11-27T19:41:47Z,robhudson,robhudson,50,23,27
27,mozanalysis,f21dadda7172fbd9c8ca2028fc7acafd604a51a6,Restore explanatory comments,Tim Smith,2018-11-26T19:36:47Z,tdsmith,tdsmith,4,4,0
28,mozanalysis,12100233d6990feb8c8816422044973c2a4b47b4,Make the tests a little more concise,Tim Smith,2018-11-21T22:39:03Z,tdsmith,tdsmith,46,19,27
29,mozanalysis,63e464bac5235067fe093371cdf1757567f19345,"Merge pull request #16 from tdsmith/coalesce-nulls

Handle null values",Rob Hudson,2018-11-26T21:28:33Z,robhudson,robhudson,54,51,3
30,mozanalysis,3a880be8a40774d1cbf3d824bfe579f875bb1770,"Fill missing zeros

Some telemetry fields are NULL when they are not reported from the client,
which for these metrics means the actual value of the metric was zero.
Fill these missing zeros so that the bootstrap metrics don't complain.",Tim Smith,2018-11-21T21:50:18Z,tdsmith,tdsmith,10,7,3
31,mozanalysis,03095cbad21fd1e5c4bd61de8f1ae7627a751e69,Test data including nulls,Tim Smith,2018-11-21T23:09:32Z,tdsmith,tdsmith,44,44,0
32,mozanalysis,1bd50c6d22a019accb02c875d0837736eaf079c0,"Merge pull request #13 from mozilla/swap-ci

Fix #5: Switch to basic bootstrap for confidence intervals",Rob Hudson,2018-11-20T20:57:05Z,robhudson,robhudson,59,29,30
33,mozanalysis,a052cbcbfe3978d93337fe7afad228bc9f32fe48,Fix #5: Switch to basic bootstrap for confidence intervals,Rob Hudson,2018-11-19T23:42:47Z,robhudson,robhudson,59,29,30
34,mozanalysis,204e35c57bf3f2091e71c5253b23678d456929e1,Tag and update changelog,Rob Hudson,2018-11-01T22:53:26Z,robhudson,robhudson,10,8,2
35,mozanalysis,e00bac897ebeafd9f4902c27d5bcbad2b909283b,"Merge pull request #9 from mozilla/analysis-skeleton

Add ExperimentAnalysis and engagement metrics",Rob Hudson,2018-11-01T22:47:57Z,robhudson,robhudson,550,530,20
36,mozanalysis,9d13bf110e6b91c0c8a822096a6af43a39c26233,Add ExperimentAnalysis and engagement metrics,Rob Hudson,2018-10-25T23:45:15Z,robhudson,robhudson,495,494,1
37,mozanalysis,eb0f6a3a20ce88c022a315ec1adf1df2a2cb1461,Set up Python formatting with black,Rob Hudson,2018-10-25T23:44:17Z,robhudson,robhudson,55,36,19
38,mozanalysis,95c7a42bba41bf5027b1cefde41b15b093600a22,"Merge pull request #8 from mozilla/add-license-header

Add license headers",Rob Hudson,2018-10-02T23:13:54Z,robhudson,robhudson,22,21,1
39,mozanalysis,7c2ad4489cb2ff559092f7eb38ed0cf4b9cc134c,Add license headers,Rob Hudson,2018-10-02T23:08:40Z,robhudson,robhudson,22,21,1
40,mozanalysis,e4d799a52269aad88c2ba5e7b0b06ee9158458d7,"Merge pull request #6 from mozilla/fix-test-cov-argument

Pass expected argument to --cov",Rob Hudson,2018-09-20T21:00:37Z,robhudson,robhudson,3,2,1
41,mozanalysis,6918d23365d2f7c59810e5afd9d8adad92ddf0a7,Pass expected argument to --cov,Rob Hudson,2018-09-20T20:42:55Z,robhudson,robhudson,3,2,1
42,mozanalysis,36f3c190bfde01a11b1edc07d66021d1d8deb1f6,Add changelog,Rob Hudson,2018-09-19T16:10:24Z,robhudson,robhudson,13,13,0
43,mozanalysis,5a1a6b1ff41a649b46f8ad05ed765d26229ce857,"Merge pull request #4 from mozilla/import-mv

Move bootstrap import path to `mozanalysis.stats`",Rob Hudson,2018-09-18T23:38:31Z,robhudson,robhudson,4,2,2
44,mozanalysis,979031903ca8441920ba4b22e8532366fde9d3f5,Move bootstrap import path to `mozanalysis.stats`,Rob Hudson,2018-09-18T23:28:29Z,robhudson,robhudson,4,2,2
45,mozanalysis,15d22fd16bf16a166e67329c7e7ef98f8aeab85e,"Merge pull request #2 from mozilla/tagging

Updates to prep for tagging releases",Rob Hudson,2018-09-18T19:50:13Z,robhudson,robhudson,39,29,10
46,mozanalysis,a9055e6578c65e1f97c09e61514ccfabaec0e5fd,Updates to prep for tagging releases,Rob Hudson,2018-09-18T17:51:04Z,robhudson,robhudson,39,29,10
47,mozanalysis,718597488e3d5a66aae30b09a074b7ec6342500e,"Merge pull request #3 from mozilla/percentile-bug

Pass boostrapped data to percentile",Rob Hudson,2018-09-18T19:47:28Z,robhudson,robhudson,14,12,2
48,mozanalysis,0fcea15d4828bfd68dce19a8f09396ffd1406e38,Pass boostrapped data to percentile,Rob Hudson,2018-09-18T19:09:05Z,robhudson,robhudson,14,12,2
49,mozanalysis,c0046df75714efa56d8bb5a0176769cf921edd3d,"Merge pull request #1 from mozilla/bootstrap

Implement distributed bootstrap (bug 1485811)",Rob Hudson,2018-09-17T23:37:06Z,robhudson,robhudson,406,404,2
50,mozanalysis,45046d9110bcd787666f81e334a4226872f6ee0f,Implement distributed bootstrap (bug 1485811),Rob Hudson,2018-09-17T23:33:21Z,robhudson,robhudson,123,123,0
51,mozanalysis,27ded4a05291671894cbdf238f8e4386c15695e0,"Add docker and testing set up

Borrowed heavily from mozilla/python_moztelemetry",Rob Hudson,2018-09-17T23:32:56Z,robhudson,robhudson,283,281,2
52,mozanalysis,b31cfb7c71fb07022df2df6a39984efd41562ea3,Initial commit,Rob Hudson,2018-09-12T18:16:25Z,robhudson,robhudson,479,479,0
53,mozanalysis,b5d3033a4d141a508719327e55fd56f658989604,"Use concrete table for main data source (#127)

* Use concrete table for main data source

Uses the `telemetry_stable.main_v4` table instead of the `telemetry.main` compatibility view for the `main` data source.

This is intended to reduce the complexity of the analysis query in order to stay within Google's complexity budget.

We expect that this is compatible with all existing metrics because the view doesn't make very many changes, although the changes it does make are fairly complex.",Tim D. Smith,2021-04-09T19:21:02Z,tdsmith,tdsmith,7,5,2
54,mozanalysis,cdfee727d254e46cc807f51d50572d24b04c7968,Add monthly time series period,Anna Scholtz,2021-03-26T18:45:42Z,scholtzan,scholtzan,29,26,3
55,mozanalysis,25ab1609b5ffe1d1f4007df0b3f973ec3ea3c16f,Make enrollments tables independent of analysis windows,Anna Scholtz,2021-02-22T21:50:34Z,scholtzan,scholtzan,32,16,16
56,mozanalysis,78459c300fd295f138e6b2e5637bb7a2b071a136,"Add descriptions to Sphinx docstrings (#124)

* Add descriptions to Sphinx docstrings

This allows us to emit the description field of our metrics and datasources to Sphinx documentation using a trivial Sphinx plugin.

* Mark parallel safe",Tim D. Smith,2021-02-08T20:22:47Z,tdsmith,tdsmith,99,64,35
57,mozanalysis,1f1d110d5bb5cd75d7ddd9142e6fa388e73a2bc6,Rename master -> main,Anna Scholtz,2021-02-03T20:17:51Z,scholtzan,scholtzan,6,3,3
58,mozanalysis,40dc0efde42177415a2b2578e58427a0fa5729ed,"Add metrics for disabling Pocket in New Tab. (#122)

* Add metrics for disabling Pocket in New Tab.",Kirill Demtchouk,2021-01-28T23:23:21Z,kirill-demtchouk,kirill-demtchouk,35,35,0
59,mozanalysis,3614a8ddbba078b6942fa01d3635db568cd542e5,"Join enrollments more rigorously... and fix what was broken (#120)

* Fixes #117. Handle duplicate client_ids more correctly.

Metric DataSources were not specific-enough when joining to the `enrollments` view: when there are multiple rows for one client_id, with different branches, rows for all branches are used for all the enrollment rows. So a cloned profile in a three-branch experiment could have up to 3*7=21 days of use in a 7 day analysis window.

Really we want to `GROUP BY e.*` when aggregating over the data source, but being SQL we need to manually list the full set of columns that uniquely identify a row.

Then, when joining this result to the others in the relevant `Experiment` method, we need to use all these join keys again.

* Handle duplicate client_ids more correctly.

Segment DataSources were not specific-enough when joining to the `enrollments` view: when there are multiple enrollments for one client_id (with different branches), the join won't be a one-to-many join from one enrollment to potentially many data source rows, it will be a many-to-many join, yielding potentially incorrect results due to the extra/duplicated datasource rows. If the enrollments have different enrollment_dates then there's further potential for error.

Really, we want to `GROUP BY e.*` when aggregating over the data source, but being SQL we need to manually list the full set of columns that uniquely identify a row.

Then, when using this in the relevant `Experiment` method, we need to list all these join keys again.

* Fix `Experiment.get_single_window_data()`

It appears that #116 / edc44eb2 broke `Experiment.get_single_window_data()` when replacing `run_query()` with `run_query_and_fetch()`. This was not caught by our tests because we can't mock BQ, so we can't test that method in a meaningful way (i.e. if we had a mock for run_query() we may well have forgotten to delete the mock, leaving the test still to pass).

I'm updating the logic to match `Experiment.get_time_series_data()`, without a deeper understanding of what's going on.

* Fix get_single_window_data() and get_time_series_data().

It appears that the method argument `enrollments_table` was misinterpreted as requiring a BigQuery results object rather than the name of the enrollments table, as a string.

* Fix BigQueryContext.run_query_and_fetch().

In some contexts, we need to provide unqualified table names. In others, it must be fully qualified.

* Don't enquote the fully qualified table name, and hope for the best.

bigquery.Client().list_rows() is unhappy when passed a fully qualified table name enquoted with backticks. So we'll pass it a nude one. Hopefully this doesn't break all our other queries...?

* Fix build_metrics_query().

The `metrics_joins` rely on access to a table named `enrollments`. Provide it!

Also be more honest in the docs for build_enrollments_query().

I changed the alias for segmented_enrollments from `e` to `se` to make it clearer that segment information is in there too.

* Address review comments

* Rename run_query

* Document requirement for custom_enrollments_query

* Go back to a trivial CTE

since table aliases apparently aren't respected inside join subqueries.

* Make a print statement more ambiguous

It could be printed for the enrollments table, not just the results.",Felix Lawrence,2021-01-04T18:51:05Z,felixlawrence,felixlawrence,91,65,26
60,mozanalysis,e6a2092050f8c92e101f016f63878b316a6b1f72,"Add a new-profile segment (#104)

Use clients_last_seen to identify profiles that enroll on (or before!) their first date of use.",Tim D. Smith,2020-12-16T23:50:15Z,tdsmith,tdsmith,12,11,1
61,mozanalysis,3ef55210cc5b544243084541a9887f9bf6868a10,Explicitly provide enrollments destination table,Anna Scholtz,2020-12-12T00:03:05Z,scholtzan,scholtzan,35,14,21
62,mozanalysis,3408dce2d063a0ed66407be65980d53148a53fa1,Fix Experiment,Anna Scholtz,2020-12-11T18:27:03Z,scholtzan,scholtzan,57,11,46
63,mozanalysis,edc44eb2c28e4b124bac0dd3881b436903900b16,Use simple queries for enrollments and metrics SQL,Anna Scholtz,2020-12-11T18:16:53Z,scholtzan,scholtzan,292,202,90
64,mozanalysis,c570bf3f569381b4e9e35b7e8588f4a432c2c70e,"Blacken (#115)

Apply black and isort; enforce black in testing",Tim D. Smith,2020-12-11T18:06:35Z,tdsmith,tdsmith,1891,1025,866
65,mozanalysis,35877058975b51ebf7ea1e385593e018ca3d1320,Enforce black style in tests,Tim D. Smith,2020-12-11T18:01:02Z,tdsmith,tdsmith,44,25,19
66,mozanalysis,a66c6cc41731740f1ad3a9b3cf9586e0c416223b,Ignore long lines,Tim D. Smith,2020-12-08T05:57:14Z,tdsmith,tdsmith,22,11,11
67,mozanalysis,855eaec3ae30818d7aa6a9ea84e0cf23aaeb05a6,isort,Tim D. Smith,2020-12-08T05:53:22Z,tdsmith,tdsmith,41,19,22
68,mozanalysis,794ecf69a52686e3d97f28739db8e86b86a7833f,Blacken,Tim D. Smith,2020-12-08T05:52:02Z,tdsmith,tdsmith,1808,982,826
69,mozanalysis,7664a9bbcd5f9733f37523f4ac68a9253785decc,"Make metric datasets configurable at runtime (#114)

* Make metric datasets configurable at runtime

Different release channels of Glean apps have their data stored in different BigQuery datasets. This departs from the legacy telemetry practice on desktop, where data from all release channels end up in a single table.
This means that, although it's reasonable to talk about a set of metrics that are valid across the different Fenix release channels, the underlying DataSources need to be customized for each release channel.
I had once expected that this would be easy to do just by defining an alternate set of DataSources and rebasing the Metrics onto the new DataSources -- but the `events` data source is a good example of why this isn't as easy as I'd like. Datasets can be complex and it would be annoying to redefine them.

Instead, allow DataSources to be templated over dataset, and have the Experiment class forward some information from the client about which dataset the metrics should be based on.

* Default to new-hotness Fenix release app_id

* Hide DataSource.from_expr

from_expr might be a template, so hide it from consumers except via from_expr_for().",Tim D. Smith,2020-12-08T05:49:15Z,tdsmith,tdsmith,186,162,24
70,mozanalysis,818a61a41191f2db8fa4a3f6105171a879f55281,"Fix ping count metrics (#113)

Addresses the issue described in #107, where the join changes the meaning of COUNT(*).",Tim D. Smith,2020-12-07T22:11:43Z,tdsmith,tdsmith,4,2,2
71,mozanalysis,d00d0e2348b89ae11cf13549e996ea6b74daef7d,"Fix enrollments query (#112)

You gotta SELECT something!",Tim D. Smith,2020-12-01T23:49:12Z,tdsmith,tdsmith,15,7,8
72,mozanalysis,78c0ff64fb96003bc91c892241d2499c46c7bb45,Revise metrics for Pocket tile clicks. (#111),Kirill Demtchouk,2020-12-01T23:09:03Z,kirill-demtchouk,kirill-demtchouk,28,14,14
73,mozanalysis,52fd238c62af921529ecf8f14a17b166d191e77f,"Materialize enrollments table (#109)

* Materialize enrollments table

Repeated references to the enrollments CTE seem to stress BigQuery out, giving rise to ""Resources exceeded during query execution: Not enough resources for query planning - too many subqueries or query is too complex."" errors.

If we use CREATE TEMPORARY TABLE to materialize the enrollments table before joining it everywhere, we get a scripting query with similar semantics and a calmer query planner.

* Write destination table in the script

It's illegal to specify a destination table name (or a create/write disposition) if a query is a script, so we need to direct the output to a named table without passing those parameters into the API.

This breaks the public API for build_query by adding a new mandatory parameter. Requiring all arguments to be passed as keyword-only will make this breakage safe, i.e. it won't accidentally and silently consume one of the existing optional arguments into the destination_table argument.

Finally, we can't rely on taking a hash of the final query to use in the name of the destination table anymore, because the query contains the name of the destination table! Get around this by emitting a template instead.

This makes two backwards-incompatible changes:
* BigQueryContext.get_query is removed and replaced by .run_script_or_fetch()
* Experiment.build_query is replaced by .build_query_template()",Tim D. Smith,2020-12-01T23:07:08Z,tdsmith,tdsmith,148,83,65
74,mozanalysis,70c1d949784616ff344c11da17efa6b54196b801,"Make sure fast fetches happen

google-cloud-bigquery will automatically instantiate and use a BigQuery storage interface if that API package and pyarrow are installed. Let's assume people want those, even though we don't ever import them directly.",Tim D. Smith,2020-11-28T01:32:01Z,tdsmith,tdsmith,2,2,0
75,mozanalysis,904af3db0e2e67461ed87f4d7550663b9336233e,"Use interesting build environments

Colab is Python 3.6.9 and Jetstream uses Python 3.7. We should keep testing on 3.6.",Tim D. Smith,2020-11-28T01:31:23Z,tdsmith,tdsmith,23,15,8
76,mozanalysis,28605bfe979ea45ad9e60a260648edee2df2b844,"Fix the `days_of_use` metric. (#107)

@SuYoungHong noticed that the results of the `days_of_use` metric introduced in PR #105 were very suspicious.

The `COUNT(*)` was counting enrollments even when they had no row in `clients_daily`. Oops.

Instead, we need to `COUNT()` a non-null column from `clients_daily`; `COUNT(ds.submission_date)` seems to be the best for communicating what this metric does? And it's not worth adding a `DISTINCT` because it's implied by `clients_daily` and the lack of other joins?

I haven't tried this code yet but I've asked Su to do so in [this notebook](https://colab.research.google.com/drive/1E-f35o3DE6FIdnmNjs7eEA413lkNjtLh).",Felix Lawrence,2020-11-20T20:49:57Z,felixlawrence,felixlawrence,2,1,1
77,mozanalysis,0b22cc48c6950d84cbce936b82d9d075a491bd77,Add a days of use metric for desktop (#105),Tim D. Smith,2020-11-18T18:55:39Z,tdsmith,tdsmith,10,10,0
78,mozanalysis,b4af558de38f8cd07dc57cd6e81f372883a5b100,"Add a bigger-is-better flag (#106)

Dashboards shouldn't look excited when we get more of a bad thing, or when performance timings increase.

Sometimes this will depend on the context of the experiment; if the wrong assertion is made here, folks can make a copy of the metric with the bit flipped.",Tim D. Smith,2020-11-18T16:16:20Z,tdsmith,tdsmith,3,3,0
79,mozanalysis,b25695b04189d746b07df89c50003b58f8c26a1c,Add/fix internal doc links to TimeSeriesResult. (#103),Felix Lawrence,2020-11-13T18:08:23Z,felixlawrence,felixlawrence,5,3,2
80,mozanalysis,f75023b8388c5abc2e7cb4debb37ecd111c6ca08,Add metrics for pocket tile clicks (#102),Felix Lawrence,2020-10-21T22:40:32Z,felixlawrence,felixlawrence,42,42,0
81,mozanalysis,651cd9c9eba8a2e0226348cf1bfd350f2c8d8f30,Emit Sphinx docs for desktop metrics (#101),Tim D. Smith,2020-10-09T18:24:37Z,tdsmith,tdsmith,34,30,4
82,mozanalysis,c526f0e3361921cc94c1f6dfecfc8bab1d0104bf,Add friendly names and descriptions for segments (#100),Tim D. Smith,2020-09-24T23:07:31Z,tdsmith,tdsmith,88,65,23
83,mozanalysis,4b3255f080870dfc4faeeab592a1f95918622025,"Add friendly names and docs to metrics definitions (#99)

* Add friendly names to metrics

* Enforce friendly names on included metrics

* Document included metrics",Tim D. Smith,2020-09-24T16:20:02Z,tdsmith,tdsmith,188,150,38
84,mozanalysis,3b581c12bed691ae9b9c5e737bb402a9c45a7e51,Declare a dtype at Series creation (#97),Tim D. Smith,2020-09-02T19:55:56Z,tdsmith,tdsmith,2,1,1
85,mozanalysis,d05bd124fc2b90bfa3ad623986deb90db71765d4,Include documentation for the BQ module (#96),Felix Lawrence,2020-08-27T19:46:10Z,felixlawrence,felixlawrence,11,9,2
86,mozanalysis,6be8e4f9ad8d12baabddea626a4ddd57ef4c4361,"Add support for Fenix experiments (#95)

Based on the pyspark work by @godelstheory for PR53.",Felix Lawrence,2020-08-27T18:34:02Z,felixlawrence,felixlawrence,208,194,14
87,mozanalysis,0638d300af06e3305ae10f1addcf96eb1faaa815,Declare experiments_column_type for normandy_events (#92),Tim D. Smith,2020-06-19T03:48:49Z,tdsmith,tdsmith,1,1,0
88,mozanalysis,96d41ab44388fc0501427bb6b34dc7a2ca2f71ab,"Merge pull request #91 from scholtzan/normandy-events

normandy_events datasource for unenroll metric",Anna Scholtz,2020-06-19T00:50:52Z,scholtzan,scholtzan,15,14,1
89,mozanalysis,33f95e54faa30340e186cbbf0cb87c45abe7585c,Add comment to normandy_events datasource,Anna Scholtz,2020-06-19T00:45:29Z,scholtzan,scholtzan,23,13,10
90,mozanalysis,6cc8406c5c9496a5a010db452b54c3ea184ec8cb,normandy_events datasource for unenroll metric,Anna Scholtz,2020-06-18T20:32:32Z,scholtzan,scholtzan,12,11,1
91,mozanalysis,3cfcb9ecc13a2b52b414766b6fca7ec14c07211e,"num_dates_enrollment must be positive (#90)

So give a nicer error message. Fixes #74.",Tim D. Smith,2020-06-16T02:10:32Z,tdsmith,tdsmith,3,3,0
92,mozanalysis,95857bb020bba5d641d97d4ff54fbfdbb0f8c360,Use mozfun UDFs (#89),Anna Scholtz,2020-06-16T00:55:23Z,scholtzan,scholtzan,14,7,7
93,mozanalysis,65c8e7066d491ca9c6b04bcba4250ad814e2ba9f,"Add and update segments (#87)

Add new segments:

* `weekday_regular_v1`
* `allweek_regular_v1`

Update `regular_users_v3 and `new_or_resurrected_v3` to use the ETL segment definitions, now that they exist.",Felix Lawrence,2020-06-10T17:24:32Z,felixlawrence,felixlawrence,22,16,6
94,mozanalysis,de65e35651ecae9a41100b583104fb578d57c762,Fix typo in docs (#86),Felix Lawrence,2020-06-10T17:22:39Z,felixlawrence,felixlawrence,2,1,1
95,mozanalysis,4b21739db4885eb70d1be61a8ad428bc930ab569,"Initialize Series with explicit dtype (#84)

Silences a DeprecationWarning that the default dtype will change.",Tim D. Smith,2020-05-12T18:42:14Z,tdsmith,tdsmith,4,2,2
96,mozanalysis,758cae99c4ecf4c9119f90ca55fe77137064ea7a,"Respond to linter changes (#85)

* Ignore ambiguous variable names

* Remove old f-string modifiers",Tim D. Smith,2020-05-12T15:15:18Z,tdsmith,tdsmith,16,14,2
97,mozanalysis,9ad04e4a78d525fc88497333f696ab26c87989df,"Update usage regularity segments to v3. (#83)

* Update usage regularity segments to v3.

Docs for these segments are [on DTMO](https://docs.telemetry.mozilla.org/concepts/segments.html#regular-users-v3).

* Oops, these segments haven't used lag since v1",Felix Lawrence,2020-05-08T21:48:54Z,felixlawrence,felixlawrence,66,10,56
98,mozanalysis,3d95970f71a30daa60606785a66c97cdb990e31c,Hyphenate spark-style date in cookbook. (#82),Felix Lawrence,2020-05-06T17:11:53Z,felixlawrence,felixlawrence,2,1,1
99,mozanalysis,c97c2bee511278817b0e3851d544f27ffb822dd6,"add cfr DataSource (#81)

* add cfr DataSource

* fix trailing whitespace

* fix experiments column type

* indentation",Leif Oines,2020-05-04T16:21:38Z,irrationalagent,irrationalagent,11,11,0
100,mozanalysis,76ab66298ebdb64fb800c2421063af4c3d070b98,Fix mangled rst; link to where to find the current version. (#80),Felix Lawrence,2020-04-18T19:37:14Z,felixlawrence,felixlawrence,4,2,2
101,mozanalysis,655bee653641272b986125edbba8c901ff38da4b,"COALESCE segments to remove NULL values (#79)

Because `clients_last_seen` is constructed from the `main` ping, and our enrollments are obtained from the `events` ping,there are enrollments without a `clients_last_seen` row that matches the submission date.

This only happens for users without any (main ping) activity in the past 28 days. Therefore these users belong in `new_irregular_users_v2`.

This problem will persist even once the segments are in the ETL.

There are terser solutions (e.g. `MAX(...=...) IS TRUE` for two segments to map `NULL` to `FALSE`), but I figured that this verbose form was the most readily understandable.",Felix Lawrence,2020-04-06T16:23:42Z,felixlawrence,felixlawrence,30,24,6
102,mozanalysis,77e7818dcb31777c443f326b7fa612de4c333514,"Add segments functionality (#76)

* Refactor code so we can reuse it for segments

* Add `Experiment._build_segments_query()` and `_build_segments_query_bits()

This code is largely copypasta from `_build_metrics_query_bits()`.

The main difference is that this builds up a largely-self-contained query (it needs `raw_enrollments` to be defined), and this query will (in a later commit) be dropped into the master query in `Experiment.build_query()` between `raw_enrollments` and `enrollments`.

The strategy is the same: `SegmentDataSource.build_query()` (coming soon!) returns a SQL query that adds one column per segment from the data source while leaving the other columns untouched and not changing the number of rows. Then in `_build_segments_query()` we combine the new columns from each data source by LEFT JOINing repeatedly and SELECTing the new columns.

* Add segment modules, tests, and docs.

Again we borrow ideas and code from the metrics library, making enough changes/simplifications that copypasta is better than DRY here.

`SegmentDataSource.build_query()` is the method that builds the segment queries that plug into `Experiment._build_segment_query()` as `LEFT JOIN`s.

Also adds three segments and their data source. These segments are documented in [this pull request to DTMO](https://github.com/mozilla/firefox-data-docs/pull/428). There is also a [related PR for bigquery-etl](https://github.com/mozilla/bigquery-etl/pull/825/); once that is merged it will be easier to query these segments: we would be able to replace the `select_expr` with the currently-commented-out versions, and replace the data source with a non-lagging window.

* Hook up segments functionality and expose it.

Let users specify a list of segments, and use the segments query in `Experiment.build_query()`.

* Trailing commas in SELECT are no longer considered malformed \o/

* Correct the `SegmentDataSource.build_query()` docstring.

And augment the `Experiment._build_segments_query()` docstring.

* Put `segment_list` as the final argument to avoid a breaking API change

* Move `sql_lint()` into a helpers module to avoid duplication

* Update segments to latest proposed definitions

Hopefully bigquery-etl will be updated before we need to merge this, so we'll be able to remove `tmp_segment_regular_users_v1` before merging.

* I miss fixtures and real tests :(

* Update usage regluarity segment to latest definition (v2)

* Update test for new variable name",Felix Lawrence,2020-04-03T18:35:54Z,felixlawrence,felixlawrence,431,372,59
103,mozanalysis,14bebdf2b4ab519b9dd74c6d73bc68670653d261,"Merge pull request #78 from benmiroglio/add-search-metrics

Add missing search metrics",Ben Miroglio,2020-04-03T15:14:02Z,benmiroglio,benmiroglio,18,18,0
104,mozanalysis,d0d775bf9c003325ef18432707d06237e7c9c54e,Add missing search metrics,benmiroglio,2020-04-02T20:16:59Z,benmiroglio,benmiroglio,18,18,0
105,mozanalysis,8b730f67ad2a15ffe8238dbf370a38b26e5fbcd7,Use new date format in docstrings,Tim D. Smith,2020-03-07T00:32:19Z,tdsmith,tdsmith,12,6,6
106,mozanalysis,f182010f2577b3a33333d513cb789b2b951d8291,"Include the right date in the error message

Avoid a little bit of repetition and branching by doing a check even if we know it can't fail.",Tim D. Smith,2020-03-07T00:27:12Z,tdsmith,tdsmith,25,11,14
107,mozanalysis,c917a0f475ea29ad117f4b4aad4e7739d2bffeea,Add test for failing case,Tim D. Smith,2020-03-07T00:21:11Z,tdsmith,tdsmith,12,12,0
108,mozanalysis,579119e2f34a9259d5a79d03d86cea89eda34280,Promote build_query to public API (#66),Tim D. Smith,2020-02-29T00:03:12Z,tdsmith,tdsmith,45,33,12
109,mozanalysis,6e0d7fa24b3dffc9a0f6f8fe1c137ed041a7bd3f,"Allow Metrics to be rebased on other DataSources (#67)

Sometimes you have tables with identical schemas and need to prefer one or the other in different contexts. These could be using `telemetry_live` tables, or using a Fenix Nightly table vs a Fenix release table. This helper facilitates that.",Tim D. Smith,2020-02-28T21:55:00Z,tdsmith,tdsmith,8,8,0
110,mozanalysis,561e1ad650d81a940562e7090b5ca5757f87c55d,Validate experiments_column_type parameter (#65),Tim D. Smith,2020-02-28T21:53:27Z,tdsmith,tdsmith,42,42,0
111,mozanalysis,9e336e0df5564c65968cdf4b89303bafdfdeca52,"Add main and crash ping data sources, and a histogram-mean aggregation (#62)

* Add main and crash ping data sources

* Add a histogram-mean aggregation function",Tim D. Smith,2020-02-28T21:52:45Z,tdsmith,tdsmith,32,32,0
112,mozanalysis,1552e9af26d63f46fe38b90faf16ffe46c53e8e9,"Remove explicit object inheritance (#64)

All classes inherit from object in Python 3. It's a brave new world!

https://twitter.com/electrolemon/status/1043183150216765440",Tim D. Smith,2020-02-28T19:26:14Z,tdsmith,tdsmith,14,7,7
113,mozanalysis,e51c929916d10f1e7dd6c0157738ab8d5c619a4c,Don't install mozanalysis into linting environment (#63),Tim D. Smith,2020-02-28T05:02:35Z,tdsmith,tdsmith,1,1,0
114,mozanalysis,2a2f73df61d474b86c51cf5e0eb07399d7cd7ae3,Add documentation for DataSource (#61),Felix Lawrence,2020-02-25T21:51:35Z,felixlawrence,felixlawrence,27,27,0
115,mozanalysis,00cfa2558c01a6f6cbfae6f090c681118a1c6af8,Add info to guide about creating datasets. (#59),Felix Lawrence,2020-02-25T16:05:03Z,felixlawrence,felixlawrence,2,2,0
116,mozanalysis,35d6d6da8a29674bf378df9a6e679b83b5853e6c,"Remove UDFs and pyarrow dependency (#58)

I expect nobody will miss these. The pyarrow dependency makes mozanalysis hard to install.",Tim D. Smith,2020-02-19T18:46:03Z,tdsmith,tdsmith,317,0,317
117,mozanalysis,277d8a7e98ac5acf9fc2e32d31003daebe2c8c7b,"Remove py27 support - abandon ship. (#57)

Tests started failing on py27, in areas untouched by recent commits. The ship is sinking, let's get off it.",Felix Lawrence,2020-02-12T00:56:44Z,felixlawrence,felixlawrence,14,4,10
118,mozanalysis,56bd4b34f18ac1fd3d048f7bc0dcb1af03e24c0c,"Add metric for connecting a firefox account (#56)

In order to add 'connect_fxa' as a metric, I had to un-break the join to the events table (the changes in `metrics/__init__.py`).

I applied this quickly to an existing onboarding experiment and the metric result was nonzero and plausible (to me).",Felix Lawrence,2020-02-12T00:40:55Z,felixlawrence,felixlawrence,64,50,14
119,mozanalysis,d9fd23c2fbc1396c6df873940a27a4975a3b0ed7,"Move to bigquery (#54)

Switch from querying via Spark to querying via BigQuery.

* Fix minor docs copypasta mistake

* Port the query code to SQL for BigQuery.

* Delete firetv docs. Other docs need updating

* Nit: make a variable name more accurate/specific

* Move BigqueryStuff into a separate module and refactor it

* Add crude unit tests; fix discovered bug

* Fix docstring example

* Update guide.

When working through my example notebook, I noticed that you can't call `.to_dataframe()` twice on the same object. This is inconvenient and I wonder if we should change our return types to just return dicts of dataframes - or possibly an iterator over `(int, DataFrame)` tuples for time series.

* Don't return RowIterators.

`Experiment.get_single_window_data()` now returns a pandas DataFrame directly. `Experiment.get_time_series_data()` now returns a new `TimeSeriesResult` object, which ideally gets turned into a `dict` but also supports loading only one value into RAM at a time.

* Appear more professional

Rename ``BigqueryStuff`` to ``BigQueryContext``, because the latter seems less hacky. Whether this class warrants a less hacky name is not implied.

* Add docs for BigQueryContext

* `add_any` now deals exclusively with bools.

* Fix bug; update docs

* Make query hashes consistent across runtimes.

In Python 3, it turns out that the `hash()` of a string is consistent within an interpreter session, but inconsistent between sessions. Great. Use a few bytes of a sha256 instead.

* Don't suggest people install mozanalysis from my personal fork

* Don't encourage people to use my dataset_id

* Obvious placeholder is obvious

* Apparently project namespaces are for billing?

* Add return type

* Fully qualify result table names for TimeSeriesResult.

The data to be extracted from a TimeSeriesResult is identified by `(project_id, dataset_id, table_name)`. Previously, `project_id` and `dataset_id` were stored in a `BigQueryContext`, separate to the `table_name`. If someone was using multiple BigQueryContext instances, with different `project_id`s or `dataset_id`s (which is a terrible idea!) then they would need to correctly match each TimeSeriesResult to the right BigQueryContext.

To remove the chance for such mismatches, TimeSeriesResult now stores a fully qualified table name: `project_id.dataset_id.table_name`.

It would be nice to deal with fully qualified table names everywhere, but when specifying a destination table (when saving results into a table), the BigQuery API seems not to allow the destination table to be specified as a fully qualified table name - instead the project_id, dataset_id and table_name must be submitted separately in three separate places (respectively: when instantiating the bigquery client, when instantiating a dataset object, and when calling the `table()` method on that dataset object. Ergh.",Felix Lawrence,2020-01-14T21:49:45Z,felixlawrence,felixlawrence,2682,736,1946
120,mozanalysis,622d5896e692406f5841c292a788e155dd24a493," Make bootstrapping work without Spark. (#55)

* Make bootstrapping work without Spark.

This makes a breaking change to the bootstrap function signatures: arguments are re-ordered so that `sc` becomes optional.

Mozanalysis will now be frequently run without a Spark context. We'll still need to bootstrap.

Now if no Spark context is supplied, non-parallel implementations of the bootstrap will be run.

* Parametrise the spark fixture to neaten the tests",Felix Lawrence,2020-01-03T23:55:41Z,felixlawrence,felixlawrence,257,156,101
121,mozanalysis,745258804198e29f5f6437f06c9eb766c3b9ed38,"Start a metrics library (#52)

Add support for a metrics library, and some initial metrics. In the process, make a breaking change to `Experiment.get_per_client_data()`, `Experiment.get_time_series_data()`, etc: `metric_list` is now a list of `Metric` instances, and these functions no longer have a `data_source` argument.

See https://github.com/mozilla/mozanalysis/pull/52 for the full gory details of the reasoning behind the design choices; an abbreviation is below.

* Add DataSource and Metric classes.

`DataSource` wraps a Spark DataFrame or table lazily, so that you can define DataSources without needing a Spark context.

`Metric` wraps a Spark Column, plus a `DataSource` for the necessary table - again so that you can define `Metric`s lazily, without issuing Spark commands.

Also add some convenience functions `agg_sum()` and `agg_any()`, representing common aggregations over Columns used when defining experiment metrics.

* Add some metrics and data sources for desktop and fire tv

* Refactor `Experiment._get_per_client_data()`, ready for batches.

We want users to be able to supply an arbitrary list of `Metric`s to `Experiment.get_per_client_data()` and `Experiment.get_time_series_data()`, without requiring that all metrics share a common `DataSource`. Therefore we need to handle joins with arbitrary numbers of `DataSource`s and associated `Metric`s.

* Add `Experiment._process_metrics()`.

Add a method that takes a list of `Metric`s and converts them to a `dict` of a list of metrics per data source DataFrame.

* Use `Metric`s not raw Columns and DataFrames.

From here on, `metric_list` refers to a list of `Metric`s rather than a list of Columns.

The user accessible `Experiment` methods (`get_per_client_data`, `get_time_series_data`, `get_time_series_data_lazy`) now take a list of `Metric`s, rather than needing to supply a DataFrame and a list of Columns.

* Move sanity check metric generation into the `DataSource` class.

This will allow `DataSource`s to implement additional custom sanity checks in the future. It also provides better column names for sanity check metrics, now that we have multiple data sources in one results DataFrame.

* Add documentation, including a tutorial/cookbook.",Felix Lawrence,2019-10-29T16:52:09Z,felixlawrence,felixlawrence,1576,1375,201
122,mozanalysis,fbdc061ee297273d4fe8938e5a7b20664478bdbb,"Add time series (#51)

Add support for querying metrics as time series. Daily and weekly time series have official support in the `Experiment` class, though it's fairly easy to DIY an arbitrary set of analysis windows too.

This required the addition of new `TimeLimits` and `AnalysisWindow` classes, and a refactor of `Experiment`.

See https://github.com/mozilla/mozanalysis/pull/51 for the full gory details of the reasoning behind the design choices.",Felix Lawrence,2019-10-16T13:48:19Z,felixlawrence,felixlawrence,773,637,136
123,mozanalysis,3cb8cb0a2910b8305e0b71242c45421dcbcecea3,"Further refactoring of Experiment class (#50)

Do more groundwork in preparation for supporting querying of time series and a metrics library.

Specifically, spin off the construction of the join conditions into a separate method so that get_per_client_data() fits on one screen and is easier to reason about.


* Move join condition construction to separate method.

* Trivial gardening

* Move data_source checking into data_source specific method.

In the future (with the metrics library) we will have multiple data_sources in one query, so that users can just list all the metrics they want to analyse without partitioning them by data_source. So all data_source functionality should eventually live inside a reduce loop - this makes that more possible.

* Rename `filter_*_for_analysis_window()` to `_process_*()`

In the future we are going to do significantly more than filtering in these methods. For now let's be less verbose, and make them private.

* Staticify static methods

* Push ugly aliases out of the way

* Lower the demanded precision from a random unit test

* Address review comments.",Felix Lawrence,2019-08-20T20:18:09Z,felixlawrence,felixlawrence,124,77,47
124,mozanalysis,7567dd6dc3a22fe18f1e7716c160550116eb2d0a,"Refactor time limits code in Experiment. (#49)

* Refactor time limits code in Experiment.

Our next priorities are to introduce a metrics library and support for querying time series of metrics data. Both of these things add complexity to the queries that get sent to Spark, and the code that builds them. Here we lay some groundwork for those features by disentangling some logic from the `Experiment` class.

Here we introduce the `TimeLimits` class: an instance of TimeLimits holds all the temporal information used when querying data for an `Experiment`. It contains the start and end of the enrollment period, the details about the analysis window, and the relevant date range for the data source.

Previously, we tried to hold minimal state and compute quantities on the fly. Instead, `TimeLimits` precomputes and stores all these variables, which is conceptually easier (particularly when we start specifying a different set of variables when working with time series). We ensure self-consistency by providing a constructor with a near-minimal set of arguments, and by using validators.",Felix Lawrence,2019-08-06T22:43:35Z,felixlawrence,felixlawrence,521,351,170
125,mozanalysis,f2c71b01f08ce9d6d2037955de09628fcc310826,"Keep using debian stretch (oldstable). (#47)

If you stand in one place long enough, the sands shift around you.

The package openjdk-8-jre-headless has been removed from the new debian (buster) and so the easiest short term fix for this is to stay on the old version.",Felix Lawrence,2019-07-17T18:25:10Z,felixlawrence,felixlawrence,10,5,5
126,mozanalysis,37c81d862d98132e07be2db220d161c64bfae71b,"Add stats functions (#44)

Add stats functions.

Introduces stats functionality to mozanalysis. There is a module for Frequentist stats and a module for Bayesian stats. So far, most of the stats functions return credible intervals or confidence intervals over some sampled quantity.

The goal here is to strike the right balance between consistency and flexibility: we want the stats functions to be as interchangable as is sensible. They all accept data in the same format (the format output by `get_per_client_data`) and try to output data in as similar formats as is sensible. I hope this format is flexible enough to accommodate future functionality too, as people add their favourite stats methods.

Fixes #12, Fixes #14",Felix Lawrence,2019-07-17T17:37:50Z,felixlawrence,felixlawrence,2161,2134,27
127,mozanalysis,c47d3366831937fd06f3a58141d3ded9d9b42d3e,"Use attrs for Experiment (#45)

* Use attrs for Experiment

Use attrs for the experiment class.
This gives us more robust immutability, a free repr, and avoids some
boilerplate.

* Allow dependency injection for get_enrollments

`get_enrollments` needs to be able to reference a table of all
enrollment events. We need to be able to shortcut this in the tests, and
we'd like Experiment to be immutable, which means no monkeypatching.

Instead, allow the function that fetches the view to be passed in,
and call any callables that we receive as `study_type` arguments.

Further, align the APIs for the view-fetchers, and perform addon-version
filtering in the body of `get_enrollments` if it's required.

* Use injection instead of mocking in tests for Experiment class",Tim D. Smith,2019-06-26T20:30:28Z,tdsmith,tdsmith,149,69,80
128,mozanalysis,2b924f822e8d494070c32a57299e18a23a93237d,Build docs for the experiment module (#43),Tim D. Smith,2019-05-25T01:52:20Z,tdsmith,tdsmith,122,68,54
129,mozanalysis,9ff8dfd7af55f58b62e419c564a3e7e61df55d50,Add tox usage note,Tim Smith,2019-05-25T00:26:38Z,tdsmith,tdsmith,9,9,0
130,mozanalysis,0ef9b4ce9a045c1eb7c430ac875b744255a37699,Fix Sphinx warning about missing path,Tim Smith,2019-05-24T23:39:56Z,tdsmith,tdsmith,2,1,1
131,mozanalysis,51e2ce12f9e22f66f841598ca71e824bda423cc6,Remove stats docs stub,Tim Smith,2019-05-24T23:33:01Z,tdsmith,tdsmith,5,0,5
132,mozanalysis,4c125edb201b8f6d9b9efa907db0abe4eef34d5c,"Simplify docs build

Keep all our extra requirements in the same place and avoid `make`.",Tim Smith,2019-05-24T23:23:20Z,tdsmith,tdsmith,236,13,223
133,mozanalysis,24c2bbf7e63cf0f7278215ef60a194ee35803925,"Remove support for testing in Docker

I think these were useful for developing on Windows but I worry they're
a little distracting since tox should work. We can revert this change if
we want them back.",Tim Smith,2019-05-24T23:20:46Z,tdsmith,tdsmith,108,6,102
134,mozanalysis,f6e3929e4289f81a9ff89f60349f5993f4219952,"Work around unsafe fork in pyspark (#41)

Touching core Objective C classes from a child process (in the case of
fork() without exec()) causes a defensive crash in recent versions of
macOS.

Pyspark forks unsafely, which triggers the defensive crash, which causes
tests to fail.

This doesn't fix anything -- it just disables the airbag -- but a proper
fix would have to land in pyspark.

Closes #40.",Tim D. Smith,2019-05-24T23:31:13Z,tdsmith,tdsmith,1,1,0
135,mozanalysis,f43a8e46af54ea8e251b8e5ece58f62367c39672,"Work around bug in Spark joining.

If you start with a DataFrame, aggregate over it, then join from the aggregation to the original DataFrame, then Spark can raise an AnalysisException, complaining about duplicated names even if you've been careful to rename them. Specifically, this happened with 'submission_date_s3'.

Since it _actually is a unique name_, we can use `F.col('submission_date_s3')` instead of `data_source.submission_date_s3` to work around this problem. If someone supplies an `enrollments` table that _does_ have a `submission_date_s3` column then Spark justifiably raises a meaningful error.

Added the fix, a short comment explaining it with a reference to the bug[1], and a test that failed before the bug was fixed.

[1] https://issues.apache.org/jira/browse/SPARK-10925",Felix Lawrence,2019-05-24T17:37:07Z,felixlawrence,felixlawrence,43,40,3
136,mozanalysis,072e86799d723bbda9bf67f2f0d446bdcdccb6e0,"Merge pull request #38 from felixlawrence/revamp-and-add-query-code

First step in a new direction.",Felix Lawrence,2019-05-16T17:55:59Z,felixlawrence,felixlawrence,1504,892,612
137,mozanalysis,b58e482fd6aec9a9a29e5037761a9e6e1b15316e,Change nomenclature per teonbrooks' review and jmccrosky's suggestion,Felix Lawrence,2019-05-02T16:53:12Z,felixlawrence,felixlawrence,92,46,46
138,mozanalysis,86150724e64380084f075099e1195d0e0afd1708,Clarify docs following teonbrooks' review,Felix Lawrence,2019-05-01T23:24:44Z,felixlawrence,felixlawrence,8,6,2
139,mozanalysis,4ac4bd7aa4490baaf6a951624043e38a16889049,Repeat the fix for repeated docs,Felix Lawrence,2019-05-01T18:30:41Z,felixlawrence,felixlawrence,12,9,3
140,mozanalysis,010fa5bb5a6095a3700796086f27c94cb0752669,Do some of teonbrooks' suggestions and more of tdsmith's,Felix Lawrence,2019-05-01T18:19:22Z,felixlawrence,felixlawrence,109,36,73
141,mozanalysis,f5e0398271526b697e51b198dff3e3c3796f4337,Do more of tdsmith's suggestions,Felix Lawrence,2019-04-29T23:41:00Z,felixlawrence,felixlawrence,173,106,67
142,mozanalysis,953092591799ff46c1b64ce693eed74e07ec79bf,Do some of tdsmith's suggestions,Felix Lawrence,2019-04-29T22:39:26Z,felixlawrence,felixlawrence,47,19,28
143,mozanalysis,9f79049305a165e367ad2bea912d31533bf89b8e,Support querying from dfs without an experiments map.,Felix Lawrence,2019-04-26T18:28:11Z,felixlawrence,felixlawrence,87,52,35
144,mozanalysis,51f3d68f1df5bf0303f096729b20f3c683215e92,There is space for this concern under the rug,Felix Lawrence,2019-04-26T17:38:41Z,felixlawrence,felixlawrence,3,0,3
145,mozanalysis,dc731f161049e8cbf75ba2444bc3f5fa9177a844,Clarify docs,Felix Lawrence,2019-04-25T23:35:50Z,felixlawrence,felixlawrence,2,1,1
146,mozanalysis,0264505555eb3c8c0ac139314fb14985c9e01a0c,"First step in a new direction.

This commit removes a lot of the existing code, and takes the first step on a new roadmap that takes mozanalysis beyond the `experiments` table, and aims to make safe and rigorous analyses easier than the alternative, while maintaining 'enough' flexibility.

This commit introduces the basic query infrastructure - most of the code that builds Spark queries.

Still to come in mozanalysis or mozreport (out of scope for this PR):
- A variety of stats functions to analyze the data output by `Experiment.get_per_client_data()`
- A library of pre-defined and blessed metrics
- Convenience functions for querying and analyzing time series (time since enrollment)
- Functions to visualize/present the output of stats functions",Felix Lawrence,2019-04-25T20:02:07Z,felixlawrence,felixlawrence,1487,875,612
147,mozanalysis,8a7246cd159923012b56be7a1d70bca6e587554e,"Merge pull request #36 from Mozilla-GitHub-Standards/master

Add Mozilla Code of Conduct",Rob Hudson,2019-04-09T15:24:49Z,robhudson,robhudson,15,15,0
148,mozanalysis,0c2a278cd52bc12beb25f7c52c45c91af35ec8c2,"Add Mozilla Code of Conduct file

Fixes #35.

_(Message COC002)_",Mozilla-GitHub-Standards,2019-03-30T07:01:33Z,Mozilla-GitHub-Standards,Mozilla-GitHub-Standards,15,15,0
149,mozanalysis,92a10c988efa67e14ac8112bc704fe3a6d5a0761,"Removing contrib/

These have moved to the new mozilla/dscontrib library.",Rob Hudson,2019-03-21T16:23:09Z,robhudson,robhudson,161,0,161
150,mozanalysis,f5b7c1df7e31b6fa1f2aa9b9274ff64e35e2356d,"Merge pull request #31 from benmiroglio/master

Add search ads metric",Felix Lawrence,2019-03-15T19:53:55Z,felixlawrence,felixlawrence,45,45,0
151,mozanalysis,498d3418879504487ae952ac56e416bfc1ee15fb,Fix flake8 errors,benmiroglio,2019-03-12T22:42:55Z,benmiroglio,benmiroglio,74,38,36
152,mozanalysis,21fd5eb1af183c6cf62efab9cd6714d2f1095edb,Add newline to end of file,benmiroglio,2019-03-12T22:33:55Z,benmiroglio,benmiroglio,2,1,1
153,mozanalysis,b5d3033a4d141a508719327e55fd56f658989604,"Use concrete table for main data source (#127)

* Use concrete table for main data source

Uses the `telemetry_stable.main_v4` table instead of the `telemetry.main` compatibility view for the `main` data source.

This is intended to reduce the complexity of the analysis query in order to stay within Google's complexity budget.

We expect that this is compatible with all existing metrics because the view doesn't make very many changes, although the changes it does make are fairly complex.",Tim D. Smith,2021-04-09T19:21:02Z,tdsmith,tdsmith,7,5,2
154,mozanalysis,cdfee727d254e46cc807f51d50572d24b04c7968,Add monthly time series period,Anna Scholtz,2021-03-26T18:45:42Z,scholtzan,scholtzan,29,26,3
155,mozanalysis,25ab1609b5ffe1d1f4007df0b3f973ec3ea3c16f,Make enrollments tables independent of analysis windows,Anna Scholtz,2021-02-22T21:50:34Z,scholtzan,scholtzan,32,16,16
156,mozanalysis,78459c300fd295f138e6b2e5637bb7a2b071a136,"Add descriptions to Sphinx docstrings (#124)

* Add descriptions to Sphinx docstrings

This allows us to emit the description field of our metrics and datasources to Sphinx documentation using a trivial Sphinx plugin.

* Mark parallel safe",Tim D. Smith,2021-02-08T20:22:47Z,tdsmith,tdsmith,99,64,35
157,mozanalysis,1f1d110d5bb5cd75d7ddd9142e6fa388e73a2bc6,Rename master -> main,Anna Scholtz,2021-02-03T20:17:51Z,scholtzan,scholtzan,6,3,3
158,mozanalysis,40dc0efde42177415a2b2578e58427a0fa5729ed,"Add metrics for disabling Pocket in New Tab. (#122)

* Add metrics for disabling Pocket in New Tab.",Kirill Demtchouk,2021-01-28T23:23:21Z,kirill-demtchouk,kirill-demtchouk,35,35,0
159,mozanalysis,3614a8ddbba078b6942fa01d3635db568cd542e5,"Join enrollments more rigorously... and fix what was broken (#120)

* Fixes #117. Handle duplicate client_ids more correctly.

Metric DataSources were not specific-enough when joining to the `enrollments` view: when there are multiple rows for one client_id, with different branches, rows for all branches are used for all the enrollment rows. So a cloned profile in a three-branch experiment could have up to 3*7=21 days of use in a 7 day analysis window.

Really we want to `GROUP BY e.*` when aggregating over the data source, but being SQL we need to manually list the full set of columns that uniquely identify a row.

Then, when joining this result to the others in the relevant `Experiment` method, we need to use all these join keys again.

* Handle duplicate client_ids more correctly.

Segment DataSources were not specific-enough when joining to the `enrollments` view: when there are multiple enrollments for one client_id (with different branches), the join won't be a one-to-many join from one enrollment to potentially many data source rows, it will be a many-to-many join, yielding potentially incorrect results due to the extra/duplicated datasource rows. If the enrollments have different enrollment_dates then there's further potential for error.

Really, we want to `GROUP BY e.*` when aggregating over the data source, but being SQL we need to manually list the full set of columns that uniquely identify a row.

Then, when using this in the relevant `Experiment` method, we need to list all these join keys again.

* Fix `Experiment.get_single_window_data()`

It appears that #116 / edc44eb2 broke `Experiment.get_single_window_data()` when replacing `run_query()` with `run_query_and_fetch()`. This was not caught by our tests because we can't mock BQ, so we can't test that method in a meaningful way (i.e. if we had a mock for run_query() we may well have forgotten to delete the mock, leaving the test still to pass).

I'm updating the logic to match `Experiment.get_time_series_data()`, without a deeper understanding of what's going on.

* Fix get_single_window_data() and get_time_series_data().

It appears that the method argument `enrollments_table` was misinterpreted as requiring a BigQuery results object rather than the name of the enrollments table, as a string.

* Fix BigQueryContext.run_query_and_fetch().

In some contexts, we need to provide unqualified table names. In others, it must be fully qualified.

* Don't enquote the fully qualified table name, and hope for the best.

bigquery.Client().list_rows() is unhappy when passed a fully qualified table name enquoted with backticks. So we'll pass it a nude one. Hopefully this doesn't break all our other queries...?

* Fix build_metrics_query().

The `metrics_joins` rely on access to a table named `enrollments`. Provide it!

Also be more honest in the docs for build_enrollments_query().

I changed the alias for segmented_enrollments from `e` to `se` to make it clearer that segment information is in there too.

* Address review comments

* Rename run_query

* Document requirement for custom_enrollments_query

* Go back to a trivial CTE

since table aliases apparently aren't respected inside join subqueries.

* Make a print statement more ambiguous

It could be printed for the enrollments table, not just the results.",Felix Lawrence,2021-01-04T18:51:05Z,felixlawrence,felixlawrence,91,65,26
160,mozanalysis,e6a2092050f8c92e101f016f63878b316a6b1f72,"Add a new-profile segment (#104)

Use clients_last_seen to identify profiles that enroll on (or before!) their first date of use.",Tim D. Smith,2020-12-16T23:50:15Z,tdsmith,tdsmith,12,11,1
161,mozanalysis,3ef55210cc5b544243084541a9887f9bf6868a10,Explicitly provide enrollments destination table,Anna Scholtz,2020-12-12T00:03:05Z,scholtzan,scholtzan,35,14,21
162,mozanalysis,3408dce2d063a0ed66407be65980d53148a53fa1,Fix Experiment,Anna Scholtz,2020-12-11T18:27:03Z,scholtzan,scholtzan,57,11,46
163,mozanalysis,edc44eb2c28e4b124bac0dd3881b436903900b16,Use simple queries for enrollments and metrics SQL,Anna Scholtz,2020-12-11T18:16:53Z,scholtzan,scholtzan,292,202,90
164,mozanalysis,c570bf3f569381b4e9e35b7e8588f4a432c2c70e,"Blacken (#115)

Apply black and isort; enforce black in testing",Tim D. Smith,2020-12-11T18:06:35Z,tdsmith,tdsmith,1891,1025,866
165,mozanalysis,35877058975b51ebf7ea1e385593e018ca3d1320,Enforce black style in tests,Tim D. Smith,2020-12-11T18:01:02Z,tdsmith,tdsmith,44,25,19
166,mozanalysis,a66c6cc41731740f1ad3a9b3cf9586e0c416223b,Ignore long lines,Tim D. Smith,2020-12-08T05:57:14Z,tdsmith,tdsmith,22,11,11
167,mozanalysis,855eaec3ae30818d7aa6a9ea84e0cf23aaeb05a6,isort,Tim D. Smith,2020-12-08T05:53:22Z,tdsmith,tdsmith,41,19,22
168,mozanalysis,794ecf69a52686e3d97f28739db8e86b86a7833f,Blacken,Tim D. Smith,2020-12-08T05:52:02Z,tdsmith,tdsmith,1808,982,826
169,mozanalysis,7664a9bbcd5f9733f37523f4ac68a9253785decc,"Make metric datasets configurable at runtime (#114)

* Make metric datasets configurable at runtime

Different release channels of Glean apps have their data stored in different BigQuery datasets. This departs from the legacy telemetry practice on desktop, where data from all release channels end up in a single table.
This means that, although it's reasonable to talk about a set of metrics that are valid across the different Fenix release channels, the underlying DataSources need to be customized for each release channel.
I had once expected that this would be easy to do just by defining an alternate set of DataSources and rebasing the Metrics onto the new DataSources -- but the `events` data source is a good example of why this isn't as easy as I'd like. Datasets can be complex and it would be annoying to redefine them.

Instead, allow DataSources to be templated over dataset, and have the Experiment class forward some information from the client about which dataset the metrics should be based on.

* Default to new-hotness Fenix release app_id

* Hide DataSource.from_expr

from_expr might be a template, so hide it from consumers except via from_expr_for().",Tim D. Smith,2020-12-08T05:49:15Z,tdsmith,tdsmith,186,162,24
170,mozanalysis,818a61a41191f2db8fa4a3f6105171a879f55281,"Fix ping count metrics (#113)

Addresses the issue described in #107, where the join changes the meaning of COUNT(*).",Tim D. Smith,2020-12-07T22:11:43Z,tdsmith,tdsmith,4,2,2
171,mozanalysis,d00d0e2348b89ae11cf13549e996ea6b74daef7d,"Fix enrollments query (#112)

You gotta SELECT something!",Tim D. Smith,2020-12-01T23:49:12Z,tdsmith,tdsmith,15,7,8
172,mozanalysis,78c0ff64fb96003bc91c892241d2499c46c7bb45,Revise metrics for Pocket tile clicks. (#111),Kirill Demtchouk,2020-12-01T23:09:03Z,kirill-demtchouk,kirill-demtchouk,28,14,14
173,mozanalysis,52fd238c62af921529ecf8f14a17b166d191e77f,"Materialize enrollments table (#109)

* Materialize enrollments table

Repeated references to the enrollments CTE seem to stress BigQuery out, giving rise to ""Resources exceeded during query execution: Not enough resources for query planning - too many subqueries or query is too complex."" errors.

If we use CREATE TEMPORARY TABLE to materialize the enrollments table before joining it everywhere, we get a scripting query with similar semantics and a calmer query planner.

* Write destination table in the script

It's illegal to specify a destination table name (or a create/write disposition) if a query is a script, so we need to direct the output to a named table without passing those parameters into the API.

This breaks the public API for build_query by adding a new mandatory parameter. Requiring all arguments to be passed as keyword-only will make this breakage safe, i.e. it won't accidentally and silently consume one of the existing optional arguments into the destination_table argument.

Finally, we can't rely on taking a hash of the final query to use in the name of the destination table anymore, because the query contains the name of the destination table! Get around this by emitting a template instead.

This makes two backwards-incompatible changes:
* BigQueryContext.get_query is removed and replaced by .run_script_or_fetch()
* Experiment.build_query is replaced by .build_query_template()",Tim D. Smith,2020-12-01T23:07:08Z,tdsmith,tdsmith,148,83,65
174,mozanalysis,70c1d949784616ff344c11da17efa6b54196b801,"Make sure fast fetches happen

google-cloud-bigquery will automatically instantiate and use a BigQuery storage interface if that API package and pyarrow are installed. Let's assume people want those, even though we don't ever import them directly.",Tim D. Smith,2020-11-28T01:32:01Z,tdsmith,tdsmith,2,2,0
175,mozanalysis,904af3db0e2e67461ed87f4d7550663b9336233e,"Use interesting build environments

Colab is Python 3.6.9 and Jetstream uses Python 3.7. We should keep testing on 3.6.",Tim D. Smith,2020-11-28T01:31:23Z,tdsmith,tdsmith,23,15,8
176,mozanalysis,28605bfe979ea45ad9e60a260648edee2df2b844,"Fix the `days_of_use` metric. (#107)

@SuYoungHong noticed that the results of the `days_of_use` metric introduced in PR #105 were very suspicious.

The `COUNT(*)` was counting enrollments even when they had no row in `clients_daily`. Oops.

Instead, we need to `COUNT()` a non-null column from `clients_daily`; `COUNT(ds.submission_date)` seems to be the best for communicating what this metric does? And it's not worth adding a `DISTINCT` because it's implied by `clients_daily` and the lack of other joins?

I haven't tried this code yet but I've asked Su to do so in [this notebook](https://colab.research.google.com/drive/1E-f35o3DE6FIdnmNjs7eEA413lkNjtLh).",Felix Lawrence,2020-11-20T20:49:57Z,felixlawrence,felixlawrence,2,1,1
177,mozanalysis,0b22cc48c6950d84cbce936b82d9d075a491bd77,Add a days of use metric for desktop (#105),Tim D. Smith,2020-11-18T18:55:39Z,tdsmith,tdsmith,10,10,0
178,mozanalysis,b4af558de38f8cd07dc57cd6e81f372883a5b100,"Add a bigger-is-better flag (#106)

Dashboards shouldn't look excited when we get more of a bad thing, or when performance timings increase.

Sometimes this will depend on the context of the experiment; if the wrong assertion is made here, folks can make a copy of the metric with the bit flipped.",Tim D. Smith,2020-11-18T16:16:20Z,tdsmith,tdsmith,3,3,0
179,mozanalysis,b25695b04189d746b07df89c50003b58f8c26a1c,Add/fix internal doc links to TimeSeriesResult. (#103),Felix Lawrence,2020-11-13T18:08:23Z,felixlawrence,felixlawrence,5,3,2
180,mozanalysis,f75023b8388c5abc2e7cb4debb37ecd111c6ca08,Add metrics for pocket tile clicks (#102),Felix Lawrence,2020-10-21T22:40:32Z,felixlawrence,felixlawrence,42,42,0
181,mozanalysis,651cd9c9eba8a2e0226348cf1bfd350f2c8d8f30,Emit Sphinx docs for desktop metrics (#101),Tim D. Smith,2020-10-09T18:24:37Z,tdsmith,tdsmith,34,30,4
182,mozanalysis,c526f0e3361921cc94c1f6dfecfc8bab1d0104bf,Add friendly names and descriptions for segments (#100),Tim D. Smith,2020-09-24T23:07:31Z,tdsmith,tdsmith,88,65,23
183,mozanalysis,4b3255f080870dfc4faeeab592a1f95918622025,"Add friendly names and docs to metrics definitions (#99)

* Add friendly names to metrics

* Enforce friendly names on included metrics

* Document included metrics",Tim D. Smith,2020-09-24T16:20:02Z,tdsmith,tdsmith,188,150,38
184,mozanalysis,3b581c12bed691ae9b9c5e737bb402a9c45a7e51,Declare a dtype at Series creation (#97),Tim D. Smith,2020-09-02T19:55:56Z,tdsmith,tdsmith,2,1,1
185,mozanalysis,d05bd124fc2b90bfa3ad623986deb90db71765d4,Include documentation for the BQ module (#96),Felix Lawrence,2020-08-27T19:46:10Z,felixlawrence,felixlawrence,11,9,2
186,mozanalysis,6be8e4f9ad8d12baabddea626a4ddd57ef4c4361,"Add support for Fenix experiments (#95)

Based on the pyspark work by @godelstheory for PR53.",Felix Lawrence,2020-08-27T18:34:02Z,felixlawrence,felixlawrence,208,194,14
187,mozanalysis,0638d300af06e3305ae10f1addcf96eb1faaa815,Declare experiments_column_type for normandy_events (#92),Tim D. Smith,2020-06-19T03:48:49Z,tdsmith,tdsmith,1,1,0
188,mozanalysis,96d41ab44388fc0501427bb6b34dc7a2ca2f71ab,"Merge pull request #91 from scholtzan/normandy-events

normandy_events datasource for unenroll metric",Anna Scholtz,2020-06-19T00:50:52Z,scholtzan,scholtzan,15,14,1
189,mozanalysis,33f95e54faa30340e186cbbf0cb87c45abe7585c,Add comment to normandy_events datasource,Anna Scholtz,2020-06-19T00:45:29Z,scholtzan,scholtzan,23,13,10
190,mozanalysis,6cc8406c5c9496a5a010db452b54c3ea184ec8cb,normandy_events datasource for unenroll metric,Anna Scholtz,2020-06-18T20:32:32Z,scholtzan,scholtzan,12,11,1
191,mozanalysis,3cfcb9ecc13a2b52b414766b6fca7ec14c07211e,"num_dates_enrollment must be positive (#90)

So give a nicer error message. Fixes #74.",Tim D. Smith,2020-06-16T02:10:32Z,tdsmith,tdsmith,3,3,0
192,mozanalysis,95857bb020bba5d641d97d4ff54fbfdbb0f8c360,Use mozfun UDFs (#89),Anna Scholtz,2020-06-16T00:55:23Z,scholtzan,scholtzan,14,7,7
193,mozanalysis,65c8e7066d491ca9c6b04bcba4250ad814e2ba9f,"Add and update segments (#87)

Add new segments:

* `weekday_regular_v1`
* `allweek_regular_v1`

Update `regular_users_v3 and `new_or_resurrected_v3` to use the ETL segment definitions, now that they exist.",Felix Lawrence,2020-06-10T17:24:32Z,felixlawrence,felixlawrence,22,16,6
194,mozanalysis,de65e35651ecae9a41100b583104fb578d57c762,Fix typo in docs (#86),Felix Lawrence,2020-06-10T17:22:39Z,felixlawrence,felixlawrence,2,1,1
195,mozanalysis,4b21739db4885eb70d1be61a8ad428bc930ab569,"Initialize Series with explicit dtype (#84)

Silences a DeprecationWarning that the default dtype will change.",Tim D. Smith,2020-05-12T18:42:14Z,tdsmith,tdsmith,4,2,2
196,mozanalysis,758cae99c4ecf4c9119f90ca55fe77137064ea7a,"Respond to linter changes (#85)

* Ignore ambiguous variable names

* Remove old f-string modifiers",Tim D. Smith,2020-05-12T15:15:18Z,tdsmith,tdsmith,16,14,2
197,mozanalysis,9ad04e4a78d525fc88497333f696ab26c87989df,"Update usage regularity segments to v3. (#83)

* Update usage regularity segments to v3.

Docs for these segments are [on DTMO](https://docs.telemetry.mozilla.org/concepts/segments.html#regular-users-v3).

* Oops, these segments haven't used lag since v1",Felix Lawrence,2020-05-08T21:48:54Z,felixlawrence,felixlawrence,66,10,56
198,mozanalysis,3d95970f71a30daa60606785a66c97cdb990e31c,Hyphenate spark-style date in cookbook. (#82),Felix Lawrence,2020-05-06T17:11:53Z,felixlawrence,felixlawrence,2,1,1
199,mozanalysis,c97c2bee511278817b0e3851d544f27ffb822dd6,"add cfr DataSource (#81)

* add cfr DataSource

* fix trailing whitespace

* fix experiments column type

* indentation",Leif Oines,2020-05-04T16:21:38Z,irrationalagent,irrationalagent,11,11,0
200,mozanalysis,76ab66298ebdb64fb800c2421063af4c3d070b98,Fix mangled rst; link to where to find the current version. (#80),Felix Lawrence,2020-04-18T19:37:14Z,felixlawrence,felixlawrence,4,2,2
201,mozanalysis,655bee653641272b986125edbba8c901ff38da4b,"COALESCE segments to remove NULL values (#79)

Because `clients_last_seen` is constructed from the `main` ping, and our enrollments are obtained from the `events` ping,there are enrollments without a `clients_last_seen` row that matches the submission date.

This only happens for users without any (main ping) activity in the past 28 days. Therefore these users belong in `new_irregular_users_v2`.

This problem will persist even once the segments are in the ETL.

There are terser solutions (e.g. `MAX(...=...) IS TRUE` for two segments to map `NULL` to `FALSE`), but I figured that this verbose form was the most readily understandable.",Felix Lawrence,2020-04-06T16:23:42Z,felixlawrence,felixlawrence,30,24,6
202,mozanalysis,77e7818dcb31777c443f326b7fa612de4c333514,"Add segments functionality (#76)

* Refactor code so we can reuse it for segments

* Add `Experiment._build_segments_query()` and `_build_segments_query_bits()

This code is largely copypasta from `_build_metrics_query_bits()`.

The main difference is that this builds up a largely-self-contained query (it needs `raw_enrollments` to be defined), and this query will (in a later commit) be dropped into the master query in `Experiment.build_query()` between `raw_enrollments` and `enrollments`.

The strategy is the same: `SegmentDataSource.build_query()` (coming soon!) returns a SQL query that adds one column per segment from the data source while leaving the other columns untouched and not changing the number of rows. Then in `_build_segments_query()` we combine the new columns from each data source by LEFT JOINing repeatedly and SELECTing the new columns.

* Add segment modules, tests, and docs.

Again we borrow ideas and code from the metrics library, making enough changes/simplifications that copypasta is better than DRY here.

`SegmentDataSource.build_query()` is the method that builds the segment queries that plug into `Experiment._build_segment_query()` as `LEFT JOIN`s.

Also adds three segments and their data source. These segments are documented in [this pull request to DTMO](https://github.com/mozilla/firefox-data-docs/pull/428). There is also a [related PR for bigquery-etl](https://github.com/mozilla/bigquery-etl/pull/825/); once that is merged it will be easier to query these segments: we would be able to replace the `select_expr` with the currently-commented-out versions, and replace the data source with a non-lagging window.

* Hook up segments functionality and expose it.

Let users specify a list of segments, and use the segments query in `Experiment.build_query()`.

* Trailing commas in SELECT are no longer considered malformed \o/

* Correct the `SegmentDataSource.build_query()` docstring.

And augment the `Experiment._build_segments_query()` docstring.

* Put `segment_list` as the final argument to avoid a breaking API change

* Move `sql_lint()` into a helpers module to avoid duplication

* Update segments to latest proposed definitions

Hopefully bigquery-etl will be updated before we need to merge this, so we'll be able to remove `tmp_segment_regular_users_v1` before merging.

* I miss fixtures and real tests :(

* Update usage regluarity segment to latest definition (v2)

* Update test for new variable name",Felix Lawrence,2020-04-03T18:35:54Z,felixlawrence,felixlawrence,431,372,59
203,mozanalysis,14bebdf2b4ab519b9dd74c6d73bc68670653d261,"Merge pull request #78 from benmiroglio/add-search-metrics

Add missing search metrics",Ben Miroglio,2020-04-03T15:14:02Z,benmiroglio,benmiroglio,18,18,0
204,mozanalysis,d0d775bf9c003325ef18432707d06237e7c9c54e,Add missing search metrics,benmiroglio,2020-04-02T20:16:59Z,benmiroglio,benmiroglio,18,18,0
205,mozanalysis,8b730f67ad2a15ffe8238dbf370a38b26e5fbcd7,Use new date format in docstrings,Tim D. Smith,2020-03-07T00:32:19Z,tdsmith,tdsmith,12,6,6
206,mozanalysis,f182010f2577b3a33333d513cb789b2b951d8291,"Include the right date in the error message

Avoid a little bit of repetition and branching by doing a check even if we know it can't fail.",Tim D. Smith,2020-03-07T00:27:12Z,tdsmith,tdsmith,25,11,14
207,mozanalysis,c917a0f475ea29ad117f4b4aad4e7739d2bffeea,Add test for failing case,Tim D. Smith,2020-03-07T00:21:11Z,tdsmith,tdsmith,12,12,0
208,mozanalysis,579119e2f34a9259d5a79d03d86cea89eda34280,Promote build_query to public API (#66),Tim D. Smith,2020-02-29T00:03:12Z,tdsmith,tdsmith,45,33,12
209,mozanalysis,6e0d7fa24b3dffc9a0f6f8fe1c137ed041a7bd3f,"Allow Metrics to be rebased on other DataSources (#67)

Sometimes you have tables with identical schemas and need to prefer one or the other in different contexts. These could be using `telemetry_live` tables, or using a Fenix Nightly table vs a Fenix release table. This helper facilitates that.",Tim D. Smith,2020-02-28T21:55:00Z,tdsmith,tdsmith,8,8,0
210,mozanalysis,561e1ad650d81a940562e7090b5ca5757f87c55d,Validate experiments_column_type parameter (#65),Tim D. Smith,2020-02-28T21:53:27Z,tdsmith,tdsmith,42,42,0
211,mozanalysis,9e336e0df5564c65968cdf4b89303bafdfdeca52,"Add main and crash ping data sources, and a histogram-mean aggregation (#62)

* Add main and crash ping data sources

* Add a histogram-mean aggregation function",Tim D. Smith,2020-02-28T21:52:45Z,tdsmith,tdsmith,32,32,0
212,mozanalysis,1552e9af26d63f46fe38b90faf16ffe46c53e8e9,"Remove explicit object inheritance (#64)

All classes inherit from object in Python 3. It's a brave new world!

https://twitter.com/electrolemon/status/1043183150216765440",Tim D. Smith,2020-02-28T19:26:14Z,tdsmith,tdsmith,14,7,7
213,mozanalysis,e51c929916d10f1e7dd6c0157738ab8d5c619a4c,Don't install mozanalysis into linting environment (#63),Tim D. Smith,2020-02-28T05:02:35Z,tdsmith,tdsmith,1,1,0
214,mozanalysis,2a2f73df61d474b86c51cf5e0eb07399d7cd7ae3,Add documentation for DataSource (#61),Felix Lawrence,2020-02-25T21:51:35Z,felixlawrence,felixlawrence,27,27,0
215,mozanalysis,00cfa2558c01a6f6cbfae6f090c681118a1c6af8,Add info to guide about creating datasets. (#59),Felix Lawrence,2020-02-25T16:05:03Z,felixlawrence,felixlawrence,2,2,0
216,mozanalysis,35d6d6da8a29674bf378df9a6e679b83b5853e6c,"Remove UDFs and pyarrow dependency (#58)

I expect nobody will miss these. The pyarrow dependency makes mozanalysis hard to install.",Tim D. Smith,2020-02-19T18:46:03Z,tdsmith,tdsmith,317,0,317
217,mozanalysis,277d8a7e98ac5acf9fc2e32d31003daebe2c8c7b,"Remove py27 support - abandon ship. (#57)

Tests started failing on py27, in areas untouched by recent commits. The ship is sinking, let's get off it.",Felix Lawrence,2020-02-12T00:56:44Z,felixlawrence,felixlawrence,14,4,10
218,mozanalysis,56bd4b34f18ac1fd3d048f7bc0dcb1af03e24c0c,"Add metric for connecting a firefox account (#56)

In order to add 'connect_fxa' as a metric, I had to un-break the join to the events table (the changes in `metrics/__init__.py`).

I applied this quickly to an existing onboarding experiment and the metric result was nonzero and plausible (to me).",Felix Lawrence,2020-02-12T00:40:55Z,felixlawrence,felixlawrence,64,50,14
219,mozanalysis,d9fd23c2fbc1396c6df873940a27a4975a3b0ed7,"Move to bigquery (#54)

Switch from querying via Spark to querying via BigQuery.

* Fix minor docs copypasta mistake

* Port the query code to SQL for BigQuery.

* Delete firetv docs. Other docs need updating

* Nit: make a variable name more accurate/specific

* Move BigqueryStuff into a separate module and refactor it

* Add crude unit tests; fix discovered bug

* Fix docstring example

* Update guide.

When working through my example notebook, I noticed that you can't call `.to_dataframe()` twice on the same object. This is inconvenient and I wonder if we should change our return types to just return dicts of dataframes - or possibly an iterator over `(int, DataFrame)` tuples for time series.

* Don't return RowIterators.

`Experiment.get_single_window_data()` now returns a pandas DataFrame directly. `Experiment.get_time_series_data()` now returns a new `TimeSeriesResult` object, which ideally gets turned into a `dict` but also supports loading only one value into RAM at a time.

* Appear more professional

Rename ``BigqueryStuff`` to ``BigQueryContext``, because the latter seems less hacky. Whether this class warrants a less hacky name is not implied.

* Add docs for BigQueryContext

* `add_any` now deals exclusively with bools.

* Fix bug; update docs

* Make query hashes consistent across runtimes.

In Python 3, it turns out that the `hash()` of a string is consistent within an interpreter session, but inconsistent between sessions. Great. Use a few bytes of a sha256 instead.

* Don't suggest people install mozanalysis from my personal fork

* Don't encourage people to use my dataset_id

* Obvious placeholder is obvious

* Apparently project namespaces are for billing?

* Add return type

* Fully qualify result table names for TimeSeriesResult.

The data to be extracted from a TimeSeriesResult is identified by `(project_id, dataset_id, table_name)`. Previously, `project_id` and `dataset_id` were stored in a `BigQueryContext`, separate to the `table_name`. If someone was using multiple BigQueryContext instances, with different `project_id`s or `dataset_id`s (which is a terrible idea!) then they would need to correctly match each TimeSeriesResult to the right BigQueryContext.

To remove the chance for such mismatches, TimeSeriesResult now stores a fully qualified table name: `project_id.dataset_id.table_name`.

It would be nice to deal with fully qualified table names everywhere, but when specifying a destination table (when saving results into a table), the BigQuery API seems not to allow the destination table to be specified as a fully qualified table name - instead the project_id, dataset_id and table_name must be submitted separately in three separate places (respectively: when instantiating the bigquery client, when instantiating a dataset object, and when calling the `table()` method on that dataset object. Ergh.",Felix Lawrence,2020-01-14T21:49:45Z,felixlawrence,felixlawrence,2682,736,1946
220,mozanalysis,622d5896e692406f5841c292a788e155dd24a493," Make bootstrapping work without Spark. (#55)

* Make bootstrapping work without Spark.

This makes a breaking change to the bootstrap function signatures: arguments are re-ordered so that `sc` becomes optional.

Mozanalysis will now be frequently run without a Spark context. We'll still need to bootstrap.

Now if no Spark context is supplied, non-parallel implementations of the bootstrap will be run.

* Parametrise the spark fixture to neaten the tests",Felix Lawrence,2020-01-03T23:55:41Z,felixlawrence,felixlawrence,257,156,101
221,mozanalysis,745258804198e29f5f6437f06c9eb766c3b9ed38,"Start a metrics library (#52)

Add support for a metrics library, and some initial metrics. In the process, make a breaking change to `Experiment.get_per_client_data()`, `Experiment.get_time_series_data()`, etc: `metric_list` is now a list of `Metric` instances, and these functions no longer have a `data_source` argument.

See https://github.com/mozilla/mozanalysis/pull/52 for the full gory details of the reasoning behind the design choices; an abbreviation is below.

* Add DataSource and Metric classes.

`DataSource` wraps a Spark DataFrame or table lazily, so that you can define DataSources without needing a Spark context.

`Metric` wraps a Spark Column, plus a `DataSource` for the necessary table - again so that you can define `Metric`s lazily, without issuing Spark commands.

Also add some convenience functions `agg_sum()` and `agg_any()`, representing common aggregations over Columns used when defining experiment metrics.

* Add some metrics and data sources for desktop and fire tv

* Refactor `Experiment._get_per_client_data()`, ready for batches.

We want users to be able to supply an arbitrary list of `Metric`s to `Experiment.get_per_client_data()` and `Experiment.get_time_series_data()`, without requiring that all metrics share a common `DataSource`. Therefore we need to handle joins with arbitrary numbers of `DataSource`s and associated `Metric`s.

* Add `Experiment._process_metrics()`.

Add a method that takes a list of `Metric`s and converts them to a `dict` of a list of metrics per data source DataFrame.

* Use `Metric`s not raw Columns and DataFrames.

From here on, `metric_list` refers to a list of `Metric`s rather than a list of Columns.

The user accessible `Experiment` methods (`get_per_client_data`, `get_time_series_data`, `get_time_series_data_lazy`) now take a list of `Metric`s, rather than needing to supply a DataFrame and a list of Columns.

* Move sanity check metric generation into the `DataSource` class.

This will allow `DataSource`s to implement additional custom sanity checks in the future. It also provides better column names for sanity check metrics, now that we have multiple data sources in one results DataFrame.

* Add documentation, including a tutorial/cookbook.",Felix Lawrence,2019-10-29T16:52:09Z,felixlawrence,felixlawrence,1576,1375,201
222,mozanalysis,fbdc061ee297273d4fe8938e5a7b20664478bdbb,"Add time series (#51)

Add support for querying metrics as time series. Daily and weekly time series have official support in the `Experiment` class, though it's fairly easy to DIY an arbitrary set of analysis windows too.

This required the addition of new `TimeLimits` and `AnalysisWindow` classes, and a refactor of `Experiment`.

See https://github.com/mozilla/mozanalysis/pull/51 for the full gory details of the reasoning behind the design choices.",Felix Lawrence,2019-10-16T13:48:19Z,felixlawrence,felixlawrence,773,637,136
223,mozanalysis,3cb8cb0a2910b8305e0b71242c45421dcbcecea3,"Further refactoring of Experiment class (#50)

Do more groundwork in preparation for supporting querying of time series and a metrics library.

Specifically, spin off the construction of the join conditions into a separate method so that get_per_client_data() fits on one screen and is easier to reason about.


* Move join condition construction to separate method.

* Trivial gardening

* Move data_source checking into data_source specific method.

In the future (with the metrics library) we will have multiple data_sources in one query, so that users can just list all the metrics they want to analyse without partitioning them by data_source. So all data_source functionality should eventually live inside a reduce loop - this makes that more possible.

* Rename `filter_*_for_analysis_window()` to `_process_*()`

In the future we are going to do significantly more than filtering in these methods. For now let's be less verbose, and make them private.

* Staticify static methods

* Push ugly aliases out of the way

* Lower the demanded precision from a random unit test

* Address review comments.",Felix Lawrence,2019-08-20T20:18:09Z,felixlawrence,felixlawrence,124,77,47
224,mozanalysis,7567dd6dc3a22fe18f1e7716c160550116eb2d0a,"Refactor time limits code in Experiment. (#49)

* Refactor time limits code in Experiment.

Our next priorities are to introduce a metrics library and support for querying time series of metrics data. Both of these things add complexity to the queries that get sent to Spark, and the code that builds them. Here we lay some groundwork for those features by disentangling some logic from the `Experiment` class.

Here we introduce the `TimeLimits` class: an instance of TimeLimits holds all the temporal information used when querying data for an `Experiment`. It contains the start and end of the enrollment period, the details about the analysis window, and the relevant date range for the data source.

Previously, we tried to hold minimal state and compute quantities on the fly. Instead, `TimeLimits` precomputes and stores all these variables, which is conceptually easier (particularly when we start specifying a different set of variables when working with time series). We ensure self-consistency by providing a constructor with a near-minimal set of arguments, and by using validators.",Felix Lawrence,2019-08-06T22:43:35Z,felixlawrence,felixlawrence,521,351,170
225,mozanalysis,f2c71b01f08ce9d6d2037955de09628fcc310826,"Keep using debian stretch (oldstable). (#47)

If you stand in one place long enough, the sands shift around you.

The package openjdk-8-jre-headless has been removed from the new debian (buster) and so the easiest short term fix for this is to stay on the old version.",Felix Lawrence,2019-07-17T18:25:10Z,felixlawrence,felixlawrence,10,5,5
226,mozanalysis,37c81d862d98132e07be2db220d161c64bfae71b,"Add stats functions (#44)

Add stats functions.

Introduces stats functionality to mozanalysis. There is a module for Frequentist stats and a module for Bayesian stats. So far, most of the stats functions return credible intervals or confidence intervals over some sampled quantity.

The goal here is to strike the right balance between consistency and flexibility: we want the stats functions to be as interchangable as is sensible. They all accept data in the same format (the format output by `get_per_client_data`) and try to output data in as similar formats as is sensible. I hope this format is flexible enough to accommodate future functionality too, as people add their favourite stats methods.

Fixes #12, Fixes #14",Felix Lawrence,2019-07-17T17:37:50Z,felixlawrence,felixlawrence,2161,2134,27
227,mozanalysis,c47d3366831937fd06f3a58141d3ded9d9b42d3e,"Use attrs for Experiment (#45)

* Use attrs for Experiment

Use attrs for the experiment class.
This gives us more robust immutability, a free repr, and avoids some
boilerplate.

* Allow dependency injection for get_enrollments

`get_enrollments` needs to be able to reference a table of all
enrollment events. We need to be able to shortcut this in the tests, and
we'd like Experiment to be immutable, which means no monkeypatching.

Instead, allow the function that fetches the view to be passed in,
and call any callables that we receive as `study_type` arguments.

Further, align the APIs for the view-fetchers, and perform addon-version
filtering in the body of `get_enrollments` if it's required.

* Use injection instead of mocking in tests for Experiment class",Tim D. Smith,2019-06-26T20:30:28Z,tdsmith,tdsmith,149,69,80
228,mozanalysis,2b924f822e8d494070c32a57299e18a23a93237d,Build docs for the experiment module (#43),Tim D. Smith,2019-05-25T01:52:20Z,tdsmith,tdsmith,122,68,54
229,mozanalysis,9ff8dfd7af55f58b62e419c564a3e7e61df55d50,Add tox usage note,Tim Smith,2019-05-25T00:26:38Z,tdsmith,tdsmith,9,9,0
230,mozanalysis,0ef9b4ce9a045c1eb7c430ac875b744255a37699,Fix Sphinx warning about missing path,Tim Smith,2019-05-24T23:39:56Z,tdsmith,tdsmith,2,1,1
231,mozanalysis,51e2ce12f9e22f66f841598ca71e824bda423cc6,Remove stats docs stub,Tim Smith,2019-05-24T23:33:01Z,tdsmith,tdsmith,5,0,5
232,mozanalysis,4c125edb201b8f6d9b9efa907db0abe4eef34d5c,"Simplify docs build

Keep all our extra requirements in the same place and avoid `make`.",Tim Smith,2019-05-24T23:23:20Z,tdsmith,tdsmith,236,13,223
233,mozanalysis,24c2bbf7e63cf0f7278215ef60a194ee35803925,"Remove support for testing in Docker

I think these were useful for developing on Windows but I worry they're
a little distracting since tox should work. We can revert this change if
we want them back.",Tim Smith,2019-05-24T23:20:46Z,tdsmith,tdsmith,108,6,102
234,mozanalysis,f6e3929e4289f81a9ff89f60349f5993f4219952,"Work around unsafe fork in pyspark (#41)

Touching core Objective C classes from a child process (in the case of
fork() without exec()) causes a defensive crash in recent versions of
macOS.

Pyspark forks unsafely, which triggers the defensive crash, which causes
tests to fail.

This doesn't fix anything -- it just disables the airbag -- but a proper
fix would have to land in pyspark.

Closes #40.",Tim D. Smith,2019-05-24T23:31:13Z,tdsmith,tdsmith,1,1,0
235,mozanalysis,f43a8e46af54ea8e251b8e5ece58f62367c39672,"Work around bug in Spark joining.

If you start with a DataFrame, aggregate over it, then join from the aggregation to the original DataFrame, then Spark can raise an AnalysisException, complaining about duplicated names even if you've been careful to rename them. Specifically, this happened with 'submission_date_s3'.

Since it _actually is a unique name_, we can use `F.col('submission_date_s3')` instead of `data_source.submission_date_s3` to work around this problem. If someone supplies an `enrollments` table that _does_ have a `submission_date_s3` column then Spark justifiably raises a meaningful error.

Added the fix, a short comment explaining it with a reference to the bug[1], and a test that failed before the bug was fixed.

[1] https://issues.apache.org/jira/browse/SPARK-10925",Felix Lawrence,2019-05-24T17:37:07Z,felixlawrence,felixlawrence,43,40,3
236,mozanalysis,072e86799d723bbda9bf67f2f0d446bdcdccb6e0,"Merge pull request #38 from felixlawrence/revamp-and-add-query-code

First step in a new direction.",Felix Lawrence,2019-05-16T17:55:59Z,felixlawrence,felixlawrence,1504,892,612
237,mozanalysis,b58e482fd6aec9a9a29e5037761a9e6e1b15316e,Change nomenclature per teonbrooks' review and jmccrosky's suggestion,Felix Lawrence,2019-05-02T16:53:12Z,felixlawrence,felixlawrence,92,46,46
238,mozanalysis,86150724e64380084f075099e1195d0e0afd1708,Clarify docs following teonbrooks' review,Felix Lawrence,2019-05-01T23:24:44Z,felixlawrence,felixlawrence,8,6,2
239,mozanalysis,4ac4bd7aa4490baaf6a951624043e38a16889049,Repeat the fix for repeated docs,Felix Lawrence,2019-05-01T18:30:41Z,felixlawrence,felixlawrence,12,9,3
240,mozanalysis,010fa5bb5a6095a3700796086f27c94cb0752669,Do some of teonbrooks' suggestions and more of tdsmith's,Felix Lawrence,2019-05-01T18:19:22Z,felixlawrence,felixlawrence,109,36,73
241,mozanalysis,f5e0398271526b697e51b198dff3e3c3796f4337,Do more of tdsmith's suggestions,Felix Lawrence,2019-04-29T23:41:00Z,felixlawrence,felixlawrence,173,106,67
242,mozanalysis,953092591799ff46c1b64ce693eed74e07ec79bf,Do some of tdsmith's suggestions,Felix Lawrence,2019-04-29T22:39:26Z,felixlawrence,felixlawrence,47,19,28
243,mozanalysis,9f79049305a165e367ad2bea912d31533bf89b8e,Support querying from dfs without an experiments map.,Felix Lawrence,2019-04-26T18:28:11Z,felixlawrence,felixlawrence,87,52,35
244,mozanalysis,51f3d68f1df5bf0303f096729b20f3c683215e92,There is space for this concern under the rug,Felix Lawrence,2019-04-26T17:38:41Z,felixlawrence,felixlawrence,3,0,3
245,mozanalysis,dc731f161049e8cbf75ba2444bc3f5fa9177a844,Clarify docs,Felix Lawrence,2019-04-25T23:35:50Z,felixlawrence,felixlawrence,2,1,1
246,mozanalysis,0264505555eb3c8c0ac139314fb14985c9e01a0c,"First step in a new direction.

This commit removes a lot of the existing code, and takes the first step on a new roadmap that takes mozanalysis beyond the `experiments` table, and aims to make safe and rigorous analyses easier than the alternative, while maintaining 'enough' flexibility.

This commit introduces the basic query infrastructure - most of the code that builds Spark queries.

Still to come in mozanalysis or mozreport (out of scope for this PR):
- A variety of stats functions to analyze the data output by `Experiment.get_per_client_data()`
- A library of pre-defined and blessed metrics
- Convenience functions for querying and analyzing time series (time since enrollment)
- Functions to visualize/present the output of stats functions",Felix Lawrence,2019-04-25T20:02:07Z,felixlawrence,felixlawrence,1487,875,612
247,mozanalysis,8a7246cd159923012b56be7a1d70bca6e587554e,"Merge pull request #36 from Mozilla-GitHub-Standards/master

Add Mozilla Code of Conduct",Rob Hudson,2019-04-09T15:24:49Z,robhudson,robhudson,15,15,0
248,mozanalysis,0c2a278cd52bc12beb25f7c52c45c91af35ec8c2,"Add Mozilla Code of Conduct file

Fixes #35.

_(Message COC002)_",Mozilla-GitHub-Standards,2019-03-30T07:01:33Z,Mozilla-GitHub-Standards,Mozilla-GitHub-Standards,15,15,0
249,mozanalysis,92a10c988efa67e14ac8112bc704fe3a6d5a0761,"Removing contrib/

These have moved to the new mozilla/dscontrib library.",Rob Hudson,2019-03-21T16:23:09Z,robhudson,robhudson,161,0,161
250,mozanalysis,f5b7c1df7e31b6fa1f2aa9b9274ff64e35e2356d,"Merge pull request #31 from benmiroglio/master

Add search ads metric",Felix Lawrence,2019-03-15T19:53:55Z,felixlawrence,felixlawrence,45,45,0
251,mozanalysis,498d3418879504487ae952ac56e416bfc1ee15fb,Fix flake8 errors,benmiroglio,2019-03-12T22:42:55Z,benmiroglio,benmiroglio,74,38,36
252,mozanalysis,21fd5eb1af183c6cf62efab9cd6714d2f1095edb,Add newline to end of file,benmiroglio,2019-03-12T22:33:55Z,benmiroglio,benmiroglio,2,1,1
